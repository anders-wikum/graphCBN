{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch has version 1.13.1+cu117\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import pandas as pd\n",
    "from data_parsing import process_file\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"PyTorch has version {}\".format(torch.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of edges: 24\n",
      "Number of flow updates: 5, final flow value: 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexandre/miniconda3/envs/cs224w/lib/python3.10/site-packages/nbformat/__init__.py:92: MissingIDFieldWarning: Code cell is missing an id field, this will become a hard error in future nbformat versions. You may want to use `normalize()` on your notebooks before validations (available since nbformat 5.1.4). Previous versions of nbformat are fixing this issue transparently, and will stop doing so in the future.\n",
      "  validate(nb)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/tmp/ipykernel_3247/1483371613.py:8\u001b[0m\n\u001b[1;32m      5\u001b[0m nodes \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]\n\u001b[1;32m      6\u001b[0m N \u001b[38;5;241m=\u001b[39m Network(nodes, edges, capacities, costs, supplies)     \n\u001b[0;32m----> 8\u001b[0m f, p \u001b[38;5;241m=\u001b[39m successive_shortest_paths(N)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrun\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msuccessive_shortest_paths.ipynb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cs224w/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2369\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2367\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2368\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2369\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/cs224w/lib/python3.10/site-packages/IPython/core/magics/execution.py:717\u001b[0m, in \u001b[0;36mExecutionMagics.run\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m preserve_keys(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshell\u001b[38;5;241m.\u001b[39muser_ns, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__file__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    716\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshell\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__file__\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m filename\n\u001b[0;32m--> 717\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msafe_execfile_ipy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraise_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    718\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    720\u001b[0m \u001b[38;5;66;03m# Control the response to exit() calls made by the script being run\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cs224w/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2875\u001b[0m, in \u001b[0;36mInteractiveShell.safe_execfile_ipy\u001b[0;34m(self, fname, shell_futures, raise_exceptions)\u001b[0m\n\u001b[1;32m   2873\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_cell(cell, silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, shell_futures\u001b[38;5;241m=\u001b[39mshell_futures)\n\u001b[1;32m   2874\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raise_exceptions:\n\u001b[0;32m-> 2875\u001b[0m     \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2876\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39msuccess:\n\u001b[1;32m   2877\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cs224w/lib/python3.10/site-packages/IPython/core/interactiveshell.py:266\u001b[0m, in \u001b[0;36mExecutionResult.raise_error\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_before_exec\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_in_exec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 266\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_in_exec\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/tmp/ipykernel_3247/1483371613.py:8\u001b[0m\n\u001b[1;32m      5\u001b[0m nodes \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]\n\u001b[1;32m      6\u001b[0m N \u001b[38;5;241m=\u001b[39m Network(nodes, edges, capacities, costs, supplies)     \n\u001b[0;32m----> 8\u001b[0m f, p \u001b[38;5;241m=\u001b[39m successive_shortest_paths(N)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "%run successive_shortest_paths.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def parse(filename) -> Network:\n",
    "#     \"\"\"\n",
    "#     Parses a network file following the DIMACS problem specification\n",
    "#     structure and transforms it into a Network object\n",
    "\n",
    "#     Some elements of the specification:\n",
    "#     - Lines starting in c are comments\n",
    "#     - Lines starting in p explain what problem to solve (can be ignored,\n",
    "#       we only consider minimum-cost flow problems)\n",
    "#     - Lines starting in n define nodes\n",
    "#     - Lines starting in a define arcs (edges)\n",
    "\n",
    "#     Args:\n",
    "#         filename: name of the file containing the network data\n",
    "\n",
    "#     Returns:\n",
    "#         The corresponding Network object\n",
    "#     \"\"\"\n",
    "#     # Lines we can ignore\n",
    "#     ignore_list = ['c', 'p']\n",
    "\n",
    "#     file = open(filename, 'r')\n",
    "\n",
    "#     # Nodes is a hashmap from node values to their supply\n",
    "#     nodes = {}\n",
    "#     # Edges is a hashmap from edges to a tuple with their capacity and cost\n",
    "#     edges = {}\n",
    "\n",
    "#     for line in file:\n",
    "#         if len(line) > 0 and line[0] not in ignore_list:\n",
    "#             if line[0] == 'n':\n",
    "#                 # Node parsing\n",
    "#                 node = [int(elem) for elem in line.split(' ')[1:]]\n",
    "#                 nodes[node[0]] = node[1]\n",
    "#             elif line[0] == 'a':\n",
    "#                 arc = [int(elem) for elem in line.split(' ')[1:]]\n",
    "#                 node1 = arc[0]\n",
    "#                 node2 = arc[1]\n",
    "#                 capacity = arc[3]\n",
    "#                 cost = arc[4]\n",
    "\n",
    "#                 # Only nodes with non-zero supply are in a \"node line\"\n",
    "#                 if node1 not in nodes:\n",
    "#                     nodes[node1] = 0\n",
    "#                 if node2 not in nodes:\n",
    "#                     nodes[node2] = 0\n",
    "#                 if (node1, node2) in edges:\n",
    "#                     # TODO not amazing (reaverages every time)\n",
    "#                     old_capacity, old_cost = edges[(node1, node2)]\n",
    "#                     new_cost = old_cost * old_capacity + cost * capacity\n",
    "#                     new_cost /= (old_capacity + capacity)\n",
    "#                     edges[(node1, node2)] = (old_capacity + capacity, new_cost)\n",
    "#                 else:\n",
    "#                     edges[(node1, node2)] = (capacity, cost)\n",
    "#     file.close()\n",
    "\n",
    "#     capacities, costs = zip(*edges.values())\n",
    "#     network = Network(list(nodes.keys()), list(edges.keys()), capacities, costs, list(nodes.values()))\n",
    "#     #TODO data types?\n",
    "#     print(f\"This dataset contains: {len(nodes.keys())} nodes and {len(edges.keys())} edges\")\n",
    "#     if len(edges.keys()) <= 1e6:\n",
    "#         index = {node: index for node, index in zip(nodes, range(len(nodes)))}\n",
    "#         x = torch.tensor([supply for supply in nodes.values()])\n",
    "#         edge_index = torch.reshape(torch.tensor([[index[e[0]], index[e[1]]] for e in edges]), (2, -1))\n",
    "#         edge_attr = torch.reshape(torch.tensor([list(attributes) for attributes in edges.values()]), (2, -1))\n",
    "#         print(\"starting to run successive shortest paths\")\n",
    "#         iter_limit = 150\n",
    "#         converged, f, p = successive_shortest_paths(network, iter_limit = iter_limit)\n",
    "#         print(\"finished running successive shortest paths\")\n",
    "#         y = dual_value(network, p)\n",
    "#         if converged:\n",
    "#             return {\"converged\": True, \"x\": x, \"edge_index\": edge_index, \"edge_attr\": edge_attr, \"y\": y}\n",
    "#     return {\"converged\": False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data, Dataset, download_url\n",
    "\n",
    "\n",
    "class MinCostDataset(Dataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        \"\"\"If these files are found in the raw directory, download is skipped\"\"\"\n",
    "        return []\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        \"\"\"If these files are found in the processed directory, processing is skipped\"\"\"\n",
    "        processed_files = []\n",
    "        path = self.processed_dir\n",
    "        for file in tqdm(os.listdir(path)):\n",
    "            file_path = os.path.join(path, file)\n",
    "            if not os.path.isdir(file_path) and not file == \"pre_filter.pt\" and not file == \"pre_transform.pt\":\n",
    "                processed_files.append(file)\n",
    "\n",
    "        return processed_files\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        idx = 32\n",
    "        path = self.raw_dir\n",
    "        for file in tqdm(os.listdir(path)):\n",
    "            print(file)\n",
    "            file_path = os.path.join(path, file)\n",
    "            if os.path.isdir(file_path):\n",
    "                continue\n",
    "            # Read data from `raw_path`.\n",
    "            output = process_file(file_path, 'nx')\n",
    "            if output[\"converged\"]:\n",
    "                x = output[\"x\"].type(torch.FloatTensor)\n",
    "                edge_index = output[\"edge_index\"]\n",
    "                edge_attr = output[\"edge_attr\"].type(torch.FloatTensor)\n",
    "                y = output[\"y\"]\n",
    "                data = Data(x = x, edge_index = edge_index, edge_attr = edge_attr, y = y, filename = file_path)\n",
    "\n",
    "                torch.save(data, osp.join(self.processed_dir, f'data_{idx}.pt'))\n",
    "                idx += 1\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.processed_file_names)\n",
    "\n",
    "    def get(self, idx):\n",
    "        data = torch.load(osp.join(self.processed_dir, f'data_{idx}.pt'))\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:00<00:00, 28088.70it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = MinCostDataset(root = \"./data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134/134 [00:00<00:00, 79687.61it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 60040.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinCostDataset(132)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134/134 [00:00<00:00, 35873.92it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 70794.40it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 74373.00it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 66293.55it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 15831.13it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 85493.88it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 87123.97it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 77277.15it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 68490.95it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 35601.24it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 121468.93it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 152561.55it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 46472.36it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 41592.30it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 221535.96it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 116051.36it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 86294.60it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 84874.17it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 71225.03it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 121102.51it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 66893.21it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 22963.71it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 21613.47it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 38111.94it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 88134.98it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 78354.49it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 91536.93it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 66781.93it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 74619.85it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 116508.44it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 71044.97it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 71862.52it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 26222.96it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 65020.45it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 61816.62it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 54381.88it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 28953.06it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 45697.76it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 49728.96it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 59443.34it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 43748.48it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 82969.70it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 76655.31it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 94858.52it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 86787.64it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 97508.11it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 51173.33it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 98326.93it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 65566.58it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 100904.26it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 60259.11it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 64232.77it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 123253.67it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 41015.60it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 69939.86it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 75008.24it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 99405.15it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 72120.72it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 60616.56it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 54450.37it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 89868.36it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 53537.51it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 13567.57it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 128553.69it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 14679.57it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 66013.24it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 59613.57it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 80521.02it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 59835.70it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 75827.95it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 63150.20it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 53855.57it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 72000.61it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 89696.26it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 50840.05it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 88607.40it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 86467.19it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 120376.26it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 66293.55it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 90944.46it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 74848.41it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 135757.67it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 72812.12it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 233695.11it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 60233.28it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 145680.85it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 191886.90it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 109580.18it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 81454.60it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 83811.03it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 64453.75it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 47541.59it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 46844.20it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 49141.97it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 31548.51it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 33254.64it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 30098.90it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 100077.77it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 72334.20it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 65897.14it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 56018.81it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 44321.17it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 61782.65it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 69267.53it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 86600.42it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 65528.36it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 22921.56it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 89297.23it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 41555.40it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 116387.81it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 83786.04it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 79271.75it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 65452.05it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 86854.70it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 38803.97it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 64240.11it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 28660.72it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 43728.06it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 56108.29it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 61110.88it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 59087.13it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 52952.40it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 79993.84it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 57368.25it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 37604.49it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 96091.08it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 94794.52it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 114514.41it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 65928.06it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 94064.73it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 40318.27it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 91581.67it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 61980.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num classes: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134/134 [00:00<00:00, 61277.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num features: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134/134 [00:00<00:00, 55324.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first graph: Data(x=[9559, 1], edge_index=[2, 29682], edge_attr=[29682, 2], y=[1, 1], filename='data/raw/road_flow_01_DC_a.txt')\n"
     ]
    }
   ],
   "source": [
    "def dataset_information(dataset):\n",
    "    print(dataset)\n",
    "    print(f\"num classes: {dataset.num_classes}\")\n",
    "    print(f\"num features: {dataset.num_features}\")\n",
    "    print(f\"first graph: {dataset[0]}\")\n",
    "\n",
    "dataset_information(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import NNConv\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class CBN(torch.nn.Module):\n",
    "    #TODO cite the colab\n",
    "    def __init__(self, input_dim, output_dim, edge_feature_dim, args):\n",
    "        super(CBN, self).__init__()\n",
    "\n",
    "        hidden_dim = args.hidden_dim\n",
    "        num_layers = args.num_layers\n",
    "        dropout = args.dropout\n",
    "\n",
    "        if num_layers > 1:\n",
    "            conv_modules = [NNConv(input_dim, hidden_dim, nn.Linear(edge_feature_dim, input_dim * hidden_dim))]\n",
    "            conv_modules.extend([NNConv(hidden_dim, hidden_dim, nn.Linear(edge_feature_dim, hidden_dim * hidden_dim)) for _ in range(num_layers - 2)])\n",
    "            conv_modules.append(NNConv(hidden_dim, output_dim, nn.Linear(edge_feature_dim, hidden_dim * output_dim)))\n",
    "\n",
    "            self.convs = nn.ModuleList(conv_modules)\n",
    "        else:\n",
    "            self.convs = nn.ModuleList([NNConv(input_dim, output_dim, nn.Linear(edge_feature_dim, input_dim * output_dim))])\n",
    "\n",
    "        self.bns = nn.ModuleList([nn.BatchNorm1d(hidden_dim) for _ in range(num_layers - 1)])\n",
    "\n",
    "        # self.post_mp = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Probability of an element getting zeroed\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "        # self.post_mp.reset_parameters()\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        for i in range(self.num_layers - 1):\n",
    "            x = self.convs[i](x, edge_index, edge_attr)\n",
    "            x = self.bns[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, self.dropout, self.training)\n",
    "        x = self.convs[-1](x, edge_index, edge_attr)\n",
    "        x = F.relu(x)\n",
    "        # x = self.post_mp(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def dual_value(N, p):\n",
    "        return np.sum([p[i] * N.b[i] for i in N.V]) + np.sum([N.u[e] * max(0, p[e[1]] - p[e[0]] - N.c[e]) for e in N.E])\n",
    "\n",
    "    # def loss(self, pred, label, x, edge_index, edge_attr):\n",
    "    #     # edge_attr[0] is capacity, edge_attr[1] is cost\n",
    "    #     print(pred.shape)\n",
    "    #     print(edge_index[0].shape)\n",
    "    #     print(pred[edge_index[1]].shape)\n",
    "    #     print(edge_attr[:, 1].shape)\n",
    "    #     reduced_cost = pred[edge_index[1]].squeeze() - pred[edge_index[0]].squeeze() - edge_attr[:, 1]\n",
    "    #     print(reduced_cost.shape)\n",
    "    #     return label - torch.dot(pred.squeeze(), x.squeeze()) - torch.dot(edge_attr[:, 0], F.relu(reduced_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DualLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DualLoss, self).__init__()\n",
    "\n",
    "    def forward(self, pred, label, x, edge_index, edge_attr):\n",
    "        # edge_attr[0] is capacity, edge_attr[1] is cost\n",
    "        #TODO is negative for the moment but if you switch the sign before the second dot product it's always positive ._.\n",
    "        reduced_cost = pred[edge_index[1]].squeeze() - pred[edge_index[0]].squeeze() - edge_attr[:, 1]\n",
    "        print(label, torch.dot(pred.squeeze(), x.squeeze()) - torch.dot(edge_attr[:, 0], F.relu(reduced_cost)))\n",
    "        return label - torch.dot(pred.squeeze(), x.squeeze()) + torch.dot(edge_attr[:, 0], F.relu(reduced_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class objectview(object):\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def build_optimizer(args, params):\n",
    "    weight_decay = args.weight_decay\n",
    "    filter_fn = filter(lambda p : p.requires_grad, params)\n",
    "    if args.opt == 'adam':\n",
    "        optimizer = optim.Adam(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
    "    elif args.opt == 'sgd':\n",
    "        optimizer = optim.SGD(filter_fn, lr=args.lr, momentum=0.95, weight_decay=weight_decay)\n",
    "    elif args.opt == 'rmsprop':\n",
    "        optimizer = optim.RMSprop(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
    "    elif args.opt == 'adagrad':\n",
    "        optimizer = optim.Adagrad(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
    "    if args.opt_scheduler == 'none':\n",
    "        return None, optimizer\n",
    "    elif args.opt_scheduler == 'step':\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=args.opt_decay_step, gamma=args.opt_decay_rate)\n",
    "    elif args.opt_scheduler == 'cos':\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.opt_restart)\n",
    "    return scheduler, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134/134 [00:00<00:00, 107814.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[944]]) tensor(-16014.3760, grad_fn=<SubBackward0>)\n",
      "loss: 16958.376953125\n",
      "tensor([[944]]) tensor(-14356.9473, grad_fn=<SubBackward0>)\n",
      "loss: 15300.947265625\n",
      "tensor([[944]]) tensor(-1138.1403, grad_fn=<SubBackward0>)\n",
      "loss: 2082.140380859375\n",
      "tensor([[944]]) tensor(16.6134, grad_fn=<SubBackward0>)\n",
      "loss: 927.3865356445312\n",
      "tensor([[944]]) tensor(0., grad_fn=<SubBackward0>)\n",
      "loss: 944.0\n",
      "tensor([[944]]) tensor(6.9020, grad_fn=<SubBackward0>)\n",
      "loss: 937.0980224609375\n",
      "tensor([[944]]) tensor(103.3330, grad_fn=<SubBackward0>)\n",
      "loss: 840.6669921875\n",
      "tensor([[944]]) tensor(0., grad_fn=<SubBackward0>)\n",
      "loss: 944.0\n",
      "tensor([[944]]) tensor(14.4042, grad_fn=<SubBackward0>)\n",
      "loss: 929.5958251953125\n",
      "tensor([[944]]) tensor(8.6901, grad_fn=<SubBackward0>)\n",
      "loss: 935.3098754882812\n",
      "tensor([[944]]) tensor(11.9000, grad_fn=<SubBackward0>)\n",
      "loss: 932.0999755859375\n",
      "tensor([[944]]) tensor(1.2791, grad_fn=<SubBackward0>)\n",
      "loss: 942.7208251953125\n",
      "tensor([[944]]) tensor(20.6822, grad_fn=<SubBackward0>)\n",
      "loss: 923.3178100585938\n",
      "tensor([[944]]) tensor(-1771.1082, grad_fn=<SubBackward0>)\n",
      "loss: 2715.108154296875\n",
      "tensor([[944]]) tensor(18.9267, grad_fn=<SubBackward0>)\n",
      "loss: 925.0732421875\n",
      "tensor([[944]]) tensor(24.3685, grad_fn=<SubBackward0>)\n",
      "loss: 919.6314697265625\n",
      "tensor([[944]]) tensor(57.0632, grad_fn=<SubBackward0>)\n",
      "loss: 886.9368286132812\n",
      "tensor([[944]]) tensor(53.4931, grad_fn=<SubBackward0>)\n",
      "loss: 890.5068969726562\n",
      "tensor([[944]]) tensor(26.5284, grad_fn=<SubBackward0>)\n",
      "loss: 917.4716186523438\n",
      "tensor([[944]]) tensor(24.4259, grad_fn=<SubBackward0>)\n",
      "loss: 919.5740966796875\n",
      "tensor([[944]]) tensor(44.5729, grad_fn=<SubBackward0>)\n",
      "loss: 899.4271240234375\n",
      "tensor([[944]]) tensor(37.4208, grad_fn=<SubBackward0>)\n",
      "loss: 906.5791625976562\n",
      "tensor([[944]]) tensor(44.7742, grad_fn=<SubBackward0>)\n",
      "loss: 899.2257690429688\n",
      "tensor([[944]]) tensor(22.1332, grad_fn=<SubBackward0>)\n",
      "loss: 921.8668212890625\n",
      "tensor([[944]]) tensor(55.5179, grad_fn=<SubBackward0>)\n",
      "loss: 888.4820556640625\n",
      "tensor([[944]]) tensor(45.2532, grad_fn=<SubBackward0>)\n",
      "loss: 898.7467651367188\n",
      "tensor([[944]]) tensor(128.0416, grad_fn=<SubBackward0>)\n",
      "loss: 815.9583740234375\n",
      "tensor([[944]]) tensor(-123.9800, grad_fn=<SubBackward0>)\n",
      "loss: 1067.97998046875\n",
      "tensor([[944]]) tensor(48.1312, grad_fn=<SubBackward0>)\n",
      "loss: 895.8687744140625\n",
      "tensor([[944]]) tensor(188.0275, grad_fn=<SubBackward0>)\n",
      "loss: 755.9724731445312\n",
      "tensor([[944]]) tensor(124.7342, grad_fn=<SubBackward0>)\n",
      "loss: 819.265869140625\n",
      "tensor([[944]]) tensor(140.9028, grad_fn=<SubBackward0>)\n",
      "loss: 803.09716796875\n",
      "tensor([[944]]) tensor(-395.1677, grad_fn=<SubBackward0>)\n",
      "loss: 1339.167724609375\n",
      "tensor([[944]]) tensor(152.3581, grad_fn=<SubBackward0>)\n",
      "loss: 791.6419067382812\n",
      "tensor([[944]]) tensor(186.7013, grad_fn=<SubBackward0>)\n",
      "loss: 757.2987060546875\n",
      "tensor([[944]]) tensor(188.4947, grad_fn=<SubBackward0>)\n",
      "loss: 755.5052490234375\n",
      "tensor([[944]]) tensor(203.1012, grad_fn=<SubBackward0>)\n",
      "loss: 740.8988037109375\n",
      "tensor([[944]]) tensor(198.1362, grad_fn=<SubBackward0>)\n",
      "loss: 745.8638305664062\n",
      "tensor([[944]]) tensor(201.3603, grad_fn=<SubBackward0>)\n",
      "loss: 742.6397094726562\n",
      "tensor([[944]]) tensor(227.9315, grad_fn=<SubBackward0>)\n",
      "loss: 716.0684814453125\n",
      "tensor([[944]]) tensor(226.3323, grad_fn=<SubBackward0>)\n",
      "loss: 717.667724609375\n",
      "tensor([[944]]) tensor(231.7638, grad_fn=<SubBackward0>)\n",
      "loss: 712.2362060546875\n",
      "tensor([[944]]) tensor(244.4898, grad_fn=<SubBackward0>)\n",
      "loss: 699.5101318359375\n",
      "tensor([[944]]) tensor(268.5257, grad_fn=<SubBackward0>)\n",
      "loss: 675.4743041992188\n",
      "tensor([[944]]) tensor(256.3674, grad_fn=<SubBackward0>)\n",
      "loss: 687.6326293945312\n",
      "tensor([[944]]) tensor(270.6282, grad_fn=<SubBackward0>)\n",
      "loss: 673.371826171875\n",
      "tensor([[944]]) tensor(224.1231, grad_fn=<SubBackward0>)\n",
      "loss: 719.8768310546875\n",
      "tensor([[944]]) tensor(341.8465, grad_fn=<SubBackward0>)\n",
      "loss: 602.153564453125\n",
      "tensor([[944]]) tensor(286.7432, grad_fn=<SubBackward0>)\n",
      "loss: 657.2567749023438\n",
      "tensor([[944]]) tensor(257.7104, grad_fn=<SubBackward0>)\n",
      "loss: 686.2896728515625\n",
      "tensor([[944]]) tensor(305.5352, grad_fn=<SubBackward0>)\n",
      "loss: 638.4647827148438\n",
      "tensor([[944]]) tensor(372.1400, grad_fn=<SubBackward0>)\n",
      "loss: 571.8599853515625\n",
      "tensor([[944]]) tensor(488.1658, grad_fn=<SubBackward0>)\n",
      "loss: 455.83416748046875\n",
      "tensor([[944]]) tensor(472.9994, grad_fn=<SubBackward0>)\n",
      "loss: 471.0006408691406\n",
      "tensor([[944]]) tensor(374.5842, grad_fn=<SubBackward0>)\n",
      "loss: 569.4158325195312\n",
      "tensor([[944]]) tensor(503.6146, grad_fn=<SubBackward0>)\n",
      "loss: 440.3853759765625\n",
      "tensor([[944]]) tensor(536.5383, grad_fn=<SubBackward0>)\n",
      "loss: 407.461669921875\n",
      "tensor([[944]]) tensor(422.3552, grad_fn=<SubBackward0>)\n",
      "loss: 521.644775390625\n",
      "tensor([[944]]) tensor(375.7147, grad_fn=<SubBackward0>)\n",
      "loss: 568.2852783203125\n",
      "tensor([[944]]) tensor(732.7864, grad_fn=<SubBackward0>)\n",
      "loss: 211.21356201171875\n",
      "tensor([[944]]) tensor(714.6285, grad_fn=<SubBackward0>)\n",
      "loss: 229.3714599609375\n",
      "tensor([[944]]) tensor(660.9737, grad_fn=<SubBackward0>)\n",
      "loss: 283.02630615234375\n",
      "tensor([[944]]) tensor(663.7673, grad_fn=<SubBackward0>)\n",
      "loss: 280.232666015625\n",
      "tensor([[944]]) tensor(643.8811, grad_fn=<SubBackward0>)\n",
      "loss: 300.118896484375\n",
      "tensor([[944]]) tensor(737.9216, grad_fn=<SubBackward0>)\n",
      "loss: 206.078369140625\n",
      "tensor([[944]]) tensor(695.8364, grad_fn=<SubBackward0>)\n",
      "loss: 248.16357421875\n",
      "tensor([[944]]) tensor(682.6551, grad_fn=<SubBackward0>)\n",
      "loss: 261.34490966796875\n",
      "tensor([[944]]) tensor(718.2442, grad_fn=<SubBackward0>)\n",
      "loss: 225.75579833984375\n",
      "tensor([[944]]) tensor(772.6144, grad_fn=<SubBackward0>)\n",
      "loss: 171.38555908203125\n",
      "tensor([[944]]) tensor(902.2423, grad_fn=<SubBackward0>)\n",
      "loss: 41.7576904296875\n",
      "tensor([[944]]) tensor(860.2880, grad_fn=<SubBackward0>)\n",
      "loss: 83.7120361328125\n",
      "tensor([[944]]) tensor(762.7725, grad_fn=<SubBackward0>)\n",
      "loss: 181.2275390625\n",
      "tensor([[944]]) tensor(895.1083, grad_fn=<SubBackward0>)\n",
      "loss: 48.8917236328125\n",
      "tensor([[944]]) tensor(1424.8579, grad_fn=<SubBackward0>)\n",
      "loss: -480.85791015625\n",
      "tensor([[944]]) tensor(946.8957, grad_fn=<SubBackward0>)\n",
      "loss: -2.89569091796875\n",
      "tensor([[944]]) tensor(1047.5492, grad_fn=<SubBackward0>)\n",
      "loss: -103.5491943359375\n",
      "tensor([[944]]) tensor(994.2958, grad_fn=<SubBackward0>)\n",
      "loss: -50.2957763671875\n",
      "tensor([[944]]) tensor(920.8983, grad_fn=<SubBackward0>)\n",
      "loss: 23.10174560546875\n",
      "tensor([[944]]) tensor(1250.8153, grad_fn=<SubBackward0>)\n",
      "loss: -306.8153076171875\n",
      "tensor([[944]]) tensor(1181.2770, grad_fn=<SubBackward0>)\n",
      "loss: -237.2769775390625\n",
      "tensor([[944]]) tensor(1202.7898, grad_fn=<SubBackward0>)\n",
      "loss: -258.789794921875\n",
      "tensor([[944]]) tensor(855.7595, grad_fn=<SubBackward0>)\n",
      "loss: 88.240478515625\n",
      "tensor([[944]]) tensor(1443.6172, grad_fn=<SubBackward0>)\n",
      "loss: -499.6171875\n",
      "tensor([[944]]) tensor(741.9293, grad_fn=<SubBackward0>)\n",
      "loss: 202.0706787109375\n",
      "tensor([[944]]) tensor(1135.9910, grad_fn=<SubBackward0>)\n",
      "loss: -191.990966796875\n",
      "tensor([[944]]) tensor(1545.6765, grad_fn=<SubBackward0>)\n",
      "loss: -601.676513671875\n",
      "tensor([[944]]) tensor(1604.6445, grad_fn=<SubBackward0>)\n",
      "loss: -660.64453125\n",
      "tensor([[944]]) tensor(1814.7788, grad_fn=<SubBackward0>)\n",
      "loss: -870.77880859375\n",
      "tensor([[944]]) tensor(1807.2849, grad_fn=<SubBackward0>)\n",
      "loss: -863.284912109375\n",
      "tensor([[944]]) tensor(1762.8798, grad_fn=<SubBackward0>)\n",
      "loss: -818.8797607421875\n",
      "tensor([[944]]) tensor(1417.7021, grad_fn=<SubBackward0>)\n",
      "loss: -473.7021484375\n",
      "tensor([[944]]) tensor(1896.1458, grad_fn=<SubBackward0>)\n",
      "loss: -952.145751953125\n",
      "tensor([[944]]) tensor(1812.3459, grad_fn=<SubBackward0>)\n",
      "loss: -868.345947265625\n",
      "tensor([[944]]) tensor(1703.3330, grad_fn=<SubBackward0>)\n",
      "loss: -759.3330078125\n",
      "tensor([[944]]) tensor(1748.7977, grad_fn=<SubBackward0>)\n",
      "loss: -804.7977294921875\n",
      "tensor([[944]]) tensor(2072.7480, grad_fn=<SubBackward0>)\n",
      "loss: -1128.748046875\n",
      "tensor([[944]]) tensor(2238.7146, grad_fn=<SubBackward0>)\n",
      "loss: -1294.714599609375\n",
      "tensor([[944]]) tensor(1770.4504, grad_fn=<SubBackward0>)\n",
      "loss: -826.450439453125\n",
      "tensor([[944]]) tensor(2647.4763, grad_fn=<SubBackward0>)\n",
      "loss: -1703.476318359375\n",
      "tensor([[944]]) tensor(2187.5151, grad_fn=<SubBackward0>)\n",
      "loss: -1243.51513671875\n",
      "tensor([[944]]) tensor(2380.1023, grad_fn=<SubBackward0>)\n",
      "loss: -1436.102294921875\n",
      "tensor([[944]]) tensor(1624.5959, grad_fn=<SubBackward0>)\n",
      "loss: -680.595947265625\n",
      "tensor([[944]]) tensor(2434.9648, grad_fn=<SubBackward0>)\n",
      "loss: -1490.96484375\n",
      "tensor([[944]]) tensor(2114.3628, grad_fn=<SubBackward0>)\n",
      "loss: -1170.36279296875\n",
      "tensor([[944]]) tensor(2266.5701, grad_fn=<SubBackward0>)\n",
      "loss: -1322.570068359375\n",
      "tensor([[944]]) tensor(3015.3711, grad_fn=<SubBackward0>)\n",
      "loss: -2071.37109375\n",
      "tensor([[944]]) tensor(2518.3191, grad_fn=<SubBackward0>)\n",
      "loss: -1574.319091796875\n",
      "tensor([[944]]) tensor(2467.3110, grad_fn=<SubBackward0>)\n",
      "loss: -1523.31103515625\n",
      "tensor([[944]]) tensor(3258.8269, grad_fn=<SubBackward0>)\n",
      "loss: -2314.826904296875\n",
      "tensor([[944]]) tensor(2730.6997, grad_fn=<SubBackward0>)\n",
      "loss: -1786.69970703125\n",
      "tensor([[944]]) tensor(2568.7598, grad_fn=<SubBackward0>)\n",
      "loss: -1624.759765625\n",
      "tensor([[944]]) tensor(2716.5254, grad_fn=<SubBackward0>)\n",
      "loss: -1772.525390625\n",
      "tensor([[944]]) tensor(2816.5103, grad_fn=<SubBackward0>)\n",
      "loss: -1872.51025390625\n",
      "tensor([[944]]) tensor(2673.0618, grad_fn=<SubBackward0>)\n",
      "loss: -1729.061767578125\n",
      "tensor([[944]]) tensor(2734.6753, grad_fn=<SubBackward0>)\n",
      "loss: -1790.67529296875\n",
      "tensor([[944]]) tensor(3806.5864, grad_fn=<SubBackward0>)\n",
      "loss: -2862.58642578125\n",
      "tensor([[944]]) tensor(3566.3022, grad_fn=<SubBackward0>)\n",
      "loss: -2622.30224609375\n",
      "tensor([[944]]) tensor(4575.7969, grad_fn=<SubBackward0>)\n",
      "loss: -3631.796875\n",
      "tensor([[944]]) tensor(3771.0715, grad_fn=<SubBackward0>)\n",
      "loss: -2827.071533203125\n",
      "tensor([[944]]) tensor(3693.3074, grad_fn=<SubBackward0>)\n",
      "loss: -2749.307373046875\n",
      "tensor([[944]]) tensor(3382.0999, grad_fn=<SubBackward0>)\n",
      "loss: -2438.099853515625\n",
      "tensor([[944]]) tensor(3850.5725, grad_fn=<SubBackward0>)\n",
      "loss: -2906.572509765625\n",
      "tensor([[944]]) tensor(4124.0698, grad_fn=<SubBackward0>)\n",
      "loss: -3180.06982421875\n",
      "tensor([[944]]) tensor(3653.0615, grad_fn=<SubBackward0>)\n",
      "loss: -2709.0615234375\n",
      "tensor([[944]]) tensor(3918.6113, grad_fn=<SubBackward0>)\n",
      "loss: -2974.611328125\n",
      "tensor([[944]]) tensor(4059.9954, grad_fn=<SubBackward0>)\n",
      "loss: -3115.995361328125\n",
      "tensor([[944]]) tensor(3860.1987, grad_fn=<SubBackward0>)\n",
      "loss: -2916.19873046875\n",
      "tensor([[944]]) tensor(4163.8936, grad_fn=<SubBackward0>)\n",
      "loss: -3219.8935546875\n",
      "tensor([[944]]) tensor(3768.0811, grad_fn=<SubBackward0>)\n",
      "loss: -2824.0810546875\n",
      "tensor([[944]]) tensor(5850.3022, grad_fn=<SubBackward0>)\n",
      "loss: -4906.30224609375\n",
      "tensor([[944]]) tensor(5101.8887, grad_fn=<SubBackward0>)\n",
      "loss: -4157.888671875\n",
      "tensor([[944]]) tensor(4389.3516, grad_fn=<SubBackward0>)\n",
      "loss: -3445.3515625\n",
      "tensor([[944]]) tensor(5042.4873, grad_fn=<SubBackward0>)\n",
      "loss: -4098.4873046875\n",
      "tensor([[944]]) tensor(4562.4014, grad_fn=<SubBackward0>)\n",
      "loss: -3618.4013671875\n",
      "tensor([[944]]) tensor(5781.3442, grad_fn=<SubBackward0>)\n",
      "loss: -4837.34423828125\n",
      "tensor([[944]]) tensor(4653.7158, grad_fn=<SubBackward0>)\n",
      "loss: -3709.7158203125\n",
      "tensor([[944]]) tensor(7766.0928, grad_fn=<SubBackward0>)\n",
      "loss: -6822.0927734375\n",
      "tensor([[944]]) tensor(5765.2197, grad_fn=<SubBackward0>)\n",
      "loss: -4821.2197265625\n",
      "tensor([[944]]) tensor(6471.1074, grad_fn=<SubBackward0>)\n",
      "loss: -5527.107421875\n",
      "tensor([[944]]) tensor(5049.3945, grad_fn=<SubBackward0>)\n",
      "loss: -4105.39453125\n",
      "tensor([[944]]) tensor(6871.4268, grad_fn=<SubBackward0>)\n",
      "loss: -5927.4267578125\n",
      "tensor([[944]]) tensor(7094.2842, grad_fn=<SubBackward0>)\n",
      "loss: -6150.2841796875\n",
      "tensor([[944]]) tensor(7092.7725, grad_fn=<SubBackward0>)\n",
      "loss: -6148.7724609375\n",
      "tensor([[944]]) tensor(5714.0757, grad_fn=<SubBackward0>)\n",
      "loss: -4770.07568359375\n",
      "tensor([[944]]) tensor(7053.2607, grad_fn=<SubBackward0>)\n",
      "loss: -6109.2607421875\n",
      "tensor([[944]]) tensor(6688.8716, grad_fn=<SubBackward0>)\n",
      "loss: -5744.87158203125\n",
      "tensor([[944]]) tensor(8162.5649, grad_fn=<SubBackward0>)\n",
      "loss: -7218.56494140625\n",
      "tensor([[944]]) tensor(7909.2852, grad_fn=<SubBackward0>)\n",
      "loss: -6965.28515625\n",
      "tensor([[944]]) tensor(7501.6191, grad_fn=<SubBackward0>)\n",
      "loss: -6557.619140625\n",
      "tensor([[944]]) tensor(8217.7891, grad_fn=<SubBackward0>)\n",
      "loss: -7273.7890625\n",
      "tensor([[944]]) tensor(9197.2852, grad_fn=<SubBackward0>)\n",
      "loss: -8253.28515625\n",
      "tensor([[944]]) tensor(7864.4424, grad_fn=<SubBackward0>)\n",
      "loss: -6920.4423828125\n",
      "tensor([[944]]) tensor(8372.5801, grad_fn=<SubBackward0>)\n",
      "loss: -7428.580078125\n",
      "tensor([[944]]) tensor(8686.3965, grad_fn=<SubBackward0>)\n",
      "loss: -7742.396484375\n",
      "tensor([[944]]) tensor(7525.4175, grad_fn=<SubBackward0>)\n",
      "loss: -6581.41748046875\n",
      "tensor([[944]]) tensor(8687.5342, grad_fn=<SubBackward0>)\n",
      "loss: -7743.5341796875\n",
      "tensor([[944]]) tensor(9250.8594, grad_fn=<SubBackward0>)\n",
      "loss: -8306.859375\n",
      "tensor([[944]]) tensor(8262.9375, grad_fn=<SubBackward0>)\n",
      "loss: -7318.9375\n",
      "tensor([[944]]) tensor(7801.9502, grad_fn=<SubBackward0>)\n",
      "loss: -6857.9501953125\n",
      "tensor([[944]]) tensor(9860.5420, grad_fn=<SubBackward0>)\n",
      "loss: -8916.5419921875\n",
      "tensor([[944]]) tensor(10195.7305, grad_fn=<SubBackward0>)\n",
      "loss: -9251.73046875\n",
      "tensor([[944]]) tensor(7545., grad_fn=<SubBackward0>)\n",
      "loss: -6601.0\n",
      "tensor([[944]]) tensor(9345.9844, grad_fn=<SubBackward0>)\n",
      "loss: -8401.984375\n",
      "tensor([[944]]) tensor(8316.0078, grad_fn=<SubBackward0>)\n",
      "loss: -7372.0078125\n",
      "tensor([[944]]) tensor(9634.1865, grad_fn=<SubBackward0>)\n",
      "loss: -8690.1865234375\n",
      "tensor([[944]]) tensor(9121.6387, grad_fn=<SubBackward0>)\n",
      "loss: -8177.638671875\n",
      "tensor([[944]]) tensor(12077.8457, grad_fn=<SubBackward0>)\n",
      "loss: -11133.845703125\n",
      "tensor([[944]]) tensor(11999.3477, grad_fn=<SubBackward0>)\n",
      "loss: -11055.34765625\n",
      "tensor([[944]]) tensor(11314.2520, grad_fn=<SubBackward0>)\n",
      "loss: -10370.251953125\n",
      "tensor([[944]]) tensor(7451.6514, grad_fn=<SubBackward0>)\n",
      "loss: -6507.6513671875\n",
      "tensor([[944]]) tensor(10861.3115, grad_fn=<SubBackward0>)\n",
      "loss: -9917.3115234375\n",
      "tensor([[944]]) tensor(12032.7236, grad_fn=<SubBackward0>)\n",
      "loss: -11088.7236328125\n",
      "tensor([[944]]) tensor(12829.1592, grad_fn=<SubBackward0>)\n",
      "loss: -11885.1591796875\n",
      "tensor([[944]]) tensor(9051.7207, grad_fn=<SubBackward0>)\n",
      "loss: -8107.720703125\n",
      "tensor([[944]]) tensor(13386.9678, grad_fn=<SubBackward0>)\n",
      "loss: -12442.9677734375\n",
      "tensor([[944]]) tensor(14656.2656, grad_fn=<SubBackward0>)\n",
      "loss: -13712.265625\n",
      "tensor([[944]]) tensor(14887.6865, grad_fn=<SubBackward0>)\n",
      "loss: -13943.6865234375\n",
      "tensor([[944]]) tensor(12596.4082, grad_fn=<SubBackward0>)\n",
      "loss: -11652.408203125\n",
      "tensor([[944]]) tensor(11999.6465, grad_fn=<SubBackward0>)\n",
      "loss: -11055.646484375\n",
      "tensor([[944]]) tensor(11320.3291, grad_fn=<SubBackward0>)\n",
      "loss: -10376.3291015625\n",
      "tensor([[944]]) tensor(14955.8379, grad_fn=<SubBackward0>)\n",
      "loss: -14011.837890625\n",
      "tensor([[944]]) tensor(12223.3340, grad_fn=<SubBackward0>)\n",
      "loss: -11279.333984375\n",
      "tensor([[944]]) tensor(12947.4258, grad_fn=<SubBackward0>)\n",
      "loss: -12003.42578125\n",
      "tensor([[944]]) tensor(15342.7979, grad_fn=<SubBackward0>)\n",
      "loss: -14398.7978515625\n",
      "tensor([[944]]) tensor(14083.6992, grad_fn=<SubBackward0>)\n",
      "loss: -13139.69921875\n",
      "tensor([[944]]) tensor(11490.2832, grad_fn=<SubBackward0>)\n",
      "loss: -10546.283203125\n",
      "tensor([[944]]) tensor(14734.2070, grad_fn=<SubBackward0>)\n",
      "loss: -13790.20703125\n",
      "tensor([[944]]) tensor(14781.1895, grad_fn=<SubBackward0>)\n",
      "loss: -13837.189453125\n",
      "tensor([[944]]) tensor(14845.2930, grad_fn=<SubBackward0>)\n",
      "loss: -13901.29296875\n",
      "tensor([[944]]) tensor(17436.4551, grad_fn=<SubBackward0>)\n",
      "loss: -16492.455078125\n",
      "tensor([[944]]) tensor(12264.5742, grad_fn=<SubBackward0>)\n",
      "loss: -11320.57421875\n",
      "tensor([[944]]) tensor(16046.5283, grad_fn=<SubBackward0>)\n",
      "loss: -15102.5283203125\n",
      "tensor([[944]]) tensor(16604.9688, grad_fn=<SubBackward0>)\n",
      "loss: -15660.96875\n",
      "tensor([[944]]) tensor(15269.7344, grad_fn=<SubBackward0>)\n",
      "loss: -14325.734375\n",
      "tensor([[944]]) tensor(11065.2871, grad_fn=<SubBackward0>)\n",
      "loss: -10121.287109375\n",
      "tensor([[944]]) tensor(15038.1826, grad_fn=<SubBackward0>)\n",
      "loss: -14094.1826171875\n",
      "tensor([[944]]) tensor(13212.3438, grad_fn=<SubBackward0>)\n",
      "loss: -12268.34375\n",
      "tensor([[944]]) tensor(17511.1172, grad_fn=<SubBackward0>)\n",
      "loss: -16567.1171875\n",
      "tensor([[944]]) tensor(19142.3281, grad_fn=<SubBackward0>)\n",
      "loss: -18198.328125\n",
      "tensor([[944]]) tensor(18618.4531, grad_fn=<SubBackward0>)\n",
      "loss: -17674.453125\n",
      "tensor([[944]]) tensor(13773.1582, grad_fn=<SubBackward0>)\n",
      "loss: -12829.158203125\n",
      "tensor([[944]]) tensor(19177.5664, grad_fn=<SubBackward0>)\n",
      "loss: -18233.56640625\n",
      "tensor([[944]]) tensor(16286.7598, grad_fn=<SubBackward0>)\n",
      "loss: -15342.759765625\n",
      "tensor([[944]]) tensor(17026.1797, grad_fn=<SubBackward0>)\n",
      "loss: -16082.1796875\n",
      "tensor([[944]]) tensor(17244.0508, grad_fn=<SubBackward0>)\n",
      "loss: -16300.05078125\n",
      "tensor([[944]]) tensor(15821.9805, grad_fn=<SubBackward0>)\n",
      "loss: -14877.98046875\n",
      "tensor([[944]]) tensor(18483.7734, grad_fn=<SubBackward0>)\n",
      "loss: -17539.7734375\n",
      "tensor([[944]]) tensor(17551.8789, grad_fn=<SubBackward0>)\n",
      "loss: -16607.87890625\n",
      "tensor([[944]]) tensor(21541.8496, grad_fn=<SubBackward0>)\n",
      "loss: -20597.849609375\n",
      "tensor([[944]]) tensor(18556.5156, grad_fn=<SubBackward0>)\n",
      "loss: -17612.515625\n",
      "tensor([[944]]) tensor(18897.9395, grad_fn=<SubBackward0>)\n",
      "loss: -17953.939453125\n",
      "tensor([[944]]) tensor(17556.2656, grad_fn=<SubBackward0>)\n",
      "loss: -16612.265625\n",
      "tensor([[944]]) tensor(24384.6836, grad_fn=<SubBackward0>)\n",
      "loss: -23440.68359375\n",
      "tensor([[944]]) tensor(16715.2617, grad_fn=<SubBackward0>)\n",
      "loss: -15771.26171875\n",
      "tensor([[944]]) tensor(27441.3203, grad_fn=<SubBackward0>)\n",
      "loss: -26497.3203125\n",
      "tensor([[944]]) tensor(24392.2969, grad_fn=<SubBackward0>)\n",
      "loss: -23448.296875\n",
      "tensor([[944]]) tensor(21595.9570, grad_fn=<SubBackward0>)\n",
      "loss: -20651.95703125\n",
      "tensor([[944]]) tensor(20260.9648, grad_fn=<SubBackward0>)\n",
      "loss: -19316.96484375\n",
      "tensor([[944]]) tensor(24183.1738, grad_fn=<SubBackward0>)\n",
      "loss: -23239.173828125\n",
      "tensor([[944]]) tensor(18852.0449, grad_fn=<SubBackward0>)\n",
      "loss: -17908.044921875\n",
      "tensor([[944]]) tensor(24324.2031, grad_fn=<SubBackward0>)\n",
      "loss: -23380.203125\n",
      "tensor([[944]]) tensor(23445.4570, grad_fn=<SubBackward0>)\n",
      "loss: -22501.45703125\n",
      "tensor([[944]]) tensor(15597.4258, grad_fn=<SubBackward0>)\n",
      "loss: -14653.42578125\n",
      "tensor([[944]]) tensor(24402.1035, grad_fn=<SubBackward0>)\n",
      "loss: -23458.103515625\n",
      "tensor([[944]]) tensor(23876.3672, grad_fn=<SubBackward0>)\n",
      "loss: -22932.3671875\n",
      "tensor([[944]]) tensor(24572.4141, grad_fn=<SubBackward0>)\n",
      "loss: -23628.4140625\n",
      "tensor([[944]]) tensor(27117.7480, grad_fn=<SubBackward0>)\n",
      "loss: -26173.748046875\n",
      "tensor([[944]]) tensor(27643.6602, grad_fn=<SubBackward0>)\n",
      "loss: -26699.66015625\n",
      "tensor([[944]]) tensor(18106.3320, grad_fn=<SubBackward0>)\n",
      "loss: -17162.33203125\n",
      "tensor([[944]]) tensor(31903.2891, grad_fn=<SubBackward0>)\n",
      "loss: -30959.2890625\n",
      "tensor([[944]]) tensor(27386.2930, grad_fn=<SubBackward0>)\n",
      "loss: -26442.29296875\n",
      "tensor([[944]]) tensor(29219.0117, grad_fn=<SubBackward0>)\n",
      "loss: -28275.01171875\n",
      "tensor([[944]]) tensor(27485.0020, grad_fn=<SubBackward0>)\n",
      "loss: -26541.001953125\n",
      "tensor([[944]]) tensor(25625.1445, grad_fn=<SubBackward0>)\n",
      "loss: -24681.14453125\n",
      "tensor([[944]]) tensor(32381.0781, grad_fn=<SubBackward0>)\n",
      "loss: -31437.078125\n",
      "tensor([[944]]) tensor(31973.5547, grad_fn=<SubBackward0>)\n",
      "loss: -31029.5546875\n",
      "tensor([[944]]) tensor(35363.8516, grad_fn=<SubBackward0>)\n",
      "loss: -34419.8515625\n",
      "tensor([[944]]) tensor(30324.2148, grad_fn=<SubBackward0>)\n",
      "loss: -29380.21484375\n",
      "tensor([[944]]) tensor(34809.1797, grad_fn=<SubBackward0>)\n",
      "loss: -33865.1796875\n",
      "tensor([[944]]) tensor(38069.8906, grad_fn=<SubBackward0>)\n",
      "loss: -37125.890625\n",
      "tensor([[944]]) tensor(37306.2969, grad_fn=<SubBackward0>)\n",
      "loss: -36362.296875\n",
      "tensor([[944]]) tensor(29515.8672, grad_fn=<SubBackward0>)\n",
      "loss: -28571.8671875\n",
      "tensor([[944]]) tensor(35678.2422, grad_fn=<SubBackward0>)\n",
      "loss: -34734.2421875\n",
      "tensor([[944]]) tensor(40823.8984, grad_fn=<SubBackward0>)\n",
      "loss: -39879.8984375\n",
      "tensor([[944]]) tensor(39148.1016, grad_fn=<SubBackward0>)\n",
      "loss: -38204.1015625\n",
      "tensor([[944]]) tensor(37658.3750, grad_fn=<SubBackward0>)\n",
      "loss: -36714.375\n",
      "tensor([[944]]) tensor(35164.1953, grad_fn=<SubBackward0>)\n",
      "loss: -34220.1953125\n",
      "tensor([[944]]) tensor(30638.3594, grad_fn=<SubBackward0>)\n",
      "loss: -29694.359375\n",
      "tensor([[944]]) tensor(35466.2734, grad_fn=<SubBackward0>)\n",
      "loss: -34522.2734375\n",
      "tensor([[944]]) tensor(35768.0039, grad_fn=<SubBackward0>)\n",
      "loss: -34824.00390625\n",
      "tensor([[482.8371],\n",
      "        [468.9378],\n",
      "        [  0.0000],\n",
      "        [  0.0000],\n",
      "        [  0.0000],\n",
      "        [  0.0000],\n",
      "        [  0.0000],\n",
      "        [  0.0000],\n",
      "        [  0.0000],\n",
      "        [  0.0000],\n",
      "        [164.3993],\n",
      "        [  0.0000],\n",
      "        [  0.0000],\n",
      "        [  0.0000],\n",
      "        [  0.0000],\n",
      "        [  0.0000],\n",
      "        [  0.0000],\n",
      "        [  0.0000],\n",
      "        [  0.0000],\n",
      "        [  0.0000]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "args = {\n",
    "    'num_layers': 5, \n",
    "    'batch_size': 32, \n",
    "    'hidden_dim': 64, \n",
    "    'dropout': 0.5, \n",
    "    'epochs': 500, \n",
    "    'opt': 'adam', \n",
    "    'opt_scheduler': 'none', \n",
    "    'opt_restart': 0, \n",
    "    'weight_decay': 5e-3, \n",
    "    'lr': 0.01\n",
    "}\n",
    "args = objectview(args)\n",
    "model = CBN(1, 1, 2, args)\n",
    "loss_fn = DualLoss()\n",
    "data = dataset[40]\n",
    "\n",
    "\n",
    "scheduler, opt = build_optimizer(args, model.parameters())\n",
    "for i in range(250):\n",
    "    model.train()\n",
    "    opt.zero_grad()\n",
    "    pred = model(data.x, data.edge_index, data.edge_attr)\n",
    "    loss = loss_fn(pred, data.y, data.x, data.edge_index, data.edge_attr)\n",
    "    print(f\"loss: {loss.item()}\")\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([482.83713, 468.93777,   0.     ,   0.     ,   0.     ,   0.     ,\n",
       "         0.     ,   0.     ,   0.     ,   0.     , 164.39926,   0.     ,\n",
       "         0.     ,   0.     ,   0.     ,   0.     ,   0.     ,   0.     ,\n",
       "         0.     ,   0.     ], dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = pred.detach().numpy().flatten()\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import trange\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "import torch_geometric.nn as pyg_nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def train(dataset, args):\n",
    "\n",
    "    print(\"Node task. test set size:\", np.sum(dataset[0]['test_mask'].numpy()))\n",
    "    print()\n",
    "    test_loader = loader = DataLoader(dataset, batch_size=args.batch_size, shuffle=False)\n",
    "\n",
    "    # build model\n",
    "    output_dim = 1 # we predict scalar potential values for each vertex\n",
    "    model = CBN(dataset.num_node_features, output_dim, dataset.num_edge_features, args)\n",
    "    scheduler, opt = build_optimizer(args, model.parameters())\n",
    "\n",
    "    # train\n",
    "    losses = []\n",
    "    test_accs = []\n",
    "    best_acc = 0\n",
    "    best_model = None\n",
    "    for epoch in trange(args.epochs, desc=\"Training\", unit=\"Epochs\"):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        for batch in loader:\n",
    "            print(f\"BATCH {batch}\")\n",
    "            opt.zero_grad()\n",
    "            pred = model(batch)\n",
    "            label = batch.y\n",
    "            print(f\"BATCH y: {batch.y.shape}\")\n",
    "            # pred = pred[batch.train_mask]\n",
    "            # label = label[batch.train_mask]\n",
    "            loss = model.loss(pred, label)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total_loss += loss.item() * batch.num_graphs\n",
    "        total_loss /= len(loader.dataset)\n",
    "        losses.append(total_loss)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "          test_acc = test(test_loader, model)\n",
    "          test_accs.append(test_acc)\n",
    "          if test_acc > best_acc:\n",
    "            best_acc = test_acc\n",
    "            best_model = copy.deepcopy(model)\n",
    "        else:\n",
    "          test_accs.append(test_accs[-1])\n",
    "\n",
    "    return test_accs, losses, best_model, best_acc, test_loader\n",
    "\n",
    "def test(loader, test_model, is_validation=False, save_model_preds=False, model_type=None):\n",
    "    test_model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    # Note that Cora is only one graph!\n",
    "    for data in loader:\n",
    "        with torch.no_grad():\n",
    "            # max(dim=1) returns values, indices tuple; only need indices\n",
    "            pred = test_model(data).max(dim=1)[1]\n",
    "            label = data.y\n",
    "\n",
    "        mask = data.val_mask if is_validation else data.test_mask\n",
    "        # node classification: only evaluate on nodes in test set\n",
    "        pred = pred[mask]\n",
    "        label = label[mask]\n",
    "\n",
    "        if save_model_preds:\n",
    "          print (\"Saving Model Predictions for Model Type\", model_type)\n",
    "\n",
    "          data = {}\n",
    "          data['pred'] = pred.view(-1).cpu().detach().numpy()\n",
    "          data['label'] = label.view(-1).cpu().detach().numpy()\n",
    "\n",
    "          df = pd.DataFrame(data=data)\n",
    "          # Save locally as csv\n",
    "          df.to_csv('MinCostFlow-' + model_type + '.csv', sep=',', index=False)\n",
    "\n",
    "        correct += pred.eq(label).sum().item()\n",
    "\n",
    "    total = 0\n",
    "    for data in loader.dataset:\n",
    "        total += torch.sum(data.val_mask if is_validation else data.test_mask).item()\n",
    "\n",
    "    return correct / total\n",
    "\n",
    "class objectview(object):\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
