{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch has version 1.13.1+cu117\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import pandas as pd\n",
    "from data_parsing import process_file\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"PyTorch has version {}\".format(torch.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data, Dataset, download_url\n",
    "\n",
    "\n",
    "class MinCostDataset(Dataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        \"\"\"If these files are found in the raw directory, download is skipped\"\"\"\n",
    "        return []\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        \"\"\"If these files are found in the processed directory, processing is skipped\"\"\"\n",
    "        processed_files = []\n",
    "        path = self.processed_dir\n",
    "        for file in tqdm(os.listdir(path)):\n",
    "            file_path = os.path.join(path, file)\n",
    "            if not os.path.isdir(file_path) and not file == \"pre_filter.pt\" and not file == \"pre_transform.pt\":\n",
    "                processed_files.append(file)\n",
    "\n",
    "        return processed_files\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        idx = 32\n",
    "        path = self.raw_dir\n",
    "        for file in tqdm(os.listdir(path)):\n",
    "            print(file)\n",
    "            file_path = os.path.join(path, file)\n",
    "            if os.path.isdir(file_path):\n",
    "                continue\n",
    "            # Read data from `raw_path`.\n",
    "            output = process_file(file_path, 'nx')\n",
    "            if output[\"converged\"]:\n",
    "                x = output[\"x\"].type(torch.FloatTensor)\n",
    "                edge_index = output[\"edge_index\"]\n",
    "                edge_attr = output[\"edge_attr\"].type(torch.FloatTensor)\n",
    "                y = output[\"y\"]\n",
    "                data = Data(x = x, edge_index = edge_index, edge_attr = edge_attr, y = y, filename = file_path)\n",
    "\n",
    "                torch.save(data, osp.join(self.processed_dir, f'data_{idx}.pt'))\n",
    "                idx += 1\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.processed_file_names)\n",
    "\n",
    "    def get(self, idx):\n",
    "        data = torch.load(osp.join(self.processed_dir, f'data_{idx}.pt'))\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:00<00:00, 60247.71it/s]\n",
      " 51%|█████     | 51/100 [00:00<00:00, 257.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netgen_94.txt\n",
      "netgen_97.txt\n",
      "netgen_57.txt\n",
      "netgen_42.txt\n",
      "netgen_43.txt\n",
      "netgen_41.txt\n",
      "netgen_65.txt\n",
      "netgen_19.txt\n",
      "netgen_3.txt\n",
      "netgen_21.txt\n",
      "netgen_99.txt\n",
      "netgen_32.txt\n",
      "netgen_40.txt\n",
      "netgen_45.txt\n",
      "netgen_4.txt\n",
      "netgen_11.txt\n",
      "netgen_96.txt\n",
      "netgen_54.txt\n",
      "netgen_88.txt\n",
      "netgen_34.txt\n",
      "netgen_80.txt\n",
      "netgen_59.txt\n",
      "netgen_27.txt\n",
      "netgen_15.txt\n",
      "netgen_98.txt\n",
      "netgen_52.txt\n",
      "netgen_76.txt\n",
      "netgen_33.txt\n",
      "netgen_20.txt\n",
      "netgen_7.txt\n",
      "netgen_77.txt\n",
      "netgen_81.txt\n",
      "netgen_91.txt\n",
      "netgen_95.txt\n",
      "netgen_2.txt\n",
      "netgen_61.txt\n",
      "netgen_35.txt\n",
      "netgen_6.txt\n",
      "netgen_8.txt\n",
      "netgen_62.txt\n",
      "netgen_24.txt\n",
      "netgen_26.txt\n",
      "netgen_16.txt\n",
      "netgen_69.txt\n",
      "netgen_90.txt\n",
      "netgen_5.txt\n",
      "netgen_66.txt\n",
      "netgen_38.txt\n",
      "netgen_12.txt\n",
      "netgen_58.txt\n",
      "netgen_36.txt\n",
      "netgen_1.txt\n",
      "netgen_53.txt\n",
      "netgen_22.txt\n",
      "netgen_63.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 276.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netgen_9.txt\n",
      "netgen_71.txt\n",
      "netgen_93.txt\n",
      "netgen_30.txt\n",
      "netgen_14.txt\n",
      "netgen_28.txt\n",
      "netgen_68.txt\n",
      "netgen_92.txt\n",
      "netgen_49.txt\n",
      "netgen_13.txt\n",
      "netgen_23.txt\n",
      "netgen_74.txt\n",
      "netgen_31.txt\n",
      "netgen_84.txt\n",
      "netgen_83.txt\n",
      "netgen_86.txt\n",
      "netgen_64.txt\n",
      "netgen_73.txt\n",
      "netgen_0.txt\n",
      "netgen_50.txt\n",
      "netgen_85.txt\n",
      "netgen_47.txt\n",
      "netgen_60.txt\n",
      "netgen_70.txt\n",
      "netgen_29.txt\n",
      "netgen_55.txt\n",
      "netgen_17.txt\n",
      "netgen_72.txt\n",
      "netgen_82.txt\n",
      "netgen_18.txt\n",
      "netgen_75.txt\n",
      "netgen_10.txt\n",
      "netgen_79.txt\n",
      "netgen_37.txt\n",
      "netgen_39.txt\n",
      "netgen_46.txt\n",
      "netgen_89.txt\n",
      "netgen_51.txt\n",
      "netgen_67.txt\n",
      "netgen_56.txt\n",
      "netgen_44.txt\n",
      "netgen_25.txt\n",
      "netgen_48.txt\n",
      "netgen_78.txt\n",
      "netgen_87.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = MinCostDataset(root = \"./data/\")\n",
    "dataset.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134/134 [00:00<00:00, 79687.61it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 60040.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinCostDataset(132)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134/134 [00:00<00:00, 35873.92it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 70794.40it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 74373.00it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 66293.55it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 15831.13it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 85493.88it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 87123.97it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 77277.15it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 68490.95it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 35601.24it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 121468.93it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 152561.55it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 46472.36it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 41592.30it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 221535.96it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 116051.36it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 86294.60it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 84874.17it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 71225.03it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 121102.51it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 66893.21it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 22963.71it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 21613.47it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 38111.94it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 88134.98it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 78354.49it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 91536.93it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 66781.93it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 74619.85it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 116508.44it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 71044.97it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 71862.52it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 26222.96it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 65020.45it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 61816.62it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 54381.88it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 28953.06it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 45697.76it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 49728.96it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 59443.34it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 43748.48it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 82969.70it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 76655.31it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 94858.52it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 86787.64it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 97508.11it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 51173.33it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 98326.93it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 65566.58it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 100904.26it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 60259.11it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 64232.77it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 123253.67it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 41015.60it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 69939.86it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 75008.24it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 99405.15it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 72120.72it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 60616.56it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 54450.37it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 89868.36it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 53537.51it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 13567.57it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 128553.69it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 14679.57it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 66013.24it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 59613.57it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 80521.02it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 59835.70it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 75827.95it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 63150.20it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 53855.57it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 72000.61it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 89696.26it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 50840.05it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 88607.40it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 86467.19it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 120376.26it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 66293.55it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 90944.46it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 74848.41it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 135757.67it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 72812.12it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 233695.11it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 60233.28it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 145680.85it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 191886.90it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 109580.18it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 81454.60it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 83811.03it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 64453.75it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 47541.59it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 46844.20it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 49141.97it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 31548.51it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 33254.64it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 30098.90it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 100077.77it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 72334.20it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 65897.14it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 56018.81it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 44321.17it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 61782.65it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 69267.53it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 86600.42it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 65528.36it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 22921.56it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 89297.23it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 41555.40it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 116387.81it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 83786.04it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 79271.75it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 65452.05it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 86854.70it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 38803.97it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 64240.11it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 28660.72it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 43728.06it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 56108.29it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 61110.88it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 59087.13it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 52952.40it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 79993.84it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 57368.25it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 37604.49it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 96091.08it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 94794.52it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 114514.41it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 65928.06it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 94064.73it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 40318.27it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 91581.67it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 61980.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num classes: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134/134 [00:00<00:00, 61277.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num features: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134/134 [00:00<00:00, 55324.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first graph: Data(x=[9559, 1], edge_index=[2, 29682], edge_attr=[29682, 2], y=[1, 1], filename='data/raw/road_flow_01_DC_a.txt')\n"
     ]
    }
   ],
   "source": [
    "def dataset_information(dataset):\n",
    "    print(dataset)\n",
    "    print(f\"num classes: {dataset.num_classes}\")\n",
    "    print(f\"num features: {dataset.num_features}\")\n",
    "    print(f\"first graph: {dataset[0]}\")\n",
    "\n",
    "dataset_information(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import NNConv\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class CBN(torch.nn.Module):\n",
    "    #TODO cite the colab\n",
    "    def __init__(self, input_dim, output_dim, edge_feature_dim, args):\n",
    "        super(CBN, self).__init__()\n",
    "\n",
    "        hidden_dim = args.hidden_dim\n",
    "        num_layers = args.num_layers\n",
    "        dropout = args.dropout\n",
    "\n",
    "        if num_layers > 1:\n",
    "            conv_modules = [NNConv(input_dim, hidden_dim, nn.Linear(edge_feature_dim, input_dim * hidden_dim))]\n",
    "            conv_modules.extend([NNConv(hidden_dim, hidden_dim, nn.Linear(edge_feature_dim, hidden_dim * hidden_dim)) for _ in range(num_layers - 2)])\n",
    "            conv_modules.append(NNConv(hidden_dim, output_dim, nn.Linear(edge_feature_dim, hidden_dim * output_dim)))\n",
    "\n",
    "            self.convs = nn.ModuleList(conv_modules)\n",
    "        else:\n",
    "            self.convs = nn.ModuleList([NNConv(input_dim, output_dim, nn.Linear(edge_feature_dim, input_dim * output_dim))])\n",
    "\n",
    "        self.bns = nn.ModuleList([nn.BatchNorm1d(hidden_dim) for _ in range(num_layers - 1)])\n",
    "\n",
    "        self.post_mp = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Probability of an element getting zeroed\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "        # self.post_mp.reset_parameters()\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        for i in range(self.num_layers - 1):\n",
    "            x = self.convs[i](x, edge_index, edge_attr)\n",
    "            x = self.bns[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, self.dropout, self.training)\n",
    "        x = self.convs[-1](x, edge_index, edge_attr)\n",
    "        #x = F.relu(x)\n",
    "        #x = self.post_mp(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def dual_value(N, p):\n",
    "        return np.sum([p[i] * N.b[i] for i in N.V]) + np.sum([N.u[e] * max(0, p[e[1]] - p[e[0]] - N.c[e]) for e in N.E])\n",
    "\n",
    "    # def loss(self, pred, label, x, edge_index, edge_attr):\n",
    "    #     # edge_attr[0] is capacity, edge_attr[1] is cost\n",
    "    #     print(pred.shape)\n",
    "    #     print(edge_index[0].shape)\n",
    "    #     print(pred[edge_index[1]].shape)\n",
    "    #     print(edge_attr[:, 1].shape)\n",
    "    #     reduced_cost = pred[edge_index[1]].squeeze() - pred[edge_index[0]].squeeze() - edge_attr[:, 1]\n",
    "    #     print(reduced_cost.shape)\n",
    "    #     return label - torch.dot(pred.squeeze(), x.squeeze()) - torch.dot(edge_attr[:, 0], F.relu(reduced_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134/134 [00:00<00:00, 37705.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.73277154  1.01464668  1.61817639  8.01464668  4.01464668  9.01464668\n",
      "  3.87053766  9.87818328  4.59986794  5.01464668  5.01464668  6.01464668\n",
      "  8.01464668 10.01464668  6.1743807   7.18194869  2.01464668  9.01464668\n",
      "  6.01464668 16.01464668] 854.999999996946\n"
     ]
    }
   ],
   "source": [
    "import cvxpy as cp\n",
    "graph = dataset[50]\n",
    "N = 20\n",
    "b = graph.x.numpy().flatten()\n",
    "costs = graph.edge_attr[:, 1].numpy().flatten()\n",
    "caps = graph.edge_attr[:, 0].numpy().flatten()\n",
    "edges = list(zip(*graph.edge_index.numpy()))\n",
    "\n",
    "y = cp.Variable(N)\n",
    "\n",
    "obj = -cp.sum([y[i] * b[i] for i in range(N)]) - cp.sum([caps[i]*cp.maximum(0, -costs[i] - y[edges[i][0]] + y[edges[i][1]]) for i in range(len(edges))])\n",
    "prob = cp.Problem(\n",
    "    cp.Maximize(obj),\n",
    "    [y>=0]\n",
    "  )\n",
    "prob.solve()\n",
    "print(y.value, prob.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[855]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 4),\n",
       " (0, 8),\n",
       " (0, 9),\n",
       " (0, 17),\n",
       " (0, 6),\n",
       " (3, 8),\n",
       " (3, 19),\n",
       " (4, 3),\n",
       " (4, 18),\n",
       " (4, 17),\n",
       " (4, 10),\n",
       " (4, 13),\n",
       " (6, 14),\n",
       " (6, 5),\n",
       " (8, 6),\n",
       " (8, 5),\n",
       " (8, 13),\n",
       " (14, 17),\n",
       " (14, 9),\n",
       " (1, 10),\n",
       " (1, 16),\n",
       " (1, 17),\n",
       " (1, 5),\n",
       " (1, 4),\n",
       " (1, 9),\n",
       " (5, 19),\n",
       " (5, 15),\n",
       " (5, 10),\n",
       " (5, 6),\n",
       " (5, 17),\n",
       " (7, 5),\n",
       " (7, 16),\n",
       " (7, 19),\n",
       " (7, 13),\n",
       " (7, 14),\n",
       " (7, 11),\n",
       " (9, 18),\n",
       " (9, 7),\n",
       " (9, 4),\n",
       " (9, 12),\n",
       " (10, 12),\n",
       " (10, 8),\n",
       " (10, 18),\n",
       " (10, 14),\n",
       " (10, 5),\n",
       " (12, 9),\n",
       " (12, 10),\n",
       " (12, 7),\n",
       " (12, 17),\n",
       " (2, 11),\n",
       " (2, 3),\n",
       " (2, 4),\n",
       " (2, 5),\n",
       " (2, 10),\n",
       " (11, 13),\n",
       " (11, 5),\n",
       " (11, 9),\n",
       " (11, 15),\n",
       " (13, 15),\n",
       " (13, 19),\n",
       " (13, 11),\n",
       " (13, 5),\n",
       " (15, 16),\n",
       " (15, 10),\n",
       " (16, 17),\n",
       " (16, 9)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.,  4., 10., 10.,  8.,  3.,  8.,  4.,  4.,  5.,  1.,  6.,  5.,  9.,\n",
       "         1.,  9., 10.,  6.,  2.,  5.,  1.,  8.,  4.,  3.,  1.,  7.,  5.,  4.,\n",
       "         2.,  2.,  1.,  1.,  7.,  6.,  4.,  5.,  1.,  7.,  6.,  3.,  8., 10.,\n",
       "         5.,  5.,  2.,  4., 10.,  4.,  1.,  4.,  9.,  5.,  9.,  4.,  5.,  3.,\n",
       "         9., 10.,  5.,  1.,  2.,  1.,  4.,  4.,  8.,  3.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.edge_attr[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_parsing import parse\n",
    "nodes, edges = parse('./data/raw/netgen_88.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "index = {node: index for node, index in zip(nodes, range(len(nodes)))}\n",
    "x = torch.tensor([supply for supply in nodes.values()]).reshape((-1, 1))\n",
    "edge_index = torch.reshape(torch.tensor([[index[e[0]], index[e[1]]] for e in edges]), (2, -1))\n",
    "edge_attr = torch.tensor([list(attributes) for attributes in edges.values()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  4,  0,  8,  0,  9,  0, 17,  0,  6,  3,  8,  3, 19,  4,  3,  4, 18,\n",
       "          4, 17,  4, 10,  4, 13,  6, 14,  6,  5,  8,  6,  8,  5,  8, 13, 14, 17,\n",
       "         14,  9,  1, 10,  1, 16,  1, 17,  1,  5,  1,  4,  1,  9,  5, 19,  5, 15,\n",
       "          5, 10,  5,  6,  5, 17,  7,  5,  7, 16,  7, 19],\n",
       "        [ 7, 13,  7, 14,  7, 11,  9, 18,  9,  7,  9,  4,  9, 12, 10, 12, 10,  8,\n",
       "         10, 18, 10, 14, 10,  5, 12,  9, 12, 10, 12,  7, 12, 17,  2, 11,  2,  3,\n",
       "          2,  4,  2,  5,  2, 10, 11, 13, 11,  5, 11,  9, 11, 15, 13, 15, 13, 19,\n",
       "         13, 11, 13,  5, 15, 16, 15, 10, 16, 17, 16,  9]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[23,  1],\n",
       "        [45,  4],\n",
       "        [29, 10],\n",
       "        [31, 10],\n",
       "        [45,  8],\n",
       "        [23,  3],\n",
       "        [41,  8],\n",
       "        [23,  4],\n",
       "        [23,  4],\n",
       "        [ 3,  5],\n",
       "        [41,  1],\n",
       "        [37,  6],\n",
       "        [23,  5],\n",
       "        [50,  9],\n",
       "        [23,  1],\n",
       "        [17,  9],\n",
       "        [30, 10],\n",
       "        [23,  6],\n",
       "        [14,  2],\n",
       "        [56,  5],\n",
       "        [17,  1],\n",
       "        [24,  8],\n",
       "        [ 6,  4],\n",
       "        [40,  3],\n",
       "        [24,  1],\n",
       "        [56,  7],\n",
       "        [47,  5],\n",
       "        [44,  4],\n",
       "        [16,  2],\n",
       "        [38,  2],\n",
       "        [56,  1],\n",
       "        [ 8,  1],\n",
       "        [19,  7],\n",
       "        [17,  6],\n",
       "        [21,  4],\n",
       "        [ 8,  5],\n",
       "        [56,  1],\n",
       "        [56,  7],\n",
       "        [13,  6],\n",
       "        [43,  3],\n",
       "        [56,  8],\n",
       "        [40, 10],\n",
       "        [18,  5],\n",
       "        [ 5,  5],\n",
       "        [ 4,  2],\n",
       "        [56,  4],\n",
       "        [ 9, 10],\n",
       "        [15,  4],\n",
       "        [44,  1],\n",
       "        [21,  4],\n",
       "        [45,  9],\n",
       "        [21,  5],\n",
       "        [ 2,  9],\n",
       "        [12,  4],\n",
       "        [21,  5],\n",
       "        [50,  3],\n",
       "        [ 9,  9],\n",
       "        [23, 10],\n",
       "        [21,  5],\n",
       "        [21,  1],\n",
       "        [ 9,  2],\n",
       "        [47,  1],\n",
       "        [21,  4],\n",
       "        [15,  4],\n",
       "        [21,  8],\n",
       "        [42,  3]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DualLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DualLoss, self).__init__()\n",
    "\n",
    "    def forward(self, pred, label, x, edge_index, edge_attr):\n",
    "        # edge_attr[0] is capacity, edge_attr[1] is cost\n",
    "        #TODO is negative for the moment but if you switch the sign before the second dot product it's always positive ._.\n",
    "        reduced_cost = pred[edge_index[1]].squeeze() - pred[edge_index[0]].squeeze() - edge_attr[:, 1]\n",
    "        print(label, -torch.dot(pred.squeeze(), x.squeeze()) - torch.dot(edge_attr[:, 0], F.relu(reduced_cost)))\n",
    "        return (label + torch.dot(pred.squeeze(), x.squeeze()) + torch.dot(edge_attr[:, 0], F.relu(reduced_cost)))/label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class objectview(object):\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def build_optimizer(args, params):\n",
    "    weight_decay = args.weight_decay\n",
    "    filter_fn = filter(lambda p : p.requires_grad, params)\n",
    "    if args.opt == 'adam':\n",
    "        optimizer = optim.Adam(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
    "    elif args.opt == 'sgd':\n",
    "        optimizer = optim.SGD(filter_fn, lr=args.lr, momentum=0.95, weight_decay=weight_decay)\n",
    "    elif args.opt == 'rmsprop':\n",
    "        optimizer = optim.RMSprop(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
    "    elif args.opt == 'adagrad':\n",
    "        optimizer = optim.Adagrad(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
    "    if args.opt_scheduler == 'none':\n",
    "        return None, optimizer\n",
    "    elif args.opt_scheduler == 'step':\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=args.opt_decay_step, gamma=args.opt_decay_rate)\n",
    "    elif args.opt_scheduler == 'cos':\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.opt_restart)\n",
    "    return scheduler, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134/134 [00:00<00:00, 54455.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[855]]) tensor(-190079.4062, grad_fn=<SubBackward0>)\n",
      "loss: 223.31509399414062\n",
      "tensor([[855]]) tensor(-189395.0625, grad_fn=<SubBackward0>)\n",
      "loss: 222.5146942138672\n",
      "tensor([[855]]) tensor(-188709.4375, grad_fn=<SubBackward0>)\n",
      "loss: 221.71279907226562\n",
      "tensor([[855]]) tensor(-188023.0625, grad_fn=<SubBackward0>)\n",
      "loss: 220.91001892089844\n",
      "tensor([[855]]) tensor(-187346.6719, grad_fn=<SubBackward0>)\n",
      "loss: 220.11891174316406\n",
      "tensor([[855]]) tensor(-186674.1094, grad_fn=<SubBackward0>)\n",
      "loss: 219.33229064941406\n",
      "tensor([[855]]) tensor(-186001.0938, grad_fn=<SubBackward0>)\n",
      "loss: 218.54513549804688\n",
      "tensor([[855]]) tensor(-185327.3281, grad_fn=<SubBackward0>)\n",
      "loss: 217.75711059570312\n",
      "tensor([[855]]) tensor(-184652.7188, grad_fn=<SubBackward0>)\n",
      "loss: 216.9680938720703\n",
      "tensor([[855]]) tensor(-183980.0312, grad_fn=<SubBackward0>)\n",
      "loss: 216.1813201904297\n",
      "tensor([[855]]) tensor(-183308.4375, grad_fn=<SubBackward0>)\n",
      "loss: 215.3958282470703\n",
      "tensor([[855]]) tensor(-182641.1562, grad_fn=<SubBackward0>)\n",
      "loss: 214.61538696289062\n",
      "tensor([[855]]) tensor(-181975.2656, grad_fn=<SubBackward0>)\n",
      "loss: 213.83656311035156\n",
      "tensor([[855]]) tensor(-181308.9375, grad_fn=<SubBackward0>)\n",
      "loss: 213.05723571777344\n",
      "tensor([[855]]) tensor(-180643.1875, grad_fn=<SubBackward0>)\n",
      "loss: 212.27857971191406\n",
      "tensor([[855]]) tensor(-179977.5938, grad_fn=<SubBackward0>)\n",
      "loss: 211.50010681152344\n",
      "tensor([[855]]) tensor(-179311.9062, grad_fn=<SubBackward0>)\n",
      "loss: 210.72152709960938\n",
      "tensor([[855]]) tensor(-178646.0625, grad_fn=<SubBackward0>)\n",
      "loss: 209.94276428222656\n",
      "tensor([[855]]) tensor(-177985.0469, grad_fn=<SubBackward0>)\n",
      "loss: 209.16964721679688\n",
      "tensor([[855]]) tensor(-177325.0469, grad_fn=<SubBackward0>)\n",
      "loss: 208.39772033691406\n",
      "tensor([[855]]) tensor(-176664.6094, grad_fn=<SubBackward0>)\n",
      "loss: 207.62527465820312\n",
      "tensor([[855]]) tensor(-176005.3438, grad_fn=<SubBackward0>)\n",
      "loss: 206.8542022705078\n",
      "tensor([[855]]) tensor(-175350.0312, grad_fn=<SubBackward0>)\n",
      "loss: 206.08775329589844\n",
      "tensor([[855]]) tensor(-174695.7656, grad_fn=<SubBackward0>)\n",
      "loss: 205.32254028320312\n",
      "tensor([[855]]) tensor(-174042.0312, grad_fn=<SubBackward0>)\n",
      "loss: 204.5579376220703\n",
      "tensor([[855]]) tensor(-173403., grad_fn=<SubBackward0>)\n",
      "loss: 203.81053161621094\n",
      "tensor([[855]]) tensor(-172764.5312, grad_fn=<SubBackward0>)\n",
      "loss: 203.06378173828125\n",
      "tensor([[855]]) tensor(-172121.4062, grad_fn=<SubBackward0>)\n",
      "loss: 202.31158447265625\n",
      "tensor([[855]]) tensor(-171477.8594, grad_fn=<SubBackward0>)\n",
      "loss: 201.55889892578125\n",
      "tensor([[855]]) tensor(-170917.4219, grad_fn=<SubBackward0>)\n",
      "loss: 200.90341186523438\n",
      "tensor([[855]]) tensor(-170356.2500, grad_fn=<SubBackward0>)\n",
      "loss: 200.2470703125\n",
      "tensor([[855]]) tensor(-169795.1250, grad_fn=<SubBackward0>)\n",
      "loss: 199.59078979492188\n",
      "tensor([[855]]) tensor(-169234.2656, grad_fn=<SubBackward0>)\n",
      "loss: 198.934814453125\n",
      "tensor([[855]]) tensor(-168720.6719, grad_fn=<SubBackward0>)\n",
      "loss: 198.33412170410156\n",
      "tensor([[855]]) tensor(-168223.8281, grad_fn=<SubBackward0>)\n",
      "loss: 197.75302124023438\n",
      "tensor([[855]]) tensor(-167728.4062, grad_fn=<SubBackward0>)\n",
      "loss: 197.17356872558594\n",
      "tensor([[855]]) tensor(-167280., grad_fn=<SubBackward0>)\n",
      "loss: 196.6491241455078\n",
      "tensor([[855]]) tensor(-166866., grad_fn=<SubBackward0>)\n",
      "loss: 196.1649169921875\n",
      "tensor([[855]]) tensor(-166460.9844, grad_fn=<SubBackward0>)\n",
      "loss: 195.6912078857422\n",
      "tensor([[855]]) tensor(-166058.0781, grad_fn=<SubBackward0>)\n",
      "loss: 195.219970703125\n",
      "tensor([[855]]) tensor(-165657.0938, grad_fn=<SubBackward0>)\n",
      "loss: 194.75099182128906\n",
      "tensor([[855]]) tensor(-165247.4062, grad_fn=<SubBackward0>)\n",
      "loss: 194.27182006835938\n",
      "tensor([[855]]) tensor(-164835.4688, grad_fn=<SubBackward0>)\n",
      "loss: 193.79002380371094\n",
      "tensor([[855]]) tensor(-164426.6250, grad_fn=<SubBackward0>)\n",
      "loss: 193.3118438720703\n",
      "tensor([[855]]) tensor(-164018.7188, grad_fn=<SubBackward0>)\n",
      "loss: 192.8347625732422\n",
      "tensor([[855]]) tensor(-163609.7500, grad_fn=<SubBackward0>)\n",
      "loss: 192.35643005371094\n",
      "tensor([[855]]) tensor(-163201.2656, grad_fn=<SubBackward0>)\n",
      "loss: 191.87867736816406\n",
      "tensor([[855]]) tensor(-162796.0781, grad_fn=<SubBackward0>)\n",
      "loss: 191.40476989746094\n",
      "tensor([[855]]) tensor(-162398.2031, grad_fn=<SubBackward0>)\n",
      "loss: 190.93942260742188\n",
      "tensor([[855]]) tensor(-162012.8750, grad_fn=<SubBackward0>)\n",
      "loss: 190.48873901367188\n",
      "tensor([[855]]) tensor(-161637.1250, grad_fn=<SubBackward0>)\n",
      "loss: 190.0492706298828\n",
      "tensor([[855]]) tensor(-161261.7188, grad_fn=<SubBackward0>)\n",
      "loss: 189.61019897460938\n",
      "tensor([[855]]) tensor(-160886.6562, grad_fn=<SubBackward0>)\n",
      "loss: 189.17152404785156\n",
      "tensor([[855]]) tensor(-160511.8281, grad_fn=<SubBackward0>)\n",
      "loss: 188.73313903808594\n",
      "tensor([[855]]) tensor(-160137.2812, grad_fn=<SubBackward0>)\n",
      "loss: 188.29505920410156\n",
      "tensor([[855]]) tensor(-159763.2969, grad_fn=<SubBackward0>)\n",
      "loss: 187.85765075683594\n",
      "tensor([[855]]) tensor(-159389.5625, grad_fn=<SubBackward0>)\n",
      "loss: 187.42054748535156\n",
      "tensor([[855]]) tensor(-159016.0469, grad_fn=<SubBackward0>)\n",
      "loss: 186.98367309570312\n",
      "tensor([[855]]) tensor(-158642.9844, grad_fn=<SubBackward0>)\n",
      "loss: 186.54734802246094\n",
      "tensor([[855]]) tensor(-158272.3438, grad_fn=<SubBackward0>)\n",
      "loss: 186.1138458251953\n",
      "tensor([[855]]) tensor(-157905.2500, grad_fn=<SubBackward0>)\n",
      "loss: 185.68450927734375\n",
      "tensor([[855]]) tensor(-157538.3438, grad_fn=<SubBackward0>)\n",
      "loss: 185.25537109375\n",
      "tensor([[855]]) tensor(-157171.6562, grad_fn=<SubBackward0>)\n",
      "loss: 184.8264923095703\n",
      "tensor([[855]]) tensor(-156803.9219, grad_fn=<SubBackward0>)\n",
      "loss: 184.39639282226562\n",
      "tensor([[855]]) tensor(-156436.0312, grad_fn=<SubBackward0>)\n",
      "loss: 183.96612548828125\n",
      "tensor([[855]]) tensor(-156067.8438, grad_fn=<SubBackward0>)\n",
      "loss: 183.53549194335938\n",
      "tensor([[855]]) tensor(-155700.0156, grad_fn=<SubBackward0>)\n",
      "loss: 183.10528564453125\n",
      "tensor([[855]]) tensor(-155331.8438, grad_fn=<SubBackward0>)\n",
      "loss: 182.67466735839844\n",
      "tensor([[855]]) tensor(-154963.5938, grad_fn=<SubBackward0>)\n",
      "loss: 182.2439727783203\n",
      "tensor([[855]]) tensor(-154595.1094, grad_fn=<SubBackward0>)\n",
      "loss: 181.81298828125\n",
      "tensor([[855]]) tensor(-154227.1406, grad_fn=<SubBackward0>)\n",
      "loss: 181.3826141357422\n",
      "tensor([[855]]) tensor(-153858.6875, grad_fn=<SubBackward0>)\n",
      "loss: 180.95167541503906\n",
      "tensor([[855]]) tensor(-153489.9688, grad_fn=<SubBackward0>)\n",
      "loss: 180.5204315185547\n",
      "tensor([[855]]) tensor(-153121.4531, grad_fn=<SubBackward0>)\n",
      "loss: 180.08941650390625\n",
      "tensor([[855]]) tensor(-152750.1094, grad_fn=<SubBackward0>)\n",
      "loss: 179.6551055908203\n",
      "tensor([[855]]) tensor(-152377.2344, grad_fn=<SubBackward0>)\n",
      "loss: 179.218994140625\n",
      "tensor([[855]]) tensor(-152003.1094, grad_fn=<SubBackward0>)\n",
      "loss: 178.7814178466797\n",
      "tensor([[855]]) tensor(-151653.7500, grad_fn=<SubBackward0>)\n",
      "loss: 178.372802734375\n",
      "tensor([[855]]) tensor(-151309.1562, grad_fn=<SubBackward0>)\n",
      "loss: 177.9697723388672\n",
      "tensor([[855]]) tensor(-150964.3125, grad_fn=<SubBackward0>)\n",
      "loss: 177.5664520263672\n",
      "tensor([[855]]) tensor(-150615.9531, grad_fn=<SubBackward0>)\n",
      "loss: 177.1590118408203\n",
      "tensor([[855]]) tensor(-150263.8281, grad_fn=<SubBackward0>)\n",
      "loss: 176.74716186523438\n",
      "tensor([[855]]) tensor(-149910.7344, grad_fn=<SubBackward0>)\n",
      "loss: 176.33419799804688\n",
      "tensor([[855]]) tensor(-149556.8438, grad_fn=<SubBackward0>)\n",
      "loss: 175.9202880859375\n",
      "tensor([[855]]) tensor(-149202.5156, grad_fn=<SubBackward0>)\n",
      "loss: 175.505859375\n",
      "tensor([[855]]) tensor(-148849.2344, grad_fn=<SubBackward0>)\n",
      "loss: 175.09266662597656\n",
      "tensor([[855]]) tensor(-148495.3438, grad_fn=<SubBackward0>)\n",
      "loss: 174.67877197265625\n",
      "tensor([[855]]) tensor(-148141.5156, grad_fn=<SubBackward0>)\n",
      "loss: 174.26492309570312\n",
      "tensor([[855]]) tensor(-147787.6562, grad_fn=<SubBackward0>)\n",
      "loss: 173.85105895996094\n",
      "tensor([[855]]) tensor(-147433.8125, grad_fn=<SubBackward0>)\n",
      "loss: 173.4372100830078\n",
      "tensor([[855]]) tensor(-147079.5625, grad_fn=<SubBackward0>)\n",
      "loss: 173.0228729248047\n",
      "tensor([[855]]) tensor(-146725.4375, grad_fn=<SubBackward0>)\n",
      "loss: 172.60870361328125\n",
      "tensor([[855]]) tensor(-146372.4688, grad_fn=<SubBackward0>)\n",
      "loss: 172.1958770751953\n",
      "tensor([[855]]) tensor(-146019.3438, grad_fn=<SubBackward0>)\n",
      "loss: 171.78285217285156\n",
      "tensor([[855]]) tensor(-145666.3438, grad_fn=<SubBackward0>)\n",
      "loss: 171.3699951171875\n",
      "tensor([[855]]) tensor(-145312.8750, grad_fn=<SubBackward0>)\n",
      "loss: 170.95657348632812\n",
      "tensor([[855]]) tensor(-144958.8438, grad_fn=<SubBackward0>)\n",
      "loss: 170.54251098632812\n",
      "tensor([[855]]) tensor(-144604.6562, grad_fn=<SubBackward0>)\n",
      "loss: 170.1282501220703\n",
      "tensor([[855]]) tensor(-144250.4688, grad_fn=<SubBackward0>)\n",
      "loss: 169.71400451660156\n",
      "tensor([[855]]) tensor(-143895.7188, grad_fn=<SubBackward0>)\n",
      "loss: 169.29908752441406\n",
      "tensor([[855]]) tensor(-143540.6094, grad_fn=<SubBackward0>)\n",
      "loss: 168.88375854492188\n",
      "tensor([[855]]) tensor(-143185.9844, grad_fn=<SubBackward0>)\n",
      "loss: 168.468994140625\n",
      "tensor([[855]]) tensor(-142831.1875, grad_fn=<SubBackward0>)\n",
      "loss: 168.05401611328125\n",
      "tensor([[855]]) tensor(-142472.6719, grad_fn=<SubBackward0>)\n",
      "loss: 167.63470458984375\n",
      "tensor([[855]]) tensor(-142112.7500, grad_fn=<SubBackward0>)\n",
      "loss: 167.2137451171875\n",
      "tensor([[855]]) tensor(-141755.2031, grad_fn=<SubBackward0>)\n",
      "loss: 166.79556274414062\n",
      "tensor([[855]]) tensor(-141396.9375, grad_fn=<SubBackward0>)\n",
      "loss: 166.3765411376953\n",
      "tensor([[855]]) tensor(-141038.0469, grad_fn=<SubBackward0>)\n",
      "loss: 165.956787109375\n",
      "tensor([[855]]) tensor(-140687.5938, grad_fn=<SubBackward0>)\n",
      "loss: 165.54689025878906\n",
      "tensor([[855]]) tensor(-140354.0781, grad_fn=<SubBackward0>)\n",
      "loss: 165.1568145751953\n",
      "tensor([[855]]) tensor(-140017.6875, grad_fn=<SubBackward0>)\n",
      "loss: 164.7633819580078\n",
      "tensor([[855]]) tensor(-139678.5312, grad_fn=<SubBackward0>)\n",
      "loss: 164.36669921875\n",
      "tensor([[855]]) tensor(-139337.1875, grad_fn=<SubBackward0>)\n",
      "loss: 163.96746826171875\n",
      "tensor([[855]]) tensor(-138993.4375, grad_fn=<SubBackward0>)\n",
      "loss: 163.5654296875\n",
      "tensor([[855]]) tensor(-138647.5781, grad_fn=<SubBackward0>)\n",
      "loss: 163.16090393066406\n",
      "tensor([[855]]) tensor(-138299.9688, grad_fn=<SubBackward0>)\n",
      "loss: 162.7543487548828\n",
      "tensor([[855]]) tensor(-137951.3281, grad_fn=<SubBackward0>)\n",
      "loss: 162.34658813476562\n",
      "tensor([[855]]) tensor(-137601.0469, grad_fn=<SubBackward0>)\n",
      "loss: 161.9368896484375\n",
      "tensor([[855]]) tensor(-137252.3281, grad_fn=<SubBackward0>)\n",
      "loss: 161.52903747558594\n",
      "tensor([[855]]) tensor(-136906.2188, grad_fn=<SubBackward0>)\n",
      "loss: 161.12423706054688\n",
      "tensor([[855]]) tensor(-136559.3750, grad_fn=<SubBackward0>)\n",
      "loss: 160.71856689453125\n",
      "tensor([[855]]) tensor(-136210.3125, grad_fn=<SubBackward0>)\n",
      "loss: 160.310302734375\n",
      "tensor([[855]]) tensor(-135857.8125, grad_fn=<SubBackward0>)\n",
      "loss: 159.8980255126953\n",
      "tensor([[855]]) tensor(-135504.2969, grad_fn=<SubBackward0>)\n",
      "loss: 159.48455810546875\n",
      "tensor([[855]]) tensor(-135150.5625, grad_fn=<SubBackward0>)\n",
      "loss: 159.07083129882812\n",
      "tensor([[855]]) tensor(-134796.1719, grad_fn=<SubBackward0>)\n",
      "loss: 158.65634155273438\n",
      "tensor([[855]]) tensor(-134440.7969, grad_fn=<SubBackward0>)\n",
      "loss: 158.24069213867188\n",
      "tensor([[855]]) tensor(-134086.2344, grad_fn=<SubBackward0>)\n",
      "loss: 157.8260040283203\n",
      "tensor([[855]]) tensor(-133770.6406, grad_fn=<SubBackward0>)\n",
      "loss: 157.45689392089844\n",
      "tensor([[855]]) tensor(-133475.8125, grad_fn=<SubBackward0>)\n",
      "loss: 157.112060546875\n",
      "tensor([[855]]) tensor(-133182.2656, grad_fn=<SubBackward0>)\n",
      "loss: 156.76873779296875\n",
      "tensor([[855]]) tensor(-132887.3750, grad_fn=<SubBackward0>)\n",
      "loss: 156.423828125\n",
      "tensor([[855]]) tensor(-132592.8438, grad_fn=<SubBackward0>)\n",
      "loss: 156.079345703125\n",
      "tensor([[855]]) tensor(-132299.4375, grad_fn=<SubBackward0>)\n",
      "loss: 155.73619079589844\n",
      "tensor([[855]]) tensor(-132006.2188, grad_fn=<SubBackward0>)\n",
      "loss: 155.3932342529297\n",
      "tensor([[855]]) tensor(-131714.0625, grad_fn=<SubBackward0>)\n",
      "loss: 155.05152893066406\n",
      "tensor([[855]]) tensor(-131421.9531, grad_fn=<SubBackward0>)\n",
      "loss: 154.7098846435547\n",
      "tensor([[855]]) tensor(-131130.5938, grad_fn=<SubBackward0>)\n",
      "loss: 154.36911010742188\n",
      "tensor([[855]]) tensor(-130841.7188, grad_fn=<SubBackward0>)\n",
      "loss: 154.03125\n",
      "tensor([[855]]) tensor(-130554.1875, grad_fn=<SubBackward0>)\n",
      "loss: 153.69496154785156\n",
      "tensor([[855]]) tensor(-130266.8203, grad_fn=<SubBackward0>)\n",
      "loss: 153.35885620117188\n",
      "tensor([[855]]) tensor(-129979.8359, grad_fn=<SubBackward0>)\n",
      "loss: 153.023193359375\n",
      "tensor([[855]]) tensor(-129693.5469, grad_fn=<SubBackward0>)\n",
      "loss: 152.6883544921875\n",
      "tensor([[855]]) tensor(-129406.2031, grad_fn=<SubBackward0>)\n",
      "loss: 152.35227966308594\n",
      "tensor([[855]]) tensor(-129117.8750, grad_fn=<SubBackward0>)\n",
      "loss: 152.0150604248047\n",
      "tensor([[855]]) tensor(-128828.2188, grad_fn=<SubBackward0>)\n",
      "loss: 151.67628479003906\n",
      "tensor([[855]]) tensor(-128558.6875, grad_fn=<SubBackward0>)\n",
      "loss: 151.3610382080078\n",
      "tensor([[855]]) tensor(-128305.9688, grad_fn=<SubBackward0>)\n",
      "loss: 151.06546020507812\n",
      "tensor([[855]]) tensor(-128056.7500, grad_fn=<SubBackward0>)\n",
      "loss: 150.7739715576172\n",
      "tensor([[855]]) tensor(-127808.1719, grad_fn=<SubBackward0>)\n",
      "loss: 150.48324584960938\n",
      "tensor([[855]]) tensor(-127560.7031, grad_fn=<SubBackward0>)\n",
      "loss: 150.1938018798828\n",
      "tensor([[855]]) tensor(-127312.6406, grad_fn=<SubBackward0>)\n",
      "loss: 149.90367126464844\n",
      "tensor([[855]]) tensor(-127069.1406, grad_fn=<SubBackward0>)\n",
      "loss: 149.61888122558594\n",
      "tensor([[855]]) tensor(-126827.6016, grad_fn=<SubBackward0>)\n",
      "loss: 149.3363800048828\n",
      "tensor([[855]]) tensor(-126603.6250, grad_fn=<SubBackward0>)\n",
      "loss: 149.0744171142578\n",
      "tensor([[855]]) tensor(-126385.4375, grad_fn=<SubBackward0>)\n",
      "loss: 148.81922912597656\n",
      "tensor([[855]]) tensor(-126166.1641, grad_fn=<SubBackward0>)\n",
      "loss: 148.56275939941406\n",
      "tensor([[855]]) tensor(-125945.5859, grad_fn=<SubBackward0>)\n",
      "loss: 148.30477905273438\n",
      "tensor([[855]]) tensor(-125728.3750, grad_fn=<SubBackward0>)\n",
      "loss: 148.0507354736328\n",
      "tensor([[855]]) tensor(-125510.8047, grad_fn=<SubBackward0>)\n",
      "loss: 147.7962646484375\n",
      "tensor([[855]]) tensor(-125292.6328, grad_fn=<SubBackward0>)\n",
      "loss: 147.5410919189453\n",
      "tensor([[855]]) tensor(-125074.1875, grad_fn=<SubBackward0>)\n",
      "loss: 147.2855987548828\n",
      "tensor([[855]]) tensor(-124855.1641, grad_fn=<SubBackward0>)\n",
      "loss: 147.02943420410156\n",
      "tensor([[855]]) tensor(-124636.7031, grad_fn=<SubBackward0>)\n",
      "loss: 146.77392578125\n",
      "tensor([[855]]) tensor(-124417.8281, grad_fn=<SubBackward0>)\n",
      "loss: 146.51792907714844\n",
      "tensor([[855]]) tensor(-124199.1016, grad_fn=<SubBackward0>)\n",
      "loss: 146.26210021972656\n",
      "tensor([[855]]) tensor(-123981.1953, grad_fn=<SubBackward0>)\n",
      "loss: 146.0072479248047\n",
      "tensor([[855]]) tensor(-123762.5156, grad_fn=<SubBackward0>)\n",
      "loss: 145.75148010253906\n",
      "tensor([[855]]) tensor(-123543.1250, grad_fn=<SubBackward0>)\n",
      "loss: 145.49488830566406\n",
      "tensor([[855]]) tensor(-123331.9062, grad_fn=<SubBackward0>)\n",
      "loss: 145.2478485107422\n",
      "tensor([[855]]) tensor(-123126.5312, grad_fn=<SubBackward0>)\n",
      "loss: 145.0076446533203\n",
      "tensor([[855]]) tensor(-122922.7812, grad_fn=<SubBackward0>)\n",
      "loss: 144.7693328857422\n",
      "tensor([[855]]) tensor(-122720.7344, grad_fn=<SubBackward0>)\n",
      "loss: 144.53302001953125\n",
      "tensor([[855]]) tensor(-122518.3828, grad_fn=<SubBackward0>)\n",
      "loss: 144.29635620117188\n",
      "tensor([[855]]) tensor(-122315.4297, grad_fn=<SubBackward0>)\n",
      "loss: 144.05897521972656\n",
      "tensor([[855]]) tensor(-122111.5469, grad_fn=<SubBackward0>)\n",
      "loss: 143.82052612304688\n",
      "tensor([[855]]) tensor(-121908.9531, grad_fn=<SubBackward0>)\n",
      "loss: 143.5835723876953\n",
      "tensor([[855]]) tensor(-121707.4375, grad_fn=<SubBackward0>)\n",
      "loss: 143.34788513183594\n",
      "tensor([[855]]) tensor(-121507.0234, grad_fn=<SubBackward0>)\n",
      "loss: 143.1134796142578\n",
      "tensor([[855]]) tensor(-121306.5859, grad_fn=<SubBackward0>)\n",
      "loss: 142.87904357910156\n",
      "tensor([[855]]) tensor(-121106.1953, grad_fn=<SubBackward0>)\n",
      "loss: 142.64466857910156\n",
      "tensor([[855]]) tensor(-120905.8438, grad_fn=<SubBackward0>)\n",
      "loss: 142.41033935546875\n",
      "tensor([[855]]) tensor(-120712.4062, grad_fn=<SubBackward0>)\n",
      "loss: 142.18409729003906\n",
      "tensor([[855]]) tensor(-120521.0938, grad_fn=<SubBackward0>)\n",
      "loss: 141.96034240722656\n",
      "tensor([[855]]) tensor(-120329.1484, grad_fn=<SubBackward0>)\n",
      "loss: 141.73583984375\n",
      "tensor([[855]]) tensor(-120136.1250, grad_fn=<SubBackward0>)\n",
      "loss: 141.5100860595703\n",
      "tensor([[855]]) tensor(-119967.6406, grad_fn=<SubBackward0>)\n",
      "loss: 141.3130340576172\n",
      "tensor([[855]]) tensor(-119805.9609, grad_fn=<SubBackward0>)\n",
      "loss: 141.12393188476562\n",
      "tensor([[855]]) tensor(-119642.3438, grad_fn=<SubBackward0>)\n",
      "loss: 140.9325714111328\n",
      "tensor([[855]]) tensor(-119474.8125, grad_fn=<SubBackward0>)\n",
      "loss: 140.7366180419922\n",
      "tensor([[855]]) tensor(-119304.8750, grad_fn=<SubBackward0>)\n",
      "loss: 140.53787231445312\n",
      "tensor([[855]]) tensor(-119132.7812, grad_fn=<SubBackward0>)\n",
      "loss: 140.3365936279297\n",
      "tensor([[855]]) tensor(-118959.9766, grad_fn=<SubBackward0>)\n",
      "loss: 140.1344757080078\n",
      "tensor([[855]]) tensor(-118784.9141, grad_fn=<SubBackward0>)\n",
      "loss: 139.92971801757812\n",
      "tensor([[855]]) tensor(-118608.5547, grad_fn=<SubBackward0>)\n",
      "loss: 139.72344970703125\n",
      "tensor([[855]]) tensor(-118431.0703, grad_fn=<SubBackward0>)\n",
      "loss: 139.515869140625\n",
      "tensor([[855]]) tensor(-118263.3516, grad_fn=<SubBackward0>)\n",
      "loss: 139.3197021484375\n",
      "tensor([[855]]) tensor(-118091.9922, grad_fn=<SubBackward0>)\n",
      "loss: 139.11929321289062\n",
      "tensor([[855]]) tensor(-117922.9219, grad_fn=<SubBackward0>)\n",
      "loss: 138.92153930664062\n",
      "tensor([[855]]) tensor(-117751.9688, grad_fn=<SubBackward0>)\n",
      "loss: 138.7216033935547\n",
      "tensor([[855]]) tensor(-117578.6094, grad_fn=<SubBackward0>)\n",
      "loss: 138.5188446044922\n",
      "tensor([[855]]) tensor(-117404.1172, grad_fn=<SubBackward0>)\n",
      "loss: 138.31475830078125\n",
      "tensor([[855]]) tensor(-117236.2109, grad_fn=<SubBackward0>)\n",
      "loss: 138.11837768554688\n",
      "tensor([[855]]) tensor(-117065.1641, grad_fn=<SubBackward0>)\n",
      "loss: 137.91831970214844\n",
      "tensor([[855]]) tensor(-116889.8750, grad_fn=<SubBackward0>)\n",
      "loss: 137.7133026123047\n",
      "tensor([[855]]) tensor(-116714.5547, grad_fn=<SubBackward0>)\n",
      "loss: 137.5082550048828\n",
      "tensor([[855]]) tensor(-116548.0859, grad_fn=<SubBackward0>)\n",
      "loss: 137.3135528564453\n",
      "tensor([[855]]) tensor(-116382.9844, grad_fn=<SubBackward0>)\n",
      "loss: 137.12045288085938\n",
      "tensor([[855]]) tensor(-116214.1719, grad_fn=<SubBackward0>)\n",
      "loss: 136.92300415039062\n",
      "tensor([[855]]) tensor(-116041.8828, grad_fn=<SubBackward0>)\n",
      "loss: 136.72149658203125\n",
      "tensor([[855]]) tensor(-115883.2656, grad_fn=<SubBackward0>)\n",
      "loss: 136.53598022460938\n",
      "tensor([[855]]) tensor(-115719.9375, grad_fn=<SubBackward0>)\n",
      "loss: 136.34495544433594\n",
      "tensor([[855]]) tensor(-115551.6562, grad_fn=<SubBackward0>)\n",
      "loss: 136.14813232421875\n",
      "tensor([[855]]) tensor(-115380.0469, grad_fn=<SubBackward0>)\n",
      "loss: 135.94741821289062\n",
      "tensor([[855]]) tensor(-115213.7578, grad_fn=<SubBackward0>)\n",
      "loss: 135.7529296875\n",
      "tensor([[855]]) tensor(-115049.6250, grad_fn=<SubBackward0>)\n",
      "loss: 135.5609588623047\n",
      "tensor([[855]]) tensor(-114880.2188, grad_fn=<SubBackward0>)\n",
      "loss: 135.36282348632812\n",
      "tensor([[855]]) tensor(-114710.0312, grad_fn=<SubBackward0>)\n",
      "loss: 135.1637725830078\n",
      "tensor([[855]]) tensor(-114540.6250, grad_fn=<SubBackward0>)\n",
      "loss: 134.96563720703125\n",
      "tensor([[855]]) tensor(-114373.5000, grad_fn=<SubBackward0>)\n",
      "loss: 134.77017211914062\n",
      "tensor([[855]]) tensor(-114207.6875, grad_fn=<SubBackward0>)\n",
      "loss: 134.5762481689453\n",
      "tensor([[855]]) tensor(-114044.4453, grad_fn=<SubBackward0>)\n",
      "loss: 134.38531494140625\n",
      "tensor([[855]]) tensor(-113877.4922, grad_fn=<SubBackward0>)\n",
      "loss: 134.19004821777344\n",
      "tensor([[855]]) tensor(-113707.3906, grad_fn=<SubBackward0>)\n",
      "loss: 133.99110412597656\n",
      "tensor([[855]]) tensor(-113542.7266, grad_fn=<SubBackward0>)\n",
      "loss: 133.7985076904297\n",
      "tensor([[855]]) tensor(-113385.9531, grad_fn=<SubBackward0>)\n",
      "loss: 133.61514282226562\n",
      "tensor([[855]]) tensor(-113227.1250, grad_fn=<SubBackward0>)\n",
      "loss: 133.42938232421875\n",
      "tensor([[855]]) tensor(-113064.4609, grad_fn=<SubBackward0>)\n",
      "loss: 133.2391357421875\n",
      "tensor([[855]]) tensor(-112900.8984, grad_fn=<SubBackward0>)\n",
      "loss: 133.04783630371094\n",
      "tensor([[855]]) tensor(-112741.1250, grad_fn=<SubBackward0>)\n",
      "loss: 132.8609619140625\n",
      "tensor([[855]]) tensor(-112580.2656, grad_fn=<SubBackward0>)\n",
      "loss: 132.67282104492188\n",
      "tensor([[855]]) tensor(-112416.7344, grad_fn=<SubBackward0>)\n",
      "loss: 132.4815673828125\n",
      "tensor([[855]]) tensor(-112255.4375, grad_fn=<SubBackward0>)\n",
      "loss: 132.29290771484375\n",
      "tensor([[855]]) tensor(-112092.5859, grad_fn=<SubBackward0>)\n",
      "loss: 132.10243225097656\n",
      "tensor([[855]]) tensor(-111930.3438, grad_fn=<SubBackward0>)\n",
      "loss: 131.91268920898438\n",
      "tensor([[855]]) tensor(-111768.3750, grad_fn=<SubBackward0>)\n",
      "loss: 131.72325134277344\n",
      "tensor([[855]]) tensor(-111606.5078, grad_fn=<SubBackward0>)\n",
      "loss: 131.53392028808594\n",
      "tensor([[855]]) tensor(-111444.2656, grad_fn=<SubBackward0>)\n",
      "loss: 131.34417724609375\n",
      "tensor([[855]]) tensor(-111283.8438, grad_fn=<SubBackward0>)\n",
      "loss: 131.1565399169922\n",
      "tensor([[855]]) tensor(-111121.8906, grad_fn=<SubBackward0>)\n",
      "loss: 130.9671173095703\n",
      "tensor([[855]]) tensor(-110960.5391, grad_fn=<SubBackward0>)\n",
      "loss: 130.77841186523438\n",
      "tensor([[855]]) tensor(-110800.4609, grad_fn=<SubBackward0>)\n",
      "loss: 130.5911865234375\n",
      "tensor([[855]]) tensor(-110640.1562, grad_fn=<SubBackward0>)\n",
      "loss: 130.4036865234375\n",
      "tensor([[855]]) tensor(-110481.3359, grad_fn=<SubBackward0>)\n",
      "loss: 130.2179412841797\n",
      "tensor([[855]]) tensor(-110323.7734, grad_fn=<SubBackward0>)\n",
      "loss: 130.0336456298828\n",
      "tensor([[855]]) tensor(-110164.7656, grad_fn=<SubBackward0>)\n",
      "loss: 129.84767150878906\n",
      "tensor([[855]]) tensor(-110005.5156, grad_fn=<SubBackward0>)\n",
      "loss: 129.6614227294922\n",
      "tensor([[855]]) tensor(-109846.7266, grad_fn=<SubBackward0>)\n",
      "loss: 129.4757080078125\n",
      "tensor([[855]]) tensor(-109684.6562, grad_fn=<SubBackward0>)\n",
      "loss: 129.28614807128906\n",
      "tensor([[855]]) tensor(-109522.0781, grad_fn=<SubBackward0>)\n",
      "loss: 129.0959930419922\n",
      "tensor([[855]]) tensor(-109362.8516, grad_fn=<SubBackward0>)\n",
      "loss: 128.90977478027344\n",
      "tensor([[855]]) tensor(-109202.8672, grad_fn=<SubBackward0>)\n",
      "loss: 128.72265625\n",
      "tensor([[855]]) tensor(-109042.4375, grad_fn=<SubBackward0>)\n",
      "loss: 128.53501892089844\n",
      "tensor([[855]]) tensor(-108882.5469, grad_fn=<SubBackward0>)\n",
      "loss: 128.34800720214844\n",
      "tensor([[855]]) tensor(-108720.7578, grad_fn=<SubBackward0>)\n",
      "loss: 128.15878295898438\n",
      "tensor([[855]]) tensor(-108559.4062, grad_fn=<SubBackward0>)\n",
      "loss: 127.97006225585938\n",
      "tensor([[855]]) tensor(-108398.5312, grad_fn=<SubBackward0>)\n",
      "loss: 127.78190612792969\n",
      "tensor([[855]]) tensor(-108236.2578, grad_fn=<SubBackward0>)\n",
      "loss: 127.59211730957031\n",
      "tensor([[855]]) tensor(-108072.8594, grad_fn=<SubBackward0>)\n",
      "loss: 127.40100860595703\n",
      "tensor([[855]]) tensor(-107909.8828, grad_fn=<SubBackward0>)\n",
      "loss: 127.21038818359375\n",
      "tensor([[855]]) tensor(-107747.1094, grad_fn=<SubBackward0>)\n",
      "loss: 127.02001190185547\n",
      "tensor([[855]]) tensor(-107584.2500, grad_fn=<SubBackward0>)\n",
      "loss: 126.82952880859375\n",
      "tensor([[855]]) tensor(-107417.5312, grad_fn=<SubBackward0>)\n",
      "loss: 126.63453674316406\n",
      "tensor([[855]]) tensor(-107248.6406, grad_fn=<SubBackward0>)\n",
      "loss: 126.43700408935547\n",
      "tensor([[855]]) tensor(-107082.2109, grad_fn=<SubBackward0>)\n",
      "loss: 126.24235534667969\n",
      "tensor([[855]]) tensor(-106914.3750, grad_fn=<SubBackward0>)\n",
      "loss: 126.04605102539062\n",
      "tensor([[855]]) tensor(-106746.8906, grad_fn=<SubBackward0>)\n",
      "loss: 125.85016632080078\n",
      "tensor([[855]]) tensor(-106576.7734, grad_fn=<SubBackward0>)\n",
      "loss: 125.65119934082031\n",
      "tensor([[855]]) tensor(-106407.2344, grad_fn=<SubBackward0>)\n",
      "loss: 125.4529037475586\n",
      "tensor([[855]]) tensor(-106234.9922, grad_fn=<SubBackward0>)\n",
      "loss: 125.25144958496094\n",
      "tensor([[855]]) tensor(-106066.7500, grad_fn=<SubBackward0>)\n",
      "loss: 125.05467987060547\n",
      "tensor([[855]]) tensor(-105894.0703, grad_fn=<SubBackward0>)\n",
      "loss: 124.85271453857422\n",
      "tensor([[855]]) tensor(-105723.0234, grad_fn=<SubBackward0>)\n",
      "loss: 124.65265655517578\n",
      "tensor([[855]]) tensor(-105551.3281, grad_fn=<SubBackward0>)\n",
      "loss: 124.45184326171875\n",
      "tensor([[855]]) tensor(-105378.0781, grad_fn=<SubBackward0>)\n",
      "loss: 124.24921417236328\n",
      "tensor([[855]]) tensor(-105207.0312, grad_fn=<SubBackward0>)\n",
      "loss: 124.04915618896484\n",
      "tensor([[855]]) tensor(-105033.2344, grad_fn=<SubBackward0>)\n",
      "loss: 123.84588623046875\n",
      "tensor([[855]]) tensor(-104859.3750, grad_fn=<SubBackward0>)\n",
      "loss: 123.64254760742188\n",
      "tensor([[855]]) tensor(-104687.1172, grad_fn=<SubBackward0>)\n",
      "loss: 123.44107055664062\n",
      "tensor([[855]]) tensor(-104516.0859, grad_fn=<SubBackward0>)\n",
      "loss: 123.24103546142578\n",
      "tensor([[855]]) tensor(-104341.0781, grad_fn=<SubBackward0>)\n",
      "loss: 123.03634643554688\n",
      "tensor([[855]]) tensor(-104170.9531, grad_fn=<SubBackward0>)\n",
      "loss: 122.83737182617188\n",
      "tensor([[855]]) tensor(-103995.1797, grad_fn=<SubBackward0>)\n",
      "loss: 122.63179016113281\n",
      "tensor([[855]]) tensor(-103820.9609, grad_fn=<SubBackward0>)\n",
      "loss: 122.42802429199219\n",
      "tensor([[855]]) tensor(-103647.3906, grad_fn=<SubBackward0>)\n",
      "loss: 122.22502136230469\n",
      "tensor([[855]]) tensor(-103475.2031, grad_fn=<SubBackward0>)\n",
      "loss: 122.02362823486328\n",
      "tensor([[855]]) tensor(-103303.3750, grad_fn=<SubBackward0>)\n",
      "loss: 121.82266235351562\n",
      "tensor([[855]]) tensor(-103130.8203, grad_fn=<SubBackward0>)\n",
      "loss: 121.62084197998047\n",
      "tensor([[855]]) tensor(-102955.3750, grad_fn=<SubBackward0>)\n",
      "loss: 121.41564178466797\n",
      "tensor([[855]]) tensor(-102781.7500, grad_fn=<SubBackward0>)\n",
      "loss: 121.21257019042969\n",
      "tensor([[855]]) tensor(-102607.6094, grad_fn=<SubBackward0>)\n",
      "loss: 121.00890350341797\n",
      "tensor([[855]]) tensor(-102437.8359, grad_fn=<SubBackward0>)\n",
      "loss: 120.81033325195312\n",
      "tensor([[855]]) tensor(-102264.3438, grad_fn=<SubBackward0>)\n",
      "loss: 120.607421875\n",
      "tensor([[855]]) tensor(-102089.6094, grad_fn=<SubBackward0>)\n",
      "loss: 120.4030532836914\n",
      "tensor([[855]]) tensor(-101917.1250, grad_fn=<SubBackward0>)\n",
      "loss: 120.2013168334961\n",
      "tensor([[855]]) tensor(-101741.1562, grad_fn=<SubBackward0>)\n",
      "loss: 119.9955062866211\n",
      "tensor([[855]]) tensor(-101571.0625, grad_fn=<SubBackward0>)\n",
      "loss: 119.79656219482422\n",
      "tensor([[855]]) tensor(-101397.3516, grad_fn=<SubBackward0>)\n",
      "loss: 119.59339141845703\n",
      "tensor([[855]]) tensor(-101224.2812, grad_fn=<SubBackward0>)\n",
      "loss: 119.39097595214844\n",
      "tensor([[855]]) tensor(-101054.2969, grad_fn=<SubBackward0>)\n",
      "loss: 119.1921615600586\n",
      "tensor([[855]]) tensor(-100882.8594, grad_fn=<SubBackward0>)\n",
      "loss: 118.99164581298828\n",
      "tensor([[855]]) tensor(-100707.8125, grad_fn=<SubBackward0>)\n",
      "loss: 118.78691864013672\n",
      "tensor([[855]]) tensor(-100534.6797, grad_fn=<SubBackward0>)\n",
      "loss: 118.58441925048828\n",
      "tensor([[855]]) tensor(-100366.2188, grad_fn=<SubBackward0>)\n",
      "loss: 118.38739013671875\n",
      "tensor([[855]]) tensor(-100200.6328, grad_fn=<SubBackward0>)\n",
      "loss: 118.1937255859375\n",
      "tensor([[855]]) tensor(-100036.1016, grad_fn=<SubBackward0>)\n",
      "loss: 118.00128936767578\n",
      "tensor([[855]]) tensor(-99873.5781, grad_fn=<SubBackward0>)\n",
      "loss: 117.81120300292969\n",
      "tensor([[855]]) tensor(-99711.1875, grad_fn=<SubBackward0>)\n",
      "loss: 117.62126922607422\n",
      "tensor([[855]]) tensor(-99552.1641, grad_fn=<SubBackward0>)\n",
      "loss: 117.4352798461914\n",
      "tensor([[855]]) tensor(-99391.2969, grad_fn=<SubBackward0>)\n",
      "loss: 117.24713134765625\n",
      "tensor([[855]]) tensor(-99228.5547, grad_fn=<SubBackward0>)\n",
      "loss: 117.0567855834961\n",
      "tensor([[855]]) tensor(-99069.5078, grad_fn=<SubBackward0>)\n",
      "loss: 116.87076568603516\n",
      "tensor([[855]]) tensor(-98908.5938, grad_fn=<SubBackward0>)\n",
      "loss: 116.68256378173828\n",
      "tensor([[855]]) tensor(-98744.6562, grad_fn=<SubBackward0>)\n",
      "loss: 116.49082946777344\n",
      "tensor([[855]]) tensor(-98585.3047, grad_fn=<SubBackward0>)\n",
      "loss: 116.30445098876953\n",
      "tensor([[855]]) tensor(-98425.1406, grad_fn=<SubBackward0>)\n",
      "loss: 116.11712646484375\n",
      "tensor([[855]]) tensor(-98265.0312, grad_fn=<SubBackward0>)\n",
      "loss: 115.92986297607422\n",
      "tensor([[855]]) tensor(-98104.0234, grad_fn=<SubBackward0>)\n",
      "loss: 115.74154663085938\n",
      "tensor([[855]]) tensor(-97948.0938, grad_fn=<SubBackward0>)\n",
      "loss: 115.55917358398438\n",
      "tensor([[855]]) tensor(-97787.0469, grad_fn=<SubBackward0>)\n",
      "loss: 115.37081146240234\n",
      "tensor([[855]]) tensor(-97623.0391, grad_fn=<SubBackward0>)\n",
      "loss: 115.17899322509766\n",
      "tensor([[855]]) tensor(-97466.0234, grad_fn=<SubBackward0>)\n",
      "loss: 114.99534606933594\n",
      "tensor([[855]]) tensor(-97309.7891, grad_fn=<SubBackward0>)\n",
      "loss: 114.8126220703125\n",
      "tensor([[855]]) tensor(-97150.8516, grad_fn=<SubBackward0>)\n",
      "loss: 114.62672424316406\n",
      "tensor([[855]]) tensor(-96992.2344, grad_fn=<SubBackward0>)\n",
      "loss: 114.44120788574219\n",
      "tensor([[855]]) tensor(-96835.3047, grad_fn=<SubBackward0>)\n",
      "loss: 114.2576675415039\n",
      "tensor([[855]]) tensor(-96675.2812, grad_fn=<SubBackward0>)\n",
      "loss: 114.07050323486328\n",
      "tensor([[855]]) tensor(-96516.0312, grad_fn=<SubBackward0>)\n",
      "loss: 113.88424682617188\n",
      "tensor([[855]]) tensor(-96353.6797, grad_fn=<SubBackward0>)\n",
      "loss: 113.6943588256836\n",
      "tensor([[855]]) tensor(-96194.3438, grad_fn=<SubBackward0>)\n",
      "loss: 113.50800323486328\n",
      "tensor([[855]]) tensor(-96032.3750, grad_fn=<SubBackward0>)\n",
      "loss: 113.31856536865234\n",
      "tensor([[855]]) tensor(-95875., grad_fn=<SubBackward0>)\n",
      "loss: 113.13450622558594\n",
      "tensor([[855]]) tensor(-95718.6016, grad_fn=<SubBackward0>)\n",
      "loss: 112.95158386230469\n",
      "tensor([[855]]) tensor(-95559.6406, grad_fn=<SubBackward0>)\n",
      "loss: 112.76566314697266\n",
      "tensor([[855]]) tensor(-95400.4609, grad_fn=<SubBackward0>)\n",
      "loss: 112.57948303222656\n",
      "tensor([[855]]) tensor(-95240.7266, grad_fn=<SubBackward0>)\n",
      "loss: 112.39266204833984\n",
      "tensor([[855]]) tensor(-95086.1719, grad_fn=<SubBackward0>)\n",
      "loss: 112.21189880371094\n",
      "tensor([[855]]) tensor(-94925.5234, grad_fn=<SubBackward0>)\n",
      "loss: 112.02400207519531\n",
      "tensor([[855]]) tensor(-94764.4922, grad_fn=<SubBackward0>)\n",
      "loss: 111.83566284179688\n",
      "tensor([[855]]) tensor(-94608.2266, grad_fn=<SubBackward0>)\n",
      "loss: 111.65289306640625\n",
      "tensor([[855]]) tensor(-94450.5547, grad_fn=<SubBackward0>)\n",
      "loss: 111.4684829711914\n",
      "tensor([[855]]) tensor(-94290.3359, grad_fn=<SubBackward0>)\n",
      "loss: 111.28109741210938\n",
      "tensor([[855]]) tensor(-94127.9375, grad_fn=<SubBackward0>)\n",
      "loss: 111.09115600585938\n",
      "tensor([[855]]) tensor(-93967.2031, grad_fn=<SubBackward0>)\n",
      "loss: 110.90316009521484\n",
      "tensor([[855]]) tensor(-93807.1484, grad_fn=<SubBackward0>)\n",
      "loss: 110.7159652709961\n",
      "tensor([[855]]) tensor(-93645.9219, grad_fn=<SubBackward0>)\n",
      "loss: 110.52739715576172\n",
      "tensor([[855]]) tensor(-93487.4453, grad_fn=<SubBackward0>)\n",
      "loss: 110.342041015625\n",
      "tensor([[855]]) tensor(-93329.3750, grad_fn=<SubBackward0>)\n",
      "loss: 110.15716552734375\n",
      "tensor([[855]]) tensor(-93169.3828, grad_fn=<SubBackward0>)\n",
      "loss: 109.97003936767578\n",
      "tensor([[855]]) tensor(-93006.4219, grad_fn=<SubBackward0>)\n",
      "loss: 109.7794418334961\n",
      "tensor([[855]]) tensor(-92843.7188, grad_fn=<SubBackward0>)\n",
      "loss: 109.58914184570312\n",
      "tensor([[855]]) tensor(-92684.1719, grad_fn=<SubBackward0>)\n",
      "loss: 109.40254211425781\n",
      "tensor([[855]]) tensor(-92523.6562, grad_fn=<SubBackward0>)\n",
      "loss: 109.21480560302734\n",
      "tensor([[855]]) tensor(-92361.2500, grad_fn=<SubBackward0>)\n",
      "loss: 109.02485656738281\n",
      "tensor([[855]]) tensor(-92201.0938, grad_fn=<SubBackward0>)\n",
      "loss: 108.83753967285156\n",
      "tensor([[855]]) tensor(-92040.6328, grad_fn=<SubBackward0>)\n",
      "loss: 108.64986419677734\n",
      "tensor([[855]]) tensor(-91878.4688, grad_fn=<SubBackward0>)\n",
      "loss: 108.46019744873047\n",
      "tensor([[855]]) tensor(-91718.3125, grad_fn=<SubBackward0>)\n",
      "loss: 108.27288055419922\n",
      "tensor([[855]]) tensor(-91561.5781, grad_fn=<SubBackward0>)\n",
      "loss: 108.08956146240234\n",
      "tensor([[855]]) tensor(-91403.8359, grad_fn=<SubBackward0>)\n",
      "loss: 107.90507507324219\n",
      "tensor([[855]]) tensor(-91250.1797, grad_fn=<SubBackward0>)\n",
      "loss: 107.72535705566406\n",
      "tensor([[855]]) tensor(-91092.8750, grad_fn=<SubBackward0>)\n",
      "loss: 107.54137420654297\n",
      "tensor([[855]]) tensor(-90942.1484, grad_fn=<SubBackward0>)\n",
      "loss: 107.3650894165039\n",
      "tensor([[855]]) tensor(-90782.2578, grad_fn=<SubBackward0>)\n",
      "loss: 107.1780776977539\n",
      "tensor([[855]]) tensor(-90622.6328, grad_fn=<SubBackward0>)\n",
      "loss: 106.99138641357422\n",
      "tensor([[855]]) tensor(-90470.7500, grad_fn=<SubBackward0>)\n",
      "loss: 106.8137435913086\n",
      "tensor([[855]]) tensor(-90318.9922, grad_fn=<SubBackward0>)\n",
      "loss: 106.63624572753906\n",
      "tensor([[855]]) tensor(-90166.2422, grad_fn=<SubBackward0>)\n",
      "loss: 106.45759582519531\n",
      "tensor([[855]]) tensor(-90011.7578, grad_fn=<SubBackward0>)\n",
      "loss: 106.27690887451172\n",
      "tensor([[855]]) tensor(-89857.7500, grad_fn=<SubBackward0>)\n",
      "loss: 106.09678649902344\n",
      "tensor([[855]]) tensor(-89698.1094, grad_fn=<SubBackward0>)\n",
      "loss: 105.91007232666016\n",
      "tensor([[855]]) tensor(-89549.2344, grad_fn=<SubBackward0>)\n",
      "loss: 105.73594665527344\n",
      "tensor([[855]]) tensor(-89399.3594, grad_fn=<SubBackward0>)\n",
      "loss: 105.56065368652344\n",
      "tensor([[855]]) tensor(-89239.1094, grad_fn=<SubBackward0>)\n",
      "loss: 105.37322998046875\n",
      "tensor([[855]]) tensor(-89086.6641, grad_fn=<SubBackward0>)\n",
      "loss: 105.19493103027344\n",
      "tensor([[855]]) tensor(-88937.2812, grad_fn=<SubBackward0>)\n",
      "loss: 105.02021026611328\n",
      "tensor([[855]]) tensor(-88780., grad_fn=<SubBackward0>)\n",
      "loss: 104.83625793457031\n",
      "tensor([[855]]) tensor(-88630.7578, grad_fn=<SubBackward0>)\n",
      "loss: 104.66170501708984\n",
      "tensor([[855]]) tensor(-88479.8438, grad_fn=<SubBackward0>)\n",
      "loss: 104.48519897460938\n",
      "tensor([[855]]) tensor(-88322.3984, grad_fn=<SubBackward0>)\n",
      "loss: 104.3010482788086\n",
      "tensor([[855]]) tensor(-88173.3438, grad_fn=<SubBackward0>)\n",
      "loss: 104.12671661376953\n",
      "tensor([[855]]) tensor(-88024.1328, grad_fn=<SubBackward0>)\n",
      "loss: 103.95220184326172\n",
      "tensor([[855]]) tensor(-87868.5938, grad_fn=<SubBackward0>)\n",
      "loss: 103.7702865600586\n",
      "tensor([[855]]) tensor(-87714.6719, grad_fn=<SubBackward0>)\n",
      "loss: 103.59025573730469\n",
      "tensor([[855]]) tensor(-87562.6797, grad_fn=<SubBackward0>)\n",
      "loss: 103.41249084472656\n",
      "tensor([[855]]) tensor(-87408.2422, grad_fn=<SubBackward0>)\n",
      "loss: 103.23186492919922\n",
      "tensor([[855]]) tensor(-87264.0625, grad_fn=<SubBackward0>)\n",
      "loss: 103.063232421875\n",
      "tensor([[855]]) tensor(-87112.9141, grad_fn=<SubBackward0>)\n",
      "loss: 102.8864517211914\n",
      "tensor([[855]]) tensor(-86956.4453, grad_fn=<SubBackward0>)\n",
      "loss: 102.70344543457031\n",
      "tensor([[855]]) tensor(-86800.2500, grad_fn=<SubBackward0>)\n",
      "loss: 102.52075958251953\n",
      "tensor([[855]]) tensor(-86651.6875, grad_fn=<SubBackward0>)\n",
      "loss: 102.34700012207031\n",
      "tensor([[855]]) tensor(-86494.6719, grad_fn=<SubBackward0>)\n",
      "loss: 102.16336059570312\n",
      "tensor([[855]]) tensor(-86348.6797, grad_fn=<SubBackward0>)\n",
      "loss: 101.99260711669922\n",
      "tensor([[855]]) tensor(-86198.3281, grad_fn=<SubBackward0>)\n",
      "loss: 101.81675720214844\n",
      "tensor([[855]]) tensor(-86040.6484, grad_fn=<SubBackward0>)\n",
      "loss: 101.63233947753906\n",
      "tensor([[855]]) tensor(-85890., grad_fn=<SubBackward0>)\n",
      "loss: 101.45613861083984\n",
      "tensor([[855]]) tensor(-85739.8594, grad_fn=<SubBackward0>)\n",
      "loss: 101.2805404663086\n",
      "tensor([[855]]) tensor(-85581.9297, grad_fn=<SubBackward0>)\n",
      "loss: 101.0958251953125\n",
      "tensor([[855]]) tensor(-85430.2969, grad_fn=<SubBackward0>)\n",
      "loss: 100.91847229003906\n",
      "tensor([[855]]) tensor(-85280.1953, grad_fn=<SubBackward0>)\n",
      "loss: 100.742919921875\n",
      "tensor([[855]]) tensor(-85129.3828, grad_fn=<SubBackward0>)\n",
      "loss: 100.5665283203125\n",
      "tensor([[855]]) tensor(-84973.4609, grad_fn=<SubBackward0>)\n",
      "loss: 100.38416290283203\n",
      "tensor([[855]]) tensor(-84821.3750, grad_fn=<SubBackward0>)\n",
      "loss: 100.20628356933594\n",
      "tensor([[855]]) tensor(-84669.5000, grad_fn=<SubBackward0>)\n",
      "loss: 100.02865600585938\n",
      "tensor([[855]]) tensor(-84522.3438, grad_fn=<SubBackward0>)\n",
      "loss: 99.8565444946289\n",
      "tensor([[855]]) tensor(-84370.3125, grad_fn=<SubBackward0>)\n",
      "loss: 99.67872619628906\n",
      "tensor([[855]]) tensor(-84213.0781, grad_fn=<SubBackward0>)\n",
      "loss: 99.49482727050781\n",
      "tensor([[855]]) tensor(-84064.8125, grad_fn=<SubBackward0>)\n",
      "loss: 99.32141876220703\n",
      "tensor([[855]]) tensor(-83910.7500, grad_fn=<SubBackward0>)\n",
      "loss: 99.14122772216797\n",
      "tensor([[855]]) tensor(-83758.4375, grad_fn=<SubBackward0>)\n",
      "loss: 98.96308135986328\n",
      "tensor([[855]]) tensor(-83607.6250, grad_fn=<SubBackward0>)\n",
      "loss: 98.78669738769531\n",
      "tensor([[855]]) tensor(-83452.6250, grad_fn=<SubBackward0>)\n",
      "loss: 98.60540771484375\n",
      "tensor([[855]]) tensor(-83308.7031, grad_fn=<SubBackward0>)\n",
      "loss: 98.43708038330078\n",
      "tensor([[855]]) tensor(-83156.9766, grad_fn=<SubBackward0>)\n",
      "loss: 98.2596206665039\n",
      "tensor([[855]]) tensor(-83011.2031, grad_fn=<SubBackward0>)\n",
      "loss: 98.08912658691406\n",
      "tensor([[855]]) tensor(-82860.2891, grad_fn=<SubBackward0>)\n",
      "loss: 97.9126205444336\n",
      "tensor([[855]]) tensor(-82718.9219, grad_fn=<SubBackward0>)\n",
      "loss: 97.74727630615234\n",
      "tensor([[855]]) tensor(-82573.4297, grad_fn=<SubBackward0>)\n",
      "loss: 97.57711029052734\n",
      "tensor([[855]]) tensor(-82420.3906, grad_fn=<SubBackward0>)\n",
      "loss: 97.39811706542969\n",
      "tensor([[855]]) tensor(-82276.2578, grad_fn=<SubBackward0>)\n",
      "loss: 97.22953796386719\n",
      "tensor([[855]]) tensor(-82133.0781, grad_fn=<SubBackward0>)\n",
      "loss: 97.06208038330078\n",
      "tensor([[855]]) tensor(-81982.2500, grad_fn=<SubBackward0>)\n",
      "loss: 96.88567352294922\n",
      "tensor([[855]]) tensor(-81829.2031, grad_fn=<SubBackward0>)\n",
      "loss: 96.70667266845703\n",
      "tensor([[855]]) tensor(-81685.9688, grad_fn=<SubBackward0>)\n",
      "loss: 96.53914642333984\n",
      "tensor([[855]]) tensor(-81539.6562, grad_fn=<SubBackward0>)\n",
      "loss: 96.3680191040039\n",
      "tensor([[855]]) tensor(-81388.5391, grad_fn=<SubBackward0>)\n",
      "loss: 96.19127655029297\n",
      "tensor([[855]]) tensor(-81246.6328, grad_fn=<SubBackward0>)\n",
      "loss: 96.02529907226562\n",
      "tensor([[855]]) tensor(-81100.6406, grad_fn=<SubBackward0>)\n",
      "loss: 95.85455322265625\n",
      "tensor([[855]]) tensor(-80954.5312, grad_fn=<SubBackward0>)\n",
      "loss: 95.68366241455078\n",
      "tensor([[855]]) tensor(-80805.1250, grad_fn=<SubBackward0>)\n",
      "loss: 95.50891876220703\n",
      "tensor([[855]]) tensor(-80658.4531, grad_fn=<SubBackward0>)\n",
      "loss: 95.33737182617188\n",
      "tensor([[855]]) tensor(-80511.1875, grad_fn=<SubBackward0>)\n",
      "loss: 95.16513061523438\n",
      "tensor([[855]]) tensor(-80364.6094, grad_fn=<SubBackward0>)\n",
      "loss: 94.99369812011719\n",
      "tensor([[855]]) tensor(-80217.7656, grad_fn=<SubBackward0>)\n",
      "loss: 94.82194519042969\n",
      "tensor([[855]]) tensor(-80069.8594, grad_fn=<SubBackward0>)\n",
      "loss: 94.64895629882812\n",
      "tensor([[855]]) tensor(-79928.1094, grad_fn=<SubBackward0>)\n",
      "loss: 94.48316955566406\n",
      "tensor([[855]]) tensor(-79780.7969, grad_fn=<SubBackward0>)\n",
      "loss: 94.31087493896484\n",
      "tensor([[855]]) tensor(-79629.9531, grad_fn=<SubBackward0>)\n",
      "loss: 94.13444519042969\n",
      "tensor([[855]]) tensor(-79484.9141, grad_fn=<SubBackward0>)\n",
      "loss: 93.96481323242188\n",
      "tensor([[855]]) tensor(-79336.1484, grad_fn=<SubBackward0>)\n",
      "loss: 93.79081726074219\n",
      "tensor([[855]]) tensor(-79187.9297, grad_fn=<SubBackward0>)\n",
      "loss: 93.61746215820312\n",
      "tensor([[855]]) tensor(-79046.0703, grad_fn=<SubBackward0>)\n",
      "loss: 93.45154571533203\n",
      "tensor([[855]]) tensor(-78898.4609, grad_fn=<SubBackward0>)\n",
      "loss: 93.27890014648438\n",
      "tensor([[855]]) tensor(-78746.5469, grad_fn=<SubBackward0>)\n",
      "loss: 93.10122680664062\n",
      "tensor([[855]]) tensor(-78599.6719, grad_fn=<SubBackward0>)\n",
      "loss: 92.929443359375\n",
      "tensor([[855]]) tensor(-78457.7969, grad_fn=<SubBackward0>)\n",
      "loss: 92.76350402832031\n",
      "tensor([[855]]) tensor(-78311.9531, grad_fn=<SubBackward0>)\n",
      "loss: 92.59292602539062\n",
      "tensor([[855]]) tensor(-78161.5312, grad_fn=<SubBackward0>)\n",
      "loss: 92.4169921875\n",
      "tensor([[855]]) tensor(-78017.5000, grad_fn=<SubBackward0>)\n",
      "loss: 92.24853515625\n",
      "tensor([[855]]) tensor(-77867.7188, grad_fn=<SubBackward0>)\n",
      "loss: 92.07335662841797\n",
      "tensor([[855]]) tensor(-77722.7344, grad_fn=<SubBackward0>)\n",
      "loss: 91.9037857055664\n",
      "tensor([[855]]) tensor(-77579.2812, grad_fn=<SubBackward0>)\n",
      "loss: 91.73600006103516\n",
      "tensor([[855]]) tensor(-77430.4688, grad_fn=<SubBackward0>)\n",
      "loss: 91.56195068359375\n",
      "tensor([[855]]) tensor(-77276.4297, grad_fn=<SubBackward0>)\n",
      "loss: 91.38179016113281\n",
      "tensor([[855]]) tensor(-77132.1328, grad_fn=<SubBackward0>)\n",
      "loss: 91.21302032470703\n",
      "tensor([[855]]) tensor(-76983.9062, grad_fn=<SubBackward0>)\n",
      "loss: 91.03965759277344\n",
      "tensor([[855]]) tensor(-76838.5625, grad_fn=<SubBackward0>)\n",
      "loss: 90.86966705322266\n",
      "tensor([[855]]) tensor(-76691.5859, grad_fn=<SubBackward0>)\n",
      "loss: 90.69776153564453\n",
      "tensor([[855]]) tensor(-76544.0859, grad_fn=<SubBackward0>)\n",
      "loss: 90.5252456665039\n",
      "tensor([[855]]) tensor(-76394.0469, grad_fn=<SubBackward0>)\n",
      "loss: 90.34976196289062\n",
      "tensor([[855]]) tensor(-76242.3125, grad_fn=<SubBackward0>)\n",
      "loss: 90.17229461669922\n",
      "tensor([[855]]) tensor(-76104.0859, grad_fn=<SubBackward0>)\n",
      "loss: 90.01062774658203\n",
      "tensor([[855]]) tensor(-75957.4375, grad_fn=<SubBackward0>)\n",
      "loss: 89.839111328125\n",
      "tensor([[855]]) tensor(-75809.5703, grad_fn=<SubBackward0>)\n",
      "loss: 89.6661605834961\n",
      "tensor([[855]]) tensor(-75674.0078, grad_fn=<SubBackward0>)\n",
      "loss: 89.50761413574219\n",
      "tensor([[855]]) tensor(-75538.7891, grad_fn=<SubBackward0>)\n",
      "loss: 89.3494644165039\n",
      "tensor([[855]]) tensor(-75401.2500, grad_fn=<SubBackward0>)\n",
      "loss: 89.1885986328125\n",
      "tensor([[855]]) tensor(-75262.3438, grad_fn=<SubBackward0>)\n",
      "loss: 89.02613067626953\n",
      "tensor([[855]]) tensor(-75122.7812, grad_fn=<SubBackward0>)\n",
      "loss: 88.86289978027344\n",
      "tensor([[855]]) tensor(-74982.2500, grad_fn=<SubBackward0>)\n",
      "loss: 88.69853973388672\n",
      "tensor([[855]]) tensor(-74841.3984, grad_fn=<SubBackward0>)\n",
      "loss: 88.53379821777344\n",
      "tensor([[855]]) tensor(-74703.5312, grad_fn=<SubBackward0>)\n",
      "loss: 88.37255096435547\n",
      "tensor([[855]]) tensor(-74563.1250, grad_fn=<SubBackward0>)\n",
      "loss: 88.20833587646484\n",
      "tensor([[855]]) tensor(-74420.1250, grad_fn=<SubBackward0>)\n",
      "loss: 88.04108428955078\n",
      "tensor([[855]]) tensor(-74282.1250, grad_fn=<SubBackward0>)\n",
      "loss: 87.87967681884766\n",
      "tensor([[855]]) tensor(-74140.9219, grad_fn=<SubBackward0>)\n",
      "loss: 87.71453094482422\n",
      "tensor([[855]]) tensor(-74003.1094, grad_fn=<SubBackward0>)\n",
      "loss: 87.5533447265625\n",
      "tensor([[855]]) tensor(-73863.5547, grad_fn=<SubBackward0>)\n",
      "loss: 87.39012145996094\n",
      "tensor([[855]]) tensor(-73723.1797, grad_fn=<SubBackward0>)\n",
      "loss: 87.22594451904297\n",
      "tensor([[855]]) tensor(-73589.9844, grad_fn=<SubBackward0>)\n",
      "loss: 87.07015991210938\n",
      "tensor([[855]]) tensor(-73450.7656, grad_fn=<SubBackward0>)\n",
      "loss: 86.9073257446289\n",
      "tensor([[855]]) tensor(-73310.9531, grad_fn=<SubBackward0>)\n",
      "loss: 86.74380493164062\n",
      "tensor([[855]]) tensor(-73174.7031, grad_fn=<SubBackward0>)\n",
      "loss: 86.5844497680664\n",
      "tensor([[855]]) tensor(-73034.8359, grad_fn=<SubBackward0>)\n",
      "loss: 86.42086029052734\n",
      "tensor([[855]]) tensor(-72897.1953, grad_fn=<SubBackward0>)\n",
      "loss: 86.25988006591797\n",
      "tensor([[855]]) tensor(-72758.7891, grad_fn=<SubBackward0>)\n",
      "loss: 86.0979995727539\n",
      "tensor([[855]]) tensor(-72623.1406, grad_fn=<SubBackward0>)\n",
      "loss: 85.93934631347656\n",
      "tensor([[855]]) tensor(-72484.0078, grad_fn=<SubBackward0>)\n",
      "loss: 85.77661895751953\n",
      "tensor([[855]]) tensor(-72343.0469, grad_fn=<SubBackward0>)\n",
      "loss: 85.61174774169922\n",
      "tensor([[855]]) tensor(-72208.7109, grad_fn=<SubBackward0>)\n",
      "loss: 85.45463562011719\n",
      "tensor([[855]]) tensor(-72077.0859, grad_fn=<SubBackward0>)\n",
      "loss: 85.3006820678711\n",
      "tensor([[855]]) tensor(-71935.9922, grad_fn=<SubBackward0>)\n",
      "loss: 85.13566589355469\n",
      "tensor([[855]]) tensor(-71795.1250, grad_fn=<SubBackward0>)\n",
      "loss: 84.97090911865234\n",
      "tensor([[855]]) tensor(-71664.4531, grad_fn=<SubBackward0>)\n",
      "loss: 84.81807708740234\n",
      "tensor([[855]]) tensor(-71528.5391, grad_fn=<SubBackward0>)\n",
      "loss: 84.65911102294922\n",
      "tensor([[855]]) tensor(-71386.2500, grad_fn=<SubBackward0>)\n",
      "loss: 84.49269104003906\n",
      "tensor([[855]]) tensor(-71240.6094, grad_fn=<SubBackward0>)\n",
      "loss: 84.32234954833984\n",
      "tensor([[855]]) tensor(-71109.0234, grad_fn=<SubBackward0>)\n",
      "loss: 84.16844940185547\n",
      "tensor([[855]]) tensor(-70966.7188, grad_fn=<SubBackward0>)\n",
      "loss: 84.00200653076172\n",
      "tensor([[855]]) tensor(-70831.0469, grad_fn=<SubBackward0>)\n",
      "loss: 83.84333038330078\n",
      "tensor([[855]]) tensor(-70698.0859, grad_fn=<SubBackward0>)\n",
      "loss: 83.68782043457031\n",
      "tensor([[855]]) tensor(-70558.9297, grad_fn=<SubBackward0>)\n",
      "loss: 83.52506256103516\n",
      "tensor([[855]]) tensor(-70414.4297, grad_fn=<SubBackward0>)\n",
      "loss: 83.3560562133789\n",
      "tensor([[855]]) tensor(-70274.6953, grad_fn=<SubBackward0>)\n",
      "loss: 83.192626953125\n",
      "tensor([[855]]) tensor(-70135.5547, grad_fn=<SubBackward0>)\n",
      "loss: 83.02989196777344\n",
      "tensor([[855]]) tensor(-69999.9219, grad_fn=<SubBackward0>)\n",
      "loss: 82.87125396728516\n",
      "tensor([[855]]) tensor(-69863.4453, grad_fn=<SubBackward0>)\n",
      "loss: 82.71163177490234\n",
      "tensor([[855]]) tensor(-69725.8203, grad_fn=<SubBackward0>)\n",
      "loss: 82.55066680908203\n",
      "tensor([[855]]) tensor(-69589.7344, grad_fn=<SubBackward0>)\n",
      "loss: 82.3915023803711\n",
      "tensor([[855]]) tensor(-69452.1797, grad_fn=<SubBackward0>)\n",
      "loss: 82.23062133789062\n",
      "tensor([[855]]) tensor(-69314.2812, grad_fn=<SubBackward0>)\n",
      "loss: 82.0693359375\n",
      "tensor([[855]]) tensor(-69180.5312, grad_fn=<SubBackward0>)\n",
      "loss: 81.91290283203125\n",
      "tensor([[855]]) tensor(-69041.8828, grad_fn=<SubBackward0>)\n",
      "loss: 81.75074005126953\n",
      "tensor([[855]]) tensor(-68902.4062, grad_fn=<SubBackward0>)\n",
      "loss: 81.58760833740234\n",
      "tensor([[855]]) tensor(-68767.1641, grad_fn=<SubBackward0>)\n",
      "loss: 81.42942810058594\n",
      "tensor([[855]]) tensor(-68628.0625, grad_fn=<SubBackward0>)\n",
      "loss: 81.26673889160156\n",
      "tensor([[855]]) tensor(-68491.2109, grad_fn=<SubBackward0>)\n",
      "loss: 81.10668182373047\n",
      "tensor([[855]]) tensor(-68355.6797, grad_fn=<SubBackward0>)\n",
      "loss: 80.94816589355469\n",
      "tensor([[855]]) tensor(-68215.1719, grad_fn=<SubBackward0>)\n",
      "loss: 80.78382873535156\n",
      "tensor([[855]]) tensor(-68080.7109, grad_fn=<SubBackward0>)\n",
      "loss: 80.6265640258789\n",
      "tensor([[855]]) tensor(-67945.5078, grad_fn=<SubBackward0>)\n",
      "loss: 80.46842956542969\n",
      "tensor([[855]]) tensor(-67808.7266, grad_fn=<SubBackward0>)\n",
      "loss: 80.3084487915039\n",
      "tensor([[855]]) tensor(-67666.2266, grad_fn=<SubBackward0>)\n",
      "loss: 80.14178466796875\n",
      "tensor([[855]]) tensor(-67535.7188, grad_fn=<SubBackward0>)\n",
      "loss: 79.98914337158203\n",
      "tensor([[855]]) tensor(-67400.6875, grad_fn=<SubBackward0>)\n",
      "loss: 79.83121490478516\n",
      "tensor([[855]]) tensor(-67258.7031, grad_fn=<SubBackward0>)\n",
      "loss: 79.66515350341797\n",
      "tensor([[855]]) tensor(-67124.1719, grad_fn=<SubBackward0>)\n",
      "loss: 79.50780487060547\n",
      "tensor([[855]]) tensor(-66984.0391, grad_fn=<SubBackward0>)\n",
      "loss: 79.34390258789062\n",
      "tensor([[855]]) tensor(-66846.8281, grad_fn=<SubBackward0>)\n",
      "loss: 79.18342590332031\n",
      "tensor([[855]]) tensor(-66710.5312, grad_fn=<SubBackward0>)\n",
      "loss: 79.02400970458984\n",
      "tensor([[855]]) tensor(-66571.0938, grad_fn=<SubBackward0>)\n",
      "loss: 78.86093139648438\n",
      "tensor([[855]]) tensor(-66435.9375, grad_fn=<SubBackward0>)\n",
      "loss: 78.70285034179688\n",
      "tensor([[855]]) tensor(-66297.3438, grad_fn=<SubBackward0>)\n",
      "loss: 78.54075622558594\n",
      "tensor([[855]]) tensor(-66158.3984, grad_fn=<SubBackward0>)\n",
      "loss: 78.37824249267578\n",
      "tensor([[855]]) tensor(-66021.4062, grad_fn=<SubBackward0>)\n",
      "loss: 78.218017578125\n",
      "tensor([[855]]) tensor(-65884.7109, grad_fn=<SubBackward0>)\n",
      "loss: 78.05814361572266\n",
      "tensor([[855]]) tensor(-65752.1406, grad_fn=<SubBackward0>)\n",
      "loss: 77.90309143066406\n",
      "tensor([[855]]) tensor(-65624.1797, grad_fn=<SubBackward0>)\n",
      "loss: 77.75342559814453\n",
      "tensor([[855]]) tensor(-65487.9414, grad_fn=<SubBackward0>)\n",
      "loss: 77.59407806396484\n",
      "tensor([[855]]) tensor(-65356.5000, grad_fn=<SubBackward0>)\n",
      "loss: 77.44035339355469\n",
      "tensor([[855]]) tensor(-65222.6758, grad_fn=<SubBackward0>)\n",
      "loss: 77.28382873535156\n",
      "tensor([[855]]) tensor(-65091.7656, grad_fn=<SubBackward0>)\n",
      "loss: 77.13072204589844\n",
      "tensor([[855]]) tensor(-64957.8516, grad_fn=<SubBackward0>)\n",
      "loss: 76.9740982055664\n",
      "tensor([[855]]) tensor(-64825.1953, grad_fn=<SubBackward0>)\n",
      "loss: 76.81893920898438\n",
      "tensor([[855]]) tensor(-64699.3281, grad_fn=<SubBackward0>)\n",
      "loss: 76.6717300415039\n",
      "tensor([[855]]) tensor(-64565.4648, grad_fn=<SubBackward0>)\n",
      "loss: 76.51516723632812\n",
      "tensor([[855]]) tensor(-64432.8555, grad_fn=<SubBackward0>)\n",
      "loss: 76.36006164550781\n",
      "tensor([[855]]) tensor(-64303.1719, grad_fn=<SubBackward0>)\n",
      "loss: 76.20838928222656\n",
      "tensor([[855]]) tensor(-64166.7109, grad_fn=<SubBackward0>)\n",
      "loss: 76.04878234863281\n",
      "tensor([[855]]) tensor(-64045.7383, grad_fn=<SubBackward0>)\n",
      "loss: 75.90729522705078\n",
      "tensor([[855]]) tensor(-63919.9922, grad_fn=<SubBackward0>)\n",
      "loss: 75.76022338867188\n",
      "tensor([[855]]) tensor(-63783.6953, grad_fn=<SubBackward0>)\n",
      "loss: 75.60081481933594\n",
      "tensor([[855]]) tensor(-63656.4141, grad_fn=<SubBackward0>)\n",
      "loss: 75.45195007324219\n",
      "tensor([[855]]) tensor(-63533.9609, grad_fn=<SubBackward0>)\n",
      "loss: 75.30872344970703\n",
      "tensor([[855]]) tensor(-63402.6367, grad_fn=<SubBackward0>)\n",
      "loss: 75.1551284790039\n",
      "tensor([[855]]) tensor(-63271.6680, grad_fn=<SubBackward0>)\n",
      "loss: 75.001953125\n",
      "tensor([[855]]) tensor(-63147.7109, grad_fn=<SubBackward0>)\n",
      "loss: 74.85697174072266\n",
      "tensor([[855]]) tensor(-63023.0586, grad_fn=<SubBackward0>)\n",
      "loss: 74.711181640625\n",
      "tensor([[855]]) tensor(-62890.9922, grad_fn=<SubBackward0>)\n",
      "loss: 74.55671691894531\n",
      "tensor([[855]]) tensor(-62773.3242, grad_fn=<SubBackward0>)\n",
      "loss: 74.4190902709961\n",
      "tensor([[855]]) tensor(-62649.2930, grad_fn=<SubBackward0>)\n",
      "loss: 74.2740249633789\n",
      "tensor([[855]]) tensor(-62519.0078, grad_fn=<SubBackward0>)\n",
      "loss: 74.12164306640625\n",
      "tensor([[855]]) tensor(-62392.3398, grad_fn=<SubBackward0>)\n",
      "loss: 73.97349548339844\n",
      "tensor([[855]]) tensor(-62270.2930, grad_fn=<SubBackward0>)\n",
      "loss: 73.83074951171875\n",
      "tensor([[855]]) tensor(-62140.1406, grad_fn=<SubBackward0>)\n",
      "loss: 73.67852783203125\n",
      "tensor([[855]]) tensor(-62016.0898, grad_fn=<SubBackward0>)\n",
      "loss: 73.53343963623047\n",
      "tensor([[855]]) tensor(-61893.1562, grad_fn=<SubBackward0>)\n",
      "loss: 73.38965606689453\n",
      "tensor([[855]]) tensor(-61766.3281, grad_fn=<SubBackward0>)\n",
      "loss: 73.24131774902344\n",
      "tensor([[855]]) tensor(-61642.3477, grad_fn=<SubBackward0>)\n",
      "loss: 73.0963134765625\n",
      "tensor([[855]]) tensor(-61512.4219, grad_fn=<SubBackward0>)\n",
      "loss: 72.94435119628906\n",
      "tensor([[855]]) tensor(-61386.6953, grad_fn=<SubBackward0>)\n",
      "loss: 72.79730224609375\n",
      "tensor([[855]]) tensor(-61264.6055, grad_fn=<SubBackward0>)\n",
      "loss: 72.65451049804688\n",
      "tensor([[855]]) tensor(-61139.8047, grad_fn=<SubBackward0>)\n",
      "loss: 72.508544921875\n",
      "tensor([[855]]) tensor(-61007.5156, grad_fn=<SubBackward0>)\n",
      "loss: 72.35382080078125\n",
      "tensor([[855]]) tensor(-60886.0859, grad_fn=<SubBackward0>)\n",
      "loss: 72.21179962158203\n",
      "tensor([[855]]) tensor(-60763.1953, grad_fn=<SubBackward0>)\n",
      "loss: 72.06806182861328\n",
      "tensor([[855]]) tensor(-60641.5000, grad_fn=<SubBackward0>)\n",
      "loss: 71.92572784423828\n",
      "tensor([[855]]) tensor(-60517.1133, grad_fn=<SubBackward0>)\n",
      "loss: 71.7802505493164\n",
      "tensor([[855]]) tensor(-60391.3203, grad_fn=<SubBackward0>)\n",
      "loss: 71.63312530517578\n",
      "tensor([[855]]) tensor(-60269.4453, grad_fn=<SubBackward0>)\n",
      "loss: 71.4905776977539\n",
      "tensor([[855]]) tensor(-60150.6836, grad_fn=<SubBackward0>)\n",
      "loss: 71.35167694091797\n",
      "tensor([[855]]) tensor(-60029.0781, grad_fn=<SubBackward0>)\n",
      "loss: 71.2094497680664\n",
      "tensor([[855]]) tensor(-59901.7852, grad_fn=<SubBackward0>)\n",
      "loss: 71.0605697631836\n",
      "tensor([[855]]) tensor(-59778.1094, grad_fn=<SubBackward0>)\n",
      "loss: 70.9159164428711\n",
      "tensor([[855]]) tensor(-59662.4414, grad_fn=<SubBackward0>)\n",
      "loss: 70.78063201904297\n",
      "tensor([[855]]) tensor(-59537.7930, grad_fn=<SubBackward0>)\n",
      "loss: 70.63484191894531\n",
      "tensor([[855]]) tensor(-59414.2734, grad_fn=<SubBackward0>)\n",
      "loss: 70.4903793334961\n",
      "tensor([[855]]) tensor(-59291.1641, grad_fn=<SubBackward0>)\n",
      "loss: 70.34638977050781\n",
      "tensor([[855]]) tensor(-59168.8945, grad_fn=<SubBackward0>)\n",
      "loss: 70.20338439941406\n",
      "tensor([[855]]) tensor(-59046.6914, grad_fn=<SubBackward0>)\n",
      "loss: 70.06045532226562\n",
      "tensor([[855]]) tensor(-58923.5391, grad_fn=<SubBackward0>)\n",
      "loss: 69.91641998291016\n",
      "tensor([[855]]) tensor(-58803.0586, grad_fn=<SubBackward0>)\n",
      "loss: 69.77550506591797\n",
      "tensor([[855]]) tensor(-58683.1836, grad_fn=<SubBackward0>)\n",
      "loss: 69.63529968261719\n",
      "tensor([[855]]) tensor(-58559.7734, grad_fn=<SubBackward0>)\n",
      "loss: 69.490966796875\n",
      "tensor([[855]]) tensor(-58443.2656, grad_fn=<SubBackward0>)\n",
      "loss: 69.35469818115234\n",
      "tensor([[855]]) tensor(-58318.2578, grad_fn=<SubBackward0>)\n",
      "loss: 69.20848846435547\n",
      "tensor([[855]]) tensor(-58196.0469, grad_fn=<SubBackward0>)\n",
      "loss: 69.0655517578125\n",
      "tensor([[855]]) tensor(-58076.5781, grad_fn=<SubBackward0>)\n",
      "loss: 68.92581939697266\n",
      "tensor([[855]]) tensor(-57951.1094, grad_fn=<SubBackward0>)\n",
      "loss: 68.7790756225586\n",
      "tensor([[855]]) tensor(-57829.1914, grad_fn=<SubBackward0>)\n",
      "loss: 68.63648223876953\n",
      "tensor([[855]]) tensor(-57704.2969, grad_fn=<SubBackward0>)\n",
      "loss: 68.49040222167969\n",
      "tensor([[855]]) tensor(-57580.2773, grad_fn=<SubBackward0>)\n",
      "loss: 68.34535217285156\n",
      "tensor([[855]]) tensor(-57457.9531, grad_fn=<SubBackward0>)\n",
      "loss: 68.20228576660156\n",
      "tensor([[855]]) tensor(-57339.6055, grad_fn=<SubBackward0>)\n",
      "loss: 68.0638656616211\n",
      "tensor([[855]]) tensor(-57214.9961, grad_fn=<SubBackward0>)\n",
      "loss: 67.91812133789062\n",
      "tensor([[855]]) tensor(-57092.3516, grad_fn=<SubBackward0>)\n",
      "loss: 67.7746810913086\n",
      "tensor([[855]]) tensor(-56969.3984, grad_fn=<SubBackward0>)\n",
      "loss: 67.63087463378906\n",
      "tensor([[855]]) tensor(-56850.0156, grad_fn=<SubBackward0>)\n",
      "loss: 67.49124908447266\n",
      "tensor([[855]]) tensor(-56727.8359, grad_fn=<SubBackward0>)\n",
      "loss: 67.34834289550781\n",
      "tensor([[855]]) tensor(-56604.3594, grad_fn=<SubBackward0>)\n",
      "loss: 67.20392608642578\n",
      "tensor([[855]]) tensor(-56483.7188, grad_fn=<SubBackward0>)\n",
      "loss: 67.06282806396484\n",
      "tensor([[855]]) tensor(-56363.9805, grad_fn=<SubBackward0>)\n",
      "loss: 66.92278289794922\n",
      "tensor([[855]]) tensor(-56240.1484, grad_fn=<SubBackward0>)\n",
      "loss: 66.7779541015625\n",
      "tensor([[855]]) tensor(-56116.3750, grad_fn=<SubBackward0>)\n",
      "loss: 66.63318634033203\n",
      "tensor([[855]]) tensor(-55999.2500, grad_fn=<SubBackward0>)\n",
      "loss: 66.49620056152344\n",
      "tensor([[855]]) tensor(-55877.1094, grad_fn=<SubBackward0>)\n",
      "loss: 66.35334777832031\n",
      "tensor([[855]]) tensor(-55754.3828, grad_fn=<SubBackward0>)\n",
      "loss: 66.20980072021484\n",
      "tensor([[855]]) tensor(-55632.2344, grad_fn=<SubBackward0>)\n",
      "loss: 66.06694030761719\n",
      "tensor([[855]]) tensor(-55511.2773, grad_fn=<SubBackward0>)\n",
      "loss: 65.92546844482422\n",
      "tensor([[855]]) tensor(-55396.2188, grad_fn=<SubBackward0>)\n",
      "loss: 65.79090118408203\n",
      "tensor([[855]]) tensor(-55275.1562, grad_fn=<SubBackward0>)\n",
      "loss: 65.64930725097656\n",
      "tensor([[855]]) tensor(-55150.0312, grad_fn=<SubBackward0>)\n",
      "loss: 65.50296020507812\n",
      "tensor([[855]]) tensor(-55024.8086, grad_fn=<SubBackward0>)\n",
      "loss: 65.35649871826172\n",
      "tensor([[855]]) tensor(-54913.3359, grad_fn=<SubBackward0>)\n",
      "loss: 65.22612762451172\n",
      "tensor([[855]]) tensor(-54787.1875, grad_fn=<SubBackward0>)\n",
      "loss: 65.07858276367188\n",
      "tensor([[855]]) tensor(-54657.0234, grad_fn=<SubBackward0>)\n",
      "loss: 64.92634582519531\n",
      "tensor([[855]]) tensor(-54542.7500, grad_fn=<SubBackward0>)\n",
      "loss: 64.79268646240234\n",
      "tensor([[855]]) tensor(-54419.2422, grad_fn=<SubBackward0>)\n",
      "loss: 64.64823913574219\n",
      "tensor([[855]]) tensor(-54301.5625, grad_fn=<SubBackward0>)\n",
      "loss: 64.5105972290039\n",
      "tensor([[855]]) tensor(-54177.4492, grad_fn=<SubBackward0>)\n",
      "loss: 64.36544036865234\n",
      "tensor([[855]]) tensor(-54056.1484, grad_fn=<SubBackward0>)\n",
      "loss: 64.22356414794922\n",
      "tensor([[855]]) tensor(-53938.4414, grad_fn=<SubBackward0>)\n",
      "loss: 64.08589935302734\n",
      "tensor([[855]]) tensor(-53816.3906, grad_fn=<SubBackward0>)\n",
      "loss: 63.943145751953125\n",
      "tensor([[855]]) tensor(-53689.0859, grad_fn=<SubBackward0>)\n",
      "loss: 63.794254302978516\n",
      "tensor([[855]]) tensor(-53567.9688, grad_fn=<SubBackward0>)\n",
      "loss: 63.65259552001953\n",
      "tensor([[855]]) tensor(-53458.0469, grad_fn=<SubBackward0>)\n",
      "loss: 63.52403259277344\n",
      "tensor([[855]]) tensor(-53333.4766, grad_fn=<SubBackward0>)\n",
      "loss: 63.378334045410156\n",
      "tensor([[855]]) tensor(-53206.6484, grad_fn=<SubBackward0>)\n",
      "loss: 63.22999954223633\n",
      "tensor([[855]]) tensor(-53092.6055, grad_fn=<SubBackward0>)\n",
      "loss: 63.096614837646484\n",
      "tensor([[855]]) tensor(-52977.9922, grad_fn=<SubBackward0>)\n",
      "loss: 62.962562561035156\n",
      "tensor([[855]]) tensor(-52848.8867, grad_fn=<SubBackward0>)\n",
      "loss: 62.811561584472656\n",
      "tensor([[855]]) tensor(-52725.3984, grad_fn=<SubBackward0>)\n",
      "loss: 62.66713333129883\n",
      "tensor([[855]]) tensor(-52610.5156, grad_fn=<SubBackward0>)\n",
      "loss: 62.53276824951172\n",
      "tensor([[855]]) tensor(-52493.2969, grad_fn=<SubBackward0>)\n",
      "loss: 62.395668029785156\n",
      "tensor([[855]]) tensor(-52363.9023, grad_fn=<SubBackward0>)\n",
      "loss: 62.24433135986328\n",
      "tensor([[855]]) tensor(-52261.1797, grad_fn=<SubBackward0>)\n",
      "loss: 62.12418746948242\n",
      "tensor([[855]]) tensor(-52149.4062, grad_fn=<SubBackward0>)\n",
      "loss: 61.99345779418945\n",
      "tensor([[855]]) tensor(-52027.4258, grad_fn=<SubBackward0>)\n",
      "loss: 61.850791931152344\n",
      "tensor([[855]]) tensor(-51898.9609, grad_fn=<SubBackward0>)\n",
      "loss: 61.700538635253906\n",
      "tensor([[855]]) tensor(-51782.8203, grad_fn=<SubBackward0>)\n",
      "loss: 61.564701080322266\n",
      "tensor([[855]]) tensor(-51667.7109, grad_fn=<SubBackward0>)\n",
      "loss: 61.43007278442383\n",
      "tensor([[855]]) tensor(-51554.9375, grad_fn=<SubBackward0>)\n",
      "loss: 61.29817199707031\n",
      "tensor([[855]]) tensor(-51438.9727, grad_fn=<SubBackward0>)\n",
      "loss: 61.162540435791016\n",
      "tensor([[855]]) tensor(-51320.9922, grad_fn=<SubBackward0>)\n",
      "loss: 61.02455139160156\n",
      "tensor([[855]]) tensor(-51205.5391, grad_fn=<SubBackward0>)\n",
      "loss: 60.88951873779297\n",
      "tensor([[855]]) tensor(-51091.0078, grad_fn=<SubBackward0>)\n",
      "loss: 60.75556564331055\n",
      "tensor([[855]]) tensor(-50977.7578, grad_fn=<SubBackward0>)\n",
      "loss: 60.62310791015625\n",
      "tensor([[855]]) tensor(-50869.5547, grad_fn=<SubBackward0>)\n",
      "loss: 60.49655532836914\n",
      "tensor([[855]]) tensor(-50761.4336, grad_fn=<SubBackward0>)\n",
      "loss: 60.37009811401367\n",
      "tensor([[855]]) tensor(-50651.9609, grad_fn=<SubBackward0>)\n",
      "loss: 60.24205780029297\n",
      "tensor([[855]]) tensor(-50542.1680, grad_fn=<SubBackward0>)\n",
      "loss: 60.1136474609375\n",
      "tensor([[855]]) tensor(-50433.0938, grad_fn=<SubBackward0>)\n",
      "loss: 59.98607635498047\n",
      "tensor([[855]]) tensor(-50323.5156, grad_fn=<SubBackward0>)\n",
      "loss: 59.857913970947266\n",
      "tensor([[855]]) tensor(-50213.6406, grad_fn=<SubBackward0>)\n",
      "loss: 59.72940444946289\n",
      "tensor([[855]]) tensor(-50106.1367, grad_fn=<SubBackward0>)\n",
      "loss: 59.603668212890625\n",
      "tensor([[855]]) tensor(-49993.0664, grad_fn=<SubBackward0>)\n",
      "loss: 59.4714241027832\n",
      "tensor([[855]]) tensor(-49882.2773, grad_fn=<SubBackward0>)\n",
      "loss: 59.34184646606445\n",
      "tensor([[855]]) tensor(-49772.2812, grad_fn=<SubBackward0>)\n",
      "loss: 59.21319580078125\n",
      "tensor([[855]]) tensor(-49660.9141, grad_fn=<SubBackward0>)\n",
      "loss: 59.08293914794922\n",
      "tensor([[855]]) tensor(-49550.1797, grad_fn=<SubBackward0>)\n",
      "loss: 58.953426361083984\n",
      "tensor([[855]]) tensor(-49437.9297, grad_fn=<SubBackward0>)\n",
      "loss: 58.822139739990234\n",
      "tensor([[855]]) tensor(-49326.7344, grad_fn=<SubBackward0>)\n",
      "loss: 58.69208526611328\n",
      "tensor([[855]]) tensor(-49219.3984, grad_fn=<SubBackward0>)\n",
      "loss: 58.56654739379883\n",
      "tensor([[855]]) tensor(-49110.1445, grad_fn=<SubBackward0>)\n",
      "loss: 58.43876647949219\n",
      "tensor([[855]]) tensor(-48999.9023, grad_fn=<SubBackward0>)\n",
      "loss: 58.3098258972168\n",
      "tensor([[855]]) tensor(-48890.6094, grad_fn=<SubBackward0>)\n",
      "loss: 58.18199920654297\n",
      "tensor([[855]]) tensor(-48779.7344, grad_fn=<SubBackward0>)\n",
      "loss: 58.05232238769531\n",
      "tensor([[855]]) tensor(-48667.4141, grad_fn=<SubBackward0>)\n",
      "loss: 57.92095184326172\n",
      "tensor([[855]]) tensor(-48556.5430, grad_fn=<SubBackward0>)\n",
      "loss: 57.79127883911133\n",
      "tensor([[855]]) tensor(-48445.7383, grad_fn=<SubBackward0>)\n",
      "loss: 57.66168212890625\n",
      "tensor([[855]]) tensor(-48333.4922, grad_fn=<SubBackward0>)\n",
      "loss: 57.530399322509766\n",
      "tensor([[855]]) tensor(-48224.9531, grad_fn=<SubBackward0>)\n",
      "loss: 57.4034538269043\n",
      "tensor([[855]]) tensor(-48114.3008, grad_fn=<SubBackward0>)\n",
      "loss: 57.2740364074707\n",
      "tensor([[855]]) tensor(-48005.4141, grad_fn=<SubBackward0>)\n",
      "loss: 57.14668273925781\n",
      "tensor([[855]]) tensor(-47895.5547, grad_fn=<SubBackward0>)\n",
      "loss: 57.018192291259766\n",
      "tensor([[855]]) tensor(-47786.3359, grad_fn=<SubBackward0>)\n",
      "loss: 56.89044952392578\n",
      "tensor([[855]]) tensor(-47678.6406, grad_fn=<SubBackward0>)\n",
      "loss: 56.76449203491211\n",
      "tensor([[855]]) tensor(-47570., grad_fn=<SubBackward0>)\n",
      "loss: 56.637428283691406\n",
      "tensor([[855]]) tensor(-47462.0234, grad_fn=<SubBackward0>)\n",
      "loss: 56.511138916015625\n",
      "tensor([[855]]) tensor(-47352.0938, grad_fn=<SubBackward0>)\n",
      "loss: 56.382564544677734\n",
      "tensor([[855]]) tensor(-47240.7070, grad_fn=<SubBackward0>)\n",
      "loss: 56.252288818359375\n",
      "tensor([[855]]) tensor(-47138.0703, grad_fn=<SubBackward0>)\n",
      "loss: 56.13224411010742\n",
      "tensor([[855]]) tensor(-47028.0898, grad_fn=<SubBackward0>)\n",
      "loss: 56.00361251831055\n",
      "tensor([[855]]) tensor(-46916.8633, grad_fn=<SubBackward0>)\n",
      "loss: 55.8735237121582\n",
      "tensor([[855]]) tensor(-46811.0508, grad_fn=<SubBackward0>)\n",
      "loss: 55.7497673034668\n",
      "tensor([[855]]) tensor(-46702.9219, grad_fn=<SubBackward0>)\n",
      "loss: 55.62329864501953\n",
      "tensor([[855]]) tensor(-46596.9609, grad_fn=<SubBackward0>)\n",
      "loss: 55.49937057495117\n",
      "tensor([[855]]) tensor(-46486.6992, grad_fn=<SubBackward0>)\n",
      "loss: 55.37040710449219\n",
      "tensor([[855]]) tensor(-46377.3477, grad_fn=<SubBackward0>)\n",
      "loss: 55.24251174926758\n",
      "tensor([[855]]) tensor(-46268.2188, grad_fn=<SubBackward0>)\n",
      "loss: 55.11487579345703\n",
      "tensor([[855]]) tensor(-46160.5234, grad_fn=<SubBackward0>)\n",
      "loss: 54.988914489746094\n",
      "tensor([[855]]) tensor(-46052.9766, grad_fn=<SubBackward0>)\n",
      "loss: 54.863128662109375\n",
      "tensor([[855]]) tensor(-45946.8516, grad_fn=<SubBackward0>)\n",
      "loss: 54.73900604248047\n",
      "tensor([[855]]) tensor(-45840.5391, grad_fn=<SubBackward0>)\n",
      "loss: 54.61466598510742\n",
      "tensor([[855]]) tensor(-45737.5469, grad_fn=<SubBackward0>)\n",
      "loss: 54.494205474853516\n",
      "tensor([[855]]) tensor(-45627.1250, grad_fn=<SubBackward0>)\n",
      "loss: 54.36505889892578\n",
      "tensor([[855]]) tensor(-45527.9453, grad_fn=<SubBackward0>)\n",
      "loss: 54.24905776977539\n",
      "tensor([[855]]) tensor(-45423.2891, grad_fn=<SubBackward0>)\n",
      "loss: 54.12665557861328\n",
      "tensor([[855]]) tensor(-45309.5898, grad_fn=<SubBackward0>)\n",
      "loss: 53.99367141723633\n",
      "tensor([[855]]) tensor(-45211.9648, grad_fn=<SubBackward0>)\n",
      "loss: 53.87948989868164\n",
      "tensor([[855]]) tensor(-45111.6602, grad_fn=<SubBackward0>)\n",
      "loss: 53.762176513671875\n",
      "tensor([[855]]) tensor(-45005.4961, grad_fn=<SubBackward0>)\n",
      "loss: 53.63800811767578\n",
      "tensor([[855]]) tensor(-44894.7188, grad_fn=<SubBackward0>)\n",
      "loss: 53.50844192504883\n",
      "tensor([[855]]) tensor(-44779.5586, grad_fn=<SubBackward0>)\n",
      "loss: 53.37375259399414\n",
      "tensor([[855]]) tensor(-44678.2461, grad_fn=<SubBackward0>)\n",
      "loss: 53.2552604675293\n",
      "tensor([[855]]) tensor(-44571.9922, grad_fn=<SubBackward0>)\n",
      "loss: 53.130985260009766\n",
      "tensor([[855]]) tensor(-44461.9141, grad_fn=<SubBackward0>)\n",
      "loss: 53.00223922729492\n",
      "tensor([[855]]) tensor(-44359.8516, grad_fn=<SubBackward0>)\n",
      "loss: 52.88286590576172\n",
      "tensor([[855]]) tensor(-44254.1680, grad_fn=<SubBackward0>)\n",
      "loss: 52.75926208496094\n",
      "tensor([[855]]) tensor(-44143.4180, grad_fn=<SubBackward0>)\n",
      "loss: 52.629730224609375\n",
      "tensor([[855]]) tensor(-44048.2695, grad_fn=<SubBackward0>)\n",
      "loss: 52.5184440612793\n",
      "tensor([[855]]) tensor(-43943.8828, grad_fn=<SubBackward0>)\n",
      "loss: 52.39635467529297\n",
      "tensor([[855]]) tensor(-43830.1406, grad_fn=<SubBackward0>)\n",
      "loss: 52.26332092285156\n",
      "tensor([[855]]) tensor(-43722.7500, grad_fn=<SubBackward0>)\n",
      "loss: 52.137718200683594\n",
      "tensor([[855]]) tensor(-43621.8516, grad_fn=<SubBackward0>)\n",
      "loss: 52.019710540771484\n",
      "tensor([[855]]) tensor(-43514.0859, grad_fn=<SubBackward0>)\n",
      "loss: 51.89366912841797\n",
      "tensor([[855]]) tensor(-43401.7734, grad_fn=<SubBackward0>)\n",
      "loss: 51.762306213378906\n",
      "tensor([[855]]) tensor(-43306.2148, grad_fn=<SubBackward0>)\n",
      "loss: 51.650543212890625\n",
      "tensor([[855]]) tensor(-43204.3789, grad_fn=<SubBackward0>)\n",
      "loss: 51.531436920166016\n",
      "tensor([[855]]) tensor(-43091.8672, grad_fn=<SubBackward0>)\n",
      "loss: 51.399845123291016\n",
      "tensor([[855]]) tensor(-42980.4062, grad_fn=<SubBackward0>)\n",
      "loss: 51.26948165893555\n",
      "tensor([[855]]) tensor(-42882.5312, grad_fn=<SubBackward0>)\n",
      "loss: 51.155006408691406\n",
      "tensor([[855]]) tensor(-42775.9844, grad_fn=<SubBackward0>)\n",
      "loss: 51.030391693115234\n",
      "tensor([[855]]) tensor(-42669.7812, grad_fn=<SubBackward0>)\n",
      "loss: 50.90617752075195\n",
      "tensor([[855]]) tensor(-42567.5625, grad_fn=<SubBackward0>)\n",
      "loss: 50.78662109375\n",
      "tensor([[855]]) tensor(-42460.0625, grad_fn=<SubBackward0>)\n",
      "loss: 50.660892486572266\n",
      "tensor([[855]]) tensor(-42354.9375, grad_fn=<SubBackward0>)\n",
      "loss: 50.53793716430664\n",
      "tensor([[855]]) tensor(-42251.2656, grad_fn=<SubBackward0>)\n",
      "loss: 50.416683197021484\n",
      "tensor([[855]]) tensor(-42151.3984, grad_fn=<SubBackward0>)\n",
      "loss: 50.29988098144531\n",
      "tensor([[855]]) tensor(-42044.9453, grad_fn=<SubBackward0>)\n",
      "loss: 50.17537307739258\n",
      "tensor([[855]]) tensor(-41947.7891, grad_fn=<SubBackward0>)\n",
      "loss: 50.06174087524414\n",
      "tensor([[855]]) tensor(-41846.2891, grad_fn=<SubBackward0>)\n",
      "loss: 49.94302749633789\n",
      "tensor([[855]]) tensor(-41738.2695, grad_fn=<SubBackward0>)\n",
      "loss: 49.816688537597656\n",
      "tensor([[855]]) tensor(-41638.2188, grad_fn=<SubBackward0>)\n",
      "loss: 49.69967269897461\n",
      "tensor([[855]]) tensor(-41535.9141, grad_fn=<SubBackward0>)\n",
      "loss: 49.58001708984375\n",
      "tensor([[855]]) tensor(-41427.7656, grad_fn=<SubBackward0>)\n",
      "loss: 49.45352554321289\n",
      "tensor([[855]]) tensor(-41325.6250, grad_fn=<SubBackward0>)\n",
      "loss: 49.33406448364258\n",
      "tensor([[855]]) tensor(-41219.4297, grad_fn=<SubBackward0>)\n",
      "loss: 49.20985794067383\n",
      "tensor([[855]]) tensor(-41117.0781, grad_fn=<SubBackward0>)\n",
      "loss: 49.09014892578125\n",
      "tensor([[855]]) tensor(-41011.6484, grad_fn=<SubBackward0>)\n",
      "loss: 48.96683883666992\n",
      "tensor([[855]]) tensor(-40907.6875, grad_fn=<SubBackward0>)\n",
      "loss: 48.84524917602539\n",
      "tensor([[855]]) tensor(-40805.4336, grad_fn=<SubBackward0>)\n",
      "loss: 48.72565460205078\n",
      "tensor([[855]]) tensor(-40701.9062, grad_fn=<SubBackward0>)\n",
      "loss: 48.60456848144531\n",
      "tensor([[855]]) tensor(-40596.2812, grad_fn=<SubBackward0>)\n",
      "loss: 48.48102951049805\n",
      "tensor([[855]]) tensor(-40496.5078, grad_fn=<SubBackward0>)\n",
      "loss: 48.36433792114258\n",
      "tensor([[855]]) tensor(-40390.8906, grad_fn=<SubBackward0>)\n",
      "loss: 48.240806579589844\n",
      "tensor([[855]]) tensor(-40292.3359, grad_fn=<SubBackward0>)\n",
      "loss: 48.12553787231445\n",
      "tensor([[855]]) tensor(-40187.0469, grad_fn=<SubBackward0>)\n",
      "loss: 48.00239562988281\n",
      "tensor([[855]]) tensor(-40081.0156, grad_fn=<SubBackward0>)\n",
      "loss: 47.878379821777344\n",
      "tensor([[855]]) tensor(-39978.9844, grad_fn=<SubBackward0>)\n",
      "loss: 47.7590446472168\n",
      "tensor([[855]]) tensor(-39872.5938, grad_fn=<SubBackward0>)\n",
      "loss: 47.634613037109375\n",
      "tensor([[855]]) tensor(-39769.5625, grad_fn=<SubBackward0>)\n",
      "loss: 47.51410675048828\n",
      "tensor([[855]]) tensor(-39664.2422, grad_fn=<SubBackward0>)\n",
      "loss: 47.390926361083984\n",
      "tensor([[855]]) tensor(-39563.9336, grad_fn=<SubBackward0>)\n",
      "loss: 47.27360534667969\n",
      "tensor([[855]]) tensor(-39462.3711, grad_fn=<SubBackward0>)\n",
      "loss: 47.15481948852539\n",
      "tensor([[855]]) tensor(-39361.3125, grad_fn=<SubBackward0>)\n",
      "loss: 47.03662109375\n",
      "tensor([[855]]) tensor(-39261.1016, grad_fn=<SubBackward0>)\n",
      "loss: 46.91941833496094\n",
      "tensor([[855]]) tensor(-39159.3203, grad_fn=<SubBackward0>)\n",
      "loss: 46.80037307739258\n",
      "tensor([[855]]) tensor(-39054.6094, grad_fn=<SubBackward0>)\n",
      "loss: 46.67790603637695\n",
      "tensor([[855]]) tensor(-38955.7148, grad_fn=<SubBackward0>)\n",
      "loss: 46.56224060058594\n",
      "tensor([[855]]) tensor(-38856.9258, grad_fn=<SubBackward0>)\n",
      "loss: 46.44669723510742\n",
      "tensor([[855]]) tensor(-38749.6328, grad_fn=<SubBackward0>)\n",
      "loss: 46.32120895385742\n",
      "tensor([[855]]) tensor(-38649.9180, grad_fn=<SubBackward0>)\n",
      "loss: 46.20458221435547\n",
      "tensor([[855]]) tensor(-38548.3828, grad_fn=<SubBackward0>)\n",
      "loss: 46.0858268737793\n",
      "tensor([[855]]) tensor(-38443.2305, grad_fn=<SubBackward0>)\n",
      "loss: 45.96284103393555\n",
      "tensor([[855]]) tensor(-38345.9883, grad_fn=<SubBackward0>)\n",
      "loss: 45.8491096496582\n",
      "tensor([[855]]) tensor(-38244.3633, grad_fn=<SubBackward0>)\n",
      "loss: 45.73025131225586\n",
      "tensor([[855]]) tensor(-38141.1836, grad_fn=<SubBackward0>)\n",
      "loss: 45.60956954956055\n",
      "tensor([[855]]) tensor(-38042.6523, grad_fn=<SubBackward0>)\n",
      "loss: 45.49433135986328\n",
      "tensor([[855]]) tensor(-37941.8945, grad_fn=<SubBackward0>)\n",
      "loss: 45.37648391723633\n",
      "tensor([[855]]) tensor(-37838.1484, grad_fn=<SubBackward0>)\n",
      "loss: 45.25514602661133\n",
      "tensor([[855]]) tensor(-37732.9336, grad_fn=<SubBackward0>)\n",
      "loss: 45.13208770751953\n",
      "tensor([[855]]) tensor(-37633.9688, grad_fn=<SubBackward0>)\n",
      "loss: 45.01633834838867\n",
      "tensor([[855]]) tensor(-37531.9180, grad_fn=<SubBackward0>)\n",
      "loss: 44.89698028564453\n",
      "tensor([[855]]) tensor(-37429.2773, grad_fn=<SubBackward0>)\n",
      "loss: 44.77693176269531\n",
      "tensor([[855]]) tensor(-37329.0781, grad_fn=<SubBackward0>)\n",
      "loss: 44.65974044799805\n",
      "tensor([[855]]) tensor(-37227.7227, grad_fn=<SubBackward0>)\n",
      "loss: 44.541194915771484\n",
      "tensor([[855]]) tensor(-37124.7891, grad_fn=<SubBackward0>)\n",
      "loss: 44.420806884765625\n",
      "tensor([[855]]) tensor(-37025.1875, grad_fn=<SubBackward0>)\n",
      "loss: 44.30431365966797\n",
      "tensor([[855]]) tensor(-36921.9648, grad_fn=<SubBackward0>)\n",
      "loss: 44.18358612060547\n",
      "tensor([[855]]) tensor(-36817.4688, grad_fn=<SubBackward0>)\n",
      "loss: 44.06136703491211\n",
      "tensor([[855]]) tensor(-36715.1289, grad_fn=<SubBackward0>)\n",
      "loss: 43.94166946411133\n",
      "tensor([[855]]) tensor(-36614.1602, grad_fn=<SubBackward0>)\n",
      "loss: 43.823577880859375\n",
      "tensor([[855]]) tensor(-36507.1016, grad_fn=<SubBackward0>)\n",
      "loss: 43.6983642578125\n",
      "tensor([[855]]) tensor(-36406.4727, grad_fn=<SubBackward0>)\n",
      "loss: 43.58066940307617\n",
      "tensor([[855]]) tensor(-36302.2969, grad_fn=<SubBackward0>)\n",
      "loss: 43.45882797241211\n",
      "tensor([[855]]) tensor(-36203.2578, grad_fn=<SubBackward0>)\n",
      "loss: 43.34299087524414\n",
      "tensor([[855]]) tensor(-36097.5156, grad_fn=<SubBackward0>)\n",
      "loss: 43.21931838989258\n",
      "tensor([[855]]) tensor(-35994.3125, grad_fn=<SubBackward0>)\n",
      "loss: 43.098609924316406\n",
      "tensor([[855]]) tensor(-35893.4531, grad_fn=<SubBackward0>)\n",
      "loss: 42.980648040771484\n",
      "tensor([[855]]) tensor(-35789.0664, grad_fn=<SubBackward0>)\n",
      "loss: 42.858558654785156\n",
      "tensor([[855]]) tensor(-35681.4961, grad_fn=<SubBackward0>)\n",
      "loss: 42.73274230957031\n",
      "tensor([[855]]) tensor(-35580.0977, grad_fn=<SubBackward0>)\n",
      "loss: 42.61415100097656\n",
      "tensor([[855]]) tensor(-35480.2422, grad_fn=<SubBackward0>)\n",
      "loss: 42.49736022949219\n",
      "tensor([[855]]) tensor(-35380.2422, grad_fn=<SubBackward0>)\n",
      "loss: 42.380401611328125\n",
      "tensor([[855]]) tensor(-35271.0508, grad_fn=<SubBackward0>)\n",
      "loss: 42.252689361572266\n",
      "tensor([[855]]) tensor(-35171.7344, grad_fn=<SubBackward0>)\n",
      "loss: 42.136531829833984\n",
      "tensor([[855]]) tensor(-35071.1367, grad_fn=<SubBackward0>)\n",
      "loss: 42.01887512207031\n",
      "tensor([[855]]) tensor(-34966.8516, grad_fn=<SubBackward0>)\n",
      "loss: 41.89690399169922\n",
      "tensor([[855]]) tensor(-34861.6172, grad_fn=<SubBackward0>)\n",
      "loss: 41.77382278442383\n",
      "tensor([[855]]) tensor(-34762.5430, grad_fn=<SubBackward0>)\n",
      "loss: 41.65794372558594\n",
      "tensor([[855]]) tensor(-34658.4570, grad_fn=<SubBackward0>)\n",
      "loss: 41.53620529174805\n",
      "tensor([[855]]) tensor(-34554.4922, grad_fn=<SubBackward0>)\n",
      "loss: 41.41461181640625\n",
      "tensor([[855]]) tensor(-34455.2617, grad_fn=<SubBackward0>)\n",
      "loss: 41.298553466796875\n",
      "tensor([[855]]) tensor(-34351.9297, grad_fn=<SubBackward0>)\n",
      "loss: 41.177696228027344\n",
      "tensor([[855]]) tensor(-34247.0859, grad_fn=<SubBackward0>)\n",
      "loss: 41.05507278442383\n",
      "tensor([[855]]) tensor(-34146.6016, grad_fn=<SubBackward0>)\n",
      "loss: 40.93754577636719\n",
      "tensor([[855]]) tensor(-34046.2617, grad_fn=<SubBackward0>)\n",
      "loss: 40.8201904296875\n",
      "tensor([[855]]) tensor(-33940.3789, grad_fn=<SubBackward0>)\n",
      "loss: 40.69635009765625\n",
      "tensor([[855]]) tensor(-33843.6250, grad_fn=<SubBackward0>)\n",
      "loss: 40.583187103271484\n",
      "tensor([[855]]) tensor(-33743.2188, grad_fn=<SubBackward0>)\n",
      "loss: 40.46575164794922\n",
      "tensor([[855]]) tensor(-33637.0664, grad_fn=<SubBackward0>)\n",
      "loss: 40.34159851074219\n",
      "tensor([[855]]) tensor(-33530.3086, grad_fn=<SubBackward0>)\n",
      "loss: 40.21673583984375\n",
      "tensor([[855]]) tensor(-33435.8672, grad_fn=<SubBackward0>)\n",
      "loss: 40.10627746582031\n",
      "tensor([[855]]) tensor(-33332.7031, grad_fn=<SubBackward0>)\n",
      "loss: 39.985618591308594\n",
      "tensor([[855]]) tensor(-33231.4727, grad_fn=<SubBackward0>)\n",
      "loss: 39.867218017578125\n",
      "tensor([[855]]) tensor(-33134.0625, grad_fn=<SubBackward0>)\n",
      "loss: 39.75328826904297\n",
      "tensor([[855]]) tensor(-33032.5391, grad_fn=<SubBackward0>)\n",
      "loss: 39.63454818725586\n",
      "tensor([[855]]) tensor(-32931.1953, grad_fn=<SubBackward0>)\n",
      "loss: 39.51601791381836\n",
      "tensor([[855]]) tensor(-32824.6445, grad_fn=<SubBackward0>)\n",
      "loss: 39.391395568847656\n",
      "tensor([[855]]) tensor(-32729.9707, grad_fn=<SubBackward0>)\n",
      "loss: 39.28066635131836\n",
      "tensor([[855]]) tensor(-32627.8691, grad_fn=<SubBackward0>)\n",
      "loss: 39.16124725341797\n",
      "tensor([[855]]) tensor(-32520.7305, grad_fn=<SubBackward0>)\n",
      "loss: 39.03594207763672\n",
      "tensor([[855]]) tensor(-32425.7324, grad_fn=<SubBackward0>)\n",
      "loss: 38.924835205078125\n",
      "tensor([[855]]) tensor(-32326.4688, grad_fn=<SubBackward0>)\n",
      "loss: 38.80873489379883\n",
      "tensor([[855]]) tensor(-32223.6914, grad_fn=<SubBackward0>)\n",
      "loss: 38.68852615356445\n",
      "tensor([[855]]) tensor(-32117.5547, grad_fn=<SubBackward0>)\n",
      "loss: 38.56439208984375\n",
      "tensor([[855]]) tensor(-32011.2539, grad_fn=<SubBackward0>)\n",
      "loss: 38.4400634765625\n",
      "tensor([[855]]) tensor(-31909.2070, grad_fn=<SubBackward0>)\n",
      "loss: 38.320709228515625\n",
      "tensor([[855]]) tensor(-31806.4512, grad_fn=<SubBackward0>)\n",
      "loss: 38.20052719116211\n",
      "tensor([[855]]) tensor(-31708.1641, grad_fn=<SubBackward0>)\n",
      "loss: 38.0855712890625\n",
      "tensor([[855]]) tensor(-31607.1074, grad_fn=<SubBackward0>)\n",
      "loss: 37.967376708984375\n",
      "tensor([[855]]) tensor(-31502.9941, grad_fn=<SubBackward0>)\n",
      "loss: 37.84560775756836\n",
      "tensor([[855]]) tensor(-31396.6504, grad_fn=<SubBackward0>)\n",
      "loss: 37.721229553222656\n",
      "tensor([[855]]) tensor(-31295.9414, grad_fn=<SubBackward0>)\n",
      "loss: 37.60343933105469\n",
      "tensor([[855]]) tensor(-31192.2930, grad_fn=<SubBackward0>)\n",
      "loss: 37.482215881347656\n",
      "tensor([[855]]) tensor(-31090.7598, grad_fn=<SubBackward0>)\n",
      "loss: 37.363460540771484\n",
      "tensor([[855]]) tensor(-30985.9375, grad_fn=<SubBackward0>)\n",
      "loss: 37.24086380004883\n",
      "tensor([[855]]) tensor(-30884.1270, grad_fn=<SubBackward0>)\n",
      "loss: 37.12178421020508\n",
      "tensor([[855]]) tensor(-30779.6719, grad_fn=<SubBackward0>)\n",
      "loss: 36.99961471557617\n",
      "tensor([[855]]) tensor(-30679.1328, grad_fn=<SubBackward0>)\n",
      "loss: 36.88202667236328\n",
      "tensor([[855]]) tensor(-30582.2930, grad_fn=<SubBackward0>)\n",
      "loss: 36.76876449584961\n",
      "tensor([[855]]) tensor(-30484.8008, grad_fn=<SubBackward0>)\n",
      "loss: 36.65473937988281\n",
      "tensor([[855]]) tensor(-30381.5859, grad_fn=<SubBackward0>)\n",
      "loss: 36.534019470214844\n",
      "tensor([[855]]) tensor(-30278.5078, grad_fn=<SubBackward0>)\n",
      "loss: 36.41345977783203\n",
      "tensor([[855]]) tensor(-30184.7695, grad_fn=<SubBackward0>)\n",
      "loss: 36.30382537841797\n",
      "tensor([[855]]) tensor(-30086.2109, grad_fn=<SubBackward0>)\n",
      "loss: 36.18854904174805\n",
      "tensor([[855]]) tensor(-29984.2891, grad_fn=<SubBackward0>)\n",
      "loss: 36.06934356689453\n",
      "tensor([[855]]) tensor(-29892.3652, grad_fn=<SubBackward0>)\n",
      "loss: 35.961830139160156\n",
      "tensor([[855]]) tensor(-29796.9023, grad_fn=<SubBackward0>)\n",
      "loss: 35.85017776489258\n",
      "tensor([[855]]) tensor(-29699.2734, grad_fn=<SubBackward0>)\n",
      "loss: 35.735992431640625\n",
      "tensor([[855]]) tensor(-29598.3145, grad_fn=<SubBackward0>)\n",
      "loss: 35.61791229248047\n",
      "tensor([[855]]) tensor(-29499.4531, grad_fn=<SubBackward0>)\n",
      "loss: 35.50228500366211\n",
      "tensor([[855]]) tensor(-29407.5449, grad_fn=<SubBackward0>)\n",
      "loss: 35.39479064941406\n",
      "tensor([[855]]) tensor(-29305.7188, grad_fn=<SubBackward0>)\n",
      "loss: 35.27569580078125\n",
      "tensor([[855]]) tensor(-29206.8281, grad_fn=<SubBackward0>)\n",
      "loss: 35.1600341796875\n",
      "tensor([[855]]) tensor(-29108.0312, grad_fn=<SubBackward0>)\n",
      "loss: 35.04447937011719\n",
      "tensor([[855]]) tensor(-29012.9004, grad_fn=<SubBackward0>)\n",
      "loss: 34.9332160949707\n",
      "tensor([[855]]) tensor(-28914.8809, grad_fn=<SubBackward0>)\n",
      "loss: 34.818572998046875\n",
      "tensor([[855]]) tensor(-28816.0273, grad_fn=<SubBackward0>)\n",
      "loss: 34.70295715332031\n",
      "tensor([[855]]) tensor(-28721.7422, grad_fn=<SubBackward0>)\n",
      "loss: 34.592681884765625\n",
      "tensor([[855]]) tensor(-28626.1133, grad_fn=<SubBackward0>)\n",
      "loss: 34.4808349609375\n",
      "tensor([[855]]) tensor(-28524.7969, grad_fn=<SubBackward0>)\n",
      "loss: 34.362335205078125\n",
      "tensor([[855]]) tensor(-28429.6367, grad_fn=<SubBackward0>)\n",
      "loss: 34.25103759765625\n",
      "tensor([[855]]) tensor(-28336.4473, grad_fn=<SubBackward0>)\n",
      "loss: 34.14204406738281\n",
      "tensor([[855]]) tensor(-28230.3203, grad_fn=<SubBackward0>)\n",
      "loss: 34.01791763305664\n",
      "tensor([[855]]) tensor(-28141.1797, grad_fn=<SubBackward0>)\n",
      "loss: 33.91366195678711\n",
      "tensor([[855]]) tensor(-28046.5938, grad_fn=<SubBackward0>)\n",
      "loss: 33.80303192138672\n",
      "tensor([[855]]) tensor(-27946.8438, grad_fn=<SubBackward0>)\n",
      "loss: 33.68636703491211\n",
      "tensor([[855]]) tensor(-27845.3008, grad_fn=<SubBackward0>)\n",
      "loss: 33.567604064941406\n",
      "tensor([[855]]) tensor(-27755.3398, grad_fn=<SubBackward0>)\n",
      "loss: 33.46238708496094\n",
      "tensor([[855]]) tensor(-27658.1250, grad_fn=<SubBackward0>)\n",
      "loss: 33.34868240356445\n",
      "tensor([[855]]) tensor(-27558.2969, grad_fn=<SubBackward0>)\n",
      "loss: 33.23192596435547\n",
      "tensor([[855]]) tensor(-27468.2910, grad_fn=<SubBackward0>)\n",
      "loss: 33.12665557861328\n",
      "tensor([[855]]) tensor(-27375.7578, grad_fn=<SubBackward0>)\n",
      "loss: 33.018428802490234\n",
      "tensor([[855]]) tensor(-27279.7891, grad_fn=<SubBackward0>)\n",
      "loss: 32.906185150146484\n",
      "tensor([[855]]) tensor(-27180.8047, grad_fn=<SubBackward0>)\n",
      "loss: 32.7904167175293\n",
      "tensor([[855]]) tensor(-27079.5352, grad_fn=<SubBackward0>)\n",
      "loss: 32.67197036743164\n",
      "tensor([[855]]) tensor(-27001.5273, grad_fn=<SubBackward0>)\n",
      "loss: 32.58073425292969\n",
      "tensor([[855]]) tensor(-26906.7090, grad_fn=<SubBackward0>)\n",
      "loss: 32.46983337402344\n",
      "tensor([[855]]) tensor(-26795.8574, grad_fn=<SubBackward0>)\n",
      "loss: 32.34018325805664\n",
      "tensor([[855]]) tensor(-26706.7305, grad_fn=<SubBackward0>)\n",
      "loss: 32.23594284057617\n",
      "tensor([[855]]) tensor(-26615.0664, grad_fn=<SubBackward0>)\n",
      "loss: 32.12873077392578\n",
      "tensor([[855]]) tensor(-26518.2578, grad_fn=<SubBackward0>)\n",
      "loss: 32.015506744384766\n",
      "tensor([[855]]) tensor(-26419.1484, grad_fn=<SubBackward0>)\n",
      "loss: 31.89958953857422\n",
      "tensor([[855]]) tensor(-26317.7969, grad_fn=<SubBackward0>)\n",
      "loss: 31.781049728393555\n",
      "tensor([[855]]) tensor(-26227.8086, grad_fn=<SubBackward0>)\n",
      "loss: 31.675800323486328\n",
      "tensor([[855]]) tensor(-26132.7285, grad_fn=<SubBackward0>)\n",
      "loss: 31.564594268798828\n",
      "tensor([[855]]) tensor(-26033.0312, grad_fn=<SubBackward0>)\n",
      "loss: 31.44799041748047\n",
      "tensor([[855]]) tensor(-25934.8887, grad_fn=<SubBackward0>)\n",
      "loss: 31.333202362060547\n",
      "tensor([[855]]) tensor(-25845.6621, grad_fn=<SubBackward0>)\n",
      "loss: 31.228843688964844\n",
      "tensor([[855]]) tensor(-25751.1758, grad_fn=<SubBackward0>)\n",
      "loss: 31.11833381652832\n",
      "tensor([[855]]) tensor(-25656.1582, grad_fn=<SubBackward0>)\n",
      "loss: 31.0072021484375\n",
      "tensor([[855]]) tensor(-25569.3984, grad_fn=<SubBackward0>)\n",
      "loss: 30.905729293823242\n",
      "tensor([[855]]) tensor(-25469.7734, grad_fn=<SubBackward0>)\n",
      "loss: 30.789209365844727\n",
      "tensor([[855]]) tensor(-25379.3555, grad_fn=<SubBackward0>)\n",
      "loss: 30.683456420898438\n",
      "tensor([[855]]) tensor(-25288.8438, grad_fn=<SubBackward0>)\n",
      "loss: 30.577594757080078\n",
      "tensor([[855]]) tensor(-25194.7012, grad_fn=<SubBackward0>)\n",
      "loss: 30.467487335205078\n",
      "tensor([[855]]) tensor(-25100.8438, grad_fn=<SubBackward0>)\n",
      "loss: 30.357711791992188\n",
      "tensor([[855]]) tensor(-25013.5156, grad_fn=<SubBackward0>)\n",
      "loss: 30.255573272705078\n",
      "tensor([[855]]) tensor(-24918.3555, grad_fn=<SubBackward0>)\n",
      "loss: 30.144275665283203\n",
      "tensor([[855]]) tensor(-24818.0117, grad_fn=<SubBackward0>)\n",
      "loss: 30.026914596557617\n",
      "tensor([[855]]) tensor(-24725.6074, grad_fn=<SubBackward0>)\n",
      "loss: 29.918838500976562\n",
      "tensor([[855]]) tensor(-24630.8672, grad_fn=<SubBackward0>)\n",
      "loss: 29.80803108215332\n",
      "tensor([[855]]) tensor(-24537.0605, grad_fn=<SubBackward0>)\n",
      "loss: 29.69831657409668\n",
      "tensor([[855]]) tensor(-24444.6758, grad_fn=<SubBackward0>)\n",
      "loss: 29.59026336669922\n",
      "tensor([[855]]) tensor(-24352.2539, grad_fn=<SubBackward0>)\n",
      "loss: 29.482168197631836\n",
      "tensor([[855]]) tensor(-24259.5176, grad_fn=<SubBackward0>)\n",
      "loss: 29.37370491027832\n",
      "tensor([[855]]) tensor(-24165.9453, grad_fn=<SubBackward0>)\n",
      "loss: 29.264263153076172\n",
      "tensor([[855]]) tensor(-24074.6055, grad_fn=<SubBackward0>)\n",
      "loss: 29.157432556152344\n",
      "tensor([[855]]) tensor(-23981.7344, grad_fn=<SubBackward0>)\n",
      "loss: 29.048812866210938\n",
      "tensor([[855]]) tensor(-23886.2539, grad_fn=<SubBackward0>)\n",
      "loss: 28.9371395111084\n",
      "tensor([[855]]) tensor(-23795.3438, grad_fn=<SubBackward0>)\n",
      "loss: 28.830810546875\n",
      "tensor([[855]]) tensor(-23702.6152, grad_fn=<SubBackward0>)\n",
      "loss: 28.72235679626465\n",
      "tensor([[855]]) tensor(-23607.9688, grad_fn=<SubBackward0>)\n",
      "loss: 28.61166000366211\n",
      "tensor([[855]]) tensor(-23512.5723, grad_fn=<SubBackward0>)\n",
      "loss: 28.500083923339844\n",
      "tensor([[855]]) tensor(-23423.3164, grad_fn=<SubBackward0>)\n",
      "loss: 28.39569091796875\n",
      "tensor([[855]]) tensor(-23325.5859, grad_fn=<SubBackward0>)\n",
      "loss: 28.281387329101562\n",
      "tensor([[855]]) tensor(-23238.3164, grad_fn=<SubBackward0>)\n",
      "loss: 28.179317474365234\n",
      "tensor([[855]]) tensor(-23145.5371, grad_fn=<SubBackward0>)\n",
      "loss: 28.070802688598633\n",
      "tensor([[855]]) tensor(-23050.5625, grad_fn=<SubBackward0>)\n",
      "loss: 27.9597225189209\n",
      "tensor([[855]]) tensor(-22955.1562, grad_fn=<SubBackward0>)\n",
      "loss: 27.84813690185547\n",
      "tensor([[855]]) tensor(-22865.3262, grad_fn=<SubBackward0>)\n",
      "loss: 27.743070602416992\n",
      "tensor([[855]]) tensor(-22769.7559, grad_fn=<SubBackward0>)\n",
      "loss: 27.63129425048828\n",
      "tensor([[855]]) tensor(-22677.1055, grad_fn=<SubBackward0>)\n",
      "loss: 27.522930145263672\n",
      "tensor([[855]]) tensor(-22582.0234, grad_fn=<SubBackward0>)\n",
      "loss: 27.411724090576172\n",
      "tensor([[855]]) tensor(-22492.9023, grad_fn=<SubBackward0>)\n",
      "loss: 27.30748748779297\n",
      "tensor([[855]]) tensor(-22403.0664, grad_fn=<SubBackward0>)\n",
      "loss: 27.202417373657227\n",
      "tensor([[855]]) tensor(-22303.3789, grad_fn=<SubBackward0>)\n",
      "loss: 27.08582305908203\n",
      "tensor([[855]]) tensor(-22214.4180, grad_fn=<SubBackward0>)\n",
      "loss: 26.981775283813477\n",
      "tensor([[855]]) tensor(-22122.3711, grad_fn=<SubBackward0>)\n",
      "loss: 26.87411880493164\n",
      "tensor([[855]]) tensor(-22028.1406, grad_fn=<SubBackward0>)\n",
      "loss: 26.763906478881836\n",
      "tensor([[855]]) tensor(-21933.2148, grad_fn=<SubBackward0>)\n",
      "loss: 26.652883529663086\n",
      "tensor([[855]]) tensor(-21841.9805, grad_fn=<SubBackward0>)\n",
      "loss: 26.54617691040039\n",
      "tensor([[855]]) tensor(-21748.4570, grad_fn=<SubBackward0>)\n",
      "loss: 26.436792373657227\n",
      "tensor([[855]]) tensor(-21655.3750, grad_fn=<SubBackward0>)\n",
      "loss: 26.327924728393555\n",
      "tensor([[855]]) tensor(-21562.9062, grad_fn=<SubBackward0>)\n",
      "loss: 26.21977424621582\n",
      "tensor([[855]]) tensor(-21471.6133, grad_fn=<SubBackward0>)\n",
      "loss: 26.11299705505371\n",
      "tensor([[855]]) tensor(-21376.1758, grad_fn=<SubBackward0>)\n",
      "loss: 26.001375198364258\n",
      "tensor([[855]]) tensor(-21286.9648, grad_fn=<SubBackward0>)\n",
      "loss: 25.897035598754883\n",
      "tensor([[855]]) tensor(-21189.6621, grad_fn=<SubBackward0>)\n",
      "loss: 25.78322982788086\n",
      "tensor([[855]]) tensor(-21102.4082, grad_fn=<SubBackward0>)\n",
      "loss: 25.68117904663086\n",
      "tensor([[855]]) tensor(-21016.9883, grad_fn=<SubBackward0>)\n",
      "loss: 25.58127212524414\n",
      "tensor([[855]]) tensor(-20926.8926, grad_fn=<SubBackward0>)\n",
      "loss: 25.47589683532715\n",
      "tensor([[855]]) tensor(-20844.9766, grad_fn=<SubBackward0>)\n",
      "loss: 25.380088806152344\n",
      "tensor([[855]]) tensor(-20757.7988, grad_fn=<SubBackward0>)\n",
      "loss: 25.278127670288086\n",
      "tensor([[855]]) tensor(-20667.4570, grad_fn=<SubBackward0>)\n",
      "loss: 25.17246437072754\n",
      "tensor([[855]]) tensor(-20586.6055, grad_fn=<SubBackward0>)\n",
      "loss: 25.07790184020996\n",
      "tensor([[855]]) tensor(-20499.8066, grad_fn=<SubBackward0>)\n",
      "loss: 24.976381301879883\n",
      "tensor([[855]]) tensor(-20413.7812, grad_fn=<SubBackward0>)\n",
      "loss: 24.87576675415039\n",
      "tensor([[855]]) tensor(-20331.0918, grad_fn=<SubBackward0>)\n",
      "loss: 24.779054641723633\n",
      "tensor([[855]]) tensor(-20243.3691, grad_fn=<SubBackward0>)\n",
      "loss: 24.676454544067383\n",
      "tensor([[855]]) tensor(-20154.8906, grad_fn=<SubBackward0>)\n",
      "loss: 24.57297134399414\n",
      "tensor([[855]]) tensor(-20076.2031, grad_fn=<SubBackward0>)\n",
      "loss: 24.480939865112305\n",
      "tensor([[855]]) tensor(-19985.7988, grad_fn=<SubBackward0>)\n",
      "loss: 24.37520408630371\n",
      "tensor([[855]]) tensor(-19904.6133, grad_fn=<SubBackward0>)\n",
      "loss: 24.280248641967773\n",
      "tensor([[855]]) tensor(-19819.5781, grad_fn=<SubBackward0>)\n",
      "loss: 24.18079376220703\n",
      "tensor([[855]]) tensor(-19735.5332, grad_fn=<SubBackward0>)\n",
      "loss: 24.082494735717773\n",
      "tensor([[855]]) tensor(-19649.8633, grad_fn=<SubBackward0>)\n",
      "loss: 23.982295989990234\n",
      "tensor([[855]]) tensor(-19566.4531, grad_fn=<SubBackward0>)\n",
      "loss: 23.884740829467773\n",
      "tensor([[855]]) tensor(-19484.2500, grad_fn=<SubBackward0>)\n",
      "loss: 23.788597106933594\n",
      "tensor([[855]]) tensor(-19406.8984, grad_fn=<SubBackward0>)\n",
      "loss: 23.69812774658203\n",
      "tensor([[855]]) tensor(-19323.2305, grad_fn=<SubBackward0>)\n",
      "loss: 23.600269317626953\n",
      "tensor([[855]]) tensor(-19243.0059, grad_fn=<SubBackward0>)\n",
      "loss: 23.506439208984375\n",
      "tensor([[855]]) tensor(-19166.3125, grad_fn=<SubBackward0>)\n",
      "loss: 23.41674041748047\n",
      "tensor([[855]]) tensor(-19085.3516, grad_fn=<SubBackward0>)\n",
      "loss: 23.32204818725586\n",
      "tensor([[855]]) tensor(-19002.9336, grad_fn=<SubBackward0>)\n",
      "loss: 23.22565269470215\n",
      "tensor([[855]]) tensor(-18925.6406, grad_fn=<SubBackward0>)\n",
      "loss: 23.135251998901367\n",
      "tensor([[855]]) tensor(-18842.3711, grad_fn=<SubBackward0>)\n",
      "loss: 23.037860870361328\n",
      "tensor([[855]]) tensor(-18770.0723, grad_fn=<SubBackward0>)\n",
      "loss: 22.95330047607422\n",
      "tensor([[855]]) tensor(-18689.2012, grad_fn=<SubBackward0>)\n",
      "loss: 22.858715057373047\n",
      "tensor([[855]]) tensor(-18608.8555, grad_fn=<SubBackward0>)\n",
      "loss: 22.76474380493164\n",
      "tensor([[855]]) tensor(-18534.2930, grad_fn=<SubBackward0>)\n",
      "loss: 22.677536010742188\n",
      "tensor([[855]]) tensor(-18455.4258, grad_fn=<SubBackward0>)\n",
      "loss: 22.58529281616211\n",
      "tensor([[855]]) tensor(-18377.6152, grad_fn=<SubBackward0>)\n",
      "loss: 22.494287490844727\n",
      "tensor([[855]]) tensor(-18296.4355, grad_fn=<SubBackward0>)\n",
      "loss: 22.39933967590332\n",
      "tensor([[855]]) tensor(-18221.8223, grad_fn=<SubBackward0>)\n",
      "loss: 22.31207275390625\n",
      "tensor([[855]]) tensor(-18148.2949, grad_fn=<SubBackward0>)\n",
      "loss: 22.226076126098633\n",
      "tensor([[855]]) tensor(-18068.5332, grad_fn=<SubBackward0>)\n",
      "loss: 22.132787704467773\n",
      "tensor([[855]]) tensor(-17991.0508, grad_fn=<SubBackward0>)\n",
      "loss: 22.042163848876953\n",
      "tensor([[855]]) tensor(-17915.9043, grad_fn=<SubBackward0>)\n",
      "loss: 21.954273223876953\n",
      "tensor([[855]]) tensor(-17845.7227, grad_fn=<SubBackward0>)\n",
      "loss: 21.872190475463867\n",
      "tensor([[855]]) tensor(-17782.1855, grad_fn=<SubBackward0>)\n",
      "loss: 21.79787826538086\n",
      "tensor([[855]]) tensor(-17710.6523, grad_fn=<SubBackward0>)\n",
      "loss: 21.71421241760254\n",
      "tensor([[855]]) tensor(-17637.1895, grad_fn=<SubBackward0>)\n",
      "loss: 21.628292083740234\n",
      "tensor([[855]]) tensor(-17572.4258, grad_fn=<SubBackward0>)\n",
      "loss: 21.55254554748535\n",
      "tensor([[855]]) tensor(-17504.5312, grad_fn=<SubBackward0>)\n",
      "loss: 21.47313690185547\n",
      "tensor([[855]]) tensor(-17436.1172, grad_fn=<SubBackward0>)\n",
      "loss: 21.39311981201172\n",
      "tensor([[855]]) tensor(-17367.3242, grad_fn=<SubBackward0>)\n",
      "loss: 21.312660217285156\n",
      "tensor([[855]]) tensor(-17300.1348, grad_fn=<SubBackward0>)\n",
      "loss: 21.23407554626465\n",
      "tensor([[855]]) tensor(-17234.2812, grad_fn=<SubBackward0>)\n",
      "loss: 21.157054901123047\n",
      "tensor([[855]]) tensor(-17168.3613, grad_fn=<SubBackward0>)\n",
      "loss: 21.079954147338867\n",
      "tensor([[855]]) tensor(-17102.3750, grad_fn=<SubBackward0>)\n",
      "loss: 21.002777099609375\n",
      "tensor([[855]]) tensor(-17036.7930, grad_fn=<SubBackward0>)\n",
      "loss: 20.92607307434082\n",
      "tensor([[855]]) tensor(-16972.6641, grad_fn=<SubBackward0>)\n",
      "loss: 20.8510684967041\n",
      "tensor([[855]]) tensor(-16907.3379, grad_fn=<SubBackward0>)\n",
      "loss: 20.7746639251709\n",
      "tensor([[855]]) tensor(-16841.0078, grad_fn=<SubBackward0>)\n",
      "loss: 20.697084426879883\n",
      "tensor([[855]]) tensor(-16775.7070, grad_fn=<SubBackward0>)\n",
      "loss: 20.620710372924805\n",
      "tensor([[855]]) tensor(-16712.4102, grad_fn=<SubBackward0>)\n",
      "loss: 20.54667854309082\n",
      "tensor([[855]]) tensor(-16649.1289, grad_fn=<SubBackward0>)\n",
      "loss: 20.472665786743164\n",
      "tensor([[855]]) tensor(-16584.1660, grad_fn=<SubBackward0>)\n",
      "loss: 20.396684646606445\n",
      "tensor([[855]]) tensor(-16521.1367, grad_fn=<SubBackward0>)\n",
      "loss: 20.322967529296875\n",
      "tensor([[855]]) tensor(-16457.0840, grad_fn=<SubBackward0>)\n",
      "loss: 20.248050689697266\n",
      "tensor([[855]]) tensor(-16392.3633, grad_fn=<SubBackward0>)\n",
      "loss: 20.17235565185547\n",
      "tensor([[855]]) tensor(-16328.5430, grad_fn=<SubBackward0>)\n",
      "loss: 20.09771156311035\n",
      "tensor([[855]]) tensor(-16265.8018, grad_fn=<SubBackward0>)\n",
      "loss: 20.024328231811523\n",
      "tensor([[855]]) tensor(-16202.9736, grad_fn=<SubBackward0>)\n",
      "loss: 19.95084571838379\n",
      "tensor([[855]]) tensor(-16138.9688, grad_fn=<SubBackward0>)\n",
      "loss: 19.875986099243164\n",
      "tensor([[855]]) tensor(-16076.6016, grad_fn=<SubBackward0>)\n",
      "loss: 19.803043365478516\n",
      "tensor([[855]]) tensor(-16013.0391, grad_fn=<SubBackward0>)\n",
      "loss: 19.728700637817383\n",
      "tensor([[855]]) tensor(-15949.5986, grad_fn=<SubBackward0>)\n",
      "loss: 19.65450096130371\n",
      "tensor([[855]]) tensor(-15885.5205, grad_fn=<SubBackward0>)\n",
      "loss: 19.57955551147461\n",
      "tensor([[855]]) tensor(-15826.0361, grad_fn=<SubBackward0>)\n",
      "loss: 19.50998306274414\n",
      "tensor([[855]]) tensor(-15761.4092, grad_fn=<SubBackward0>)\n",
      "loss: 19.43439483642578\n",
      "tensor([[855]]) tensor(-15699.9102, grad_fn=<SubBackward0>)\n",
      "loss: 19.362468719482422\n",
      "tensor([[855]]) tensor(-15637.8535, grad_fn=<SubBackward0>)\n",
      "loss: 19.289886474609375\n",
      "tensor([[855]]) tensor(-15574.4307, grad_fn=<SubBackward0>)\n",
      "loss: 19.215707778930664\n",
      "tensor([[855]]) tensor(-15512.1172, grad_fn=<SubBackward0>)\n",
      "loss: 19.1428279876709\n",
      "tensor([[855]]) tensor(-15450.0537, grad_fn=<SubBackward0>)\n",
      "loss: 19.07023811340332\n",
      "tensor([[855]]) tensor(-15388.4941, grad_fn=<SubBackward0>)\n",
      "loss: 18.998239517211914\n",
      "tensor([[855]]) tensor(-15325.9551, grad_fn=<SubBackward0>)\n",
      "loss: 18.925094604492188\n",
      "tensor([[855]]) tensor(-15264.8848, grad_fn=<SubBackward0>)\n",
      "loss: 18.853666305541992\n",
      "tensor([[855]]) tensor(-15202.3105, grad_fn=<SubBackward0>)\n",
      "loss: 18.780479431152344\n",
      "tensor([[855]]) tensor(-15140.1328, grad_fn=<SubBackward0>)\n",
      "loss: 18.7077579498291\n",
      "tensor([[855]]) tensor(-15078.2129, grad_fn=<SubBackward0>)\n",
      "loss: 18.63533592224121\n",
      "tensor([[855]]) tensor(-15015.7871, grad_fn=<SubBackward0>)\n",
      "loss: 18.56232452392578\n",
      "tensor([[855]]) tensor(-14952.9141, grad_fn=<SubBackward0>)\n",
      "loss: 18.488788604736328\n",
      "tensor([[855]]) tensor(-14889.9570, grad_fn=<SubBackward0>)\n",
      "loss: 18.41515350341797\n",
      "tensor([[855]]) tensor(-14826.8887, grad_fn=<SubBackward0>)\n",
      "loss: 18.34139060974121\n",
      "tensor([[855]]) tensor(-14764.3330, grad_fn=<SubBackward0>)\n",
      "loss: 18.268226623535156\n",
      "tensor([[855]]) tensor(-14702.2715, grad_fn=<SubBackward0>)\n",
      "loss: 18.19563865661621\n",
      "tensor([[855]]) tensor(-14639.5918, grad_fn=<SubBackward0>)\n",
      "loss: 18.122329711914062\n",
      "tensor([[855]]) tensor(-14576.9727, grad_fn=<SubBackward0>)\n",
      "loss: 18.049091339111328\n",
      "tensor([[855]]) tensor(-14514.5000, grad_fn=<SubBackward0>)\n",
      "loss: 17.976022720336914\n",
      "tensor([[855]]) tensor(-14450.8398, grad_fn=<SubBackward0>)\n",
      "loss: 17.901567459106445\n",
      "tensor([[855]]) tensor(-14390.9629, grad_fn=<SubBackward0>)\n",
      "loss: 17.83153533935547\n",
      "tensor([[855]]) tensor(-14326.6504, grad_fn=<SubBackward0>)\n",
      "loss: 17.756317138671875\n",
      "tensor([[855]]) tensor(-14265.7256, grad_fn=<SubBackward0>)\n",
      "loss: 17.68505859375\n",
      "tensor([[855]]) tensor(-14202.0859, grad_fn=<SubBackward0>)\n",
      "loss: 17.610626220703125\n",
      "tensor([[855]]) tensor(-14140.5000, grad_fn=<SubBackward0>)\n",
      "loss: 17.538597106933594\n",
      "tensor([[855]]) tensor(-14077.9727, grad_fn=<SubBackward0>)\n",
      "loss: 17.465465545654297\n",
      "tensor([[855]]) tensor(-14015.2002, grad_fn=<SubBackward0>)\n",
      "loss: 17.392047882080078\n",
      "tensor([[855]]) tensor(-13951.3262, grad_fn=<SubBackward0>)\n",
      "loss: 17.317340850830078\n",
      "tensor([[855]]) tensor(-13889.8594, grad_fn=<SubBackward0>)\n",
      "loss: 17.24544906616211\n",
      "tensor([[855]]) tensor(-13828.8467, grad_fn=<SubBackward0>)\n",
      "loss: 17.174089431762695\n",
      "tensor([[855]]) tensor(-13767.7070, grad_fn=<SubBackward0>)\n",
      "loss: 17.102581024169922\n",
      "tensor([[855]]) tensor(-13706.0547, grad_fn=<SubBackward0>)\n",
      "loss: 17.030473709106445\n",
      "tensor([[855]]) tensor(-13646.4062, grad_fn=<SubBackward0>)\n",
      "loss: 16.960708618164062\n",
      "tensor([[855]]) tensor(-13587.8418, grad_fn=<SubBackward0>)\n",
      "loss: 16.8922119140625\n",
      "tensor([[855]]) tensor(-13529.9268, grad_fn=<SubBackward0>)\n",
      "loss: 16.82447624206543\n",
      "tensor([[855]]) tensor(-13474.1475, grad_fn=<SubBackward0>)\n",
      "loss: 16.75923728942871\n",
      "tensor([[855]]) tensor(-13420.6338, grad_fn=<SubBackward0>)\n",
      "loss: 16.69664764404297\n",
      "tensor([[855]]) tensor(-13363.7539, grad_fn=<SubBackward0>)\n",
      "loss: 16.6301212310791\n",
      "tensor([[855]]) tensor(-13306.6250, grad_fn=<SubBackward0>)\n",
      "loss: 16.563304901123047\n",
      "tensor([[855]]) tensor(-13254.1084, grad_fn=<SubBackward0>)\n",
      "loss: 16.501880645751953\n",
      "tensor([[855]]) tensor(-13200.5586, grad_fn=<SubBackward0>)\n",
      "loss: 16.43924903869629\n",
      "tensor([[855]]) tensor(-13147.4922, grad_fn=<SubBackward0>)\n",
      "loss: 16.37718391418457\n",
      "tensor([[855]]) tensor(-13095.1875, grad_fn=<SubBackward0>)\n",
      "loss: 16.316009521484375\n",
      "tensor([[855]]) tensor(-13040.0850, grad_fn=<SubBackward0>)\n",
      "loss: 16.251562118530273\n",
      "tensor([[855]]) tensor(-12986.8633, grad_fn=<SubBackward0>)\n",
      "loss: 16.189313888549805\n",
      "tensor([[855]]) tensor(-12932.8223, grad_fn=<SubBackward0>)\n",
      "loss: 16.126108169555664\n",
      "tensor([[855]]) tensor(-12877.5850, grad_fn=<SubBackward0>)\n",
      "loss: 16.06150245666504\n",
      "tensor([[855]]) tensor(-12822.6348, grad_fn=<SubBackward0>)\n",
      "loss: 15.997233390808105\n",
      "tensor([[855]]) tensor(-12774.3643, grad_fn=<SubBackward0>)\n",
      "loss: 15.940776824951172\n",
      "tensor([[855]]) tensor(-12724.4697, grad_fn=<SubBackward0>)\n",
      "loss: 15.882420539855957\n",
      "tensor([[855]]) tensor(-12673.3564, grad_fn=<SubBackward0>)\n",
      "loss: 15.822639465332031\n",
      "tensor([[855]]) tensor(-12622.2891, grad_fn=<SubBackward0>)\n",
      "loss: 15.762910842895508\n",
      "tensor([[855]]) tensor(-12571.9023, grad_fn=<SubBackward0>)\n",
      "loss: 15.7039794921875\n",
      "tensor([[855]]) tensor(-12525.0684, grad_fn=<SubBackward0>)\n",
      "loss: 15.649202346801758\n",
      "tensor([[855]]) tensor(-12472.8887, grad_fn=<SubBackward0>)\n",
      "loss: 15.588173866271973\n",
      "tensor([[855]]) tensor(-12422.0674, grad_fn=<SubBackward0>)\n",
      "loss: 15.52873420715332\n",
      "tensor([[855]]) tensor(-12373.5469, grad_fn=<SubBackward0>)\n",
      "loss: 15.47198486328125\n",
      "tensor([[855]]) tensor(-12323.6924, grad_fn=<SubBackward0>)\n",
      "loss: 15.413675308227539\n",
      "tensor([[855]]) tensor(-12273.7568, grad_fn=<SubBackward0>)\n",
      "loss: 15.355271339416504\n",
      "tensor([[855]]) tensor(-12222.4775, grad_fn=<SubBackward0>)\n",
      "loss: 15.295295715332031\n",
      "tensor([[855]]) tensor(-12171.5586, grad_fn=<SubBackward0>)\n",
      "loss: 15.235740661621094\n",
      "tensor([[855]]) tensor(-12121.0156, grad_fn=<SubBackward0>)\n",
      "loss: 15.176626205444336\n",
      "tensor([[855]]) tensor(-12070.4736, grad_fn=<SubBackward0>)\n",
      "loss: 15.117512702941895\n",
      "tensor([[855]]) tensor(-12021.1592, grad_fn=<SubBackward0>)\n",
      "loss: 15.059835433959961\n",
      "tensor([[855]]) tensor(-11970.4375, grad_fn=<SubBackward0>)\n",
      "loss: 15.00051212310791\n",
      "tensor([[855]]) tensor(-11921.1289, grad_fn=<SubBackward0>)\n",
      "loss: 14.942840576171875\n",
      "tensor([[855]]) tensor(-11873.0557, grad_fn=<SubBackward0>)\n",
      "loss: 14.886614799499512\n",
      "tensor([[855]]) tensor(-11822.8262, grad_fn=<SubBackward0>)\n",
      "loss: 14.827866554260254\n",
      "tensor([[855]]) tensor(-11771.1875, grad_fn=<SubBackward0>)\n",
      "loss: 14.767470359802246\n",
      "tensor([[855]]) tensor(-11721.0312, grad_fn=<SubBackward0>)\n",
      "loss: 14.708808898925781\n",
      "tensor([[855]]) tensor(-11670.2334, grad_fn=<SubBackward0>)\n",
      "loss: 14.649395942687988\n",
      "tensor([[855]]) tensor(-11620.5693, grad_fn=<SubBackward0>)\n",
      "loss: 14.591309547424316\n",
      "tensor([[855]]) tensor(-11568.8398, grad_fn=<SubBackward0>)\n",
      "loss: 14.530806541442871\n",
      "tensor([[855]]) tensor(-11518.1553, grad_fn=<SubBackward0>)\n",
      "loss: 14.471527099609375\n",
      "tensor([[855]]) tensor(-11469.5020, grad_fn=<SubBackward0>)\n",
      "loss: 14.41462230682373\n",
      "tensor([[855]]) tensor(-11420.4834, grad_fn=<SubBackward0>)\n",
      "loss: 14.357290267944336\n",
      "tensor([[855]]) tensor(-11371.1182, grad_fn=<SubBackward0>)\n",
      "loss: 14.299553871154785\n",
      "tensor([[855]]) tensor(-11321.1982, grad_fn=<SubBackward0>)\n",
      "loss: 14.241167068481445\n",
      "tensor([[855]]) tensor(-11270.1006, grad_fn=<SubBackward0>)\n",
      "loss: 14.181404113769531\n",
      "tensor([[855]]) tensor(-11220.8291, grad_fn=<SubBackward0>)\n",
      "loss: 14.12377643585205\n",
      "tensor([[855]]) tensor(-11172.3008, grad_fn=<SubBackward0>)\n",
      "loss: 14.067018508911133\n",
      "tensor([[855]]) tensor(-11120.6436, grad_fn=<SubBackward0>)\n",
      "loss: 14.006600379943848\n",
      "tensor([[855]]) tensor(-11070.3828, grad_fn=<SubBackward0>)\n",
      "loss: 13.947815895080566\n",
      "tensor([[855]]) tensor(-11022.7188, grad_fn=<SubBackward0>)\n",
      "loss: 13.892068862915039\n",
      "tensor([[855]]) tensor(-10975.8311, grad_fn=<SubBackward0>)\n",
      "loss: 13.83722972869873\n",
      "tensor([[855]]) tensor(-10924.2061, grad_fn=<SubBackward0>)\n",
      "loss: 13.776848793029785\n",
      "tensor([[855]]) tensor(-10875.2041, grad_fn=<SubBackward0>)\n",
      "loss: 13.719536781311035\n",
      "tensor([[855]]) tensor(-10826.9883, grad_fn=<SubBackward0>)\n",
      "loss: 13.6631441116333\n",
      "tensor([[855]]) tensor(-10778.0586, grad_fn=<SubBackward0>)\n",
      "loss: 13.605916023254395\n",
      "tensor([[855]]) tensor(-10728.2266, grad_fn=<SubBackward0>)\n",
      "loss: 13.547633171081543\n",
      "tensor([[855]]) tensor(-10679.4619, grad_fn=<SubBackward0>)\n",
      "loss: 13.490598678588867\n",
      "tensor([[855]]) tensor(-10632.6230, grad_fn=<SubBackward0>)\n",
      "loss: 13.435816764831543\n",
      "tensor([[855]]) tensor(-10585.0420, grad_fn=<SubBackward0>)\n",
      "loss: 13.380166053771973\n",
      "tensor([[855]]) tensor(-10536.4258, grad_fn=<SubBackward0>)\n",
      "loss: 13.323305130004883\n",
      "tensor([[855]]) tensor(-10488.1104, grad_fn=<SubBackward0>)\n",
      "loss: 13.266796112060547\n",
      "tensor([[855]]) tensor(-10439.8281, grad_fn=<SubBackward0>)\n",
      "loss: 13.210325241088867\n",
      "tensor([[855]]) tensor(-10391.2031, grad_fn=<SubBackward0>)\n",
      "loss: 13.153453826904297\n",
      "tensor([[855]]) tensor(-10347.6172, grad_fn=<SubBackward0>)\n",
      "loss: 13.102476119995117\n",
      "tensor([[855]]) tensor(-10298.0059, grad_fn=<SubBackward0>)\n",
      "loss: 13.044451713562012\n",
      "tensor([[855]]) tensor(-10248.7080, grad_fn=<SubBackward0>)\n",
      "loss: 12.98679256439209\n",
      "tensor([[855]]) tensor(-10201.5020, grad_fn=<SubBackward0>)\n",
      "loss: 12.931581497192383\n",
      "tensor([[855]]) tensor(-10153.6934, grad_fn=<SubBackward0>)\n",
      "loss: 12.875664710998535\n",
      "tensor([[855]]) tensor(-10106.5537, grad_fn=<SubBackward0>)\n",
      "loss: 12.820530891418457\n",
      "tensor([[855]]) tensor(-10058.3486, grad_fn=<SubBackward0>)\n",
      "loss: 12.764150619506836\n",
      "tensor([[855]]) tensor(-10010.6426, grad_fn=<SubBackward0>)\n",
      "loss: 12.708353996276855\n",
      "tensor([[855]]) tensor(-9962.3906, grad_fn=<SubBackward0>)\n",
      "loss: 12.651918411254883\n",
      "tensor([[855]]) tensor(-9914.0586, grad_fn=<SubBackward0>)\n",
      "loss: 12.595390319824219\n",
      "tensor([[855]]) tensor(-9865.1387, grad_fn=<SubBackward0>)\n",
      "loss: 12.53817367553711\n",
      "tensor([[855]]) tensor(-9820.8936, grad_fn=<SubBackward0>)\n",
      "loss: 12.486425399780273\n",
      "tensor([[855]]) tensor(-9771.5098, grad_fn=<SubBackward0>)\n",
      "loss: 12.428666114807129\n",
      "tensor([[855]]) tensor(-9722.8691, grad_fn=<SubBackward0>)\n",
      "loss: 12.371776580810547\n",
      "tensor([[855]]) tensor(-9675.6367, grad_fn=<SubBackward0>)\n",
      "loss: 12.316534042358398\n",
      "tensor([[855]]) tensor(-9627.7910, grad_fn=<SubBackward0>)\n",
      "loss: 12.260574340820312\n",
      "tensor([[855]]) tensor(-9579.8369, grad_fn=<SubBackward0>)\n",
      "loss: 12.204487800598145\n",
      "tensor([[855]]) tensor(-9532.8906, grad_fn=<SubBackward0>)\n",
      "loss: 12.149580001831055\n",
      "tensor([[855]]) tensor(-9484.0898, grad_fn=<SubBackward0>)\n",
      "loss: 12.09250259399414\n",
      "tensor([[855]]) tensor(-9433.2598, grad_fn=<SubBackward0>)\n",
      "loss: 12.033052444458008\n",
      "tensor([[855]]) tensor(-9385.0244, grad_fn=<SubBackward0>)\n",
      "loss: 11.97663688659668\n",
      "tensor([[855]]) tensor(-9337.8672, grad_fn=<SubBackward0>)\n",
      "loss: 11.92148208618164\n",
      "tensor([[855]]) tensor(-9289.2822, grad_fn=<SubBackward0>)\n",
      "loss: 11.864657402038574\n",
      "tensor([[855]]) tensor(-9241.0244, grad_fn=<SubBackward0>)\n",
      "loss: 11.808216094970703\n",
      "tensor([[855]]) tensor(-9191.8848, grad_fn=<SubBackward0>)\n",
      "loss: 11.750741958618164\n",
      "tensor([[855]]) tensor(-9144.0244, grad_fn=<SubBackward0>)\n",
      "loss: 11.694765090942383\n",
      "tensor([[855]]) tensor(-9097.9902, grad_fn=<SubBackward0>)\n",
      "loss: 11.640924453735352\n",
      "tensor([[855]]) tensor(-9050.4893, grad_fn=<SubBackward0>)\n",
      "loss: 11.585367202758789\n",
      "tensor([[855]]) tensor(-9002.1250, grad_fn=<SubBackward0>)\n",
      "loss: 11.528800964355469\n",
      "tensor([[855]]) tensor(-8953.0654, grad_fn=<SubBackward0>)\n",
      "loss: 11.471421241760254\n",
      "tensor([[855]]) tensor(-8904.0850, grad_fn=<SubBackward0>)\n",
      "loss: 11.41413402557373\n",
      "tensor([[855]]) tensor(-8856.1299, grad_fn=<SubBackward0>)\n",
      "loss: 11.358046531677246\n",
      "tensor([[855]]) tensor(-8807.4414, grad_fn=<SubBackward0>)\n",
      "loss: 11.301100730895996\n",
      "tensor([[855]]) tensor(-8762.8652, grad_fn=<SubBackward0>)\n",
      "loss: 11.2489652633667\n",
      "tensor([[855]]) tensor(-8712.2656, grad_fn=<SubBackward0>)\n",
      "loss: 11.189784049987793\n",
      "tensor([[855]]) tensor(-8666.2559, grad_fn=<SubBackward0>)\n",
      "loss: 11.135972023010254\n",
      "tensor([[855]]) tensor(-8619.5713, grad_fn=<SubBackward0>)\n",
      "loss: 11.08137035369873\n",
      "tensor([[855]]) tensor(-8573.8457, grad_fn=<SubBackward0>)\n",
      "loss: 11.027889251708984\n",
      "tensor([[855]]) tensor(-8525.7021, grad_fn=<SubBackward0>)\n",
      "loss: 10.97158145904541\n",
      "tensor([[855]]) tensor(-8477.7295, grad_fn=<SubBackward0>)\n",
      "loss: 10.915472984313965\n",
      "tensor([[855]]) tensor(-8429.8193, grad_fn=<SubBackward0>)\n",
      "loss: 10.859437942504883\n",
      "tensor([[855]]) tensor(-8379.6553, grad_fn=<SubBackward0>)\n",
      "loss: 10.800765991210938\n",
      "tensor([[855]]) tensor(-8330.2305, grad_fn=<SubBackward0>)\n",
      "loss: 10.742959976196289\n",
      "tensor([[855]]) tensor(-8282.8594, grad_fn=<SubBackward0>)\n",
      "loss: 10.687554359436035\n",
      "tensor([[855]]) tensor(-8236.7402, grad_fn=<SubBackward0>)\n",
      "loss: 10.633614540100098\n",
      "tensor([[855]]) tensor(-8187.1221, grad_fn=<SubBackward0>)\n",
      "loss: 10.575581550598145\n",
      "tensor([[855]]) tensor(-8140.1738, grad_fn=<SubBackward0>)\n",
      "loss: 10.520670890808105\n",
      "tensor([[855]]) tensor(-8092.4912, grad_fn=<SubBackward0>)\n",
      "loss: 10.4649019241333\n",
      "tensor([[855]]) tensor(-8045.0688, grad_fn=<SubBackward0>)\n",
      "loss: 10.409438133239746\n",
      "tensor([[855]]) tensor(-7996.3721, grad_fn=<SubBackward0>)\n",
      "loss: 10.352481842041016\n",
      "tensor([[855]]) tensor(-7949.6836, grad_fn=<SubBackward0>)\n",
      "loss: 10.29787540435791\n",
      "tensor([[855]]) tensor(-7904.0713, grad_fn=<SubBackward0>)\n",
      "loss: 10.244527816772461\n",
      "tensor([[855]]) tensor(-7858.6802, grad_fn=<SubBackward0>)\n",
      "loss: 10.191439628601074\n",
      "tensor([[855]]) tensor(-7812.3730, grad_fn=<SubBackward0>)\n",
      "loss: 10.13727855682373\n",
      "tensor([[855]]) tensor(-7765.0137, grad_fn=<SubBackward0>)\n",
      "loss: 10.081887245178223\n",
      "tensor([[855]]) tensor(-7717.2383, grad_fn=<SubBackward0>)\n",
      "loss: 10.026009559631348\n",
      "tensor([[855]]) tensor(-7670.6553, grad_fn=<SubBackward0>)\n",
      "loss: 9.971527099609375\n",
      "tensor([[855]]) tensor(-7624.0547, grad_fn=<SubBackward0>)\n",
      "loss: 9.917022705078125\n",
      "tensor([[855]]) tensor(-7576.4658, grad_fn=<SubBackward0>)\n",
      "loss: 9.861363410949707\n",
      "tensor([[855]]) tensor(-7532.2715, grad_fn=<SubBackward0>)\n",
      "loss: 9.809674263000488\n",
      "tensor([[855]]) tensor(-7483.0977, grad_fn=<SubBackward0>)\n",
      "loss: 9.752161026000977\n",
      "tensor([[855]]) tensor(-7437.1406, grad_fn=<SubBackward0>)\n",
      "loss: 9.698410034179688\n",
      "tensor([[855]]) tensor(-7392.3472, grad_fn=<SubBackward0>)\n",
      "loss: 9.64601993560791\n",
      "tensor([[855]]) tensor(-7346.5103, grad_fn=<SubBackward0>)\n",
      "loss: 9.592409133911133\n",
      "tensor([[855]]) tensor(-7299.0557, grad_fn=<SubBackward0>)\n",
      "loss: 9.536907196044922\n",
      "tensor([[855]]) tensor(-7253.5488, grad_fn=<SubBackward0>)\n",
      "loss: 9.483682632446289\n",
      "tensor([[855]]) tensor(-7208.1040, grad_fn=<SubBackward0>)\n",
      "loss: 9.430530548095703\n",
      "tensor([[855]]) tensor(-7162.9165, grad_fn=<SubBackward0>)\n",
      "loss: 9.377679824829102\n",
      "tensor([[855]]) tensor(-7117.1729, grad_fn=<SubBackward0>)\n",
      "loss: 9.324178695678711\n",
      "tensor([[855]]) tensor(-7073.9565, grad_fn=<SubBackward0>)\n",
      "loss: 9.273633003234863\n",
      "tensor([[855]]) tensor(-7025.6528, grad_fn=<SubBackward0>)\n",
      "loss: 9.217138290405273\n",
      "tensor([[855]]) tensor(-6993.5156, grad_fn=<SubBackward0>)\n",
      "loss: 9.179550170898438\n",
      "tensor([[855]]) tensor(-6956.4658, grad_fn=<SubBackward0>)\n",
      "loss: 9.13621711730957\n",
      "tensor([[855]]) tensor(-6915.3848, grad_fn=<SubBackward0>)\n",
      "loss: 9.08816909790039\n",
      "tensor([[855]]) tensor(-6881.9277, grad_fn=<SubBackward0>)\n",
      "loss: 9.04903793334961\n",
      "tensor([[855]]) tensor(-6854.2427, grad_fn=<SubBackward0>)\n",
      "loss: 9.016657829284668\n",
      "tensor([[855]]) tensor(-6815.1528, grad_fn=<SubBackward0>)\n",
      "loss: 8.970938682556152\n",
      "tensor([[855]]) tensor(-6782.5781, grad_fn=<SubBackward0>)\n",
      "loss: 8.932840347290039\n",
      "tensor([[855]]) tensor(-6750.1260, grad_fn=<SubBackward0>)\n",
      "loss: 8.89488410949707\n",
      "tensor([[855]]) tensor(-6717.8047, grad_fn=<SubBackward0>)\n",
      "loss: 8.857081413269043\n",
      "tensor([[855]]) tensor(-6688.1533, grad_fn=<SubBackward0>)\n",
      "loss: 8.822402000427246\n",
      "tensor([[855]]) tensor(-6659.0332, grad_fn=<SubBackward0>)\n",
      "loss: 8.788342475891113\n",
      "tensor([[855]]) tensor(-6630.8506, grad_fn=<SubBackward0>)\n",
      "loss: 8.755380630493164\n",
      "tensor([[855]]) tensor(-6600.3643, grad_fn=<SubBackward0>)\n",
      "loss: 8.719724655151367\n",
      "tensor([[855]]) tensor(-6571.3223, grad_fn=<SubBackward0>)\n",
      "loss: 8.68575668334961\n",
      "tensor([[855]]) tensor(-6543.2158, grad_fn=<SubBackward0>)\n",
      "loss: 8.652883529663086\n",
      "tensor([[855]]) tensor(-6516.1694, grad_fn=<SubBackward0>)\n",
      "loss: 8.621251106262207\n",
      "tensor([[855]]) tensor(-6489.1821, grad_fn=<SubBackward0>)\n",
      "loss: 8.589686393737793\n",
      "tensor([[855]]) tensor(-6463.6685, grad_fn=<SubBackward0>)\n",
      "loss: 8.559845924377441\n",
      "tensor([[855]]) tensor(-6438.0537, grad_fn=<SubBackward0>)\n",
      "loss: 8.529887199401855\n",
      "tensor([[855]]) tensor(-6418.3770, grad_fn=<SubBackward0>)\n",
      "loss: 8.506874084472656\n",
      "tensor([[855]]) tensor(-6397.2607, grad_fn=<SubBackward0>)\n",
      "loss: 8.482176780700684\n",
      "tensor([[855]]) tensor(-6375.8721, grad_fn=<SubBackward0>)\n",
      "loss: 8.457159996032715\n",
      "tensor([[855]]) tensor(-6354.0107, grad_fn=<SubBackward0>)\n",
      "loss: 8.431591987609863\n",
      "tensor([[855]]) tensor(-6333.3701, grad_fn=<SubBackward0>)\n",
      "loss: 8.407450675964355\n",
      "tensor([[855]]) tensor(-6314.7632, grad_fn=<SubBackward0>)\n",
      "loss: 8.385687828063965\n",
      "tensor([[855]]) tensor(-6294.3394, grad_fn=<SubBackward0>)\n",
      "loss: 8.361800193786621\n",
      "tensor([[855]]) tensor(-6271.9180, grad_fn=<SubBackward0>)\n",
      "loss: 8.335577011108398\n",
      "tensor([[855]]) tensor(-6251.8687, grad_fn=<SubBackward0>)\n",
      "loss: 8.312127113342285\n",
      "tensor([[855]]) tensor(-6233.9907, grad_fn=<SubBackward0>)\n",
      "loss: 8.291216850280762\n",
      "tensor([[855]]) tensor(-6213.2188, grad_fn=<SubBackward0>)\n",
      "loss: 8.266922950744629\n",
      "tensor([[855]]) tensor(-6196.0049, grad_fn=<SubBackward0>)\n",
      "loss: 8.24678897857666\n",
      "tensor([[855]]) tensor(-6178.1094, grad_fn=<SubBackward0>)\n",
      "loss: 8.225858688354492\n",
      "tensor([[855]]) tensor(-6158.7749, grad_fn=<SubBackward0>)\n",
      "loss: 8.203245162963867\n",
      "tensor([[855]]) tensor(-6137.4912, grad_fn=<SubBackward0>)\n",
      "loss: 8.178352355957031\n",
      "tensor([[855]]) tensor(-6118.5610, grad_fn=<SubBackward0>)\n",
      "loss: 8.156211853027344\n",
      "tensor([[855]]) tensor(-6101.0190, grad_fn=<SubBackward0>)\n",
      "loss: 8.13569450378418\n",
      "tensor([[855]]) tensor(-6080.0439, grad_fn=<SubBackward0>)\n",
      "loss: 8.111162185668945\n",
      "tensor([[855]]) tensor(-6065.6602, grad_fn=<SubBackward0>)\n",
      "loss: 8.094339370727539\n",
      "tensor([[855]]) tensor(-6050.2104, grad_fn=<SubBackward0>)\n",
      "loss: 8.076269149780273\n",
      "tensor([[855]]) tensor(-6031.7173, grad_fn=<SubBackward0>)\n",
      "loss: 8.05463981628418\n",
      "tensor([[855]]) tensor(-6013.1309, grad_fn=<SubBackward0>)\n",
      "loss: 8.032901763916016\n",
      "tensor([[855]]) tensor(-5996.5503, grad_fn=<SubBackward0>)\n",
      "loss: 8.013508796691895\n",
      "tensor([[855]]) tensor(-5979.5264, grad_fn=<SubBackward0>)\n",
      "loss: 7.993597984313965\n",
      "tensor([[855]]) tensor(-5963.9844, grad_fn=<SubBackward0>)\n",
      "loss: 7.9754204750061035\n",
      "tensor([[855]]) tensor(-5947.8579, grad_fn=<SubBackward0>)\n",
      "loss: 7.956559181213379\n",
      "tensor([[855]]) tensor(-5930.4727, grad_fn=<SubBackward0>)\n",
      "loss: 7.936225414276123\n",
      "tensor([[855]]) tensor(-5914.4980, grad_fn=<SubBackward0>)\n",
      "loss: 7.91754150390625\n",
      "tensor([[855]]) tensor(-5898.9507, grad_fn=<SubBackward0>)\n",
      "loss: 7.899357318878174\n",
      "tensor([[855]]) tensor(-5882.9468, grad_fn=<SubBackward0>)\n",
      "loss: 7.880639553070068\n",
      "tensor([[855]]) tensor(-5866.4141, grad_fn=<SubBackward0>)\n",
      "loss: 7.861302852630615\n",
      "tensor([[855]]) tensor(-5850.4360, grad_fn=<SubBackward0>)\n",
      "loss: 7.842615127563477\n",
      "tensor([[855]]) tensor(-5834.5586, grad_fn=<SubBackward0>)\n",
      "loss: 7.824045181274414\n",
      "tensor([[855]]) tensor(-5821.5181, grad_fn=<SubBackward0>)\n",
      "loss: 7.808793067932129\n",
      "tensor([[855]]) tensor(-5804.1045, grad_fn=<SubBackward0>)\n",
      "loss: 7.788426399230957\n",
      "tensor([[855]]) tensor(-5789.1729, grad_fn=<SubBackward0>)\n",
      "loss: 7.770962238311768\n",
      "tensor([[855]]) tensor(-5774.0391, grad_fn=<SubBackward0>)\n",
      "loss: 7.753262042999268\n",
      "tensor([[855]]) tensor(-5756.8452, grad_fn=<SubBackward0>)\n",
      "loss: 7.733152389526367\n",
      "tensor([[855]]) tensor(-5741.8501, grad_fn=<SubBackward0>)\n",
      "loss: 7.715614318847656\n",
      "tensor([[855]]) tensor(-5726.0186, grad_fn=<SubBackward0>)\n",
      "loss: 7.6970977783203125\n",
      "tensor([[855]]) tensor(-5710.3291, grad_fn=<SubBackward0>)\n",
      "loss: 7.678747653961182\n",
      "tensor([[855]]) tensor(-5693.8784, grad_fn=<SubBackward0>)\n",
      "loss: 7.659506797790527\n",
      "tensor([[855]]) tensor(-5681.1416, grad_fn=<SubBackward0>)\n",
      "loss: 7.6446099281311035\n",
      "tensor([[855]]) tensor(-5664.3081, grad_fn=<SubBackward0>)\n",
      "loss: 7.624921798706055\n",
      "tensor([[855]]) tensor(-5648.7188, grad_fn=<SubBackward0>)\n",
      "loss: 7.606688499450684\n",
      "tensor([[855]]) tensor(-5634.6787, grad_fn=<SubBackward0>)\n",
      "loss: 7.590267658233643\n",
      "tensor([[855]]) tensor(-5617.2979, grad_fn=<SubBackward0>)\n",
      "loss: 7.569939136505127\n",
      "tensor([[855]]) tensor(-5600.8887, grad_fn=<SubBackward0>)\n",
      "loss: 7.550746917724609\n",
      "tensor([[855]]) tensor(-5587.1328, grad_fn=<SubBackward0>)\n",
      "loss: 7.534658432006836\n",
      "tensor([[855]]) tensor(-5569.6870, grad_fn=<SubBackward0>)\n",
      "loss: 7.514253616333008\n",
      "tensor([[855]]) tensor(-5556.8477, grad_fn=<SubBackward0>)\n",
      "loss: 7.499237060546875\n",
      "tensor([[855]]) tensor(-5543.2476, grad_fn=<SubBackward0>)\n",
      "loss: 7.483330249786377\n",
      "tensor([[855]]) tensor(-5526.6553, grad_fn=<SubBackward0>)\n",
      "loss: 7.463924407958984\n",
      "tensor([[855]]) tensor(-5510.3428, grad_fn=<SubBackward0>)\n",
      "loss: 7.444845199584961\n",
      "tensor([[855]]) tensor(-5492.8267, grad_fn=<SubBackward0>)\n",
      "loss: 7.42435884475708\n",
      "tensor([[855]]) tensor(-5479.7515, grad_fn=<SubBackward0>)\n",
      "loss: 7.409066200256348\n",
      "tensor([[855]]) tensor(-5462.5205, grad_fn=<SubBackward0>)\n",
      "loss: 7.388912677764893\n",
      "tensor([[855]]) tensor(-5447.5605, grad_fn=<SubBackward0>)\n",
      "loss: 7.371415615081787\n",
      "tensor([[855]]) tensor(-5432.2715, grad_fn=<SubBackward0>)\n",
      "loss: 7.353533744812012\n",
      "tensor([[855]]) tensor(-5415.6816, grad_fn=<SubBackward0>)\n",
      "loss: 7.334130764007568\n",
      "tensor([[855]]) tensor(-5402.0430, grad_fn=<SubBackward0>)\n",
      "loss: 7.318179130554199\n",
      "tensor([[855]]) tensor(-5387.5962, grad_fn=<SubBackward0>)\n",
      "loss: 7.301281929016113\n",
      "tensor([[855]]) tensor(-5369.2466, grad_fn=<SubBackward0>)\n",
      "loss: 7.279820442199707\n",
      "tensor([[855]]) tensor(-5354.6904, grad_fn=<SubBackward0>)\n",
      "loss: 7.262795925140381\n",
      "tensor([[855]]) tensor(-5338.3315, grad_fn=<SubBackward0>)\n",
      "loss: 7.2436628341674805\n",
      "tensor([[855]]) tensor(-5325.6611, grad_fn=<SubBackward0>)\n",
      "loss: 7.2288432121276855\n",
      "tensor([[855]]) tensor(-5313.5605, grad_fn=<SubBackward0>)\n",
      "loss: 7.214690685272217\n",
      "tensor([[855]]) tensor(-5298.0889, grad_fn=<SubBackward0>)\n",
      "loss: 7.196595191955566\n",
      "tensor([[855]]) tensor(-5289.6987, grad_fn=<SubBackward0>)\n",
      "loss: 7.186782360076904\n",
      "tensor([[855]]) tensor(-5276.0771, grad_fn=<SubBackward0>)\n",
      "loss: 7.1708502769470215\n",
      "tensor([[855]]) tensor(-5264.8696, grad_fn=<SubBackward0>)\n",
      "loss: 7.157742023468018\n",
      "tensor([[855]]) tensor(-5253.0708, grad_fn=<SubBackward0>)\n",
      "loss: 7.143942356109619\n",
      "tensor([[855]]) tensor(-5239.8027, grad_fn=<SubBackward0>)\n",
      "loss: 7.128424167633057\n",
      "tensor([[855]]) tensor(-5230.8662, grad_fn=<SubBackward0>)\n",
      "loss: 7.117972373962402\n",
      "tensor([[855]]) tensor(-5216.6152, grad_fn=<SubBackward0>)\n",
      "loss: 7.101304531097412\n",
      "tensor([[855]]) tensor(-5200.5269, grad_fn=<SubBackward0>)\n",
      "loss: 7.0824875831604\n",
      "tensor([[855]]) tensor(-5190.8135, grad_fn=<SubBackward0>)\n",
      "loss: 7.071126937866211\n",
      "tensor([[855]]) tensor(-5179.1079, grad_fn=<SubBackward0>)\n",
      "loss: 7.057435989379883\n",
      "tensor([[855]]) tensor(-5165.5449, grad_fn=<SubBackward0>)\n",
      "loss: 7.0415730476379395\n",
      "tensor([[855]]) tensor(-5153.4482, grad_fn=<SubBackward0>)\n",
      "loss: 7.0274248123168945\n",
      "tensor([[855]]) tensor(-5137.7637, grad_fn=<SubBackward0>)\n",
      "loss: 7.009080410003662\n",
      "tensor([[855]]) tensor(-5121.8682, grad_fn=<SubBackward0>)\n",
      "loss: 6.9904890060424805\n",
      "tensor([[855]]) tensor(-5111.4438, grad_fn=<SubBackward0>)\n",
      "loss: 6.978296756744385\n",
      "tensor([[855]]) tensor(-5096.5195, grad_fn=<SubBackward0>)\n",
      "loss: 6.960841655731201\n",
      "tensor([[855]]) tensor(-5086.9902, grad_fn=<SubBackward0>)\n",
      "loss: 6.949696063995361\n",
      "tensor([[855]]) tensor(-5075.3462, grad_fn=<SubBackward0>)\n",
      "loss: 6.93607759475708\n",
      "tensor([[855]]) tensor(-5061.5889, grad_fn=<SubBackward0>)\n",
      "loss: 6.919987201690674\n",
      "tensor([[855]]) tensor(-5047.3306, grad_fn=<SubBackward0>)\n",
      "loss: 6.903310775756836\n",
      "tensor([[855]]) tensor(-5032.5488, grad_fn=<SubBackward0>)\n",
      "loss: 6.886022090911865\n",
      "tensor([[855]]) tensor(-5021.7466, grad_fn=<SubBackward0>)\n",
      "loss: 6.873387813568115\n",
      "tensor([[855]]) tensor(-5007.9858, grad_fn=<SubBackward0>)\n",
      "loss: 6.857293605804443\n",
      "tensor([[855]]) tensor(-4994.6807, grad_fn=<SubBackward0>)\n",
      "loss: 6.841731548309326\n",
      "tensor([[855]]) tensor(-4979.9976, grad_fn=<SubBackward0>)\n",
      "loss: 6.824558734893799\n",
      "tensor([[855]]) tensor(-4972.5083, grad_fn=<SubBackward0>)\n",
      "loss: 6.815799236297607\n",
      "tensor([[855]]) tensor(-4955.8882, grad_fn=<SubBackward0>)\n",
      "loss: 6.796360492706299\n",
      "tensor([[855]]) tensor(-4942.7539, grad_fn=<SubBackward0>)\n",
      "loss: 6.780998706817627\n",
      "tensor([[855]]) tensor(-4931.6689, grad_fn=<SubBackward0>)\n",
      "loss: 6.768033981323242\n",
      "tensor([[855]]) tensor(-4917.8350, grad_fn=<SubBackward0>)\n",
      "loss: 6.751853942871094\n",
      "tensor([[855]]) tensor(-4904.2422, grad_fn=<SubBackward0>)\n",
      "loss: 6.735955715179443\n",
      "tensor([[855]]) tensor(-4894.2295, grad_fn=<SubBackward0>)\n",
      "loss: 6.724245071411133\n",
      "tensor([[855]]) tensor(-4880.0166, grad_fn=<SubBackward0>)\n",
      "loss: 6.7076215744018555\n",
      "tensor([[855]]) tensor(-4866.7124, grad_fn=<SubBackward0>)\n",
      "loss: 6.692061424255371\n",
      "tensor([[855]]) tensor(-4853.6494, grad_fn=<SubBackward0>)\n",
      "loss: 6.676783084869385\n",
      "tensor([[855]]) tensor(-4840.7246, grad_fn=<SubBackward0>)\n",
      "loss: 6.661666393280029\n",
      "tensor([[855]]) tensor(-4829.2021, grad_fn=<SubBackward0>)\n",
      "loss: 6.648189544677734\n",
      "tensor([[855]]) tensor(-4815.6284, grad_fn=<SubBackward0>)\n",
      "loss: 6.6323137283325195\n",
      "tensor([[855]]) tensor(-4804.1479, grad_fn=<SubBackward0>)\n",
      "loss: 6.618886470794678\n",
      "tensor([[855]]) tensor(-4793.4648, grad_fn=<SubBackward0>)\n",
      "loss: 6.606391429901123\n",
      "tensor([[855]]) tensor(-4779.4893, grad_fn=<SubBackward0>)\n",
      "loss: 6.590045928955078\n",
      "tensor([[855]]) tensor(-4770.4951, grad_fn=<SubBackward0>)\n",
      "loss: 6.579526424407959\n",
      "tensor([[855]]) tensor(-4759.4072, grad_fn=<SubBackward0>)\n",
      "loss: 6.566558361053467\n",
      "tensor([[855]]) tensor(-4744.4219, grad_fn=<SubBackward0>)\n",
      "loss: 6.5490312576293945\n",
      "tensor([[855]]) tensor(-4735.5107, grad_fn=<SubBackward0>)\n",
      "loss: 6.538609027862549\n",
      "tensor([[855]]) tensor(-4725.8623, grad_fn=<SubBackward0>)\n",
      "loss: 6.527324199676514\n",
      "tensor([[855]]) tensor(-4713.7271, grad_fn=<SubBackward0>)\n",
      "loss: 6.513131141662598\n",
      "tensor([[855]]) tensor(-4701.6885, grad_fn=<SubBackward0>)\n",
      "loss: 6.499050617218018\n",
      "tensor([[855]]) tensor(-4687.8652, grad_fn=<SubBackward0>)\n",
      "loss: 6.482883453369141\n",
      "tensor([[855]]) tensor(-4673.6772, grad_fn=<SubBackward0>)\n",
      "loss: 6.466289043426514\n",
      "tensor([[855]]) tensor(-4664.1079, grad_fn=<SubBackward0>)\n",
      "loss: 6.455097198486328\n",
      "tensor([[855]]) tensor(-4652.6445, grad_fn=<SubBackward0>)\n",
      "loss: 6.441689491271973\n",
      "tensor([[855]]) tensor(-4640.0176, grad_fn=<SubBackward0>)\n",
      "loss: 6.426921367645264\n",
      "tensor([[855]]) tensor(-4628.4136, grad_fn=<SubBackward0>)\n",
      "loss: 6.413349151611328\n",
      "tensor([[855]]) tensor(-4621.3965, grad_fn=<SubBackward0>)\n",
      "loss: 6.405142307281494\n",
      "tensor([[855]]) tensor(-4609.9688, grad_fn=<SubBackward0>)\n",
      "loss: 6.391776084899902\n",
      "tensor([[855]]) tensor(-4593.8926, grad_fn=<SubBackward0>)\n",
      "loss: 6.372973918914795\n",
      "tensor([[855]]) tensor(-4584.5010, grad_fn=<SubBackward0>)\n",
      "loss: 6.361989498138428\n",
      "tensor([[855]]) tensor(-4575.4307, grad_fn=<SubBackward0>)\n",
      "loss: 6.351380825042725\n",
      "tensor([[855]]) tensor(-4563.9326, grad_fn=<SubBackward0>)\n",
      "loss: 6.33793306350708\n",
      "tensor([[855]]) tensor(-4553.4766, grad_fn=<SubBackward0>)\n",
      "loss: 6.3257036209106445\n",
      "tensor([[855]]) tensor(-4540.2793, grad_fn=<SubBackward0>)\n",
      "loss: 6.310268402099609\n",
      "tensor([[855]]) tensor(-4525.8188, grad_fn=<SubBackward0>)\n",
      "loss: 6.293355464935303\n",
      "tensor([[855]]) tensor(-4514.8164, grad_fn=<SubBackward0>)\n",
      "loss: 6.280487060546875\n",
      "tensor([[855]]) tensor(-4504.2480, grad_fn=<SubBackward0>)\n",
      "loss: 6.268126487731934\n",
      "tensor([[855]]) tensor(-4494.0986, grad_fn=<SubBackward0>)\n",
      "loss: 6.256255626678467\n",
      "tensor([[855]]) tensor(-4483.1543, grad_fn=<SubBackward0>)\n",
      "loss: 6.243455410003662\n",
      "tensor([[855]]) tensor(-4473.7583, grad_fn=<SubBackward0>)\n",
      "loss: 6.232465744018555\n",
      "tensor([[855]]) tensor(-4463.8555, grad_fn=<SubBackward0>)\n",
      "loss: 6.220883369445801\n",
      "tensor([[855]]) tensor(-4455.8018, grad_fn=<SubBackward0>)\n",
      "loss: 6.211463928222656\n",
      "tensor([[855]]) tensor(-4446.7178, grad_fn=<SubBackward0>)\n",
      "loss: 6.200839519500732\n",
      "tensor([[855]]) tensor(-4436.0044, grad_fn=<SubBackward0>)\n",
      "loss: 6.188309192657471\n",
      "tensor([[855]]) tensor(-4429.1611, grad_fn=<SubBackward0>)\n",
      "loss: 6.180305480957031\n",
      "tensor([[855]]) tensor(-4418.7607, grad_fn=<SubBackward0>)\n",
      "loss: 6.1681413650512695\n",
      "tensor([[855]]) tensor(-4408.3882, grad_fn=<SubBackward0>)\n",
      "loss: 6.156009674072266\n",
      "tensor([[855]]) tensor(-4398.9434, grad_fn=<SubBackward0>)\n",
      "loss: 6.144962787628174\n",
      "tensor([[855]]) tensor(-4389.3701, grad_fn=<SubBackward0>)\n",
      "loss: 6.133766174316406\n",
      "tensor([[855]]) tensor(-4379.1362, grad_fn=<SubBackward0>)\n",
      "loss: 6.121796607971191\n",
      "tensor([[855]]) tensor(-4368.2612, grad_fn=<SubBackward0>)\n",
      "loss: 6.109077453613281\n",
      "tensor([[855]]) tensor(-4356.9146, grad_fn=<SubBackward0>)\n",
      "loss: 6.09580659866333\n",
      "tensor([[855]]) tensor(-4345.8652, grad_fn=<SubBackward0>)\n",
      "loss: 6.082883358001709\n",
      "tensor([[855]]) tensor(-4336.1855, grad_fn=<SubBackward0>)\n",
      "loss: 6.071561813354492\n",
      "tensor([[855]]) tensor(-4324.8848, grad_fn=<SubBackward0>)\n",
      "loss: 6.058344841003418\n",
      "tensor([[855]]) tensor(-4323.0566, grad_fn=<SubBackward0>)\n",
      "loss: 6.056206703186035\n",
      "tensor([[855]]) tensor(-4315.0737, grad_fn=<SubBackward0>)\n",
      "loss: 6.04686975479126\n",
      "tensor([[855]]) tensor(-4301.9600, grad_fn=<SubBackward0>)\n",
      "loss: 6.031532287597656\n",
      "tensor([[855]]) tensor(-4295.5234, grad_fn=<SubBackward0>)\n",
      "loss: 6.024003982543945\n",
      "tensor([[855]]) tensor(-4286.5532, grad_fn=<SubBackward0>)\n",
      "loss: 6.01351261138916\n",
      "tensor([[855]]) tensor(-4273.3687, grad_fn=<SubBackward0>)\n",
      "loss: 5.998092174530029\n",
      "tensor([[855]]) tensor(-4275.9375, grad_fn=<SubBackward0>)\n",
      "loss: 6.001096725463867\n",
      "tensor([[855]]) tensor(-4271.0308, grad_fn=<SubBackward0>)\n",
      "loss: 5.995357513427734\n",
      "tensor([[855]]) tensor(-4258.3813, grad_fn=<SubBackward0>)\n",
      "loss: 5.980563163757324\n",
      "tensor([[855]]) tensor(-4242.1177, grad_fn=<SubBackward0>)\n",
      "loss: 5.961541175842285\n",
      "tensor([[855]]) tensor(-4236.1660, grad_fn=<SubBackward0>)\n",
      "loss: 5.954580307006836\n",
      "tensor([[855]]) tensor(-4224.7466, grad_fn=<SubBackward0>)\n",
      "loss: 5.941224098205566\n",
      "tensor([[855]]) tensor(-4215.3301, grad_fn=<SubBackward0>)\n",
      "loss: 5.930210590362549\n",
      "tensor([[855]]) tensor(-4208.7168, grad_fn=<SubBackward0>)\n",
      "loss: 5.922475814819336\n",
      "tensor([[855]]) tensor(-4199.0493, grad_fn=<SubBackward0>)\n",
      "loss: 5.911168575286865\n",
      "tensor([[855]]) tensor(-4190.3945, grad_fn=<SubBackward0>)\n",
      "loss: 5.901046276092529\n",
      "tensor([[855]]) tensor(-4184.9014, grad_fn=<SubBackward0>)\n",
      "loss: 5.8946213722229\n",
      "tensor([[855]]) tensor(-4174.5840, grad_fn=<SubBackward0>)\n",
      "loss: 5.882554531097412\n",
      "tensor([[855]]) tensor(-4166.7354, grad_fn=<SubBackward0>)\n",
      "loss: 5.8733744621276855\n",
      "tensor([[855]]) tensor(-4158.0205, grad_fn=<SubBackward0>)\n",
      "loss: 5.863182067871094\n",
      "tensor([[855]]) tensor(-4154.2368, grad_fn=<SubBackward0>)\n",
      "loss: 5.8587565422058105\n",
      "tensor([[855]]) tensor(-4142.9761, grad_fn=<SubBackward0>)\n",
      "loss: 5.845585823059082\n",
      "tensor([[855]]) tensor(-4136.2686, grad_fn=<SubBackward0>)\n",
      "loss: 5.837740898132324\n",
      "tensor([[855]]) tensor(-4126.4375, grad_fn=<SubBackward0>)\n",
      "loss: 5.826242923736572\n",
      "tensor([[855]]) tensor(-4118.2993, grad_fn=<SubBackward0>)\n",
      "loss: 5.8167243003845215\n",
      "tensor([[855]]) tensor(-4111.8999, grad_fn=<SubBackward0>)\n",
      "loss: 5.809239864349365\n",
      "tensor([[855]]) tensor(-4101.7812, grad_fn=<SubBackward0>)\n",
      "loss: 5.797404766082764\n",
      "tensor([[855]]) tensor(-4101.6426, grad_fn=<SubBackward0>)\n",
      "loss: 5.797242641448975\n",
      "tensor([[855]]) tensor(-4094.7290, grad_fn=<SubBackward0>)\n",
      "loss: 5.789156913757324\n",
      "tensor([[855]]) tensor(-4080.1089, grad_fn=<SubBackward0>)\n",
      "loss: 5.772057056427002\n",
      "tensor([[855]]) tensor(-4076.7646, grad_fn=<SubBackward0>)\n",
      "loss: 5.768145561218262\n",
      "tensor([[855]]) tensor(-4069.0840, grad_fn=<SubBackward0>)\n",
      "loss: 5.759162425994873\n",
      "tensor([[855]]) tensor(-4060.9575, grad_fn=<SubBackward0>)\n",
      "loss: 5.749658107757568\n",
      "tensor([[855]]) tensor(-4053.5332, grad_fn=<SubBackward0>)\n",
      "loss: 5.740974426269531\n",
      "tensor([[855]]) tensor(-4044.8521, grad_fn=<SubBackward0>)\n",
      "loss: 5.730821132659912\n",
      "tensor([[855]]) tensor(-4036.0793, grad_fn=<SubBackward0>)\n",
      "loss: 5.720560550689697\n",
      "tensor([[855]]) tensor(-4029.6665, grad_fn=<SubBackward0>)\n",
      "loss: 5.71306037902832\n",
      "tensor([[855]]) tensor(-4019.7358, grad_fn=<SubBackward0>)\n",
      "loss: 5.701445579528809\n",
      "tensor([[855]]) tensor(-4011.3430, grad_fn=<SubBackward0>)\n",
      "loss: 5.691628932952881\n",
      "tensor([[855]]) tensor(-4001.2666, grad_fn=<SubBackward0>)\n",
      "loss: 5.679843902587891\n",
      "tensor([[855]]) tensor(-3990.3479, grad_fn=<SubBackward0>)\n",
      "loss: 5.6670732498168945\n",
      "tensor([[855]]) tensor(-3985.0876, grad_fn=<SubBackward0>)\n",
      "loss: 5.660921573638916\n",
      "tensor([[855]]) tensor(-3974.9834, grad_fn=<SubBackward0>)\n",
      "loss: 5.649103164672852\n",
      "tensor([[855]]) tensor(-3968.2310, grad_fn=<SubBackward0>)\n",
      "loss: 5.641205787658691\n",
      "tensor([[855]]) tensor(-3961.4363, grad_fn=<SubBackward0>)\n",
      "loss: 5.633259296417236\n",
      "tensor([[855]]) tensor(-3956.8064, grad_fn=<SubBackward0>)\n",
      "loss: 5.627843856811523\n",
      "tensor([[855]]) tensor(-3947.6655, grad_fn=<SubBackward0>)\n",
      "loss: 5.617152690887451\n",
      "tensor([[855]]) tensor(-3939.0317, grad_fn=<SubBackward0>)\n",
      "loss: 5.607054710388184\n",
      "tensor([[855]]) tensor(-3928.9783, grad_fn=<SubBackward0>)\n",
      "loss: 5.5952959060668945\n",
      "tensor([[855]]) tensor(-3921.6213, grad_fn=<SubBackward0>)\n",
      "loss: 5.586691856384277\n",
      "tensor([[855]]) tensor(-3909.8267, grad_fn=<SubBackward0>)\n",
      "loss: 5.572896480560303\n",
      "tensor([[855]]) tensor(-3908.3179, grad_fn=<SubBackward0>)\n",
      "loss: 5.571132183074951\n",
      "tensor([[855]]) tensor(-3903.6553, grad_fn=<SubBackward0>)\n",
      "loss: 5.565678596496582\n",
      "tensor([[855]]) tensor(-3889.2087, grad_fn=<SubBackward0>)\n",
      "loss: 5.5487823486328125\n",
      "tensor([[855]]) tensor(-3880.9790, grad_fn=<SubBackward0>)\n",
      "loss: 5.539156913757324\n",
      "tensor([[855]]) tensor(-3877.8584, grad_fn=<SubBackward0>)\n",
      "loss: 5.535506725311279\n",
      "tensor([[855]]) tensor(-3866.5850, grad_fn=<SubBackward0>)\n",
      "loss: 5.522321701049805\n",
      "tensor([[855]]) tensor(-3859.6558, grad_fn=<SubBackward0>)\n",
      "loss: 5.514217376708984\n",
      "tensor([[855]]) tensor(-3850.8276, grad_fn=<SubBackward0>)\n",
      "loss: 5.503891944885254\n",
      "tensor([[855]]) tensor(-3840.3040, grad_fn=<SubBackward0>)\n",
      "loss: 5.491583824157715\n",
      "tensor([[855]]) tensor(-3831.3823, grad_fn=<SubBackward0>)\n",
      "loss: 5.481148719787598\n",
      "tensor([[855]]) tensor(-3824.3359, grad_fn=<SubBackward0>)\n",
      "loss: 5.472907543182373\n",
      "tensor([[855]]) tensor(-3819.0137, grad_fn=<SubBackward0>)\n",
      "loss: 5.466682434082031\n",
      "tensor([[855]]) tensor(-3811.4373, grad_fn=<SubBackward0>)\n",
      "loss: 5.457820892333984\n",
      "tensor([[855]]) tensor(-3798.4473, grad_fn=<SubBackward0>)\n",
      "loss: 5.442628383636475\n",
      "tensor([[855]]) tensor(-3795.2146, grad_fn=<SubBackward0>)\n",
      "loss: 5.438847541809082\n",
      "tensor([[855]]) tensor(-3788.1401, grad_fn=<SubBackward0>)\n",
      "loss: 5.430573463439941\n",
      "tensor([[855]]) tensor(-3781.0588, grad_fn=<SubBackward0>)\n",
      "loss: 5.422290802001953\n",
      "tensor([[855]]) tensor(-3777.7119, grad_fn=<SubBackward0>)\n",
      "loss: 5.418376445770264\n",
      "tensor([[855]]) tensor(-3767.3611, grad_fn=<SubBackward0>)\n",
      "loss: 5.4062700271606445\n",
      "tensor([[855]]) tensor(-3756.4111, grad_fn=<SubBackward0>)\n",
      "loss: 5.393463134765625\n",
      "tensor([[855]]) tensor(-3752.5359, grad_fn=<SubBackward0>)\n",
      "loss: 5.388930797576904\n",
      "tensor([[855]]) tensor(-3743.4424, grad_fn=<SubBackward0>)\n",
      "loss: 5.378295421600342\n",
      "tensor([[855]]) tensor(-3732.5249, grad_fn=<SubBackward0>)\n",
      "loss: 5.36552619934082\n",
      "tensor([[855]]) tensor(-3724.8896, grad_fn=<SubBackward0>)\n",
      "loss: 5.356595993041992\n",
      "tensor([[855]]) tensor(-3715.7192, grad_fn=<SubBackward0>)\n",
      "loss: 5.345870494842529\n",
      "tensor([[855]]) tensor(-3708.7910, grad_fn=<SubBackward0>)\n",
      "loss: 5.337767124176025\n",
      "tensor([[855]]) tensor(-3699.6238, grad_fn=<SubBackward0>)\n",
      "loss: 5.327045440673828\n",
      "tensor([[855]]) tensor(-3695.1377, grad_fn=<SubBackward0>)\n",
      "loss: 5.321798324584961\n",
      "tensor([[855]]) tensor(-3685.1846, grad_fn=<SubBackward0>)\n",
      "loss: 5.310157299041748\n",
      "tensor([[855]]) tensor(-3676.9670, grad_fn=<SubBackward0>)\n",
      "loss: 5.300546646118164\n",
      "tensor([[855]]) tensor(-3668.7717, grad_fn=<SubBackward0>)\n",
      "loss: 5.290961265563965\n",
      "tensor([[855]]) tensor(-3660.3289, grad_fn=<SubBackward0>)\n",
      "loss: 5.281086444854736\n",
      "tensor([[855]]) tensor(-3654.0015, grad_fn=<SubBackward0>)\n",
      "loss: 5.273685932159424\n",
      "tensor([[855]]) tensor(-3647.2649, grad_fn=<SubBackward0>)\n",
      "loss: 5.265806674957275\n",
      "tensor([[855]]) tensor(-3640.9590, grad_fn=<SubBackward0>)\n",
      "loss: 5.258431434631348\n",
      "tensor([[855]]) tensor(-3630.8296, grad_fn=<SubBackward0>)\n",
      "loss: 5.246584415435791\n",
      "tensor([[855]]) tensor(-3625.3838, grad_fn=<SubBackward0>)\n",
      "loss: 5.240214824676514\n",
      "tensor([[855]]) tensor(-3616.5417, grad_fn=<SubBackward0>)\n",
      "loss: 5.2298736572265625\n",
      "tensor([[855]]) tensor(-3614.0862, grad_fn=<SubBackward0>)\n",
      "loss: 5.227001190185547\n",
      "tensor([[855]]) tensor(-3602.8896, grad_fn=<SubBackward0>)\n",
      "loss: 5.2139058113098145\n",
      "tensor([[855]]) tensor(-3595.5415, grad_fn=<SubBackward0>)\n",
      "loss: 5.2053117752075195\n",
      "tensor([[855]]) tensor(-3586.7100, grad_fn=<SubBackward0>)\n",
      "loss: 5.194982528686523\n",
      "tensor([[855]]) tensor(-3579.8982, grad_fn=<SubBackward0>)\n",
      "loss: 5.187015533447266\n",
      "tensor([[855]]) tensor(-3573.7522, grad_fn=<SubBackward0>)\n",
      "loss: 5.179826736450195\n",
      "tensor([[855]]) tensor(-3566.0583, grad_fn=<SubBackward0>)\n",
      "loss: 5.170828819274902\n",
      "tensor([[855]]) tensor(-3558.7158, grad_fn=<SubBackward0>)\n",
      "loss: 5.162240505218506\n",
      "tensor([[855]]) tensor(-3546.9478, grad_fn=<SubBackward0>)\n",
      "loss: 5.148477077484131\n",
      "tensor([[855]]) tensor(-3545.0830, grad_fn=<SubBackward0>)\n",
      "loss: 5.14629602432251\n",
      "tensor([[855]]) tensor(-3538.7434, grad_fn=<SubBackward0>)\n",
      "loss: 5.138881683349609\n",
      "tensor([[855]]) tensor(-3528.1106, grad_fn=<SubBackward0>)\n",
      "loss: 5.1264448165893555\n",
      "tensor([[855]]) tensor(-3520.2441, grad_fn=<SubBackward0>)\n",
      "loss: 5.117244720458984\n",
      "tensor([[855]]) tensor(-3516.9810, grad_fn=<SubBackward0>)\n",
      "loss: 5.113428115844727\n",
      "tensor([[855]]) tensor(-3505.0457, grad_fn=<SubBackward0>)\n",
      "loss: 5.099468231201172\n",
      "tensor([[855]]) tensor(-3500.9473, grad_fn=<SubBackward0>)\n",
      "loss: 5.094675064086914\n",
      "tensor([[855]]) tensor(-3498.0513, grad_fn=<SubBackward0>)\n",
      "loss: 5.091288089752197\n",
      "tensor([[855]]) tensor(-3487.5498, grad_fn=<SubBackward0>)\n",
      "loss: 5.079005718231201\n",
      "tensor([[855]]) tensor(-3476.1245, grad_fn=<SubBackward0>)\n",
      "loss: 5.065642833709717\n",
      "tensor([[855]]) tensor(-3468.3691, grad_fn=<SubBackward0>)\n",
      "loss: 5.056571960449219\n",
      "tensor([[855]]) tensor(-3458.1958, grad_fn=<SubBackward0>)\n",
      "loss: 5.044673442840576\n",
      "tensor([[855]]) tensor(-3452.0598, grad_fn=<SubBackward0>)\n",
      "loss: 5.037496566772461\n",
      "tensor([[855]]) tensor(-3445.3826, grad_fn=<SubBackward0>)\n",
      "loss: 5.029687404632568\n",
      "tensor([[855]]) tensor(-3435.7693, grad_fn=<SubBackward0>)\n",
      "loss: 5.018444061279297\n",
      "tensor([[855]]) tensor(-3429.9385, grad_fn=<SubBackward0>)\n",
      "loss: 5.011623859405518\n",
      "tensor([[855]]) tensor(-3418.5674, grad_fn=<SubBackward0>)\n",
      "loss: 4.998324394226074\n",
      "tensor([[855]]) tensor(-3411.4619, grad_fn=<SubBackward0>)\n",
      "loss: 4.99001407623291\n",
      "tensor([[855]]) tensor(-3407.3723, grad_fn=<SubBackward0>)\n",
      "loss: 4.985230445861816\n",
      "tensor([[855]]) tensor(-3400.3545, grad_fn=<SubBackward0>)\n",
      "loss: 4.977022647857666\n",
      "tensor([[855]]) tensor(-3390.6155, grad_fn=<SubBackward0>)\n",
      "loss: 4.965632438659668\n",
      "tensor([[855]]) tensor(-3383.2837, grad_fn=<SubBackward0>)\n",
      "loss: 4.957056999206543\n",
      "tensor([[855]]) tensor(-3376.1201, grad_fn=<SubBackward0>)\n",
      "loss: 4.948678493499756\n",
      "tensor([[855]]) tensor(-3366.6318, grad_fn=<SubBackward0>)\n",
      "loss: 4.9375810623168945\n",
      "tensor([[855]]) tensor(-3364.7673, grad_fn=<SubBackward0>)\n",
      "loss: 4.935400485992432\n",
      "tensor([[855]]) tensor(-3357.3208, grad_fn=<SubBackward0>)\n",
      "loss: 4.926691055297852\n",
      "tensor([[855]]) tensor(-3344.8618, grad_fn=<SubBackward0>)\n",
      "loss: 4.912118911743164\n",
      "tensor([[855]]) tensor(-3338.3679, grad_fn=<SubBackward0>)\n",
      "loss: 4.904524326324463\n",
      "tensor([[855]]) tensor(-3327.7229, grad_fn=<SubBackward0>)\n",
      "loss: 4.892073154449463\n",
      "tensor([[855]]) tensor(-3325.9028, grad_fn=<SubBackward0>)\n",
      "loss: 4.889945030212402\n",
      "tensor([[855]]) tensor(-3315.9048, grad_fn=<SubBackward0>)\n",
      "loss: 4.878251075744629\n",
      "tensor([[855]]) tensor(-3306.9580, grad_fn=<SubBackward0>)\n",
      "loss: 4.8677873611450195\n",
      "tensor([[855]]) tensor(-3298.8071, grad_fn=<SubBackward0>)\n",
      "loss: 4.8582539558410645\n",
      "tensor([[855]]) tensor(-3288.7183, grad_fn=<SubBackward0>)\n",
      "loss: 4.84645414352417\n",
      "tensor([[855]]) tensor(-3284.9622, grad_fn=<SubBackward0>)\n",
      "loss: 4.842061519622803\n",
      "tensor([[855]]) tensor(-3276.2466, grad_fn=<SubBackward0>)\n",
      "loss: 4.831867218017578\n",
      "tensor([[855]]) tensor(-3266.0710, grad_fn=<SubBackward0>)\n",
      "loss: 4.819965839385986\n",
      "tensor([[855]]) tensor(-3259.6758, grad_fn=<SubBackward0>)\n",
      "loss: 4.812486171722412\n",
      "tensor([[855]]) tensor(-3252.9099, grad_fn=<SubBackward0>)\n",
      "loss: 4.804573059082031\n",
      "tensor([[855]]) tensor(-3245.5144, grad_fn=<SubBackward0>)\n",
      "loss: 4.795923709869385\n",
      "tensor([[855]]) tensor(-3236.5945, grad_fn=<SubBackward0>)\n",
      "loss: 4.7854905128479\n",
      "tensor([[855]]) tensor(-3229.8804, grad_fn=<SubBackward0>)\n",
      "loss: 4.777637958526611\n",
      "tensor([[855]]) tensor(-3222.0725, grad_fn=<SubBackward0>)\n",
      "loss: 4.768506050109863\n",
      "tensor([[855]]) tensor(-3213.7886, grad_fn=<SubBackward0>)\n",
      "loss: 4.758817195892334\n",
      "tensor([[855]]) tensor(-3207.2295, grad_fn=<SubBackward0>)\n",
      "loss: 4.751145839691162\n",
      "tensor([[855]]) tensor(-3196.6140, grad_fn=<SubBackward0>)\n",
      "loss: 4.738729953765869\n",
      "tensor([[855]]) tensor(-3190.3906, grad_fn=<SubBackward0>)\n",
      "loss: 4.731451034545898\n",
      "tensor([[855]]) tensor(-3183.4688, grad_fn=<SubBackward0>)\n",
      "loss: 4.723355293273926\n",
      "tensor([[855]]) tensor(-3173.0027, grad_fn=<SubBackward0>)\n",
      "loss: 4.711114406585693\n",
      "tensor([[855]]) tensor(-3163.4072, grad_fn=<SubBackward0>)\n",
      "loss: 4.699891567230225\n",
      "tensor([[855]]) tensor(-3157.2297, grad_fn=<SubBackward0>)\n",
      "loss: 4.692666530609131\n",
      "tensor([[855]]) tensor(-3150.9404, grad_fn=<SubBackward0>)\n",
      "loss: 4.685310363769531\n",
      "tensor([[855]]) tensor(-3142.0664, grad_fn=<SubBackward0>)\n",
      "loss: 4.674931526184082\n",
      "tensor([[855]]) tensor(-3138.6997, grad_fn=<SubBackward0>)\n",
      "loss: 4.670993804931641\n",
      "tensor([[855]]) tensor(-3128.6914, grad_fn=<SubBackward0>)\n",
      "loss: 4.65928840637207\n",
      "tensor([[855]]) tensor(-3124.1641, grad_fn=<SubBackward0>)\n",
      "loss: 4.653993129730225\n",
      "tensor([[855]]) tensor(-3114.7339, grad_fn=<SubBackward0>)\n",
      "loss: 4.642963409423828\n",
      "tensor([[855]]) tensor(-3106.4802, grad_fn=<SubBackward0>)\n",
      "loss: 4.633310317993164\n",
      "tensor([[855]]) tensor(-3099.1836, grad_fn=<SubBackward0>)\n",
      "loss: 4.624776363372803\n",
      "tensor([[855]]) tensor(-3087.9939, grad_fn=<SubBackward0>)\n",
      "loss: 4.611688613891602\n",
      "tensor([[855]]) tensor(-3078.8926, grad_fn=<SubBackward0>)\n",
      "loss: 4.601044178009033\n",
      "tensor([[855]]) tensor(-3072.7119, grad_fn=<SubBackward0>)\n",
      "loss: 4.593815326690674\n",
      "tensor([[855]]) tensor(-3063.9824, grad_fn=<SubBackward0>)\n",
      "loss: 4.5836052894592285\n",
      "tensor([[855]]) tensor(-3059.6479, grad_fn=<SubBackward0>)\n",
      "loss: 4.578535556793213\n",
      "tensor([[855]]) tensor(-3050.9084, grad_fn=<SubBackward0>)\n",
      "loss: 4.568314075469971\n",
      "tensor([[855]]) tensor(-3043.7942, grad_fn=<SubBackward0>)\n",
      "loss: 4.559993267059326\n",
      "tensor([[855]]) tensor(-3034.9446, grad_fn=<SubBackward0>)\n",
      "loss: 4.549642562866211\n",
      "tensor([[855]]) tensor(-3029.3806, grad_fn=<SubBackward0>)\n",
      "loss: 4.543135166168213\n",
      "tensor([[855]]) tensor(-3019.2312, grad_fn=<SubBackward0>)\n",
      "loss: 4.531264781951904\n",
      "tensor([[855]]) tensor(-3017.3289, grad_fn=<SubBackward0>)\n",
      "loss: 4.52903938293457\n",
      "tensor([[855]]) tensor(-3009.3391, grad_fn=<SubBackward0>)\n",
      "loss: 4.519694805145264\n",
      "tensor([[855]]) tensor(-3002.2839, grad_fn=<SubBackward0>)\n",
      "loss: 4.511443138122559\n",
      "tensor([[855]]) tensor(-2990.8574, grad_fn=<SubBackward0>)\n",
      "loss: 4.4980788230896\n",
      "tensor([[855]]) tensor(-2990.5781, grad_fn=<SubBackward0>)\n",
      "loss: 4.4977521896362305\n",
      "tensor([[855]]) tensor(-2978.8928, grad_fn=<SubBackward0>)\n",
      "loss: 4.4840850830078125\n",
      "tensor([[855]]) tensor(-2976.1340, grad_fn=<SubBackward0>)\n",
      "loss: 4.480858325958252\n",
      "tensor([[855]]) tensor(-2965.1792, grad_fn=<SubBackward0>)\n",
      "loss: 4.468045711517334\n",
      "tensor([[855]]) tensor(-2958.5405, grad_fn=<SubBackward0>)\n",
      "loss: 4.4602813720703125\n",
      "tensor([[855]]) tensor(-2955.7537, grad_fn=<SubBackward0>)\n",
      "loss: 4.457021713256836\n",
      "tensor([[855]]) tensor(-2942.9297, grad_fn=<SubBackward0>)\n",
      "loss: 4.442022800445557\n",
      "tensor([[855]]) tensor(-2940.3320, grad_fn=<SubBackward0>)\n",
      "loss: 4.4389848709106445\n",
      "tensor([[855]]) tensor(-2930.2305, grad_fn=<SubBackward0>)\n",
      "loss: 4.427170276641846\n",
      "tensor([[855]]) tensor(-2919.6968, grad_fn=<SubBackward0>)\n",
      "loss: 4.414850234985352\n",
      "tensor([[855]]) tensor(-2916.7949, grad_fn=<SubBackward0>)\n",
      "loss: 4.411456108093262\n",
      "tensor([[855]]) tensor(-2899.7754, grad_fn=<SubBackward0>)\n",
      "loss: 4.391550064086914\n",
      "tensor([[855]]) tensor(-2900.3860, grad_fn=<SubBackward0>)\n",
      "loss: 4.392264366149902\n",
      "tensor([[855]]) tensor(-2887.6914, grad_fn=<SubBackward0>)\n",
      "loss: 4.377417087554932\n",
      "tensor([[855]]) tensor(-2890.4832, grad_fn=<SubBackward0>)\n",
      "loss: 4.380681991577148\n",
      "tensor([[855]]) tensor(-2871.3188, grad_fn=<SubBackward0>)\n",
      "loss: 4.358267784118652\n",
      "tensor([[855]]) tensor(-2873.5732, grad_fn=<SubBackward0>)\n",
      "loss: 4.360904216766357\n",
      "tensor([[855]]) tensor(-2869.3672, grad_fn=<SubBackward0>)\n",
      "loss: 4.355985164642334\n",
      "tensor([[855]]) tensor(-2858.7495, grad_fn=<SubBackward0>)\n",
      "loss: 4.34356689453125\n",
      "tensor([[855]]) tensor(-2842.8125, grad_fn=<SubBackward0>)\n",
      "loss: 4.324926853179932\n",
      "tensor([[855]]) tensor(-2846.1260, grad_fn=<SubBackward0>)\n",
      "loss: 4.328802108764648\n",
      "tensor([[855]]) tensor(-2827.5002, grad_fn=<SubBackward0>)\n",
      "loss: 4.307017803192139\n",
      "tensor([[855]]) tensor(-2836.2673, grad_fn=<SubBackward0>)\n",
      "loss: 4.317271709442139\n",
      "tensor([[855]]) tensor(-2830.2842, grad_fn=<SubBackward0>)\n",
      "loss: 4.310274124145508\n",
      "tensor([[855]]) tensor(-2812.8164, grad_fn=<SubBackward0>)\n",
      "loss: 4.289843559265137\n",
      "tensor([[855]]) tensor(-2800.5605, grad_fn=<SubBackward0>)\n",
      "loss: 4.275509357452393\n",
      "tensor([[855]]) tensor(-2795.9417, grad_fn=<SubBackward0>)\n",
      "loss: 4.270107269287109\n",
      "tensor([[855]]) tensor(-2787.8101, grad_fn=<SubBackward0>)\n",
      "loss: 4.260596752166748\n",
      "tensor([[855]]) tensor(-2787.9441, grad_fn=<SubBackward0>)\n",
      "loss: 4.260753154754639\n",
      "tensor([[855]]) tensor(-2779.8584, grad_fn=<SubBackward0>)\n",
      "loss: 4.251296520233154\n",
      "tensor([[855]]) tensor(-2762.7322, grad_fn=<SubBackward0>)\n",
      "loss: 4.231265544891357\n",
      "tensor([[855]]) tensor(-2767.0845, grad_fn=<SubBackward0>)\n",
      "loss: 4.236356258392334\n",
      "tensor([[855]]) tensor(-2750.0559, grad_fn=<SubBackward0>)\n",
      "loss: 4.216439723968506\n",
      "tensor([[855]]) tensor(-2745.1899, grad_fn=<SubBackward0>)\n",
      "loss: 4.210748672485352\n",
      "tensor([[855]]) tensor(-2742.5928, grad_fn=<SubBackward0>)\n",
      "loss: 4.2077107429504395\n",
      "tensor([[855]]) tensor(-2731.9431, grad_fn=<SubBackward0>)\n",
      "loss: 4.195255279541016\n",
      "tensor([[855]]) tensor(-2717.0657, grad_fn=<SubBackward0>)\n",
      "loss: 4.177854537963867\n",
      "tensor([[855]]) tensor(-2712.8589, grad_fn=<SubBackward0>)\n",
      "loss: 4.172934532165527\n",
      "tensor([[855]]) tensor(-2701.4177, grad_fn=<SubBackward0>)\n",
      "loss: 4.159553050994873\n",
      "tensor([[855]]) tensor(-2700.2410, grad_fn=<SubBackward0>)\n",
      "loss: 4.158176422119141\n",
      "tensor([[855]]) tensor(-2697.0767, grad_fn=<SubBackward0>)\n",
      "loss: 4.154475688934326\n",
      "tensor([[855]]) tensor(-2686.5127, grad_fn=<SubBackward0>)\n",
      "loss: 4.142119884490967\n",
      "tensor([[855]]) tensor(-2671.3430, grad_fn=<SubBackward0>)\n",
      "loss: 4.124377727508545\n",
      "tensor([[855]]) tensor(-2677.7744, grad_fn=<SubBackward0>)\n",
      "loss: 4.131899833679199\n",
      "tensor([[855]]) tensor(-2662.3833, grad_fn=<SubBackward0>)\n",
      "loss: 4.113898754119873\n",
      "tensor([[855]]) tensor(-2658.0964, grad_fn=<SubBackward0>)\n",
      "loss: 4.108884811401367\n",
      "tensor([[855]]) tensor(-2659.0881, grad_fn=<SubBackward0>)\n",
      "loss: 4.110044479370117\n",
      "tensor([[855]]) tensor(-2652.1470, grad_fn=<SubBackward0>)\n",
      "loss: 4.101926326751709\n",
      "tensor([[855]]) tensor(-2639.1167, grad_fn=<SubBackward0>)\n",
      "loss: 4.086686134338379\n",
      "tensor([[855]]) tensor(-2621.7695, grad_fn=<SubBackward0>)\n",
      "loss: 4.066397190093994\n",
      "tensor([[855]]) tensor(-2628.2646, grad_fn=<SubBackward0>)\n",
      "loss: 4.073993682861328\n",
      "tensor([[855]]) tensor(-2607.2483, grad_fn=<SubBackward0>)\n",
      "loss: 4.049413204193115\n",
      "tensor([[855]]) tensor(-2618.6135, grad_fn=<SubBackward0>)\n",
      "loss: 4.062705993652344\n",
      "tensor([[855]]) tensor(-2621.3333, grad_fn=<SubBackward0>)\n",
      "loss: 4.065886974334717\n",
      "tensor([[855]]) tensor(-2607.7173, grad_fn=<SubBackward0>)\n",
      "loss: 4.049961566925049\n",
      "tensor([[855]]) tensor(-2589.9292, grad_fn=<SubBackward0>)\n",
      "loss: 4.0291571617126465\n",
      "tensor([[855]]) tensor(-2577.6328, grad_fn=<SubBackward0>)\n",
      "loss: 4.014775276184082\n",
      "tensor([[855]]) tensor(-2573.6699, grad_fn=<SubBackward0>)\n",
      "loss: 4.010140419006348\n",
      "tensor([[855]]) tensor(-2571.0439, grad_fn=<SubBackward0>)\n",
      "loss: 4.007069110870361\n",
      "tensor([[855]]) tensor(-2553.7959, grad_fn=<SubBackward0>)\n",
      "loss: 3.986895799636841\n",
      "tensor([[855]]) tensor(-2545.1873, grad_fn=<SubBackward0>)\n",
      "loss: 3.9768271446228027\n",
      "tensor([[855]]) tensor(-2541.3000, grad_fn=<SubBackward0>)\n",
      "loss: 3.972280740737915\n",
      "tensor([[855]]) tensor(-2531.0146, grad_fn=<SubBackward0>)\n",
      "loss: 3.9602510929107666\n",
      "tensor([[855]]) tensor(-2523.8196, grad_fn=<SubBackward0>)\n",
      "loss: 3.951835870742798\n",
      "tensor([[855]]) tensor(-2519.6023, grad_fn=<SubBackward0>)\n",
      "loss: 3.9469032287597656\n",
      "tensor([[855]]) tensor(-2511.0862, grad_fn=<SubBackward0>)\n",
      "loss: 3.9369428157806396\n",
      "tensor([[855]]) tensor(-2498.2737, grad_fn=<SubBackward0>)\n",
      "loss: 3.921957492828369\n",
      "tensor([[855]]) tensor(-2489.5862, grad_fn=<SubBackward0>)\n",
      "loss: 3.911796808242798\n",
      "tensor([[855]]) tensor(-2481.3030, grad_fn=<SubBackward0>)\n",
      "loss: 3.902108669281006\n",
      "tensor([[855]]) tensor(-2475.5532, grad_fn=<SubBackward0>)\n",
      "loss: 3.895383834838867\n",
      "tensor([[855]]) tensor(-2467.5625, grad_fn=<SubBackward0>)\n",
      "loss: 3.886038064956665\n",
      "tensor([[855]]) tensor(-2457.5476, grad_fn=<SubBackward0>)\n",
      "loss: 3.8743247985839844\n",
      "tensor([[855]]) tensor(-2449.3240, grad_fn=<SubBackward0>)\n",
      "loss: 3.864706516265869\n",
      "tensor([[855]]) tensor(-2448.2437, grad_fn=<SubBackward0>)\n",
      "loss: 3.863442897796631\n",
      "tensor([[855]]) tensor(-2440.1523, grad_fn=<SubBackward0>)\n",
      "loss: 3.8539793491363525\n",
      "tensor([[855]]) tensor(-2436.2605, grad_fn=<SubBackward0>)\n",
      "loss: 3.8494274616241455\n",
      "tensor([[855]]) tensor(-2427.1272, grad_fn=<SubBackward0>)\n",
      "loss: 3.838745355606079\n",
      "tensor([[855]]) tensor(-2421.3979, grad_fn=<SubBackward0>)\n",
      "loss: 3.8320443630218506\n",
      "tensor([[855]]) tensor(-2418.4927, grad_fn=<SubBackward0>)\n",
      "loss: 3.828646421432495\n",
      "tensor([[855]]) tensor(-2410.6052, grad_fn=<SubBackward0>)\n",
      "loss: 3.8194212913513184\n",
      "tensor([[855]]) tensor(-2403.2881, grad_fn=<SubBackward0>)\n",
      "loss: 3.8108632564544678\n",
      "tensor([[855]]) tensor(-2393.4424, grad_fn=<SubBackward0>)\n",
      "loss: 3.7993478775024414\n",
      "tensor([[855]]) tensor(-2382.7832, grad_fn=<SubBackward0>)\n",
      "loss: 3.7868809700012207\n",
      "tensor([[855]]) tensor(-2389.3044, grad_fn=<SubBackward0>)\n",
      "loss: 3.794508218765259\n",
      "tensor([[855]]) tensor(-2369.7490, grad_fn=<SubBackward0>)\n",
      "loss: 3.7716362476348877\n",
      "tensor([[855]]) tensor(-2365.2485, grad_fn=<SubBackward0>)\n",
      "loss: 3.7663724422454834\n",
      "tensor([[855]]) tensor(-2359.0923, grad_fn=<SubBackward0>)\n",
      "loss: 3.759172201156616\n",
      "tensor([[855]]) tensor(-2347.8374, grad_fn=<SubBackward0>)\n",
      "loss: 3.7460086345672607\n",
      "tensor([[855]]) tensor(-2359.0281, grad_fn=<SubBackward0>)\n",
      "loss: 3.759097099304199\n",
      "tensor([[855]]) tensor(-2338.1528, grad_fn=<SubBackward0>)\n",
      "loss: 3.7346816062927246\n",
      "tensor([[855]]) tensor(-2339.6519, grad_fn=<SubBackward0>)\n",
      "loss: 3.7364349365234375\n",
      "tensor([[855]]) tensor(-2340.1294, grad_fn=<SubBackward0>)\n",
      "loss: 3.7369935512542725\n",
      "tensor([[855]]) tensor(-2330.4941, grad_fn=<SubBackward0>)\n",
      "loss: 3.725724220275879\n",
      "tensor([[855]]) tensor(-2311.6733, grad_fn=<SubBackward0>)\n",
      "loss: 3.70371150970459\n",
      "tensor([[855]]) tensor(-2320.6133, grad_fn=<SubBackward0>)\n",
      "loss: 3.714167594909668\n",
      "tensor([[855]]) tensor(-2306.5293, grad_fn=<SubBackward0>)\n",
      "loss: 3.697695016860962\n",
      "tensor([[855]]) tensor(-2304.4497, grad_fn=<SubBackward0>)\n",
      "loss: 3.695262908935547\n",
      "tensor([[855]]) tensor(-2306.7822, grad_fn=<SubBackward0>)\n",
      "loss: 3.697990894317627\n",
      "tensor([[855]]) tensor(-2302.3315, grad_fn=<SubBackward0>)\n",
      "loss: 3.6927855014801025\n",
      "tensor([[855]]) tensor(-2290.7029, grad_fn=<SubBackward0>)\n",
      "loss: 3.679184675216675\n",
      "tensor([[855]]) tensor(-2275.0317, grad_fn=<SubBackward0>)\n",
      "loss: 3.660855770111084\n",
      "tensor([[855]]) tensor(-2274.2275, grad_fn=<SubBackward0>)\n",
      "loss: 3.6599152088165283\n",
      "tensor([[855]]) tensor(-2259.4275, grad_fn=<SubBackward0>)\n",
      "loss: 3.6426053047180176\n",
      "tensor([[855]]) tensor(-2257.5874, grad_fn=<SubBackward0>)\n",
      "loss: 3.6404531002044678\n",
      "tensor([[855]]) tensor(-2254.6387, grad_fn=<SubBackward0>)\n",
      "loss: 3.6370043754577637\n",
      "tensor([[855]]) tensor(-2245.1116, grad_fn=<SubBackward0>)\n",
      "loss: 3.625861406326294\n",
      "tensor([[855]]) tensor(-2231.7256, grad_fn=<SubBackward0>)\n",
      "loss: 3.6102054119110107\n",
      "tensor([[855]]) tensor(-2224.9934, grad_fn=<SubBackward0>)\n",
      "loss: 3.6023313999176025\n",
      "tensor([[855]]) tensor(-2223.9663, grad_fn=<SubBackward0>)\n",
      "loss: 3.601130247116089\n",
      "tensor([[855]]) tensor(-2223.2847, grad_fn=<SubBackward0>)\n",
      "loss: 3.6003329753875732\n",
      "tensor([[855]]) tensor(-2213.9907, grad_fn=<SubBackward0>)\n",
      "loss: 3.5894627571105957\n",
      "tensor([[855]]) tensor(-2207.2012, grad_fn=<SubBackward0>)\n",
      "loss: 3.58152174949646\n",
      "tensor([[855]]) tensor(-2203.6587, grad_fn=<SubBackward0>)\n",
      "loss: 3.577378511428833\n",
      "tensor([[855]]) tensor(-2194.4587, grad_fn=<SubBackward0>)\n",
      "loss: 3.5666184425354004\n",
      "tensor([[855]]) tensor(-2182.9868, grad_fn=<SubBackward0>)\n",
      "loss: 3.5532009601593018\n",
      "tensor([[855]]) tensor(-2184.5469, grad_fn=<SubBackward0>)\n",
      "loss: 3.555025577545166\n",
      "tensor([[855]]) tensor(-2178.4116, grad_fn=<SubBackward0>)\n",
      "loss: 3.5478498935699463\n",
      "tensor([[855]]) tensor(-2173.2795, grad_fn=<SubBackward0>)\n",
      "loss: 3.5418474674224854\n",
      "tensor([[855]]) tensor(-2168.6045, grad_fn=<SubBackward0>)\n",
      "loss: 3.53637957572937\n",
      "tensor([[855]]) tensor(-2162.2808, grad_fn=<SubBackward0>)\n",
      "loss: 3.5289833545684814\n",
      "tensor([[855]]) tensor(-2148.7014, grad_fn=<SubBackward0>)\n",
      "loss: 3.513101100921631\n",
      "tensor([[855]]) tensor(-2145.1995, grad_fn=<SubBackward0>)\n",
      "loss: 3.509005308151245\n",
      "tensor([[855]]) tensor(-2138.5452, grad_fn=<SubBackward0>)\n",
      "loss: 3.5012223720550537\n",
      "tensor([[855]]) tensor(-2135.6653, grad_fn=<SubBackward0>)\n",
      "loss: 3.497854232788086\n",
      "tensor([[855]]) tensor(-2134.1121, grad_fn=<SubBackward0>)\n",
      "loss: 3.496037483215332\n",
      "tensor([[855]]) tensor(-2126.1086, grad_fn=<SubBackward0>)\n",
      "loss: 3.4866766929626465\n",
      "tensor([[855]]) tensor(-2118.3340, grad_fn=<SubBackward0>)\n",
      "loss: 3.477583646774292\n",
      "tensor([[855]]) tensor(-2111.1511, grad_fn=<SubBackward0>)\n",
      "loss: 3.4691824913024902\n",
      "tensor([[855]]) tensor(-2110.9629, grad_fn=<SubBackward0>)\n",
      "loss: 3.4689624309539795\n",
      "tensor([[855]]) tensor(-2102.8950, grad_fn=<SubBackward0>)\n",
      "loss: 3.459526300430298\n",
      "tensor([[855]]) tensor(-2090.2957, grad_fn=<SubBackward0>)\n",
      "loss: 3.4447901248931885\n",
      "tensor([[855]]) tensor(-2082.1885, grad_fn=<SubBackward0>)\n",
      "loss: 3.4353082180023193\n",
      "tensor([[855]]) tensor(-2074.3728, grad_fn=<SubBackward0>)\n",
      "loss: 3.4261670112609863\n",
      "tensor([[855]]) tensor(-2075.0603, grad_fn=<SubBackward0>)\n",
      "loss: 3.426971197128296\n",
      "tensor([[855]]) tensor(-2073.0972, grad_fn=<SubBackward0>)\n",
      "loss: 3.4246749877929688\n",
      "tensor([[855]]) tensor(-2066.2778, grad_fn=<SubBackward0>)\n",
      "loss: 3.416699171066284\n",
      "tensor([[855]]) tensor(-2055.7693, grad_fn=<SubBackward0>)\n",
      "loss: 3.4044084548950195\n",
      "tensor([[855]]) tensor(-2042.3636, grad_fn=<SubBackward0>)\n",
      "loss: 3.3887293338775635\n",
      "tensor([[855]]) tensor(-2055.2095, grad_fn=<SubBackward0>)\n",
      "loss: 3.4037537574768066\n",
      "tensor([[855]]) tensor(-2037.5508, grad_fn=<SubBackward0>)\n",
      "loss: 3.3831002712249756\n",
      "tensor([[855]]) tensor(-2035.7672, grad_fn=<SubBackward0>)\n",
      "loss: 3.381014108657837\n",
      "tensor([[855]]) tensor(-2042.5388, grad_fn=<SubBackward0>)\n",
      "loss: 3.388934373855591\n",
      "tensor([[855]]) tensor(-2038.4430, grad_fn=<SubBackward0>)\n",
      "loss: 3.3841440677642822\n",
      "tensor([[855]]) tensor(-2024.5994, grad_fn=<SubBackward0>)\n",
      "loss: 3.367952585220337\n",
      "tensor([[855]]) tensor(-2011.8679, grad_fn=<SubBackward0>)\n",
      "loss: 3.3530619144439697\n",
      "tensor([[855]]) tensor(-2006.1855, grad_fn=<SubBackward0>)\n",
      "loss: 3.3464157581329346\n",
      "tensor([[855]]) tensor(-2004.7480, grad_fn=<SubBackward0>)\n",
      "loss: 3.3447346687316895\n",
      "tensor([[855]]) tensor(-1985.6888, grad_fn=<SubBackward0>)\n",
      "loss: 3.3224432468414307\n",
      "tensor([[855]]) tensor(-1988.5725, grad_fn=<SubBackward0>)\n",
      "loss: 3.3258159160614014\n",
      "tensor([[855]]) tensor(-1988.0901, grad_fn=<SubBackward0>)\n",
      "loss: 3.325251579284668\n",
      "tensor([[855]]) tensor(-1979.4961, grad_fn=<SubBackward0>)\n",
      "loss: 3.315200090408325\n",
      "tensor([[855]]) tensor(-1966.6019, grad_fn=<SubBackward0>)\n",
      "loss: 3.300119161605835\n",
      "tensor([[855]]) tensor(-1961.5472, grad_fn=<SubBackward0>)\n",
      "loss: 3.2942070960998535\n",
      "tensor([[855]]) tensor(-1957.1165, grad_fn=<SubBackward0>)\n",
      "loss: 3.289025068283081\n",
      "tensor([[855]]) tensor(-1941.9155, grad_fn=<SubBackward0>)\n",
      "loss: 3.2712461948394775\n",
      "tensor([[855]]) tensor(-1937.1895, grad_fn=<SubBackward0>)\n",
      "loss: 3.265718698501587\n",
      "tensor([[855]]) tensor(-1935.9703, grad_fn=<SubBackward0>)\n",
      "loss: 3.2642927169799805\n",
      "tensor([[855]]) tensor(-1931.0253, grad_fn=<SubBackward0>)\n",
      "loss: 3.2585089206695557\n",
      "tensor([[855]]) tensor(-1920.4299, grad_fn=<SubBackward0>)\n",
      "loss: 3.246116876602173\n",
      "tensor([[855]]) tensor(-1911.7123, grad_fn=<SubBackward0>)\n",
      "loss: 3.2359209060668945\n",
      "tensor([[855]]) tensor(-1902.9795, grad_fn=<SubBackward0>)\n",
      "loss: 3.2257070541381836\n",
      "tensor([[855]]) tensor(-1911.3236, grad_fn=<SubBackward0>)\n",
      "loss: 3.235466241836548\n",
      "tensor([[855]]) tensor(-1891.9614, grad_fn=<SubBackward0>)\n",
      "loss: 3.212820291519165\n",
      "tensor([[855]]) tensor(-1897.9854, grad_fn=<SubBackward0>)\n",
      "loss: 3.2198657989501953\n",
      "tensor([[855]]) tensor(-1896.2782, grad_fn=<SubBackward0>)\n",
      "loss: 3.2178690433502197\n",
      "tensor([[855]]) tensor(-1884.9812, grad_fn=<SubBackward0>)\n",
      "loss: 3.2046563625335693\n",
      "tensor([[855]]) tensor(-1869.3687, grad_fn=<SubBackward0>)\n",
      "loss: 3.1863961219787598\n",
      "tensor([[855]]) tensor(-1876.8109, grad_fn=<SubBackward0>)\n",
      "loss: 3.1951005458831787\n",
      "tensor([[855]]) tensor(-1858.3572, grad_fn=<SubBackward0>)\n",
      "loss: 3.1735172271728516\n",
      "tensor([[855]]) tensor(-1863.0013, grad_fn=<SubBackward0>)\n",
      "loss: 3.1789491176605225\n",
      "tensor([[855]]) tensor(-1868.6631, grad_fn=<SubBackward0>)\n",
      "loss: 3.1855709552764893\n",
      "tensor([[855]]) tensor(-1863.4915, grad_fn=<SubBackward0>)\n",
      "loss: 3.1795222759246826\n",
      "tensor([[855]]) tensor(-1852.3059, grad_fn=<SubBackward0>)\n",
      "loss: 3.1664397716522217\n",
      "tensor([[855]]) tensor(-1835.7769, grad_fn=<SubBackward0>)\n",
      "loss: 3.1471073627471924\n",
      "tensor([[855]]) tensor(-1820.2664, grad_fn=<SubBackward0>)\n",
      "loss: 3.1289665699005127\n",
      "tensor([[855]]) tensor(-1826.0449, grad_fn=<SubBackward0>)\n",
      "loss: 3.1357250213623047\n",
      "tensor([[855]]) tensor(-1807.8662, grad_fn=<SubBackward0>)\n",
      "loss: 3.1144633293151855\n",
      "tensor([[855]]) tensor(-1803.9845, grad_fn=<SubBackward0>)\n",
      "loss: 3.1099236011505127\n",
      "tensor([[855]]) tensor(-1797.3434, grad_fn=<SubBackward0>)\n",
      "loss: 3.102156162261963\n",
      "tensor([[855]]) tensor(-1791.2039, grad_fn=<SubBackward0>)\n",
      "loss: 3.094975233078003\n",
      "tensor([[855]]) tensor(-1782.4037, grad_fn=<SubBackward0>)\n",
      "loss: 3.0846827030181885\n",
      "tensor([[855]]) tensor(-1780.1702, grad_fn=<SubBackward0>)\n",
      "loss: 3.0820703506469727\n",
      "tensor([[855]]) tensor(-1773.8870, grad_fn=<SubBackward0>)\n",
      "loss: 3.074721574783325\n",
      "tensor([[855]]) tensor(-1764.0302, grad_fn=<SubBackward0>)\n",
      "loss: 3.0631930828094482\n",
      "tensor([[855]]) tensor(-1760.5658, grad_fn=<SubBackward0>)\n",
      "loss: 3.0591413974761963\n",
      "tensor([[855]]) tensor(-1756.3402, grad_fn=<SubBackward0>)\n",
      "loss: 3.05419921875\n",
      "tensor([[855]]) tensor(-1756.7939, grad_fn=<SubBackward0>)\n",
      "loss: 3.054729700088501\n",
      "tensor([[855]]) tensor(-1749.5012, grad_fn=<SubBackward0>)\n",
      "loss: 3.0462002754211426\n",
      "tensor([[855]]) tensor(-1734.1580, grad_fn=<SubBackward0>)\n",
      "loss: 3.028254985809326\n",
      "tensor([[855]]) tensor(-1739.8190, grad_fn=<SubBackward0>)\n",
      "loss: 3.0348758697509766\n",
      "tensor([[855]]) tensor(-1727.5060, grad_fn=<SubBackward0>)\n",
      "loss: 3.020474672317505\n",
      "tensor([[855]]) tensor(-1718.8912, grad_fn=<SubBackward0>)\n",
      "loss: 3.0103988647460938\n",
      "tensor([[855]]) tensor(-1716.1226, grad_fn=<SubBackward0>)\n",
      "loss: 3.0071609020233154\n",
      "tensor([[855]]) tensor(-1704.3120, grad_fn=<SubBackward0>)\n",
      "loss: 2.993347406387329\n",
      "tensor([[855]]) tensor(-1706.7643, grad_fn=<SubBackward0>)\n",
      "loss: 2.996215343475342\n",
      "tensor([[855]]) tensor(-1690.3684, grad_fn=<SubBackward0>)\n",
      "loss: 2.977039098739624\n",
      "tensor([[855]]) tensor(-1692.6276, grad_fn=<SubBackward0>)\n",
      "loss: 2.9796814918518066\n",
      "tensor([[855]]) tensor(-1689.8347, grad_fn=<SubBackward0>)\n",
      "loss: 2.976414918899536\n",
      "tensor([[855]]) tensor(-1679.0819, grad_fn=<SubBackward0>)\n",
      "loss: 2.963838577270508\n",
      "tensor([[855]]) tensor(-1689.8705, grad_fn=<SubBackward0>)\n",
      "loss: 2.976456642150879\n",
      "tensor([[855]]) tensor(-1673.0714, grad_fn=<SubBackward0>)\n",
      "loss: 2.9568088054656982\n",
      "tensor([[855]]) tensor(-1668.8822, grad_fn=<SubBackward0>)\n",
      "loss: 2.951908826828003\n",
      "tensor([[855]]) tensor(-1672.7256, grad_fn=<SubBackward0>)\n",
      "loss: 2.956404209136963\n",
      "tensor([[855]]) tensor(-1665.2797, grad_fn=<SubBackward0>)\n",
      "loss: 2.947695732116699\n",
      "tensor([[855]]) tensor(-1648.2385, grad_fn=<SubBackward0>)\n",
      "loss: 2.927764415740967\n",
      "tensor([[855]]) tensor(-1665.6335, grad_fn=<SubBackward0>)\n",
      "loss: 2.9481093883514404\n",
      "tensor([[855]]) tensor(-1652.9421, grad_fn=<SubBackward0>)\n",
      "loss: 2.9332656860351562\n",
      "tensor([[855]]) tensor(-1638.4274, grad_fn=<SubBackward0>)\n",
      "loss: 2.9162890911102295\n",
      "tensor([[855]]) tensor(-1646.7495, grad_fn=<SubBackward0>)\n",
      "loss: 2.92602276802063\n",
      "tensor([[855]]) tensor(-1643.3656, grad_fn=<SubBackward0>)\n",
      "loss: 2.922064781188965\n",
      "tensor([[855]]) tensor(-1629.7104, grad_fn=<SubBackward0>)\n",
      "loss: 2.9060940742492676\n",
      "tensor([[855]]) tensor(-1613.5536, grad_fn=<SubBackward0>)\n",
      "loss: 2.887197256088257\n",
      "tensor([[855]]) tensor(-1628.8752, grad_fn=<SubBackward0>)\n",
      "loss: 2.9051172733306885\n",
      "tensor([[855]]) tensor(-1619.4153, grad_fn=<SubBackward0>)\n",
      "loss: 2.8940529823303223\n",
      "tensor([[855]]) tensor(-1602.0696, grad_fn=<SubBackward0>)\n",
      "loss: 2.873765707015991\n",
      "tensor([[855]]) tensor(-1606.1909, grad_fn=<SubBackward0>)\n",
      "loss: 2.8785858154296875\n",
      "tensor([[855]]) tensor(-1601.5582, grad_fn=<SubBackward0>)\n",
      "loss: 2.8731672763824463\n",
      "tensor([[855]]) tensor(-1591.2062, grad_fn=<SubBackward0>)\n",
      "loss: 2.8610599040985107\n",
      "tensor([[855]]) tensor(-1578.6957, grad_fn=<SubBackward0>)\n",
      "loss: 2.8464279174804688\n",
      "tensor([[855]]) tensor(-1589.5881, grad_fn=<SubBackward0>)\n",
      "loss: 2.8591673374176025\n",
      "tensor([[855]]) tensor(-1575.5883, grad_fn=<SubBackward0>)\n",
      "loss: 2.8427934646606445\n",
      "tensor([[855]]) tensor(-1577.4073, grad_fn=<SubBackward0>)\n",
      "loss: 2.8449206352233887\n",
      "tensor([[855]]) tensor(-1573.2864, grad_fn=<SubBackward0>)\n",
      "loss: 2.8401010036468506\n",
      "tensor([[855]]) tensor(-1563.5601, grad_fn=<SubBackward0>)\n",
      "loss: 2.8287250995635986\n",
      "tensor([[855]]) tensor(-1552.6790, grad_fn=<SubBackward0>)\n",
      "loss: 2.8159987926483154\n",
      "tensor([[855]]) tensor(-1555.7667, grad_fn=<SubBackward0>)\n",
      "loss: 2.819610118865967\n",
      "tensor([[855]]) tensor(-1569.2667, grad_fn=<SubBackward0>)\n",
      "loss: 2.835399866104126\n",
      "tensor([[855]]) tensor(-1544.1597, grad_fn=<SubBackward0>)\n",
      "loss: 2.806034803390503\n",
      "tensor([[855]]) tensor(-1531.8718, grad_fn=<SubBackward0>)\n",
      "loss: 2.7916629314422607\n",
      "tensor([[855]]) tensor(-1535.7908, grad_fn=<SubBackward0>)\n",
      "loss: 2.7962465286254883\n",
      "tensor([[855]]) tensor(-1534.7594, grad_fn=<SubBackward0>)\n",
      "loss: 2.7950403690338135\n",
      "tensor([[855]]) tensor(-1524.6791, grad_fn=<SubBackward0>)\n",
      "loss: 2.783250570297241\n",
      "tensor([[855]]) tensor(-1513.9332, grad_fn=<SubBackward0>)\n",
      "loss: 2.7706820964813232\n",
      "tensor([[855]]) tensor(-1514.4554, grad_fn=<SubBackward0>)\n",
      "loss: 2.7712931632995605\n",
      "tensor([[855]]) tensor(-1502.9775, grad_fn=<SubBackward0>)\n",
      "loss: 2.757868528366089\n",
      "tensor([[855]]) tensor(-1500.0754, grad_fn=<SubBackward0>)\n",
      "loss: 2.75447416305542\n",
      "tensor([[855]]) tensor(-1499.0171, grad_fn=<SubBackward0>)\n",
      "loss: 2.7532362937927246\n",
      "tensor([[855]]) tensor(-1494.9216, grad_fn=<SubBackward0>)\n",
      "loss: 2.748446464538574\n",
      "tensor([[855]]) tensor(-1486.3533, grad_fn=<SubBackward0>)\n",
      "loss: 2.738424777984619\n",
      "tensor([[855]]) tensor(-1479.3005, grad_fn=<SubBackward0>)\n",
      "loss: 2.7301759719848633\n",
      "tensor([[855]]) tensor(-1472.2034, grad_fn=<SubBackward0>)\n",
      "loss: 2.7218751907348633\n",
      "tensor([[855]]) tensor(-1473.0531, grad_fn=<SubBackward0>)\n",
      "loss: 2.7228691577911377\n",
      "tensor([[855]]) tensor(-1474.1782, grad_fn=<SubBackward0>)\n",
      "loss: 2.724184989929199\n",
      "tensor([[855]]) tensor(-1467.3331, grad_fn=<SubBackward0>)\n",
      "loss: 2.716179132461548\n",
      "tensor([[855]]) tensor(-1455.6707, grad_fn=<SubBackward0>)\n",
      "loss: 2.7025387287139893\n",
      "tensor([[855]]) tensor(-1453.1470, grad_fn=<SubBackward0>)\n",
      "loss: 2.699587106704712\n",
      "tensor([[855]]) tensor(-1440.2738, grad_fn=<SubBackward0>)\n",
      "loss: 2.6845309734344482\n",
      "tensor([[855]]) tensor(-1437.8425, grad_fn=<SubBackward0>)\n",
      "loss: 2.681687116622925\n",
      "tensor([[855]]) tensor(-1434.9764, grad_fn=<SubBackward0>)\n",
      "loss: 2.678335189819336\n",
      "tensor([[855]]) tensor(-1428.8263, grad_fn=<SubBackward0>)\n",
      "loss: 2.6711416244506836\n",
      "tensor([[855]]) tensor(-1430.1368, grad_fn=<SubBackward0>)\n",
      "loss: 2.6726744174957275\n",
      "tensor([[855]]) tensor(-1421.2114, grad_fn=<SubBackward0>)\n",
      "loss: 2.6622354984283447\n",
      "tensor([[855]]) tensor(-1418.6350, grad_fn=<SubBackward0>)\n",
      "loss: 2.65922212600708\n",
      "tensor([[855]]) tensor(-1410.1509, grad_fn=<SubBackward0>)\n",
      "loss: 2.649299383163452\n",
      "tensor([[855]]) tensor(-1416.1428, grad_fn=<SubBackward0>)\n",
      "loss: 2.6563074588775635\n",
      "tensor([[855]]) tensor(-1399.4209, grad_fn=<SubBackward0>)\n",
      "loss: 2.636749505996704\n",
      "tensor([[855]]) tensor(-1403.0967, grad_fn=<SubBackward0>)\n",
      "loss: 2.6410486698150635\n",
      "tensor([[855]]) tensor(-1402.7305, grad_fn=<SubBackward0>)\n",
      "loss: 2.640620470046997\n",
      "tensor([[855]]) tensor(-1387.5686, grad_fn=<SubBackward0>)\n",
      "loss: 2.622887372970581\n",
      "tensor([[855]]) tensor(-1394.1582, grad_fn=<SubBackward0>)\n",
      "loss: 2.630594491958618\n",
      "tensor([[855]]) tensor(-1377.2277, grad_fn=<SubBackward0>)\n",
      "loss: 2.610792398452759\n",
      "tensor([[855]]) tensor(-1377.3695, grad_fn=<SubBackward0>)\n",
      "loss: 2.6109585762023926\n",
      "tensor([[855]]) tensor(-1376.1243, grad_fn=<SubBackward0>)\n",
      "loss: 2.609502077102661\n",
      "tensor([[855]]) tensor(-1368.9656, grad_fn=<SubBackward0>)\n",
      "loss: 2.6011292934417725\n",
      "tensor([[855]]) tensor(-1362.4424, grad_fn=<SubBackward0>)\n",
      "loss: 2.5934998989105225\n",
      "tensor([[855]]) tensor(-1373.6735, grad_fn=<SubBackward0>)\n",
      "loss: 2.606635570526123\n",
      "tensor([[855]]) tensor(-1354.1624, grad_fn=<SubBackward0>)\n",
      "loss: 2.583815574645996\n",
      "tensor([[855]]) tensor(-1352.8250, grad_fn=<SubBackward0>)\n",
      "loss: 2.5822513103485107\n",
      "tensor([[855]]) tensor(-1352.7949, grad_fn=<SubBackward0>)\n",
      "loss: 2.582216262817383\n",
      "tensor([[855]]) tensor(-1346.7764, grad_fn=<SubBackward0>)\n",
      "loss: 2.575176954269409\n",
      "tensor([[855]]) tensor(-1337.4205, grad_fn=<SubBackward0>)\n",
      "loss: 2.564234495162964\n",
      "tensor([[855]]) tensor(-1343.3860, grad_fn=<SubBackward0>)\n",
      "loss: 2.571211576461792\n",
      "tensor([[855]]) tensor(-1329.9546, grad_fn=<SubBackward0>)\n",
      "loss: 2.555502414703369\n",
      "tensor([[855]]) tensor(-1328.0996, grad_fn=<SubBackward0>)\n",
      "loss: 2.553332805633545\n",
      "tensor([[855]]) tensor(-1326.5343, grad_fn=<SubBackward0>)\n",
      "loss: 2.551501989364624\n",
      "tensor([[855]]) tensor(-1322.3296, grad_fn=<SubBackward0>)\n",
      "loss: 2.546584367752075\n",
      "tensor([[855]]) tensor(-1315.5474, grad_fn=<SubBackward0>)\n",
      "loss: 2.538651943206787\n",
      "tensor([[855]]) tensor(-1307.2671, grad_fn=<SubBackward0>)\n",
      "loss: 2.5289673805236816\n",
      "tensor([[855]]) tensor(-1324.0288, grad_fn=<SubBackward0>)\n",
      "loss: 2.548571825027466\n",
      "tensor([[855]]) tensor(-1303.3932, grad_fn=<SubBackward0>)\n",
      "loss: 2.5244362354278564\n",
      "tensor([[855]]) tensor(-1309.1677, grad_fn=<SubBackward0>)\n",
      "loss: 2.5311903953552246\n",
      "tensor([[855]]) tensor(-1321.4871, grad_fn=<SubBackward0>)\n",
      "loss: 2.5455989837646484\n",
      "tensor([[855]]) tensor(-1315.9430, grad_fn=<SubBackward0>)\n",
      "loss: 2.539114475250244\n",
      "tensor([[855]]) tensor(-1305.5056, grad_fn=<SubBackward0>)\n",
      "loss: 2.526907205581665\n",
      "tensor([[855]]) tensor(-1293.3695, grad_fn=<SubBackward0>)\n",
      "loss: 2.5127129554748535\n",
      "tensor([[855]]) tensor(-1287.9490, grad_fn=<SubBackward0>)\n",
      "loss: 2.506373167037964\n",
      "tensor([[855]]) tensor(-1288.8669, grad_fn=<SubBackward0>)\n",
      "loss: 2.507446765899658\n",
      "tensor([[855]]) tensor(-1294.3831, grad_fn=<SubBackward0>)\n",
      "loss: 2.5138983726501465\n",
      "tensor([[855]]) tensor(-1274.8940, grad_fn=<SubBackward0>)\n",
      "loss: 2.4911041259765625\n",
      "tensor([[855]]) tensor(-1269.2478, grad_fn=<SubBackward0>)\n",
      "loss: 2.4845004081726074\n",
      "tensor([[855]]) tensor(-1269.6040, grad_fn=<SubBackward0>)\n",
      "loss: 2.484916925430298\n",
      "tensor([[855]]) tensor(-1266.7314, grad_fn=<SubBackward0>)\n",
      "loss: 2.4815571308135986\n",
      "tensor([[855]]) tensor(-1263.0995, grad_fn=<SubBackward0>)\n",
      "loss: 2.477309465408325\n",
      "tensor([[855]]) tensor(-1255.9984, grad_fn=<SubBackward0>)\n",
      "loss: 2.4690041542053223\n",
      "tensor([[855]]) tensor(-1245.5966, grad_fn=<SubBackward0>)\n",
      "loss: 2.4568381309509277\n",
      "tensor([[855]]) tensor(-1255.2424, grad_fn=<SubBackward0>)\n",
      "loss: 2.4681198596954346\n",
      "tensor([[855]]) tensor(-1248.9199, grad_fn=<SubBackward0>)\n",
      "loss: 2.4607250690460205\n",
      "tensor([[855]]) tensor(-1230.9454, grad_fn=<SubBackward0>)\n",
      "loss: 2.439702033996582\n",
      "tensor([[855]]) tensor(-1229.2258, grad_fn=<SubBackward0>)\n",
      "loss: 2.4376909732818604\n",
      "tensor([[855]]) tensor(-1224.9979, grad_fn=<SubBackward0>)\n",
      "loss: 2.432746171951294\n",
      "tensor([[855]]) tensor(-1226.4296, grad_fn=<SubBackward0>)\n",
      "loss: 2.434420585632324\n",
      "tensor([[855]]) tensor(-1224.6992, grad_fn=<SubBackward0>)\n",
      "loss: 2.432396650314331\n",
      "tensor([[855]]) tensor(-1218.5457, grad_fn=<SubBackward0>)\n",
      "loss: 2.425199508666992\n",
      "tensor([[855]]) tensor(-1210.0024, grad_fn=<SubBackward0>)\n",
      "loss: 2.415207624435425\n",
      "tensor([[855]]) tensor(-1206.9907, grad_fn=<SubBackward0>)\n",
      "loss: 2.411684989929199\n",
      "tensor([[855]]) tensor(-1201.5403, grad_fn=<SubBackward0>)\n",
      "loss: 2.4053101539611816\n",
      "tensor([[855]]) tensor(-1194.8977, grad_fn=<SubBackward0>)\n",
      "loss: 2.3975412845611572\n",
      "tensor([[855]]) tensor(-1190.9081, grad_fn=<SubBackward0>)\n",
      "loss: 2.3928749561309814\n",
      "tensor([[855]]) tensor(-1192.7268, grad_fn=<SubBackward0>)\n",
      "loss: 2.3950021266937256\n",
      "tensor([[855]]) tensor(-1193.4720, grad_fn=<SubBackward0>)\n",
      "loss: 2.395873785018921\n",
      "tensor([[855]]) tensor(-1191.8821, grad_fn=<SubBackward0>)\n",
      "loss: 2.3940141201019287\n",
      "tensor([[855]]) tensor(-1186.3999, grad_fn=<SubBackward0>)\n",
      "loss: 2.3876023292541504\n",
      "tensor([[855]]) tensor(-1178.7710, grad_fn=<SubBackward0>)\n",
      "loss: 2.3786795139312744\n",
      "tensor([[855]]) tensor(-1170.0450, grad_fn=<SubBackward0>)\n",
      "loss: 2.368473768234253\n",
      "tensor([[855]]) tensor(-1177.3069, grad_fn=<SubBackward0>)\n",
      "loss: 2.376967191696167\n",
      "tensor([[855]]) tensor(-1163.3958, grad_fn=<SubBackward0>)\n",
      "loss: 2.360696792602539\n",
      "tensor([[855]]) tensor(-1163.1211, grad_fn=<SubBackward0>)\n",
      "loss: 2.3603756427764893\n",
      "tensor([[855]]) tensor(-1164.1062, grad_fn=<SubBackward0>)\n",
      "loss: 2.361527681350708\n",
      "tensor([[855]]) tensor(-1163.3611, grad_fn=<SubBackward0>)\n",
      "loss: 2.360656261444092\n",
      "tensor([[855]]) tensor(-1159.0812, grad_fn=<SubBackward0>)\n",
      "loss: 2.3556504249572754\n",
      "tensor([[855]]) tensor(-1150.3787, grad_fn=<SubBackward0>)\n",
      "loss: 2.3454720973968506\n",
      "tensor([[855]]) tensor(-1144.8210, grad_fn=<SubBackward0>)\n",
      "loss: 2.3389720916748047\n",
      "tensor([[855]]) tensor(-1143.0017, grad_fn=<SubBackward0>)\n",
      "loss: 2.3368442058563232\n",
      "tensor([[855]]) tensor(-1137.0767, grad_fn=<SubBackward0>)\n",
      "loss: 2.3299143314361572\n",
      "tensor([[855]]) tensor(-1129.3108, grad_fn=<SubBackward0>)\n",
      "loss: 2.320831298828125\n",
      "tensor([[855]]) tensor(-1123.2061, grad_fn=<SubBackward0>)\n",
      "loss: 2.3136913776397705\n",
      "tensor([[855]]) tensor(-1118.7695, grad_fn=<SubBackward0>)\n",
      "loss: 2.308502435684204\n",
      "tensor([[855]]) tensor(-1123.2423, grad_fn=<SubBackward0>)\n",
      "loss: 2.3137335777282715\n",
      "tensor([[855]]) tensor(-1113.6980, grad_fn=<SubBackward0>)\n",
      "loss: 2.3025708198547363\n",
      "tensor([[855]]) tensor(-1115.9500, grad_fn=<SubBackward0>)\n",
      "loss: 2.3052046298980713\n",
      "tensor([[855]]) tensor(-1116.3335, grad_fn=<SubBackward0>)\n",
      "loss: 2.3056530952453613\n",
      "tensor([[855]]) tensor(-1114.5321, grad_fn=<SubBackward0>)\n",
      "loss: 2.30354642868042\n",
      "tensor([[855]]) tensor(-1109.3868, grad_fn=<SubBackward0>)\n",
      "loss: 2.2975285053253174\n",
      "tensor([[855]]) tensor(-1102.2858, grad_fn=<SubBackward0>)\n",
      "loss: 2.2892231941223145\n",
      "tensor([[855]]) tensor(-1093.8835, grad_fn=<SubBackward0>)\n",
      "loss: 2.2793960571289062\n",
      "tensor([[855]]) tensor(-1084.2810, grad_fn=<SubBackward0>)\n",
      "loss: 2.268164873123169\n",
      "tensor([[855]]) tensor(-1089.9062, grad_fn=<SubBackward0>)\n",
      "loss: 2.2747440338134766\n",
      "tensor([[855]]) tensor(-1081.0449, grad_fn=<SubBackward0>)\n",
      "loss: 2.2643799781799316\n",
      "tensor([[855]]) tensor(-1074.2727, grad_fn=<SubBackward0>)\n",
      "loss: 2.2564592361450195\n",
      "tensor([[855]]) tensor(-1071.6689, grad_fn=<SubBackward0>)\n",
      "loss: 2.2534139156341553\n",
      "tensor([[855]]) tensor(-1070.7581, grad_fn=<SubBackward0>)\n",
      "loss: 2.2523486614227295\n",
      "tensor([[855]]) tensor(-1067.9818, grad_fn=<SubBackward0>)\n",
      "loss: 2.2491016387939453\n",
      "tensor([[855]]) tensor(-1061.9243, grad_fn=<SubBackward0>)\n",
      "loss: 2.2420167922973633\n",
      "tensor([[855]]) tensor(-1053.4741, grad_fn=<SubBackward0>)\n",
      "loss: 2.232133388519287\n",
      "tensor([[855]]) tensor(-1045.6139, grad_fn=<SubBackward0>)\n",
      "loss: 2.22294020652771\n",
      "tensor([[855]]) tensor(-1052.3264, grad_fn=<SubBackward0>)\n",
      "loss: 2.2307910919189453\n",
      "tensor([[855]]) tensor(-1040.4485, grad_fn=<SubBackward0>)\n",
      "loss: 2.2168989181518555\n",
      "tensor([[855]]) tensor(-1040.2947, grad_fn=<SubBackward0>)\n",
      "loss: 2.216718912124634\n",
      "tensor([[855]]) tensor(-1036.7126, grad_fn=<SubBackward0>)\n",
      "loss: 2.212529420852661\n",
      "tensor([[855]]) tensor(-1029.7891, grad_fn=<SubBackward0>)\n",
      "loss: 2.2044315338134766\n",
      "tensor([[855]]) tensor(-1020.5822, grad_fn=<SubBackward0>)\n",
      "loss: 2.1936633586883545\n",
      "tensor([[855]]) tensor(-1038.8693, grad_fn=<SubBackward0>)\n",
      "loss: 2.2150516510009766\n",
      "tensor([[855]]) tensor(-1019.0588, grad_fn=<SubBackward0>)\n",
      "loss: 2.1918816566467285\n",
      "tensor([[855]]) tensor(-1020.2724, grad_fn=<SubBackward0>)\n",
      "loss: 2.193301200866699\n",
      "tensor([[855]]) tensor(-1024.6713, grad_fn=<SubBackward0>)\n",
      "loss: 2.198446035385132\n",
      "tensor([[855]]) tensor(-1029.0757, grad_fn=<SubBackward0>)\n",
      "loss: 2.2035973072052\n",
      "tensor([[855]]) tensor(-1027.6630, grad_fn=<SubBackward0>)\n",
      "loss: 2.2019450664520264\n",
      "tensor([[855]]) tensor(-1020.3846, grad_fn=<SubBackward0>)\n",
      "loss: 2.193432331085205\n",
      "tensor([[855]]) tensor(-1010.2962, grad_fn=<SubBackward0>)\n",
      "loss: 2.1816329956054688\n",
      "tensor([[855]]) tensor(-999.6895, grad_fn=<SubBackward0>)\n",
      "loss: 2.169227361679077\n",
      "tensor([[855]]) tensor(-988.9813, grad_fn=<SubBackward0>)\n",
      "loss: 2.156703233718872\n",
      "tensor([[855]]) tensor(-991.0167, grad_fn=<SubBackward0>)\n",
      "loss: 2.159083843231201\n",
      "tensor([[855]]) tensor(-993.1241, grad_fn=<SubBackward0>)\n",
      "loss: 2.161548614501953\n",
      "tensor([[855]]) tensor(-980.5604, grad_fn=<SubBackward0>)\n",
      "loss: 2.1468541622161865\n",
      "tensor([[855]]) tensor(-972.9232, grad_fn=<SubBackward0>)\n",
      "loss: 2.1379218101501465\n",
      "tensor([[855]]) tensor(-973.2952, grad_fn=<SubBackward0>)\n",
      "loss: 2.138356924057007\n",
      "tensor([[855]]) tensor(-972.8903, grad_fn=<SubBackward0>)\n",
      "loss: 2.137883424758911\n",
      "tensor([[855]]) tensor(-969.1068, grad_fn=<SubBackward0>)\n",
      "loss: 2.133458375930786\n",
      "tensor([[855]]) tensor(-962.2840, grad_fn=<SubBackward0>)\n",
      "loss: 2.1254782676696777\n",
      "tensor([[855]]) tensor(-953.6444, grad_fn=<SubBackward0>)\n",
      "loss: 2.1153736114501953\n",
      "tensor([[855]]) tensor(-953.4043, grad_fn=<SubBackward0>)\n",
      "loss: 2.1150927543640137\n",
      "tensor([[855]]) tensor(-948.7578, grad_fn=<SubBackward0>)\n",
      "loss: 2.1096582412719727\n",
      "tensor([[855]]) tensor(-942.1113, grad_fn=<SubBackward0>)\n",
      "loss: 2.101884603500366\n",
      "tensor([[855]]) tensor(-943.2119, grad_fn=<SubBackward0>)\n",
      "loss: 2.1031718254089355\n",
      "tensor([[855]]) tensor(-941.1403, grad_fn=<SubBackward0>)\n",
      "loss: 2.1007490158081055\n",
      "tensor([[855]]) tensor(-936.7570, grad_fn=<SubBackward0>)\n",
      "loss: 2.0956220626831055\n",
      "tensor([[855]]) tensor(-930.2808, grad_fn=<SubBackward0>)\n",
      "loss: 2.088047742843628\n",
      "tensor([[855]]) tensor(-928.3520, grad_fn=<SubBackward0>)\n",
      "loss: 2.085791826248169\n",
      "tensor([[855]]) tensor(-926.8939, grad_fn=<SubBackward0>)\n",
      "loss: 2.0840864181518555\n",
      "tensor([[855]]) tensor(-921.0693, grad_fn=<SubBackward0>)\n",
      "loss: 2.0772740840911865\n",
      "tensor([[855]]) tensor(-912.0948, grad_fn=<SubBackward0>)\n",
      "loss: 2.0667777061462402\n",
      "tensor([[855]]) tensor(-909.1726, grad_fn=<SubBackward0>)\n",
      "loss: 2.0633597373962402\n",
      "tensor([[855]]) tensor(-903.6505, grad_fn=<SubBackward0>)\n",
      "loss: 2.056901216506958\n",
      "tensor([[855]]) tensor(-898.1038, grad_fn=<SubBackward0>)\n",
      "loss: 2.0504138469696045\n",
      "tensor([[855]]) tensor(-892.7017, grad_fn=<SubBackward0>)\n",
      "loss: 2.044095516204834\n",
      "tensor([[855]]) tensor(-892.6619, grad_fn=<SubBackward0>)\n",
      "loss: 2.044049024581909\n",
      "tensor([[855]]) tensor(-893.9510, grad_fn=<SubBackward0>)\n",
      "loss: 2.0455567836761475\n",
      "tensor([[855]]) tensor(-892.6093, grad_fn=<SubBackward0>)\n",
      "loss: 2.043987512588501\n",
      "tensor([[855]]) tensor(-888.1520, grad_fn=<SubBackward0>)\n",
      "loss: 2.038774251937866\n",
      "tensor([[855]]) tensor(-881.3964, grad_fn=<SubBackward0>)\n",
      "loss: 2.0308730602264404\n",
      "tensor([[855]]) tensor(-872.3893, grad_fn=<SubBackward0>)\n",
      "loss: 2.020338296890259\n",
      "tensor([[855]]) tensor(-879.8706, grad_fn=<SubBackward0>)\n",
      "loss: 2.0290884971618652\n",
      "tensor([[855]]) tensor(-874.5573, grad_fn=<SubBackward0>)\n",
      "loss: 2.022873878479004\n",
      "tensor([[855]]) tensor(-861.1833, grad_fn=<SubBackward0>)\n",
      "loss: 2.0072319507598877\n",
      "tensor([[855]]) tensor(-862.3162, grad_fn=<SubBackward0>)\n",
      "loss: 2.008556842803955\n",
      "tensor([[855]]) tensor(-860.8048, grad_fn=<SubBackward0>)\n",
      "loss: 2.006789207458496\n",
      "tensor([[855]]) tensor(-856.7548, grad_fn=<SubBackward0>)\n",
      "loss: 2.0020525455474854\n",
      "tensor([[855]]) tensor(-851.6014, grad_fn=<SubBackward0>)\n",
      "loss: 1.9960250854492188\n",
      "tensor([[855]]) tensor(-845.9271, grad_fn=<SubBackward0>)\n",
      "loss: 1.9893884658813477\n",
      "tensor([[855]]) tensor(-843.5845, grad_fn=<SubBackward0>)\n",
      "loss: 1.9866485595703125\n",
      "tensor([[855]]) tensor(-837.1249, grad_fn=<SubBackward0>)\n",
      "loss: 1.9790934324264526\n",
      "tensor([[855]]) tensor(-833.3948, grad_fn=<SubBackward0>)\n",
      "loss: 1.9747307300567627\n",
      "tensor([[855]]) tensor(-830.1624, grad_fn=<SubBackward0>)\n",
      "loss: 1.9709501266479492\n",
      "tensor([[855]]) tensor(-824.8143, grad_fn=<SubBackward0>)\n",
      "loss: 1.9646949768066406\n",
      "tensor([[855]]) tensor(-818.5706, grad_fn=<SubBackward0>)\n",
      "loss: 1.9573924541473389\n",
      "tensor([[855]]) tensor(-815.6289, grad_fn=<SubBackward0>)\n",
      "loss: 1.9539519548416138\n",
      "tensor([[855]]) tensor(-811.1847, grad_fn=<SubBackward0>)\n",
      "loss: 1.948754072189331\n",
      "tensor([[855]]) tensor(-809.2211, grad_fn=<SubBackward0>)\n",
      "loss: 1.9464573860168457\n",
      "tensor([[855]]) tensor(-803.3777, grad_fn=<SubBackward0>)\n",
      "loss: 1.9396229982376099\n",
      "tensor([[855]]) tensor(-801.1138, grad_fn=<SubBackward0>)\n",
      "loss: 1.936975121498108\n",
      "tensor([[855]]) tensor(-798.5131, grad_fn=<SubBackward0>)\n",
      "loss: 1.9339333772659302\n",
      "tensor([[855]]) tensor(-794.2432, grad_fn=<SubBackward0>)\n",
      "loss: 1.9289393424987793\n",
      "tensor([[855]]) tensor(-788.2659, grad_fn=<SubBackward0>)\n",
      "loss: 1.9219484329223633\n",
      "tensor([[855]]) tensor(-796.4847, grad_fn=<SubBackward0>)\n",
      "loss: 1.93156099319458\n",
      "tensor([[855]]) tensor(-781.5875, grad_fn=<SubBackward0>)\n",
      "loss: 1.914137363433838\n",
      "tensor([[855]]) tensor(-780.1661, grad_fn=<SubBackward0>)\n",
      "loss: 1.9124748706817627\n",
      "tensor([[855]]) tensor(-775.9139, grad_fn=<SubBackward0>)\n",
      "loss: 1.9075015783309937\n",
      "tensor([[855]]) tensor(-770.4796, grad_fn=<SubBackward0>)\n",
      "loss: 1.9011456966400146\n",
      "tensor([[855]]) tensor(-766.3679, grad_fn=<SubBackward0>)\n",
      "loss: 1.8963367938995361\n",
      "tensor([[855]]) tensor(-763.3024, grad_fn=<SubBackward0>)\n",
      "loss: 1.8927513360977173\n",
      "tensor([[855]]) tensor(-761.0332, grad_fn=<SubBackward0>)\n",
      "loss: 1.8900972604751587\n",
      "tensor([[855]]) tensor(-758.0815, grad_fn=<SubBackward0>)\n",
      "loss: 1.8866450786590576\n",
      "tensor([[855]]) tensor(-754.8909, grad_fn=<SubBackward0>)\n",
      "loss: 1.88291335105896\n",
      "tensor([[855]]) tensor(-750.7657, grad_fn=<SubBackward0>)\n",
      "loss: 1.8780885934829712\n",
      "tensor([[855]]) tensor(-745.3525, grad_fn=<SubBackward0>)\n",
      "loss: 1.8717573881149292\n",
      "tensor([[855]]) tensor(-740.7342, grad_fn=<SubBackward0>)\n",
      "loss: 1.8663556575775146\n",
      "tensor([[855]]) tensor(-738.3506, grad_fn=<SubBackward0>)\n",
      "loss: 1.8635679483413696\n",
      "tensor([[855]]) tensor(-733.6300, grad_fn=<SubBackward0>)\n",
      "loss: 1.8580467700958252\n",
      "tensor([[855]]) tensor(-731.9568, grad_fn=<SubBackward0>)\n",
      "loss: 1.8560898303985596\n",
      "tensor([[855]]) tensor(-729.0623, grad_fn=<SubBackward0>)\n",
      "loss: 1.852704405784607\n",
      "tensor([[855]]) tensor(-726.4492, grad_fn=<SubBackward0>)\n",
      "loss: 1.8496482372283936\n",
      "tensor([[855]]) tensor(-724.8233, grad_fn=<SubBackward0>)\n",
      "loss: 1.84774649143219\n",
      "tensor([[855]]) tensor(-720.1435, grad_fn=<SubBackward0>)\n",
      "loss: 1.8422731161117554\n",
      "tensor([[855]]) tensor(-714.0876, grad_fn=<SubBackward0>)\n",
      "loss: 1.8351901769638062\n",
      "tensor([[855]]) tensor(-713.6058, grad_fn=<SubBackward0>)\n",
      "loss: 1.8346266746520996\n",
      "tensor([[855]]) tensor(-704.1255, grad_fn=<SubBackward0>)\n",
      "loss: 1.8235385417938232\n",
      "tensor([[855]]) tensor(-705.8297, grad_fn=<SubBackward0>)\n",
      "loss: 1.8255318403244019\n",
      "tensor([[855]]) tensor(-704.5527, grad_fn=<SubBackward0>)\n",
      "loss: 1.8240382671356201\n",
      "tensor([[855]]) tensor(-701.3613, grad_fn=<SubBackward0>)\n",
      "loss: 1.8203057050704956\n",
      "tensor([[855]]) tensor(-701.8506, grad_fn=<SubBackward0>)\n",
      "loss: 1.8208779096603394\n",
      "tensor([[855]]) tensor(-699.3282, grad_fn=<SubBackward0>)\n",
      "loss: 1.817927598953247\n",
      "tensor([[855]]) tensor(-693.7127, grad_fn=<SubBackward0>)\n",
      "loss: 1.8113597631454468\n",
      "tensor([[855]]) tensor(-692.5820, grad_fn=<SubBackward0>)\n",
      "loss: 1.8100374937057495\n",
      "tensor([[855]]) tensor(-689.8057, grad_fn=<SubBackward0>)\n",
      "loss: 1.8067902326583862\n",
      "tensor([[855]]) tensor(-685.2057, grad_fn=<SubBackward0>)\n",
      "loss: 1.80141019821167\n",
      "tensor([[855]]) tensor(-678.3412, grad_fn=<SubBackward0>)\n",
      "loss: 1.793381690979004\n",
      "tensor([[855]]) tensor(-669.4432, grad_fn=<SubBackward0>)\n",
      "loss: 1.782974362373352\n",
      "tensor([[855]]) tensor(-669.5504, grad_fn=<SubBackward0>)\n",
      "loss: 1.783099889755249\n",
      "tensor([[855]]) tensor(-669.3976, grad_fn=<SubBackward0>)\n",
      "loss: 1.782921314239502\n",
      "tensor([[855]]) tensor(-660.8192, grad_fn=<SubBackward0>)\n",
      "loss: 1.7728878259658813\n",
      "tensor([[855]]) tensor(-656.7397, grad_fn=<SubBackward0>)\n",
      "loss: 1.7681167125701904\n",
      "tensor([[855]]) tensor(-659.1921, grad_fn=<SubBackward0>)\n",
      "loss: 1.7709850072860718\n",
      "tensor([[855]]) tensor(-656.7350, grad_fn=<SubBackward0>)\n",
      "loss: 1.7681111097335815\n",
      "tensor([[855]]) tensor(-649.9076, grad_fn=<SubBackward0>)\n",
      "loss: 1.7601258754730225\n",
      "tensor([[855]]) tensor(-643.7708, grad_fn=<SubBackward0>)\n",
      "loss: 1.75294828414917\n",
      "tensor([[855]]) tensor(-645.7878, grad_fn=<SubBackward0>)\n",
      "loss: 1.7553074359893799\n",
      "tensor([[855]]) tensor(-637.2066, grad_fn=<SubBackward0>)\n",
      "loss: 1.745270848274231\n",
      "tensor([[855]]) tensor(-632.5840, grad_fn=<SubBackward0>)\n",
      "loss: 1.7398643493652344\n",
      "tensor([[855]]) tensor(-631.6898, grad_fn=<SubBackward0>)\n",
      "loss: 1.7388184070587158\n",
      "tensor([[855]]) tensor(-630.4561, grad_fn=<SubBackward0>)\n",
      "loss: 1.7373754978179932\n",
      "tensor([[855]]) tensor(-626.0490, grad_fn=<SubBackward0>)\n",
      "loss: 1.7322211265563965\n",
      "tensor([[855]]) tensor(-619.3096, grad_fn=<SubBackward0>)\n",
      "loss: 1.7243386507034302\n",
      "tensor([[855]]) tensor(-622.5886, grad_fn=<SubBackward0>)\n",
      "loss: 1.728173851966858\n",
      "tensor([[855]]) tensor(-615.4760, grad_fn=<SubBackward0>)\n",
      "loss: 1.7198550701141357\n",
      "tensor([[855]]) tensor(-607.4952, grad_fn=<SubBackward0>)\n",
      "loss: 1.7105207443237305\n",
      "tensor([[855]]) tensor(-607.2707, grad_fn=<SubBackward0>)\n",
      "loss: 1.7102582454681396\n",
      "tensor([[855]]) tensor(-606.9906, grad_fn=<SubBackward0>)\n",
      "loss: 1.7099305391311646\n",
      "tensor([[855]]) tensor(-602.7783, grad_fn=<SubBackward0>)\n",
      "loss: 1.7050038576126099\n",
      "tensor([[855]]) tensor(-597.5590, grad_fn=<SubBackward0>)\n",
      "loss: 1.698899507522583\n",
      "tensor([[855]]) tensor(-593.6472, grad_fn=<SubBackward0>)\n",
      "loss: 1.694324254989624\n",
      "tensor([[855]]) tensor(-591.7145, grad_fn=<SubBackward0>)\n",
      "loss: 1.692063808441162\n",
      "tensor([[855]]) tensor(-589.8072, grad_fn=<SubBackward0>)\n",
      "loss: 1.6898329257965088\n",
      "tensor([[855]]) tensor(-585.4171, grad_fn=<SubBackward0>)\n",
      "loss: 1.6846983432769775\n",
      "tensor([[855]]) tensor(-582.8639, grad_fn=<SubBackward0>)\n",
      "loss: 1.6817121505737305\n",
      "tensor([[855]]) tensor(-577.5161, grad_fn=<SubBackward0>)\n",
      "loss: 1.67545747756958\n",
      "tensor([[855]]) tensor(-587.5994, grad_fn=<SubBackward0>)\n",
      "loss: 1.6872507333755493\n",
      "tensor([[855]]) tensor(-569.4315, grad_fn=<SubBackward0>)\n",
      "loss: 1.6660016775131226\n",
      "tensor([[855]]) tensor(-569.9047, grad_fn=<SubBackward0>)\n",
      "loss: 1.6665551662445068\n",
      "tensor([[855]]) tensor(-567.1185, grad_fn=<SubBackward0>)\n",
      "loss: 1.6632963418960571\n",
      "tensor([[855]]) tensor(-560.7900, grad_fn=<SubBackward0>)\n",
      "loss: 1.6558947563171387\n",
      "tensor([[855]]) tensor(-560.7367, grad_fn=<SubBackward0>)\n",
      "loss: 1.6558324098587036\n",
      "tensor([[855]]) tensor(-557.0553, grad_fn=<SubBackward0>)\n",
      "loss: 1.651526689529419\n",
      "tensor([[855]]) tensor(-553.9771, grad_fn=<SubBackward0>)\n",
      "loss: 1.6479263305664062\n",
      "tensor([[855]]) tensor(-551.3774, grad_fn=<SubBackward0>)\n",
      "loss: 1.6448858976364136\n",
      "tensor([[855]]) tensor(-549.2682, grad_fn=<SubBackward0>)\n",
      "loss: 1.6424190998077393\n",
      "tensor([[855]]) tensor(-546.7357, grad_fn=<SubBackward0>)\n",
      "loss: 1.639456868171692\n",
      "tensor([[855]]) tensor(-545.7777, grad_fn=<SubBackward0>)\n",
      "loss: 1.6383365392684937\n",
      "tensor([[855]]) tensor(-538.7601, grad_fn=<SubBackward0>)\n",
      "loss: 1.6301286220550537\n",
      "tensor([[855]]) tensor(-535.8394, grad_fn=<SubBackward0>)\n",
      "loss: 1.626712679862976\n",
      "tensor([[855]]) tensor(-532.7355, grad_fn=<SubBackward0>)\n",
      "loss: 1.6230825185775757\n",
      "tensor([[855]]) tensor(-529.7234, grad_fn=<SubBackward0>)\n",
      "loss: 1.6195595264434814\n",
      "tensor([[855]]) tensor(-531.1895, grad_fn=<SubBackward0>)\n",
      "loss: 1.6212742328643799\n",
      "tensor([[855]]) tensor(-529.3502, grad_fn=<SubBackward0>)\n",
      "loss: 1.619123101234436\n",
      "tensor([[855]]) tensor(-525.6586, grad_fn=<SubBackward0>)\n",
      "loss: 1.6148053407669067\n",
      "tensor([[855]]) tensor(-522.3489, grad_fn=<SubBackward0>)\n",
      "loss: 1.6109343767166138\n",
      "tensor([[855]]) tensor(-524.7034, grad_fn=<SubBackward0>)\n",
      "loss: 1.6136881113052368\n",
      "tensor([[855]]) tensor(-515.8728, grad_fn=<SubBackward0>)\n",
      "loss: 1.6033600568771362\n",
      "tensor([[855]]) tensor(-513.3623, grad_fn=<SubBackward0>)\n",
      "loss: 1.6004236936569214\n",
      "tensor([[855]]) tensor(-510.2147, grad_fn=<SubBackward0>)\n",
      "loss: 1.5967423915863037\n",
      "tensor([[855]]) tensor(-505.4552, grad_fn=<SubBackward0>)\n",
      "loss: 1.5911756753921509\n",
      "tensor([[855]]) tensor(-507.0751, grad_fn=<SubBackward0>)\n",
      "loss: 1.5930702686309814\n",
      "tensor([[855]]) tensor(-501.6118, grad_fn=<SubBackward0>)\n",
      "loss: 1.58668053150177\n",
      "tensor([[855]]) tensor(-497.9833, grad_fn=<SubBackward0>)\n",
      "loss: 1.5824365615844727\n",
      "tensor([[855]]) tensor(-495.0778, grad_fn=<SubBackward0>)\n",
      "loss: 1.5790385007858276\n",
      "tensor([[855]]) tensor(-494.2964, grad_fn=<SubBackward0>)\n",
      "loss: 1.5781244039535522\n",
      "tensor([[855]]) tensor(-496.3207, grad_fn=<SubBackward0>)\n",
      "loss: 1.5804921388626099\n",
      "tensor([[855]]) tensor(-491.7126, grad_fn=<SubBackward0>)\n",
      "loss: 1.5751025676727295\n",
      "tensor([[855]]) tensor(-488.6710, grad_fn=<SubBackward0>)\n",
      "loss: 1.5715450048446655\n",
      "tensor([[855]]) tensor(-483.9053, grad_fn=<SubBackward0>)\n",
      "loss: 1.5659711360931396\n",
      "tensor([[855]]) tensor(-484.2010, grad_fn=<SubBackward0>)\n",
      "loss: 1.566316843032837\n",
      "tensor([[855]]) tensor(-479.3017, grad_fn=<SubBackward0>)\n",
      "loss: 1.5605868101119995\n",
      "tensor([[855]]) tensor(-481.9688, grad_fn=<SubBackward0>)\n",
      "loss: 1.5637061595916748\n",
      "tensor([[855]]) tensor(-485.3557, grad_fn=<SubBackward0>)\n",
      "loss: 1.5676674842834473\n",
      "tensor([[855]]) tensor(-485.3112, grad_fn=<SubBackward0>)\n",
      "loss: 1.5676153898239136\n",
      "tensor([[855]]) tensor(-482.1617, grad_fn=<SubBackward0>)\n",
      "loss: 1.5639317035675049\n",
      "tensor([[855]]) tensor(-477.4683, grad_fn=<SubBackward0>)\n",
      "loss: 1.5584423542022705\n",
      "tensor([[855]]) tensor(-470.5866, grad_fn=<SubBackward0>)\n",
      "loss: 1.55039381980896\n",
      "tensor([[855]]) tensor(-463.0577, grad_fn=<SubBackward0>)\n",
      "loss: 1.5415879487991333\n",
      "tensor([[855]]) tensor(-470.8751, grad_fn=<SubBackward0>)\n",
      "loss: 1.5507311820983887\n",
      "tensor([[855]]) tensor(-460.0420, grad_fn=<SubBackward0>)\n",
      "loss: 1.5380607843399048\n",
      "tensor([[855]]) tensor(-458.7880, grad_fn=<SubBackward0>)\n",
      "loss: 1.5365941524505615\n",
      "tensor([[855]]) tensor(-461.3809, grad_fn=<SubBackward0>)\n",
      "loss: 1.5396267175674438\n",
      "tensor([[855]]) tensor(-458.9930, grad_fn=<SubBackward0>)\n",
      "loss: 1.5368338823318481\n",
      "tensor([[855]]) tensor(-453.0955, grad_fn=<SubBackward0>)\n",
      "loss: 1.5299361944198608\n",
      "tensor([[855]]) tensor(-448.8659, grad_fn=<SubBackward0>)\n",
      "loss: 1.5249894857406616\n",
      "tensor([[855]]) tensor(-446.0834, grad_fn=<SubBackward0>)\n",
      "loss: 1.5217349529266357\n",
      "tensor([[855]]) tensor(-442.8763, grad_fn=<SubBackward0>)\n",
      "loss: 1.5179839134216309\n",
      "tensor([[855]]) tensor(-443.5005, grad_fn=<SubBackward0>)\n",
      "loss: 1.5187140703201294\n",
      "tensor([[855]]) tensor(-442.6584, grad_fn=<SubBackward0>)\n",
      "loss: 1.5177291631698608\n",
      "tensor([[855]]) tensor(-439.3865, grad_fn=<SubBackward0>)\n",
      "loss: 1.5139023065567017\n",
      "tensor([[855]]) tensor(-435.0637, grad_fn=<SubBackward0>)\n",
      "loss: 1.508846402168274\n",
      "tensor([[855]]) tensor(-429.9525, grad_fn=<SubBackward0>)\n",
      "loss: 1.502868413925171\n",
      "tensor([[855]]) tensor(-426.2806, grad_fn=<SubBackward0>)\n",
      "loss: 1.498573899269104\n",
      "tensor([[855]]) tensor(-426.2520, grad_fn=<SubBackward0>)\n",
      "loss: 1.4985402822494507\n",
      "tensor([[855]]) tensor(-424.6872, grad_fn=<SubBackward0>)\n",
      "loss: 1.496710181236267\n",
      "tensor([[855]]) tensor(-419.7560, grad_fn=<SubBackward0>)\n",
      "loss: 1.4909428358078003\n",
      "tensor([[855]]) tensor(-424.4224, grad_fn=<SubBackward0>)\n",
      "loss: 1.4964004755020142\n",
      "tensor([[855]]) tensor(-414.1022, grad_fn=<SubBackward0>)\n",
      "loss: 1.4843300580978394\n",
      "tensor([[855]]) tensor(-415.5467, grad_fn=<SubBackward0>)\n",
      "loss: 1.486019492149353\n",
      "tensor([[855]]) tensor(-414.5129, grad_fn=<SubBackward0>)\n",
      "loss: 1.484810471534729\n",
      "tensor([[855]]) tensor(-411.6120, grad_fn=<SubBackward0>)\n",
      "loss: 1.4814176559448242\n",
      "tensor([[855]]) tensor(-406.8771, grad_fn=<SubBackward0>)\n",
      "loss: 1.4758797883987427\n",
      "tensor([[855]]) tensor(-406.0768, grad_fn=<SubBackward0>)\n",
      "loss: 1.4749436378479004\n",
      "tensor([[855]]) tensor(-402.7330, grad_fn=<SubBackward0>)\n",
      "loss: 1.4710326194763184\n",
      "tensor([[855]]) tensor(-396.0398, grad_fn=<SubBackward0>)\n",
      "loss: 1.4632043838500977\n",
      "tensor([[855]]) tensor(-393.2162, grad_fn=<SubBackward0>)\n",
      "loss: 1.4599019289016724\n",
      "tensor([[855]]) tensor(-391.3542, grad_fn=<SubBackward0>)\n",
      "loss: 1.4577242136001587\n",
      "tensor([[855]]) tensor(-391.3142, grad_fn=<SubBackward0>)\n",
      "loss: 1.4576774835586548\n",
      "tensor([[855]]) tensor(-391.1476, grad_fn=<SubBackward0>)\n",
      "loss: 1.4574825763702393\n",
      "tensor([[855]]) tensor(-389.7184, grad_fn=<SubBackward0>)\n",
      "loss: 1.4558110237121582\n",
      "tensor([[855]]) tensor(-386.3961, grad_fn=<SubBackward0>)\n",
      "loss: 1.451925277709961\n",
      "tensor([[855]]) tensor(-384.3510, grad_fn=<SubBackward0>)\n",
      "loss: 1.449533224105835\n",
      "tensor([[855]]) tensor(-379.4043, grad_fn=<SubBackward0>)\n",
      "loss: 1.4437477588653564\n",
      "tensor([[855]]) tensor(-374.8414, grad_fn=<SubBackward0>)\n",
      "loss: 1.4384108781814575\n",
      "tensor([[855]]) tensor(-376.4327, grad_fn=<SubBackward0>)\n",
      "loss: 1.4402722120285034\n",
      "tensor([[855]]) tensor(-370.4248, grad_fn=<SubBackward0>)\n",
      "loss: 1.4332454204559326\n",
      "tensor([[855]]) tensor(-370.8384, grad_fn=<SubBackward0>)\n",
      "loss: 1.4337290525436401\n",
      "tensor([[855]]) tensor(-367.6111, grad_fn=<SubBackward0>)\n",
      "loss: 1.4299545288085938\n",
      "tensor([[855]]) tensor(-362.3574, grad_fn=<SubBackward0>)\n",
      "loss: 1.4238098859786987\n",
      "tensor([[855]]) tensor(-362.5593, grad_fn=<SubBackward0>)\n",
      "loss: 1.4240460395812988\n",
      "tensor([[855]]) tensor(-361.2155, grad_fn=<SubBackward0>)\n",
      "loss: 1.4224743843078613\n",
      "tensor([[855]]) tensor(-354.4687, grad_fn=<SubBackward0>)\n",
      "loss: 1.4145833253860474\n",
      "tensor([[855]]) tensor(-351.8599, grad_fn=<SubBackward0>)\n",
      "loss: 1.4115320444107056\n",
      "tensor([[855]]) tensor(-350.9988, grad_fn=<SubBackward0>)\n",
      "loss: 1.410524845123291\n",
      "tensor([[855]]) tensor(-349.4332, grad_fn=<SubBackward0>)\n",
      "loss: 1.408693790435791\n",
      "tensor([[855]]) tensor(-344.0786, grad_fn=<SubBackward0>)\n",
      "loss: 1.4024311304092407\n",
      "tensor([[855]]) tensor(-345.4845, grad_fn=<SubBackward0>)\n",
      "loss: 1.4040753841400146\n",
      "tensor([[855]]) tensor(-338.3649, grad_fn=<SubBackward0>)\n",
      "loss: 1.3957483768463135\n",
      "tensor([[855]]) tensor(-336.1649, grad_fn=<SubBackward0>)\n",
      "loss: 1.3931753635406494\n",
      "tensor([[855]]) tensor(-335.0123, grad_fn=<SubBackward0>)\n",
      "loss: 1.39182710647583\n",
      "tensor([[855]]) tensor(-333.1599, grad_fn=<SubBackward0>)\n",
      "loss: 1.3896607160568237\n",
      "tensor([[855]]) tensor(-329.9265, grad_fn=<SubBackward0>)\n",
      "loss: 1.3858789205551147\n",
      "tensor([[855]]) tensor(-326.4149, grad_fn=<SubBackward0>)\n",
      "loss: 1.3817718029022217\n",
      "tensor([[855]]) tensor(-321.2394, grad_fn=<SubBackward0>)\n",
      "loss: 1.375718593597412\n",
      "tensor([[855]]) tensor(-328.3839, grad_fn=<SubBackward0>)\n",
      "loss: 1.3840745687484741\n",
      "tensor([[855]]) tensor(-321.1791, grad_fn=<SubBackward0>)\n",
      "loss: 1.3756481409072876\n",
      "tensor([[855]]) tensor(-323.3362, grad_fn=<SubBackward0>)\n",
      "loss: 1.3781709671020508\n",
      "tensor([[855]]) tensor(-322.0724, grad_fn=<SubBackward0>)\n",
      "loss: 1.3766928911209106\n",
      "tensor([[855]]) tensor(-317.0200, grad_fn=<SubBackward0>)\n",
      "loss: 1.3707836866378784\n",
      "tensor([[855]]) tensor(-311.4200, grad_fn=<SubBackward0>)\n",
      "loss: 1.3642339706420898\n",
      "tensor([[855]]) tensor(-305.4286, grad_fn=<SubBackward0>)\n",
      "loss: 1.3572263717651367\n",
      "tensor([[855]]) tensor(-305.5099, grad_fn=<SubBackward0>)\n",
      "loss: 1.3573215007781982\n",
      "tensor([[855]]) tensor(-305.4676, grad_fn=<SubBackward0>)\n",
      "loss: 1.3572719097137451\n",
      "tensor([[855]]) tensor(-303.4125, grad_fn=<SubBackward0>)\n",
      "loss: 1.3548684120178223\n",
      "tensor([[855]]) tensor(-299.0063, grad_fn=<SubBackward0>)\n",
      "loss: 1.349714994430542\n",
      "tensor([[855]]) tensor(-295.0699, grad_fn=<SubBackward0>)\n",
      "loss: 1.3451108932495117\n",
      "tensor([[855]]) tensor(-295.0562, grad_fn=<SubBackward0>)\n",
      "loss: 1.345094919204712\n",
      "tensor([[855]]) tensor(-290.5969, grad_fn=<SubBackward0>)\n",
      "loss: 1.3398793935775757\n",
      "tensor([[855]]) tensor(-293.3668, grad_fn=<SubBackward0>)\n",
      "loss: 1.3431191444396973\n",
      "tensor([[855]]) tensor(-291.5988, grad_fn=<SubBackward0>)\n",
      "loss: 1.3410512208938599\n",
      "tensor([[855]]) tensor(-287.1517, grad_fn=<SubBackward0>)\n",
      "loss: 1.3358500003814697\n",
      "tensor([[855]]) tensor(-280.3519, grad_fn=<SubBackward0>)\n",
      "loss: 1.3278969526290894\n",
      "tensor([[855]]) tensor(-288.9091, grad_fn=<SubBackward0>)\n",
      "loss: 1.3379055261611938\n",
      "tensor([[855]]) tensor(-274.4205, grad_fn=<SubBackward0>)\n",
      "loss: 1.3209595680236816\n",
      "tensor([[855]]) tensor(-277.6340, grad_fn=<SubBackward0>)\n",
      "loss: 1.3247181177139282\n",
      "tensor([[855]]) tensor(-278.8712, grad_fn=<SubBackward0>)\n",
      "loss: 1.3261651992797852\n",
      "tensor([[855]]) tensor(-275.7427, grad_fn=<SubBackward0>)\n",
      "loss: 1.322506070137024\n",
      "tensor([[855]]) tensor(-273.2881, grad_fn=<SubBackward0>)\n",
      "loss: 1.3196351528167725\n",
      "tensor([[855]]) tensor(-269.3973, grad_fn=<SubBackward0>)\n",
      "loss: 1.315084457397461\n",
      "tensor([[855]]) tensor(-262.6467, grad_fn=<SubBackward0>)\n",
      "loss: 1.3071891069412231\n",
      "tensor([[855]]) tensor(-258.1023, grad_fn=<SubBackward0>)\n",
      "loss: 1.301874041557312\n",
      "tensor([[855]]) tensor(-259.7822, grad_fn=<SubBackward0>)\n",
      "loss: 1.303838849067688\n",
      "tensor([[855]]) tensor(-260.0151, grad_fn=<SubBackward0>)\n",
      "loss: 1.3041112422943115\n",
      "tensor([[855]]) tensor(-255.8688, grad_fn=<SubBackward0>)\n",
      "loss: 1.2992618083953857\n",
      "tensor([[855]]) tensor(-253.6382, grad_fn=<SubBackward0>)\n",
      "loss: 1.2966527938842773\n",
      "tensor([[855]]) tensor(-244.9747, grad_fn=<SubBackward0>)\n",
      "loss: 1.286520004272461\n",
      "tensor([[855]]) tensor(-247.2875, grad_fn=<SubBackward0>)\n",
      "loss: 1.2892251014709473\n",
      "tensor([[855]]) tensor(-242.2701, grad_fn=<SubBackward0>)\n",
      "loss: 1.283356785774231\n",
      "tensor([[855]]) tensor(-237.0322, grad_fn=<SubBackward0>)\n",
      "loss: 1.2772306203842163\n",
      "tensor([[855]]) tensor(-239.5121, grad_fn=<SubBackward0>)\n",
      "loss: 1.280131220817566\n",
      "tensor([[855]]) tensor(-236.3472, grad_fn=<SubBackward0>)\n",
      "loss: 1.2764294147491455\n",
      "tensor([[855]]) tensor(-236.8408, grad_fn=<SubBackward0>)\n",
      "loss: 1.2770068645477295\n",
      "tensor([[855]]) tensor(-236.0214, grad_fn=<SubBackward0>)\n",
      "loss: 1.2760484218597412\n",
      "tensor([[855]]) tensor(-230.9722, grad_fn=<SubBackward0>)\n",
      "loss: 1.270142912864685\n",
      "tensor([[855]]) tensor(-224.0430, grad_fn=<SubBackward0>)\n",
      "loss: 1.2620385885238647\n",
      "tensor([[855]]) tensor(-224.3224, grad_fn=<SubBackward0>)\n",
      "loss: 1.262365460395813\n",
      "tensor([[855]]) tensor(-217.7806, grad_fn=<SubBackward0>)\n",
      "loss: 1.2547142505645752\n",
      "tensor([[855]]) tensor(-217.3687, grad_fn=<SubBackward0>)\n",
      "loss: 1.2542322874069214\n",
      "tensor([[855]]) tensor(-218.5748, grad_fn=<SubBackward0>)\n",
      "loss: 1.2556428909301758\n",
      "tensor([[855]]) tensor(-217.5501, grad_fn=<SubBackward0>)\n",
      "loss: 1.2544444799423218\n",
      "tensor([[855]]) tensor(-215.2792, grad_fn=<SubBackward0>)\n",
      "loss: 1.25178861618042\n",
      "tensor([[855]]) tensor(-211.7291, grad_fn=<SubBackward0>)\n",
      "loss: 1.247636318206787\n",
      "tensor([[855]]) tensor(-206.5812, grad_fn=<SubBackward0>)\n",
      "loss: 1.2416155338287354\n",
      "tensor([[855]]) tensor(-200.7120, grad_fn=<SubBackward0>)\n",
      "loss: 1.2347508668899536\n",
      "tensor([[855]]) tensor(-195.0003, grad_fn=<SubBackward0>)\n",
      "loss: 1.2280704975128174\n",
      "tensor([[855]]) tensor(-198.3918, grad_fn=<SubBackward0>)\n",
      "loss: 1.2320373058319092\n",
      "tensor([[855]]) tensor(-196.4976, grad_fn=<SubBackward0>)\n",
      "loss: 1.2298216819763184\n",
      "tensor([[855]]) tensor(-195.9660, grad_fn=<SubBackward0>)\n",
      "loss: 1.2292001247406006\n",
      "tensor([[855]]) tensor(-189.4028, grad_fn=<SubBackward0>)\n",
      "loss: 1.2215237617492676\n",
      "tensor([[855]]) tensor(-188.1857, grad_fn=<SubBackward0>)\n",
      "loss: 1.2201002836227417\n",
      "tensor([[855]]) tensor(-181.4042, grad_fn=<SubBackward0>)\n",
      "loss: 1.21216881275177\n",
      "tensor([[855]]) tensor(-182.4664, grad_fn=<SubBackward0>)\n",
      "loss: 1.2134109735488892\n",
      "tensor([[855]]) tensor(-179.6311, grad_fn=<SubBackward0>)\n",
      "loss: 1.2100948095321655\n",
      "tensor([[855]]) tensor(-182.1011, grad_fn=<SubBackward0>)\n",
      "loss: 1.2129837274551392\n",
      "tensor([[855]]) tensor(-173.3383, grad_fn=<SubBackward0>)\n",
      "loss: 1.2027349472045898\n",
      "tensor([[855]]) tensor(-172.7834, grad_fn=<SubBackward0>)\n",
      "loss: 1.2020858526229858\n",
      "tensor([[855]]) tensor(-173.9766, grad_fn=<SubBackward0>)\n",
      "loss: 1.2034813165664673\n",
      "tensor([[855]]) tensor(-172.6053, grad_fn=<SubBackward0>)\n",
      "loss: 1.201877474784851\n",
      "tensor([[855]]) tensor(-174.8682, grad_fn=<SubBackward0>)\n",
      "loss: 1.2045241594314575\n",
      "tensor([[855]]) tensor(-165.8528, grad_fn=<SubBackward0>)\n",
      "loss: 1.1939798593521118\n",
      "tensor([[855]]) tensor(-160.4133, grad_fn=<SubBackward0>)\n",
      "loss: 1.1876178979873657\n",
      "tensor([[855]]) tensor(-157.1760, grad_fn=<SubBackward0>)\n",
      "loss: 1.1838315725326538\n",
      "tensor([[855]]) tensor(-153.7419, grad_fn=<SubBackward0>)\n",
      "loss: 1.1798151731491089\n",
      "tensor([[855]]) tensor(-154.1116, grad_fn=<SubBackward0>)\n",
      "loss: 1.1802475452423096\n",
      "tensor([[855]]) tensor(-154.8812, grad_fn=<SubBackward0>)\n",
      "loss: 1.181147575378418\n",
      "tensor([[855]]) tensor(-149.8762, grad_fn=<SubBackward0>)\n",
      "loss: 1.1752938032150269\n",
      "tensor([[855]]) tensor(-146.7158, grad_fn=<SubBackward0>)\n",
      "loss: 1.1715973615646362\n",
      "tensor([[855]]) tensor(-141.4926, grad_fn=<SubBackward0>)\n",
      "loss: 1.1654884815216064\n",
      "tensor([[855]]) tensor(-138.0676, grad_fn=<SubBackward0>)\n",
      "loss: 1.161482572555542\n",
      "tensor([[855]]) tensor(-132.5963, grad_fn=<SubBackward0>)\n",
      "loss: 1.1550832986831665\n",
      "tensor([[855]]) tensor(-131.4042, grad_fn=<SubBackward0>)\n",
      "loss: 1.1536891460418701\n",
      "tensor([[855]]) tensor(-132.2604, grad_fn=<SubBackward0>)\n",
      "loss: 1.1546905040740967\n",
      "tensor([[855]]) tensor(-132.0323, grad_fn=<SubBackward0>)\n",
      "loss: 1.1544238328933716\n",
      "tensor([[855]]) tensor(-128.2937, grad_fn=<SubBackward0>)\n",
      "loss: 1.1500511169433594\n",
      "tensor([[855]]) tensor(-124.8287, grad_fn=<SubBackward0>)\n",
      "loss: 1.145998477935791\n",
      "tensor([[855]]) tensor(-121.6321, grad_fn=<SubBackward0>)\n",
      "loss: 1.1422598361968994\n",
      "tensor([[855]]) tensor(-121.4857, grad_fn=<SubBackward0>)\n",
      "loss: 1.142088532447815\n",
      "tensor([[855]]) tensor(-112.8693, grad_fn=<SubBackward0>)\n",
      "loss: 1.132010817527771\n",
      "tensor([[855]]) tensor(-111.8086, grad_fn=<SubBackward0>)\n",
      "loss: 1.1307703256607056\n",
      "tensor([[855]]) tensor(-110.1105, grad_fn=<SubBackward0>)\n",
      "loss: 1.1287841796875\n",
      "tensor([[855]]) tensor(-114.0959, grad_fn=<SubBackward0>)\n",
      "loss: 1.1334455013275146\n",
      "tensor([[855]]) tensor(-112.9344, grad_fn=<SubBackward0>)\n",
      "loss: 1.132086992263794\n",
      "tensor([[855]]) tensor(-106.4082, grad_fn=<SubBackward0>)\n",
      "loss: 1.1244540214538574\n",
      "tensor([[855]]) tensor(-100.7487, grad_fn=<SubBackward0>)\n",
      "loss: 1.1178346872329712\n",
      "tensor([[855]]) tensor(-97.2575, grad_fn=<SubBackward0>)\n",
      "loss: 1.1137514114379883\n",
      "tensor([[855]]) tensor(-101.7632, grad_fn=<SubBackward0>)\n",
      "loss: 1.1190212965011597\n",
      "tensor([[855]]) tensor(-97.0172, grad_fn=<SubBackward0>)\n",
      "loss: 1.113470435142517\n",
      "tensor([[855]]) tensor(-91.8942, grad_fn=<SubBackward0>)\n",
      "loss: 1.1074786186218262\n",
      "tensor([[855]]) tensor(-85.5674, grad_fn=<SubBackward0>)\n",
      "loss: 1.100078821182251\n",
      "tensor([[855]]) tensor(-93.3776, grad_fn=<SubBackward0>)\n",
      "loss: 1.1092135906219482\n",
      "tensor([[855]]) tensor(-83.5842, grad_fn=<SubBackward0>)\n",
      "loss: 1.0977592468261719\n",
      "tensor([[855]]) tensor(-84.1498, grad_fn=<SubBackward0>)\n",
      "loss: 1.0984208583831787\n",
      "tensor([[855]]) tensor(-83.7325, grad_fn=<SubBackward0>)\n",
      "loss: 1.0979326963424683\n",
      "tensor([[855]]) tensor(-80.0140, grad_fn=<SubBackward0>)\n",
      "loss: 1.0935837030410767\n",
      "tensor([[855]]) tensor(-74.5399, grad_fn=<SubBackward0>)\n",
      "loss: 1.0871812105178833\n",
      "tensor([[855]]) tensor(-69.7862, grad_fn=<SubBackward0>)\n",
      "loss: 1.0816212892532349\n",
      "tensor([[855]]) tensor(-66.9931, grad_fn=<SubBackward0>)\n",
      "loss: 1.0783544778823853\n",
      "tensor([[855]]) tensor(-64.9252, grad_fn=<SubBackward0>)\n",
      "loss: 1.0759358406066895\n",
      "tensor([[855]]) tensor(-64.3690, grad_fn=<SubBackward0>)\n",
      "loss: 1.0752854347229004\n",
      "tensor([[855]]) tensor(-61.0188, grad_fn=<SubBackward0>)\n",
      "loss: 1.0713670253753662\n",
      "tensor([[855]]) tensor(-59.5684, grad_fn=<SubBackward0>)\n",
      "loss: 1.0696706771850586\n",
      "tensor([[855]]) tensor(-53.8918, grad_fn=<SubBackward0>)\n",
      "loss: 1.0630314350128174\n",
      "tensor([[855]]) tensor(-52.8671, grad_fn=<SubBackward0>)\n",
      "loss: 1.0618329048156738\n",
      "tensor([[855]]) tensor(-52.3315, grad_fn=<SubBackward0>)\n",
      "loss: 1.0612064599990845\n",
      "tensor([[855]]) tensor(-50.6930, grad_fn=<SubBackward0>)\n",
      "loss: 1.0592900514602661\n",
      "tensor([[855]]) tensor(-45.7043, grad_fn=<SubBackward0>)\n",
      "loss: 1.0534553527832031\n",
      "tensor([[855]]) tensor(-43.8149, grad_fn=<SubBackward0>)\n",
      "loss: 1.0512454509735107\n",
      "tensor([[855]]) tensor(-40.4854, grad_fn=<SubBackward0>)\n",
      "loss: 1.0473512411117554\n",
      "tensor([[855]]) tensor(-42.2943, grad_fn=<SubBackward0>)\n",
      "loss: 1.0494670867919922\n",
      "tensor([[855]]) tensor(-36.2158, grad_fn=<SubBackward0>)\n",
      "loss: 1.0423576831817627\n",
      "tensor([[855]]) tensor(-32.2096, grad_fn=<SubBackward0>)\n",
      "loss: 1.0376720428466797\n",
      "tensor([[855]]) tensor(-38.1024, grad_fn=<SubBackward0>)\n",
      "loss: 1.0445642471313477\n",
      "tensor([[855]]) tensor(-29.5477, grad_fn=<SubBackward0>)\n",
      "loss: 1.0345587730407715\n",
      "tensor([[855]]) tensor(-30.9242, grad_fn=<SubBackward0>)\n",
      "loss: 1.0361686944961548\n",
      "tensor([[855]]) tensor(-30.3672, grad_fn=<SubBackward0>)\n",
      "loss: 1.0355172157287598\n",
      "tensor([[855]]) tensor(-27.5508, grad_fn=<SubBackward0>)\n",
      "loss: 1.032223105430603\n",
      "tensor([[855]]) tensor(-22.7337, grad_fn=<SubBackward0>)\n",
      "loss: 1.0265891551971436\n",
      "tensor([[855]]) tensor(-17.9743, grad_fn=<SubBackward0>)\n",
      "loss: 1.0210225582122803\n",
      "tensor([[855]]) tensor(-19.3325, grad_fn=<SubBackward0>)\n",
      "loss: 1.0226110219955444\n",
      "tensor([[855]]) tensor(-18.5399, grad_fn=<SubBackward0>)\n",
      "loss: 1.021684169769287\n",
      "tensor([[855]]) tensor(-18.3609, grad_fn=<SubBackward0>)\n",
      "loss: 1.0214747190475464\n",
      "tensor([[855]]) tensor(-14.8975, grad_fn=<SubBackward0>)\n",
      "loss: 1.0174239873886108\n",
      "tensor([[855]]) tensor(-5.9558, grad_fn=<SubBackward0>)\n",
      "loss: 1.0069658756256104\n",
      "tensor([[855]]) tensor(-10.3953, grad_fn=<SubBackward0>)\n",
      "loss: 1.0121582746505737\n",
      "tensor([[855]]) tensor(-6.3500, grad_fn=<SubBackward0>)\n",
      "loss: 1.0074269771575928\n",
      "tensor([[855]]) tensor(-2.7309, grad_fn=<SubBackward0>)\n",
      "loss: 1.003193974494934\n",
      "tensor([[855]]) tensor(-3.9522, grad_fn=<SubBackward0>)\n",
      "loss: 1.004622459411621\n",
      "tensor([[855]]) tensor(-4.7273, grad_fn=<SubBackward0>)\n",
      "loss: 1.0055290460586548\n",
      "tensor([[855]]) tensor(-1.4204, grad_fn=<SubBackward0>)\n",
      "loss: 1.0016613006591797\n",
      "tensor([[855]]) tensor(4.5568, grad_fn=<SubBackward0>)\n",
      "loss: 0.9946704506874084\n",
      "tensor([[855]]) tensor(9.7936, grad_fn=<SubBackward0>)\n",
      "loss: 0.9885455369949341\n",
      "tensor([[855]]) tensor(4.7206, grad_fn=<SubBackward0>)\n",
      "loss: 0.9944787621498108\n",
      "tensor([[855]]) tensor(11.9032, grad_fn=<SubBackward0>)\n",
      "loss: 0.986078143119812\n",
      "tensor([[855]]) tensor(12.5801, grad_fn=<SubBackward0>)\n",
      "loss: 0.9852864742279053\n",
      "tensor([[855]]) tensor(14.7981, grad_fn=<SubBackward0>)\n",
      "loss: 0.982692301273346\n",
      "tensor([[855]]) tensor(17.2654, grad_fn=<SubBackward0>)\n",
      "loss: 0.9798065423965454\n",
      "tensor([[855]]) tensor(21.3883, grad_fn=<SubBackward0>)\n",
      "loss: 0.9749844670295715\n",
      "tensor([[855]]) tensor(23.6067, grad_fn=<SubBackward0>)\n",
      "loss: 0.972389817237854\n",
      "tensor([[855]]) tensor(22.5854, grad_fn=<SubBackward0>)\n",
      "loss: 0.9735842943191528\n",
      "tensor([[855]]) tensor(22.7200, grad_fn=<SubBackward0>)\n",
      "loss: 0.973426878452301\n",
      "tensor([[855]]) tensor(23.0404, grad_fn=<SubBackward0>)\n",
      "loss: 0.9730521440505981\n",
      "tensor([[855]]) tensor(21.8486, grad_fn=<SubBackward0>)\n",
      "loss: 0.9744460582733154\n",
      "tensor([[855]]) tensor(25.2137, grad_fn=<SubBackward0>)\n",
      "loss: 0.9705102443695068\n",
      "tensor([[855]]) tensor(33.0129, grad_fn=<SubBackward0>)\n",
      "loss: 0.961388349533081\n",
      "tensor([[855]]) tensor(42.0912, grad_fn=<SubBackward0>)\n",
      "loss: 0.9507705569267273\n",
      "tensor([[855]]) tensor(37.3146, grad_fn=<SubBackward0>)\n",
      "loss: 0.9563572406768799\n",
      "tensor([[855]]) tensor(38.3306, grad_fn=<SubBackward0>)\n",
      "loss: 0.9551689028739929\n",
      "tensor([[855]]) tensor(37.6251, grad_fn=<SubBackward0>)\n",
      "loss: 0.9559940099716187\n",
      "tensor([[855]]) tensor(41.1152, grad_fn=<SubBackward0>)\n",
      "loss: 0.9519121050834656\n",
      "tensor([[855]]) tensor(47.6437, grad_fn=<SubBackward0>)\n",
      "loss: 0.9442763924598694\n",
      "tensor([[855]]) tensor(50.7781, grad_fn=<SubBackward0>)\n",
      "loss: 0.9406103491783142\n",
      "tensor([[855]]) tensor(50.8936, grad_fn=<SubBackward0>)\n",
      "loss: 0.9404754042625427\n",
      "tensor([[855]]) tensor(53.5040, grad_fn=<SubBackward0>)\n",
      "loss: 0.9374222159385681\n",
      "tensor([[855]]) tensor(52.1561, grad_fn=<SubBackward0>)\n",
      "loss: 0.9389986991882324\n",
      "tensor([[855]]) tensor(55.0383, grad_fn=<SubBackward0>)\n",
      "loss: 0.9356277585029602\n",
      "tensor([[855]]) tensor(58.5636, grad_fn=<SubBackward0>)\n",
      "loss: 0.9315045475959778\n",
      "tensor([[855]]) tensor(65.7938, grad_fn=<SubBackward0>)\n",
      "loss: 0.9230482578277588\n",
      "tensor([[855]]) tensor(59.3745, grad_fn=<SubBackward0>)\n",
      "loss: 0.9305561780929565\n",
      "tensor([[855]]) tensor(65.5840, grad_fn=<SubBackward0>)\n",
      "loss: 0.9232935309410095\n",
      "tensor([[855]]) tensor(66.6349, grad_fn=<SubBackward0>)\n",
      "loss: 0.922064483165741\n",
      "tensor([[855]]) tensor(68.0779, grad_fn=<SubBackward0>)\n",
      "loss: 0.920376718044281\n",
      "tensor([[855]]) tensor(68.5366, grad_fn=<SubBackward0>)\n",
      "loss: 0.9198402166366577\n",
      "tensor([[855]]) tensor(73.5287, grad_fn=<SubBackward0>)\n",
      "loss: 0.91400146484375\n",
      "tensor([[855]]) tensor(79.4979, grad_fn=<SubBackward0>)\n",
      "loss: 0.9070199728012085\n",
      "tensor([[855]]) tensor(74.9866, grad_fn=<SubBackward0>)\n",
      "loss: 0.9122963547706604\n",
      "tensor([[855]]) tensor(84.4205, grad_fn=<SubBackward0>)\n",
      "loss: 0.9012625217437744\n",
      "tensor([[855]]) tensor(84.6855, grad_fn=<SubBackward0>)\n",
      "loss: 0.9009525775909424\n",
      "tensor([[855]]) tensor(86.4548, grad_fn=<SubBackward0>)\n",
      "loss: 0.8988832235336304\n",
      "tensor([[855]]) tensor(88.7736, grad_fn=<SubBackward0>)\n",
      "loss: 0.8961712718009949\n",
      "tensor([[855]]) tensor(93.6389, grad_fn=<SubBackward0>)\n",
      "loss: 0.8904808759689331\n",
      "tensor([[855]]) tensor(98.4904, grad_fn=<SubBackward0>)\n",
      "loss: 0.8848065733909607\n",
      "tensor([[855]]) tensor(97.3336, grad_fn=<SubBackward0>)\n",
      "loss: 0.8861595988273621\n",
      "tensor([[855]]) tensor(96.2776, grad_fn=<SubBackward0>)\n",
      "loss: 0.8873946070671082\n",
      "tensor([[855]]) tensor(99.2068, grad_fn=<SubBackward0>)\n",
      "loss: 0.8839685916900635\n",
      "tensor([[855]]) tensor(98.0044, grad_fn=<SubBackward0>)\n",
      "loss: 0.8853749632835388\n",
      "tensor([[855]]) tensor(100.1562, grad_fn=<SubBackward0>)\n",
      "loss: 0.8828582167625427\n",
      "tensor([[855]]) tensor(106.0102, grad_fn=<SubBackward0>)\n",
      "loss: 0.8760114908218384\n",
      "tensor([[855]]) tensor(110.3431, grad_fn=<SubBackward0>)\n",
      "loss: 0.8709437251091003\n",
      "tensor([[855]]) tensor(111.8946, grad_fn=<SubBackward0>)\n",
      "loss: 0.8691291213035583\n",
      "tensor([[855]]) tensor(109.8880, grad_fn=<SubBackward0>)\n",
      "loss: 0.8714759945869446\n",
      "tensor([[855]]) tensor(116.7840, grad_fn=<SubBackward0>)\n",
      "loss: 0.8634105324745178\n",
      "tensor([[855]]) tensor(111.5870, grad_fn=<SubBackward0>)\n",
      "loss: 0.8694888353347778\n",
      "tensor([[855]]) tensor(122.5334, grad_fn=<SubBackward0>)\n",
      "loss: 0.8566860556602478\n",
      "tensor([[855]]) tensor(120.4945, grad_fn=<SubBackward0>)\n",
      "loss: 0.8590707778930664\n",
      "tensor([[855]]) tensor(119.8434, grad_fn=<SubBackward0>)\n",
      "loss: 0.859832227230072\n",
      "tensor([[855]]) tensor(122.5413, grad_fn=<SubBackward0>)\n",
      "loss: 0.8566768765449524\n",
      "tensor([[855]]) tensor(128.9904, grad_fn=<SubBackward0>)\n",
      "loss: 0.849134087562561\n",
      "tensor([[855]]) tensor(132.6409, grad_fn=<SubBackward0>)\n",
      "loss: 0.8448644876480103\n",
      "tensor([[855]]) tensor(135.4331, grad_fn=<SubBackward0>)\n",
      "loss: 0.8415986895561218\n",
      "tensor([[855]]) tensor(139.6387, grad_fn=<SubBackward0>)\n",
      "loss: 0.8366799354553223\n",
      "tensor([[855]]) tensor(137.8314, grad_fn=<SubBackward0>)\n",
      "loss: 0.8387936353683472\n",
      "tensor([[855]]) tensor(142.0561, grad_fn=<SubBackward0>)\n",
      "loss: 0.8338525295257568\n",
      "tensor([[855]]) tensor(138.5266, grad_fn=<SubBackward0>)\n",
      "loss: 0.8379806280136108\n",
      "tensor([[855]]) tensor(143.1428, grad_fn=<SubBackward0>)\n",
      "loss: 0.8325815200805664\n",
      "tensor([[855]]) tensor(143.7543, grad_fn=<SubBackward0>)\n",
      "loss: 0.8318663239479065\n",
      "tensor([[855]]) tensor(148.4152, grad_fn=<SubBackward0>)\n",
      "loss: 0.826414942741394\n",
      "tensor([[855]]) tensor(151.8812, grad_fn=<SubBackward0>)\n",
      "loss: 0.8223612308502197\n",
      "tensor([[855]]) tensor(143.3537, grad_fn=<SubBackward0>)\n",
      "loss: 0.8323348760604858\n",
      "tensor([[855]]) tensor(153.1898, grad_fn=<SubBackward0>)\n",
      "loss: 0.8208306431770325\n",
      "tensor([[855]]) tensor(157.6589, grad_fn=<SubBackward0>)\n",
      "loss: 0.8156036138534546\n",
      "tensor([[855]]) tensor(151.9004, grad_fn=<SubBackward0>)\n",
      "loss: 0.8223387002944946\n",
      "tensor([[855]]) tensor(159.0486, grad_fn=<SubBackward0>)\n",
      "loss: 0.8139781951904297\n",
      "tensor([[855]]) tensor(158.2948, grad_fn=<SubBackward0>)\n",
      "loss: 0.8148598670959473\n",
      "tensor([[855]]) tensor(163.3839, grad_fn=<SubBackward0>)\n",
      "loss: 0.8089078068733215\n",
      "tensor([[855]]) tensor(167.0743, grad_fn=<SubBackward0>)\n",
      "loss: 0.8045914769172668\n",
      "tensor([[855]]) tensor(164.9918, grad_fn=<SubBackward0>)\n",
      "loss: 0.8070271015167236\n",
      "tensor([[855]]) tensor(169.6387, grad_fn=<SubBackward0>)\n",
      "loss: 0.8015921115875244\n",
      "tensor([[855]]) tensor(172.0240, grad_fn=<SubBackward0>)\n",
      "loss: 0.7988022565841675\n",
      "tensor([[855]]) tensor(169.8682, grad_fn=<SubBackward0>)\n",
      "loss: 0.8013237118721008\n",
      "tensor([[855]]) tensor(174.6589, grad_fn=<SubBackward0>)\n",
      "loss: 0.795720636844635\n",
      "tensor([[855]]) tensor(173.3154, grad_fn=<SubBackward0>)\n",
      "loss: 0.7972918748855591\n",
      "tensor([[855]]) tensor(174.9708, grad_fn=<SubBackward0>)\n",
      "loss: 0.7953558564186096\n",
      "tensor([[855]]) tensor(181.1328, grad_fn=<SubBackward0>)\n",
      "loss: 0.788148820400238\n",
      "tensor([[855]]) tensor(182.4764, grad_fn=<SubBackward0>)\n",
      "loss: 0.7865773439407349\n",
      "tensor([[855]]) tensor(182.0886, grad_fn=<SubBackward0>)\n",
      "loss: 0.7870308756828308\n",
      "tensor([[855]]) tensor(187.4432, grad_fn=<SubBackward0>)\n",
      "loss: 0.7807681560516357\n",
      "tensor([[855]]) tensor(185.0045, grad_fn=<SubBackward0>)\n",
      "loss: 0.7836205363273621\n",
      "tensor([[855]]) tensor(187.8278, grad_fn=<SubBackward0>)\n",
      "loss: 0.7803183197975159\n",
      "tensor([[855]]) tensor(187.6235, grad_fn=<SubBackward0>)\n",
      "loss: 0.7805573344230652\n",
      "tensor([[855]]) tensor(195.5709, grad_fn=<SubBackward0>)\n",
      "loss: 0.7712621688842773\n",
      "tensor([[855]]) tensor(192.1351, grad_fn=<SubBackward0>)\n",
      "loss: 0.7752805948257446\n",
      "tensor([[855]]) tensor(194.7671, grad_fn=<SubBackward0>)\n",
      "loss: 0.7722022533416748\n",
      "tensor([[855]]) tensor(198.6255, grad_fn=<SubBackward0>)\n",
      "loss: 0.7676894664764404\n",
      "tensor([[855]]) tensor(203.6389, grad_fn=<SubBackward0>)\n",
      "loss: 0.7618259191513062\n",
      "tensor([[855]]) tensor(200.1989, grad_fn=<SubBackward0>)\n",
      "loss: 0.765849232673645\n",
      "tensor([[855]]) tensor(197.7535, grad_fn=<SubBackward0>)\n",
      "loss: 0.7687093019485474\n",
      "tensor([[855]]) tensor(203.2459, grad_fn=<SubBackward0>)\n",
      "loss: 0.7622854709625244\n",
      "tensor([[855]]) tensor(211.9965, grad_fn=<SubBackward0>)\n",
      "loss: 0.7520508766174316\n",
      "tensor([[855]]) tensor(200.2944, grad_fn=<SubBackward0>)\n",
      "loss: 0.7657375931739807\n",
      "tensor([[855]]) tensor(206.8932, grad_fn=<SubBackward0>)\n",
      "loss: 0.7580196857452393\n",
      "tensor([[855]]) tensor(205.7477, grad_fn=<SubBackward0>)\n",
      "loss: 0.7593593597412109\n",
      "tensor([[855]]) tensor(208.2649, grad_fn=<SubBackward0>)\n",
      "loss: 0.7564153075218201\n",
      "tensor([[855]]) tensor(213.1583, grad_fn=<SubBackward0>)\n",
      "loss: 0.7506920099258423\n",
      "tensor([[855]]) tensor(215.8518, grad_fn=<SubBackward0>)\n",
      "loss: 0.7475417256355286\n",
      "tensor([[855]]) tensor(217.6080, grad_fn=<SubBackward0>)\n",
      "loss: 0.7454876899719238\n",
      "tensor([[855]]) tensor(222.8995, grad_fn=<SubBackward0>)\n",
      "loss: 0.7392988801002502\n",
      "tensor([[855]]) tensor(221.3915, grad_fn=<SubBackward0>)\n",
      "loss: 0.741062581539154\n",
      "tensor([[855]]) tensor(229.5096, grad_fn=<SubBackward0>)\n",
      "loss: 0.7315677404403687\n",
      "tensor([[855]]) tensor(224.9855, grad_fn=<SubBackward0>)\n",
      "loss: 0.7368590235710144\n",
      "tensor([[855]]) tensor(221.4829, grad_fn=<SubBackward0>)\n",
      "loss: 0.740955650806427\n",
      "tensor([[855]]) tensor(227.3793, grad_fn=<SubBackward0>)\n",
      "loss: 0.7340593338012695\n",
      "tensor([[855]]) tensor(230.0410, grad_fn=<SubBackward0>)\n",
      "loss: 0.7309462428092957\n",
      "tensor([[855]]) tensor(232.8557, grad_fn=<SubBackward0>)\n",
      "loss: 0.7276541590690613\n",
      "tensor([[855]]) tensor(236.0189, grad_fn=<SubBackward0>)\n",
      "loss: 0.7239544987678528\n",
      "tensor([[855]]) tensor(235.1083, grad_fn=<SubBackward0>)\n",
      "loss: 0.7250195145606995\n",
      "tensor([[855]]) tensor(242.9105, grad_fn=<SubBackward0>)\n",
      "loss: 0.7158942222595215\n",
      "tensor([[855]]) tensor(242.0117, grad_fn=<SubBackward0>)\n",
      "loss: 0.7169454097747803\n",
      "tensor([[855]]) tensor(244.6236, grad_fn=<SubBackward0>)\n",
      "loss: 0.713890552520752\n",
      "tensor([[855]]) tensor(249.2988, grad_fn=<SubBackward0>)\n",
      "loss: 0.7084224820137024\n",
      "tensor([[855]]) tensor(243.2761, grad_fn=<SubBackward0>)\n",
      "loss: 0.7154666185379028\n",
      "tensor([[855]]) tensor(257.0604, grad_fn=<SubBackward0>)\n",
      "loss: 0.6993445754051208\n",
      "tensor([[855]]) tensor(255.3373, grad_fn=<SubBackward0>)\n",
      "loss: 0.7013599276542664\n",
      "tensor([[855]]) tensor(254.8312, grad_fn=<SubBackward0>)\n",
      "loss: 0.7019518613815308\n",
      "tensor([[855]]) tensor(256.5783, grad_fn=<SubBackward0>)\n",
      "loss: 0.699908435344696\n",
      "tensor([[855]]) tensor(259.6815, grad_fn=<SubBackward0>)\n",
      "loss: 0.696278989315033\n",
      "tensor([[855]]) tensor(260.8313, grad_fn=<SubBackward0>)\n",
      "loss: 0.6949341297149658\n",
      "tensor([[855]]) tensor(262.0731, grad_fn=<SubBackward0>)\n",
      "loss: 0.6934817433357239\n",
      "tensor([[855]]) tensor(268.5725, grad_fn=<SubBackward0>)\n",
      "loss: 0.6858801245689392\n",
      "tensor([[855]]) tensor(258.0959, grad_fn=<SubBackward0>)\n",
      "loss: 0.6981334686279297\n",
      "tensor([[855]]) tensor(265.8061, grad_fn=<SubBackward0>)\n",
      "loss: 0.6891157031059265\n",
      "tensor([[855]]) tensor(275.1799, grad_fn=<SubBackward0>)\n",
      "loss: 0.6781522035598755\n",
      "tensor([[855]]) tensor(265.8054, grad_fn=<SubBackward0>)\n",
      "loss: 0.6891164779663086\n",
      "tensor([[855]]) tensor(271.7612, grad_fn=<SubBackward0>)\n",
      "loss: 0.6821506023406982\n",
      "tensor([[855]]) tensor(270.6673, grad_fn=<SubBackward0>)\n",
      "loss: 0.6834300756454468\n",
      "tensor([[855]]) tensor(269.8176, grad_fn=<SubBackward0>)\n",
      "loss: 0.6844238042831421\n",
      "tensor([[855]]) tensor(267.4376, grad_fn=<SubBackward0>)\n",
      "loss: 0.6872075200080872\n",
      "tensor([[855]]) tensor(270.6834, grad_fn=<SubBackward0>)\n",
      "loss: 0.6834112405776978\n",
      "tensor([[855]]) tensor(278.4358, grad_fn=<SubBackward0>)\n",
      "loss: 0.6743441224098206\n",
      "tensor([[855]]) tensor(284.7446, grad_fn=<SubBackward0>)\n",
      "loss: 0.6669653654098511\n",
      "tensor([[855]]) tensor(292.8282, grad_fn=<SubBackward0>)\n",
      "loss: 0.6575108766555786\n",
      "tensor([[855]]) tensor(273.5775, grad_fn=<SubBackward0>)\n",
      "loss: 0.6800262928009033\n",
      "tensor([[855]]) tensor(278.0912, grad_fn=<SubBackward0>)\n",
      "loss: 0.6747471690177917\n",
      "tensor([[855]]) tensor(299.0956, grad_fn=<SubBackward0>)\n",
      "loss: 0.6501805186271667\n",
      "tensor([[855]]) tensor(292.3337, grad_fn=<SubBackward0>)\n",
      "loss: 0.658089280128479\n",
      "tensor([[855]]) tensor(290.7609, grad_fn=<SubBackward0>)\n",
      "loss: 0.6599287390708923\n",
      "tensor([[855]]) tensor(294.0636, grad_fn=<SubBackward0>)\n",
      "loss: 0.6560659408569336\n",
      "tensor([[855]]) tensor(294.0786, grad_fn=<SubBackward0>)\n",
      "loss: 0.6560484766960144\n",
      "tensor([[855]]) tensor(297.0626, grad_fn=<SubBackward0>)\n",
      "loss: 0.6525583267211914\n",
      "tensor([[855]]) tensor(303.9323, grad_fn=<SubBackward0>)\n",
      "loss: 0.6445236206054688\n",
      "tensor([[855]]) tensor(312.6585, grad_fn=<SubBackward0>)\n",
      "loss: 0.6343175172805786\n",
      "tensor([[855]]) tensor(306.2560, grad_fn=<SubBackward0>)\n",
      "loss: 0.6418058276176453\n",
      "tensor([[855]]) tensor(308.6667, grad_fn=<SubBackward0>)\n",
      "loss: 0.6389862298965454\n",
      "tensor([[855]]) tensor(308.2059, grad_fn=<SubBackward0>)\n",
      "loss: 0.639525294303894\n",
      "tensor([[855]]) tensor(313.6610, grad_fn=<SubBackward0>)\n",
      "loss: 0.6331450343132019\n",
      "tensor([[855]]) tensor(318.7488, grad_fn=<SubBackward0>)\n",
      "loss: 0.627194344997406\n",
      "tensor([[855]]) tensor(319.5641, grad_fn=<SubBackward0>)\n",
      "loss: 0.6262408494949341\n",
      "tensor([[855]]) tensor(319.6207, grad_fn=<SubBackward0>)\n",
      "loss: 0.6261746883392334\n",
      "tensor([[855]]) tensor(322.3126, grad_fn=<SubBackward0>)\n",
      "loss: 0.6230261921882629\n",
      "tensor([[855]]) tensor(326.2777, grad_fn=<SubBackward0>)\n",
      "loss: 0.6183886528015137\n",
      "tensor([[855]]) tensor(328.3588, grad_fn=<SubBackward0>)\n",
      "loss: 0.6159546375274658\n",
      "tensor([[855]]) tensor(329.1254, grad_fn=<SubBackward0>)\n",
      "loss: 0.6150580048561096\n",
      "tensor([[855]]) tensor(327.4251, grad_fn=<SubBackward0>)\n",
      "loss: 0.6170466542243958\n",
      "tensor([[855]]) tensor(333.4154, grad_fn=<SubBackward0>)\n",
      "loss: 0.6100404858589172\n",
      "tensor([[855]]) tensor(337.9391, grad_fn=<SubBackward0>)\n",
      "loss: 0.6047495603561401\n",
      "tensor([[855]]) tensor(340.9954, grad_fn=<SubBackward0>)\n",
      "loss: 0.6011750102043152\n",
      "tensor([[855]]) tensor(341.3075, grad_fn=<SubBackward0>)\n",
      "loss: 0.6008099317550659\n",
      "tensor([[855]]) tensor(339.0635, grad_fn=<SubBackward0>)\n",
      "loss: 0.6034344434738159\n",
      "tensor([[855]]) tensor(341.4849, grad_fn=<SubBackward0>)\n",
      "loss: 0.6006024479866028\n",
      "tensor([[855]]) tensor(345.9108, grad_fn=<SubBackward0>)\n",
      "loss: 0.5954259037971497\n",
      "tensor([[855]]) tensor(349.8469, grad_fn=<SubBackward0>)\n",
      "loss: 0.5908223390579224\n",
      "tensor([[855]]) tensor(354.7949, grad_fn=<SubBackward0>)\n",
      "loss: 0.5850352644920349\n",
      "tensor([[855]]) tensor(352.5605, grad_fn=<SubBackward0>)\n",
      "loss: 0.5876485705375671\n",
      "tensor([[855]]) tensor(360.9682, grad_fn=<SubBackward0>)\n",
      "loss: 0.5778149962425232\n",
      "tensor([[855]]) tensor(355.1188, grad_fn=<SubBackward0>)\n",
      "loss: 0.5846563577651978\n",
      "tensor([[855]]) tensor(363.3868, grad_fn=<SubBackward0>)\n",
      "loss: 0.5749862194061279\n",
      "tensor([[855]]) tensor(366.2420, grad_fn=<SubBackward0>)\n",
      "loss: 0.5716467499732971\n",
      "tensor([[855]]) tensor(363.4575, grad_fn=<SubBackward0>)\n",
      "loss: 0.5749035477638245\n",
      "tensor([[855]]) tensor(370.3554, grad_fn=<SubBackward0>)\n",
      "loss: 0.5668357610702515\n",
      "tensor([[855]]) tensor(370.8571, grad_fn=<SubBackward0>)\n",
      "loss: 0.5662489533424377\n",
      "tensor([[855]]) tensor(372.4771, grad_fn=<SubBackward0>)\n",
      "loss: 0.5643542408943176\n",
      "tensor([[855]]) tensor(372.2569, grad_fn=<SubBackward0>)\n",
      "loss: 0.5646117925643921\n",
      "tensor([[855]]) tensor(375.4037, grad_fn=<SubBackward0>)\n",
      "loss: 0.5609312653541565\n",
      "tensor([[855]]) tensor(380.1705, grad_fn=<SubBackward0>)\n",
      "loss: 0.5553560853004456\n",
      "tensor([[855]]) tensor(378.0745, grad_fn=<SubBackward0>)\n",
      "loss: 0.5578075647354126\n",
      "tensor([[855]]) tensor(376.0591, grad_fn=<SubBackward0>)\n",
      "loss: 0.560164749622345\n",
      "tensor([[855]]) tensor(382.6077, grad_fn=<SubBackward0>)\n",
      "loss: 0.5525056719779968\n",
      "tensor([[855]]) tensor(382.7215, grad_fn=<SubBackward0>)\n",
      "loss: 0.5523725152015686\n",
      "tensor([[855]]) tensor(385.6459, grad_fn=<SubBackward0>)\n",
      "loss: 0.5489522218704224\n",
      "tensor([[855]]) tensor(383.3511, grad_fn=<SubBackward0>)\n",
      "loss: 0.5516360998153687\n",
      "tensor([[855]]) tensor(389.0957, grad_fn=<SubBackward0>)\n",
      "loss: 0.5449172854423523\n",
      "tensor([[855]]) tensor(391.3549, grad_fn=<SubBackward0>)\n",
      "loss: 0.5422749519348145\n",
      "tensor([[855]]) tensor(390.2690, grad_fn=<SubBackward0>)\n",
      "loss: 0.5435450673103333\n",
      "tensor([[855]]) tensor(385.3714, grad_fn=<SubBackward0>)\n",
      "loss: 0.5492731928825378\n",
      "tensor([[855]]) tensor(386.2103, grad_fn=<SubBackward0>)\n",
      "loss: 0.5482920408248901\n",
      "tensor([[855]]) tensor(391.9882, grad_fn=<SubBackward0>)\n",
      "loss: 0.5415342450141907\n",
      "tensor([[855]]) tensor(386.7659, grad_fn=<SubBackward0>)\n",
      "loss: 0.547642171382904\n",
      "tensor([[855]]) tensor(392.4987, grad_fn=<SubBackward0>)\n",
      "loss: 0.5409372448921204\n",
      "tensor([[855]]) tensor(392.5925, grad_fn=<SubBackward0>)\n",
      "loss: 0.5408275127410889\n",
      "tensor([[855]]) tensor(390.4295, grad_fn=<SubBackward0>)\n",
      "loss: 0.543357253074646\n",
      "tensor([[855]]) tensor(391.7410, grad_fn=<SubBackward0>)\n",
      "loss: 0.5418233871459961\n",
      "tensor([[855]]) tensor(399.5546, grad_fn=<SubBackward0>)\n",
      "loss: 0.5326846837997437\n",
      "tensor([[855]]) tensor(400.3259, grad_fn=<SubBackward0>)\n",
      "loss: 0.5317826271057129\n",
      "tensor([[855]]) tensor(392.1512, grad_fn=<SubBackward0>)\n",
      "loss: 0.5413436889648438\n",
      "tensor([[855]]) tensor(402.1863, grad_fn=<SubBackward0>)\n",
      "loss: 0.5296066999435425\n",
      "tensor([[855]]) tensor(403.1189, grad_fn=<SubBackward0>)\n",
      "loss: 0.5285159349441528\n",
      "tensor([[855]]) tensor(400.8475, grad_fn=<SubBackward0>)\n",
      "loss: 0.531172513961792\n",
      "tensor([[855]]) tensor(403.6314, grad_fn=<SubBackward0>)\n",
      "loss: 0.5279164910316467\n",
      "tensor([[855]]) tensor(409.6245, grad_fn=<SubBackward0>)\n",
      "loss: 0.5209071040153503\n",
      "tensor([[855]]) tensor(413.9713, grad_fn=<SubBackward0>)\n",
      "loss: 0.5158230066299438\n",
      "tensor([[855]]) tensor(398.8489, grad_fn=<SubBackward0>)\n",
      "loss: 0.5335100293159485\n",
      "tensor([[855]]) tensor(401.1026, grad_fn=<SubBackward0>)\n",
      "loss: 0.5308741331100464\n",
      "tensor([[855]]) tensor(415.3456, grad_fn=<SubBackward0>)\n",
      "loss: 0.5142156481742859\n",
      "tensor([[855]]) tensor(413.3693, grad_fn=<SubBackward0>)\n",
      "loss: 0.5165271162986755\n",
      "tensor([[855]]) tensor(413.0126, grad_fn=<SubBackward0>)\n",
      "loss: 0.5169442892074585\n",
      "tensor([[855]]) tensor(416.6943, grad_fn=<SubBackward0>)\n",
      "loss: 0.5126382112503052\n",
      "tensor([[855]]) tensor(419.8755, grad_fn=<SubBackward0>)\n",
      "loss: 0.508917510509491\n",
      "tensor([[855]]) tensor(423.8227, grad_fn=<SubBackward0>)\n",
      "loss: 0.5043009519577026\n",
      "tensor([[855]]) tensor(415.7702, grad_fn=<SubBackward0>)\n",
      "loss: 0.5137190818786621\n",
      "tensor([[855]]) tensor(423.3739, grad_fn=<SubBackward0>)\n",
      "loss: 0.5048258304595947\n",
      "tensor([[855]]) tensor(423.1116, grad_fn=<SubBackward0>)\n",
      "loss: 0.5051326751708984\n",
      "tensor([[855]]) tensor(428.7836, grad_fn=<SubBackward0>)\n",
      "loss: 0.49849867820739746\n",
      "tensor([[855]]) tensor(427.2012, grad_fn=<SubBackward0>)\n",
      "loss: 0.5003494620323181\n",
      "tensor([[855]]) tensor(428.9835, grad_fn=<SubBackward0>)\n",
      "loss: 0.49826493859291077\n",
      "tensor([[855]]) tensor(433.0923, grad_fn=<SubBackward0>)\n",
      "loss: 0.4934592843055725\n",
      "tensor([[855]]) tensor(431.7760, grad_fn=<SubBackward0>)\n",
      "loss: 0.49499887228012085\n",
      "tensor([[855]]) tensor(429.9751, grad_fn=<SubBackward0>)\n",
      "loss: 0.4971051514148712\n",
      "tensor([[855]]) tensor(431.9761, grad_fn=<SubBackward0>)\n",
      "loss: 0.4947648346424103\n",
      "tensor([[855]]) tensor(437.2189, grad_fn=<SubBackward0>)\n",
      "loss: 0.4886328876018524\n",
      "tensor([[855]]) tensor(436.9300, grad_fn=<SubBackward0>)\n",
      "loss: 0.4889707565307617\n",
      "tensor([[855]]) tensor(431.0728, grad_fn=<SubBackward0>)\n",
      "loss: 0.4958212673664093\n",
      "tensor([[855]]) tensor(440.5623, grad_fn=<SubBackward0>)\n",
      "loss: 0.4847224950790405\n",
      "tensor([[855]]) tensor(441.2274, grad_fn=<SubBackward0>)\n",
      "loss: 0.48394450545310974\n",
      "tensor([[855]]) tensor(443.5626, grad_fn=<SubBackward0>)\n",
      "loss: 0.48121339082717896\n",
      "tensor([[855]]) tensor(440.0012, grad_fn=<SubBackward0>)\n",
      "loss: 0.48537877202033997\n",
      "tensor([[855]]) tensor(445.3269, grad_fn=<SubBackward0>)\n",
      "loss: 0.47914981842041016\n",
      "tensor([[855]]) tensor(445.1924, grad_fn=<SubBackward0>)\n",
      "loss: 0.4793071150779724\n",
      "tensor([[855]]) tensor(440.2390, grad_fn=<SubBackward0>)\n",
      "loss: 0.4851006269454956\n",
      "tensor([[855]]) tensor(441.8614, grad_fn=<SubBackward0>)\n",
      "loss: 0.48320305347442627\n",
      "tensor([[855]]) tensor(448.3778, grad_fn=<SubBackward0>)\n",
      "loss: 0.47558149695396423\n",
      "tensor([[855]]) tensor(448.8390, grad_fn=<SubBackward0>)\n",
      "loss: 0.47504207491874695\n",
      "tensor([[855]]) tensor(439.8599, grad_fn=<SubBackward0>)\n",
      "loss: 0.48554402589797974\n",
      "tensor([[855]]) tensor(448.7656, grad_fn=<SubBackward0>)\n",
      "loss: 0.4751279354095459\n",
      "tensor([[855]]) tensor(443.7834, grad_fn=<SubBackward0>)\n",
      "loss: 0.4809550344944\n",
      "tensor([[855]]) tensor(450.9175, grad_fn=<SubBackward0>)\n",
      "loss: 0.47261106967926025\n",
      "tensor([[855]]) tensor(454.7849, grad_fn=<SubBackward0>)\n",
      "loss: 0.4680878520011902\n",
      "tensor([[855]]) tensor(454.0877, grad_fn=<SubBackward0>)\n",
      "loss: 0.46890324354171753\n",
      "tensor([[855]]) tensor(453.6730, grad_fn=<SubBackward0>)\n",
      "loss: 0.46938827633857727\n",
      "tensor([[855]]) tensor(457.7142, grad_fn=<SubBackward0>)\n",
      "loss: 0.46466171741485596\n",
      "tensor([[855]]) tensor(456.6375, grad_fn=<SubBackward0>)\n",
      "loss: 0.4659211039543152\n",
      "tensor([[855]]) tensor(453.0131, grad_fn=<SubBackward0>)\n",
      "loss: 0.4701600968837738\n",
      "tensor([[855]]) tensor(458.4025, grad_fn=<SubBackward0>)\n",
      "loss: 0.46385669708251953\n",
      "tensor([[855]]) tensor(466.1962, grad_fn=<SubBackward0>)\n",
      "loss: 0.45474129915237427\n",
      "tensor([[855]]) tensor(454.4493, grad_fn=<SubBackward0>)\n",
      "loss: 0.4684803783893585\n",
      "tensor([[855]]) tensor(460.1014, grad_fn=<SubBackward0>)\n",
      "loss: 0.46186965703964233\n",
      "tensor([[855]]) tensor(468.3162, grad_fn=<SubBackward0>)\n",
      "loss: 0.45226171612739563\n",
      "tensor([[855]]) tensor(467.2999, grad_fn=<SubBackward0>)\n",
      "loss: 0.45345041155815125\n",
      "tensor([[855]]) tensor(461.0915, grad_fn=<SubBackward0>)\n",
      "loss: 0.4607117176055908\n",
      "tensor([[855]]) tensor(464.8893, grad_fn=<SubBackward0>)\n",
      "loss: 0.456269770860672\n",
      "tensor([[855]]) tensor(471.9143, grad_fn=<SubBackward0>)\n",
      "loss: 0.4480534493923187\n",
      "tensor([[855]]) tensor(474.2360, grad_fn=<SubBackward0>)\n",
      "loss: 0.4453379809856415\n",
      "tensor([[855]]) tensor(470.6613, grad_fn=<SubBackward0>)\n",
      "loss: 0.44951900839805603\n",
      "tensor([[855]]) tensor(475.2798, grad_fn=<SubBackward0>)\n",
      "loss: 0.4441172480583191\n",
      "tensor([[855]]) tensor(475.8802, grad_fn=<SubBackward0>)\n",
      "loss: 0.44341495633125305\n",
      "tensor([[855]]) tensor(475.4599, grad_fn=<SubBackward0>)\n",
      "loss: 0.4439065754413605\n",
      "tensor([[855]]) tensor(473.9209, grad_fn=<SubBackward0>)\n",
      "loss: 0.4457065463066101\n",
      "tensor([[855]]) tensor(477.9235, grad_fn=<SubBackward0>)\n",
      "loss: 0.4410251975059509\n",
      "tensor([[855]]) tensor(485.5338, grad_fn=<SubBackward0>)\n",
      "loss: 0.43212419748306274\n",
      "tensor([[855]]) tensor(488.1694, grad_fn=<SubBackward0>)\n",
      "loss: 0.42904168367385864\n",
      "tensor([[855]]) tensor(482.7914, grad_fn=<SubBackward0>)\n",
      "loss: 0.43533167243003845\n",
      "tensor([[855]]) tensor(493.3501, grad_fn=<SubBackward0>)\n",
      "loss: 0.4229823350906372\n",
      "tensor([[855]]) tensor(492.5568, grad_fn=<SubBackward0>)\n",
      "loss: 0.42391014099121094\n",
      "tensor([[855]]) tensor(494.1008, grad_fn=<SubBackward0>)\n",
      "loss: 0.4221042990684509\n",
      "tensor([[855]]) tensor(496.8000, grad_fn=<SubBackward0>)\n",
      "loss: 0.41894736886024475\n",
      "tensor([[855]]) tensor(493.7813, grad_fn=<SubBackward0>)\n",
      "loss: 0.42247799038887024\n",
      "tensor([[855]]) tensor(496.8224, grad_fn=<SubBackward0>)\n",
      "loss: 0.41892117261886597\n",
      "tensor([[855]]) tensor(497.2661, grad_fn=<SubBackward0>)\n",
      "loss: 0.41840216517448425\n",
      "tensor([[855]]) tensor(501.4169, grad_fn=<SubBackward0>)\n",
      "loss: 0.4135475158691406\n",
      "tensor([[855]]) tensor(496.8883, grad_fn=<SubBackward0>)\n",
      "loss: 0.4188441336154938\n",
      "tensor([[855]]) tensor(504.8085, grad_fn=<SubBackward0>)\n",
      "loss: 0.40958067774772644\n",
      "tensor([[855]]) tensor(498.3154, grad_fn=<SubBackward0>)\n",
      "loss: 0.41717496514320374\n",
      "tensor([[855]]) tensor(499.7976, grad_fn=<SubBackward0>)\n",
      "loss: 0.4154413938522339\n",
      "tensor([[855]]) tensor(499.9996, grad_fn=<SubBackward0>)\n",
      "loss: 0.415205180644989\n",
      "tensor([[855]]) tensor(500.6163, grad_fn=<SubBackward0>)\n",
      "loss: 0.414483904838562\n",
      "tensor([[855]]) tensor(502.3692, grad_fn=<SubBackward0>)\n",
      "loss: 0.4124336540699005\n",
      "tensor([[855]]) tensor(511.5587, grad_fn=<SubBackward0>)\n",
      "loss: 0.4016857445240021\n",
      "tensor([[855]]) tensor(507.4120, grad_fn=<SubBackward0>)\n",
      "loss: 0.40653565526008606\n",
      "tensor([[855]]) tensor(502.8788, grad_fn=<SubBackward0>)\n",
      "loss: 0.4118376672267914\n",
      "tensor([[855]]) tensor(513.2963, grad_fn=<SubBackward0>)\n",
      "loss: 0.39965346455574036\n",
      "tensor([[855]]) tensor(506.5854, grad_fn=<SubBackward0>)\n",
      "loss: 0.40750250220298767\n",
      "tensor([[855]]) tensor(515.8962, grad_fn=<SubBackward0>)\n",
      "loss: 0.39661264419555664\n",
      "tensor([[855]]) tensor(507.8088, grad_fn=<SubBackward0>)\n",
      "loss: 0.40607157349586487\n",
      "tensor([[855]]) tensor(501.7309, grad_fn=<SubBackward0>)\n",
      "loss: 0.41318026185035706\n",
      "tensor([[855]]) tensor(503.9571, grad_fn=<SubBackward0>)\n",
      "loss: 0.4105764925479889\n",
      "tensor([[855]]) tensor(505.4750, grad_fn=<SubBackward0>)\n",
      "loss: 0.40880119800567627\n",
      "tensor([[855]]) tensor(511.5030, grad_fn=<SubBackward0>)\n",
      "loss: 0.40175092220306396\n",
      "tensor([[855]]) tensor(519.7585, grad_fn=<SubBackward0>)\n",
      "loss: 0.39209532737731934\n",
      "tensor([[855]]) tensor(519.2136, grad_fn=<SubBackward0>)\n",
      "loss: 0.3927326798439026\n",
      "tensor([[855]]) tensor(515.4116, grad_fn=<SubBackward0>)\n",
      "loss: 0.39717939496040344\n",
      "tensor([[855]]) tensor(522.9186, grad_fn=<SubBackward0>)\n",
      "loss: 0.38839927315711975\n",
      "tensor([[855]]) tensor(522.7255, grad_fn=<SubBackward0>)\n",
      "loss: 0.3886251151561737\n",
      "tensor([[855]]) tensor(521.3500, grad_fn=<SubBackward0>)\n",
      "loss: 0.3902338743209839\n",
      "tensor([[855]]) tensor(520.1204, grad_fn=<SubBackward0>)\n",
      "loss: 0.3916720151901245\n",
      "tensor([[855]]) tensor(521.4374, grad_fn=<SubBackward0>)\n",
      "loss: 0.39013171195983887\n",
      "tensor([[855]]) tensor(525.6074, grad_fn=<SubBackward0>)\n",
      "loss: 0.38525456190109253\n",
      "tensor([[855]]) tensor(526.8846, grad_fn=<SubBackward0>)\n",
      "loss: 0.3837607204914093\n",
      "tensor([[855]]) tensor(530.5970, grad_fn=<SubBackward0>)\n",
      "loss: 0.3794187009334564\n",
      "tensor([[855]]) tensor(529.9237, grad_fn=<SubBackward0>)\n",
      "loss: 0.3802061975002289\n",
      "tensor([[855]]) tensor(527.9180, grad_fn=<SubBackward0>)\n",
      "loss: 0.3825520873069763\n",
      "tensor([[855]]) tensor(525.3165, grad_fn=<SubBackward0>)\n",
      "loss: 0.3855947256088257\n",
      "tensor([[855]]) tensor(535.9429, grad_fn=<SubBackward0>)\n",
      "loss: 0.37316617369651794\n",
      "tensor([[855]]) tensor(532.9468, grad_fn=<SubBackward0>)\n",
      "loss: 0.37667039036750793\n",
      "tensor([[855]]) tensor(535.6010, grad_fn=<SubBackward0>)\n",
      "loss: 0.3735661804676056\n",
      "tensor([[855]]) tensor(534.4560, grad_fn=<SubBackward0>)\n",
      "loss: 0.3749052584171295\n",
      "tensor([[855]]) tensor(529.1277, grad_fn=<SubBackward0>)\n",
      "loss: 0.3811371624469757\n",
      "tensor([[855]]) tensor(529.9435, grad_fn=<SubBackward0>)\n",
      "loss: 0.38018304109573364\n",
      "tensor([[855]]) tensor(532.4055, grad_fn=<SubBackward0>)\n",
      "loss: 0.37730348110198975\n",
      "tensor([[855]]) tensor(539.2884, grad_fn=<SubBackward0>)\n",
      "loss: 0.36925333738327026\n",
      "tensor([[855]]) tensor(548.2855, grad_fn=<SubBackward0>)\n",
      "loss: 0.35873037576675415\n",
      "tensor([[855]]) tensor(541.3994, grad_fn=<SubBackward0>)\n",
      "loss: 0.36678433418273926\n",
      "tensor([[855]]) tensor(545.2332, grad_fn=<SubBackward0>)\n",
      "loss: 0.3623003363609314\n",
      "tensor([[855]]) tensor(552.9535, grad_fn=<SubBackward0>)\n",
      "loss: 0.3532707393169403\n",
      "tensor([[855]]) tensor(552.2876, grad_fn=<SubBackward0>)\n",
      "loss: 0.35404959321022034\n",
      "tensor([[855]]) tensor(548.3513, grad_fn=<SubBackward0>)\n",
      "loss: 0.3586534559726715\n",
      "tensor([[855]]) tensor(548.1572, grad_fn=<SubBackward0>)\n",
      "loss: 0.35888051986694336\n",
      "tensor([[855]]) tensor(549.7609, grad_fn=<SubBackward0>)\n",
      "loss: 0.3570047914981842\n",
      "tensor([[855]]) tensor(554.6853, grad_fn=<SubBackward0>)\n",
      "loss: 0.351245254278183\n",
      "tensor([[855]]) tensor(557.6814, grad_fn=<SubBackward0>)\n",
      "loss: 0.34774109721183777\n",
      "tensor([[855]]) tensor(560.2576, grad_fn=<SubBackward0>)\n",
      "loss: 0.344728022813797\n",
      "tensor([[855]]) tensor(560.5999, grad_fn=<SubBackward0>)\n",
      "loss: 0.3443276584148407\n",
      "tensor([[855]]) tensor(564.8949, grad_fn=<SubBackward0>)\n",
      "loss: 0.3393041789531708\n",
      "tensor([[855]]) tensor(560.2539, grad_fn=<SubBackward0>)\n",
      "loss: 0.34473228454589844\n",
      "tensor([[855]]) tensor(564.9770, grad_fn=<SubBackward0>)\n",
      "loss: 0.33920818567276\n",
      "tensor([[855]]) tensor(561.1899, grad_fn=<SubBackward0>)\n",
      "loss: 0.34363749623298645\n",
      "tensor([[855]]) tensor(563.2554, grad_fn=<SubBackward0>)\n",
      "loss: 0.34122177958488464\n",
      "tensor([[855]]) tensor(567.2174, grad_fn=<SubBackward0>)\n",
      "loss: 0.3365878164768219\n",
      "tensor([[855]]) tensor(567.3196, grad_fn=<SubBackward0>)\n",
      "loss: 0.33646824955940247\n",
      "tensor([[855]]) tensor(566.7881, grad_fn=<SubBackward0>)\n",
      "loss: 0.33708998560905457\n",
      "tensor([[855]]) tensor(566.5443, grad_fn=<SubBackward0>)\n",
      "loss: 0.33737513422966003\n",
      "tensor([[855]]) tensor(571.4372, grad_fn=<SubBackward0>)\n",
      "loss: 0.3316524028778076\n",
      "tensor([[855]]) tensor(565.9919, grad_fn=<SubBackward0>)\n",
      "loss: 0.33802106976509094\n",
      "tensor([[855]]) tensor(573.8814, grad_fn=<SubBackward0>)\n",
      "loss: 0.3287936747074127\n",
      "tensor([[855]]) tensor(567.8628, grad_fn=<SubBackward0>)\n",
      "loss: 0.33583301305770874\n",
      "tensor([[855]]) tensor(565.2546, grad_fn=<SubBackward0>)\n",
      "loss: 0.33888348937034607\n",
      "tensor([[855]]) tensor(567.2669, grad_fn=<SubBackward0>)\n",
      "loss: 0.336529940366745\n",
      "tensor([[855]]) tensor(571.0274, grad_fn=<SubBackward0>)\n",
      "loss: 0.33213168382644653\n",
      "tensor([[855]]) tensor(573.3752, grad_fn=<SubBackward0>)\n",
      "loss: 0.3293856680393219\n",
      "tensor([[855]]) tensor(576.9578, grad_fn=<SubBackward0>)\n",
      "loss: 0.3251955211162567\n",
      "tensor([[855]]) tensor(573.3264, grad_fn=<SubBackward0>)\n",
      "loss: 0.3294428586959839\n",
      "tensor([[855]]) tensor(573.5582, grad_fn=<SubBackward0>)\n",
      "loss: 0.32917168736457825\n",
      "tensor([[855]]) tensor(577.4826, grad_fn=<SubBackward0>)\n",
      "loss: 0.32458174228668213\n",
      "tensor([[855]]) tensor(577.8978, grad_fn=<SubBackward0>)\n",
      "loss: 0.324096143245697\n",
      "tensor([[855]]) tensor(577.5313, grad_fn=<SubBackward0>)\n",
      "loss: 0.32452479004859924\n",
      "tensor([[855]]) tensor(578.9384, grad_fn=<SubBackward0>)\n",
      "loss: 0.3228790760040283\n",
      "tensor([[855]]) tensor(582.2294, grad_fn=<SubBackward0>)\n",
      "loss: 0.31902989745140076\n",
      "tensor([[855]]) tensor(578.6292, grad_fn=<SubBackward0>)\n",
      "loss: 0.3232406973838806\n",
      "tensor([[855]]) tensor(580.5276, grad_fn=<SubBackward0>)\n",
      "loss: 0.3210203945636749\n",
      "tensor([[855]]) tensor(576.6237, grad_fn=<SubBackward0>)\n",
      "loss: 0.32558637857437134\n",
      "tensor([[855]]) tensor(581.1543, grad_fn=<SubBackward0>)\n",
      "loss: 0.32028740644454956\n",
      "tensor([[855]]) tensor(581.1057, grad_fn=<SubBackward0>)\n",
      "loss: 0.3203442692756653\n",
      "tensor([[855]]) tensor(578.9636, grad_fn=<SubBackward0>)\n",
      "loss: 0.3228496313095093\n",
      "tensor([[855]]) tensor(582.5070, grad_fn=<SubBackward0>)\n",
      "loss: 0.318705290555954\n",
      "tensor([[855]]) tensor(582.1381, grad_fn=<SubBackward0>)\n",
      "loss: 0.3191367983818054\n",
      "tensor([[855]]) tensor(576.4625, grad_fn=<SubBackward0>)\n",
      "loss: 0.3257748484611511\n",
      "tensor([[855]]) tensor(576.7326, grad_fn=<SubBackward0>)\n",
      "loss: 0.32545894384384155\n",
      "tensor([[855]]) tensor(583.5583, grad_fn=<SubBackward0>)\n",
      "loss: 0.3174756169319153\n",
      "tensor([[855]]) tensor(582.3318, grad_fn=<SubBackward0>)\n",
      "loss: 0.3189102113246918\n",
      "tensor([[855]]) tensor(579.3997, grad_fn=<SubBackward0>)\n",
      "loss: 0.32233962416648865\n",
      "tensor([[855]]) tensor(585.5817, grad_fn=<SubBackward0>)\n",
      "loss: 0.31510910391807556\n",
      "tensor([[855]]) tensor(585.9211, grad_fn=<SubBackward0>)\n",
      "loss: 0.3147121071815491\n",
      "tensor([[855]]) tensor(582.0852, grad_fn=<SubBackward0>)\n",
      "loss: 0.3191986382007599\n",
      "tensor([[855]]) tensor(580.9308, grad_fn=<SubBackward0>)\n",
      "loss: 0.32054880261421204\n",
      "tensor([[855]]) tensor(589.3259, grad_fn=<SubBackward0>)\n",
      "loss: 0.31072998046875\n",
      "tensor([[855]]) tensor(589.9121, grad_fn=<SubBackward0>)\n",
      "loss: 0.3100443184375763\n",
      "tensor([[855]]) tensor(586.4274, grad_fn=<SubBackward0>)\n",
      "loss: 0.31411996483802795\n",
      "tensor([[855]]) tensor(591.8486, grad_fn=<SubBackward0>)\n",
      "loss: 0.30777937173843384\n",
      "tensor([[855]]) tensor(593.0649, grad_fn=<SubBackward0>)\n",
      "loss: 0.3063567876815796\n",
      "tensor([[855]]) tensor(587.9161, grad_fn=<SubBackward0>)\n",
      "loss: 0.31237882375717163\n",
      "tensor([[855]]) tensor(589.9327, grad_fn=<SubBackward0>)\n",
      "loss: 0.3100201487541199\n",
      "tensor([[855]]) tensor(594.3270, grad_fn=<SubBackward0>)\n",
      "loss: 0.3048807382583618\n",
      "tensor([[855]]) tensor(598.2855, grad_fn=<SubBackward0>)\n",
      "loss: 0.3002508580684662\n",
      "tensor([[855]]) tensor(599.4216, grad_fn=<SubBackward0>)\n",
      "loss: 0.2989221513271332\n",
      "tensor([[855]]) tensor(601.5570, grad_fn=<SubBackward0>)\n",
      "loss: 0.29642459750175476\n",
      "tensor([[855]]) tensor(597.9075, grad_fn=<SubBackward0>)\n",
      "loss: 0.30069297552108765\n",
      "tensor([[855]]) tensor(597.5771, grad_fn=<SubBackward0>)\n",
      "loss: 0.3010794222354889\n",
      "tensor([[855]]) tensor(602.6064, grad_fn=<SubBackward0>)\n",
      "loss: 0.2951972186565399\n",
      "tensor([[855]]) tensor(602.8861, grad_fn=<SubBackward0>)\n",
      "loss: 0.2948700487613678\n",
      "tensor([[855]]) tensor(603.9926, grad_fn=<SubBackward0>)\n",
      "loss: 0.2935759127140045\n",
      "tensor([[855]]) tensor(608.7257, grad_fn=<SubBackward0>)\n",
      "loss: 0.2880401015281677\n",
      "tensor([[855]]) tensor(607.5289, grad_fn=<SubBackward0>)\n",
      "loss: 0.289439857006073\n",
      "tensor([[855]]) tensor(608.3136, grad_fn=<SubBackward0>)\n",
      "loss: 0.28852206468582153\n",
      "tensor([[855]]) tensor(609.8173, grad_fn=<SubBackward0>)\n",
      "loss: 0.28676342964172363\n",
      "tensor([[855]]) tensor(606.2156, grad_fn=<SubBackward0>)\n",
      "loss: 0.2909758687019348\n",
      "tensor([[855]]) tensor(610.8105, grad_fn=<SubBackward0>)\n",
      "loss: 0.2856016755104065\n",
      "tensor([[855]]) tensor(611.9187, grad_fn=<SubBackward0>)\n",
      "loss: 0.2843056619167328\n",
      "tensor([[855]]) tensor(606.8828, grad_fn=<SubBackward0>)\n",
      "loss: 0.2901955842971802\n",
      "tensor([[855]]) tensor(609.9783, grad_fn=<SubBackward0>)\n",
      "loss: 0.2865751087665558\n",
      "tensor([[855]]) tensor(608.2628, grad_fn=<SubBackward0>)\n",
      "loss: 0.2885814607143402\n",
      "tensor([[855]]) tensor(606.8569, grad_fn=<SubBackward0>)\n",
      "loss: 0.2902258038520813\n",
      "tensor([[855]]) tensor(615.0637, grad_fn=<SubBackward0>)\n",
      "loss: 0.2806272506713867\n",
      "tensor([[855]]) tensor(608.8428, grad_fn=<SubBackward0>)\n",
      "loss: 0.2879031300544739\n",
      "tensor([[855]]) tensor(605.3475, grad_fn=<SubBackward0>)\n",
      "loss: 0.2919911742210388\n",
      "tensor([[855]]) tensor(606.5686, grad_fn=<SubBackward0>)\n",
      "loss: 0.29056304693222046\n",
      "tensor([[855]]) tensor(612.1443, grad_fn=<SubBackward0>)\n",
      "loss: 0.28404179215431213\n",
      "tensor([[855]]) tensor(616.9147, grad_fn=<SubBackward0>)\n",
      "loss: 0.27846238017082214\n",
      "tensor([[855]]) tensor(610.8375, grad_fn=<SubBackward0>)\n",
      "loss: 0.2855701744556427\n",
      "tensor([[855]]) tensor(617.1859, grad_fn=<SubBackward0>)\n",
      "loss: 0.2781451940536499\n",
      "tensor([[855]]) tensor(615.8412, grad_fn=<SubBackward0>)\n",
      "loss: 0.2797178328037262\n",
      "tensor([[855]]) tensor(614.9863, grad_fn=<SubBackward0>)\n",
      "loss: 0.28071773052215576\n",
      "tensor([[855]]) tensor(612.7094, grad_fn=<SubBackward0>)\n",
      "loss: 0.283380925655365\n",
      "tensor([[855]]) tensor(613.3594, grad_fn=<SubBackward0>)\n",
      "loss: 0.2826206088066101\n",
      "tensor([[855]]) tensor(618.6652, grad_fn=<SubBackward0>)\n",
      "loss: 0.27641502022743225\n",
      "tensor([[855]]) tensor(622.8435, grad_fn=<SubBackward0>)\n",
      "loss: 0.27152809500694275\n",
      "tensor([[855]]) tensor(616.6316, grad_fn=<SubBackward0>)\n",
      "loss: 0.27879345417022705\n",
      "tensor([[855]]) tensor(616.5125, grad_fn=<SubBackward0>)\n",
      "loss: 0.2789327800273895\n",
      "tensor([[855]]) tensor(625.6053, grad_fn=<SubBackward0>)\n",
      "loss: 0.26829779148101807\n",
      "tensor([[855]]) tensor(620.7992, grad_fn=<SubBackward0>)\n",
      "loss: 0.27391907572746277\n",
      "tensor([[855]]) tensor(616.8212, grad_fn=<SubBackward0>)\n",
      "loss: 0.2785717248916626\n",
      "tensor([[855]]) tensor(615.7157, grad_fn=<SubBackward0>)\n",
      "loss: 0.279864639043808\n",
      "tensor([[855]]) tensor(619.9288, grad_fn=<SubBackward0>)\n",
      "loss: 0.27493712306022644\n",
      "tensor([[855]]) tensor(628.8821, grad_fn=<SubBackward0>)\n",
      "loss: 0.26446533203125\n",
      "tensor([[855]]) tensor(625.1611, grad_fn=<SubBackward0>)\n",
      "loss: 0.26881739497184753\n",
      "tensor([[855]]) tensor(617.1331, grad_fn=<SubBackward0>)\n",
      "loss: 0.27820688486099243\n",
      "tensor([[855]]) tensor(630.2911, grad_fn=<SubBackward0>)\n",
      "loss: 0.2628174424171448\n",
      "tensor([[855]]) tensor(627.6011, grad_fn=<SubBackward0>)\n",
      "loss: 0.26596370339393616\n",
      "tensor([[855]]) tensor(621.7397, grad_fn=<SubBackward0>)\n",
      "loss: 0.27281898260116577\n",
      "tensor([[855]]) tensor(621.6864, grad_fn=<SubBackward0>)\n",
      "loss: 0.2728813588619232\n",
      "tensor([[855]]) tensor(624.8544, grad_fn=<SubBackward0>)\n",
      "loss: 0.269176185131073\n",
      "tensor([[855]]) tensor(631.0665, grad_fn=<SubBackward0>)\n",
      "loss: 0.26191049814224243\n",
      "tensor([[855]]) tensor(634.4142, grad_fn=<SubBackward0>)\n",
      "loss: 0.25799503922462463\n",
      "tensor([[855]]) tensor(622.6959, grad_fn=<SubBackward0>)\n",
      "loss: 0.2717006802558899\n",
      "tensor([[855]]) tensor(630.5920, grad_fn=<SubBackward0>)\n",
      "loss: 0.2624654173851013\n",
      "tensor([[855]]) tensor(635.7139, grad_fn=<SubBackward0>)\n",
      "loss: 0.25647497177124023\n",
      "tensor([[855]]) tensor(629.3842, grad_fn=<SubBackward0>)\n",
      "loss: 0.26387819647789\n",
      "tensor([[855]]) tensor(633.4224, grad_fn=<SubBackward0>)\n",
      "loss: 0.2591550648212433\n",
      "tensor([[855]]) tensor(635.1443, grad_fn=<SubBackward0>)\n",
      "loss: 0.25714111328125\n",
      "tensor([[855]]) tensor(635.3768, grad_fn=<SubBackward0>)\n",
      "loss: 0.25686922669410706\n",
      "tensor([[855]]) tensor(628.3754, grad_fn=<SubBackward0>)\n",
      "loss: 0.2650579512119293\n",
      "tensor([[855]]) tensor(631.5842, grad_fn=<SubBackward0>)\n",
      "loss: 0.2613050937652588\n",
      "tensor([[855]]) tensor(641.3068, grad_fn=<SubBackward0>)\n",
      "loss: 0.24993352591991425\n",
      "tensor([[855]]) tensor(628.9728, grad_fn=<SubBackward0>)\n",
      "loss: 0.2643592655658722\n",
      "tensor([[855]]) tensor(624.1776, grad_fn=<SubBackward0>)\n",
      "loss: 0.2699677348136902\n",
      "tensor([[855]]) tensor(631.9829, grad_fn=<SubBackward0>)\n",
      "loss: 0.26083865761756897\n",
      "tensor([[855]]) tensor(640.5494, grad_fn=<SubBackward0>)\n",
      "loss: 0.2508193850517273\n",
      "tensor([[855]]) tensor(637.6624, grad_fn=<SubBackward0>)\n",
      "loss: 0.25419607758522034\n",
      "tensor([[855]]) tensor(634.4285, grad_fn=<SubBackward0>)\n",
      "loss: 0.25797832012176514\n",
      "tensor([[855]]) tensor(640.3093, grad_fn=<SubBackward0>)\n",
      "loss: 0.2511001527309418\n",
      "tensor([[855]]) tensor(644.0054, grad_fn=<SubBackward0>)\n",
      "loss: 0.24677734076976776\n",
      "tensor([[855]]) tensor(648.5637, grad_fn=<SubBackward0>)\n",
      "loss: 0.2414458990097046\n",
      "tensor([[855]]) tensor(648.6219, grad_fn=<SubBackward0>)\n",
      "loss: 0.24137787520885468\n",
      "tensor([[855]]) tensor(642.0549, grad_fn=<SubBackward0>)\n",
      "loss: 0.24905861914157867\n",
      "tensor([[855]]) tensor(643.0453, grad_fn=<SubBackward0>)\n",
      "loss: 0.24790017306804657\n",
      "tensor([[855]]) tensor(653.0089, grad_fn=<SubBackward0>)\n",
      "loss: 0.23624689877033234\n",
      "tensor([[855]]) tensor(644.6012, grad_fn=<SubBackward0>)\n",
      "loss: 0.2460804581642151\n",
      "tensor([[855]]) tensor(644.2109, grad_fn=<SubBackward0>)\n",
      "loss: 0.246536985039711\n",
      "tensor([[855]]) tensor(645.8306, grad_fn=<SubBackward0>)\n",
      "loss: 0.24464261531829834\n",
      "tensor([[855]]) tensor(651.3193, grad_fn=<SubBackward0>)\n",
      "loss: 0.23822300136089325\n",
      "tensor([[855]]) tensor(652.2368, grad_fn=<SubBackward0>)\n",
      "loss: 0.2371499240398407\n",
      "tensor([[855]]) tensor(652.1088, grad_fn=<SubBackward0>)\n",
      "loss: 0.23729965090751648\n",
      "tensor([[855]]) tensor(656.1287, grad_fn=<SubBackward0>)\n",
      "loss: 0.23259805142879486\n",
      "tensor([[855]]) tensor(652.2285, grad_fn=<SubBackward0>)\n",
      "loss: 0.23715966939926147\n",
      "tensor([[855]]) tensor(659.4839, grad_fn=<SubBackward0>)\n",
      "loss: 0.22867374122142792\n",
      "tensor([[855]]) tensor(657.1817, grad_fn=<SubBackward0>)\n",
      "loss: 0.23136642575263977\n",
      "tensor([[855]]) tensor(658.9828, grad_fn=<SubBackward0>)\n",
      "loss: 0.2292598932981491\n",
      "tensor([[855]]) tensor(660.0740, grad_fn=<SubBackward0>)\n",
      "loss: 0.22798365354537964\n",
      "tensor([[855]]) tensor(661.9660, grad_fn=<SubBackward0>)\n",
      "loss: 0.2257707715034485\n",
      "tensor([[855]]) tensor(661.7569, grad_fn=<SubBackward0>)\n",
      "loss: 0.22601532936096191\n",
      "tensor([[855]]) tensor(663.0214, grad_fn=<SubBackward0>)\n",
      "loss: 0.22453638911247253\n",
      "tensor([[855]]) tensor(663.6627, grad_fn=<SubBackward0>)\n",
      "loss: 0.22378624975681305\n",
      "tensor([[855]]) tensor(664.0679, grad_fn=<SubBackward0>)\n",
      "loss: 0.22331245243549347\n",
      "tensor([[855]]) tensor(665.0606, grad_fn=<SubBackward0>)\n",
      "loss: 0.22215135395526886\n",
      "tensor([[855]]) tensor(663.9851, grad_fn=<SubBackward0>)\n",
      "loss: 0.22340919077396393\n",
      "tensor([[855]]) tensor(667.2441, grad_fn=<SubBackward0>)\n",
      "loss: 0.21959751844406128\n",
      "tensor([[855]]) tensor(669.2935, grad_fn=<SubBackward0>)\n",
      "loss: 0.21720056235790253\n",
      "tensor([[855]]) tensor(664.4366, grad_fn=<SubBackward0>)\n",
      "loss: 0.22288113832473755\n",
      "tensor([[855]]) tensor(668.6473, grad_fn=<SubBackward0>)\n",
      "loss: 0.21795636415481567\n",
      "tensor([[855]]) tensor(664.3137, grad_fn=<SubBackward0>)\n",
      "loss: 0.22302497923374176\n",
      "tensor([[855]]) tensor(664.0649, grad_fn=<SubBackward0>)\n",
      "loss: 0.22331582009792328\n",
      "tensor([[855]]) tensor(670.9813, grad_fn=<SubBackward0>)\n",
      "loss: 0.21522656083106995\n",
      "tensor([[855]]) tensor(672.3249, grad_fn=<SubBackward0>)\n",
      "loss: 0.21365509927272797\n",
      "tensor([[855]]) tensor(672.2439, grad_fn=<SubBackward0>)\n",
      "loss: 0.21374981105327606\n",
      "tensor([[855]]) tensor(670.0622, grad_fn=<SubBackward0>)\n",
      "loss: 0.21630153059959412\n",
      "tensor([[855]]) tensor(676.3382, grad_fn=<SubBackward0>)\n",
      "loss: 0.20896115899085999\n",
      "tensor([[855]]) tensor(675.3777, grad_fn=<SubBackward0>)\n",
      "loss: 0.21008454263210297\n",
      "tensor([[855]]) tensor(675.8622, grad_fn=<SubBackward0>)\n",
      "loss: 0.20951788127422333\n",
      "tensor([[855]]) tensor(673.7153, grad_fn=<SubBackward0>)\n",
      "loss: 0.2120288908481598\n",
      "tensor([[855]]) tensor(679.1204, grad_fn=<SubBackward0>)\n",
      "loss: 0.20570722222328186\n",
      "tensor([[855]]) tensor(677.0558, grad_fn=<SubBackward0>)\n",
      "loss: 0.2081218659877777\n",
      "tensor([[855]]) tensor(679.3625, grad_fn=<SubBackward0>)\n",
      "loss: 0.20542392134666443\n",
      "tensor([[855]]) tensor(676.7781, grad_fn=<SubBackward0>)\n",
      "loss: 0.2084466516971588\n",
      "tensor([[855]]) tensor(678.3009, grad_fn=<SubBackward0>)\n",
      "loss: 0.20666560530662537\n",
      "tensor([[855]]) tensor(677.7968, grad_fn=<SubBackward0>)\n",
      "loss: 0.2072552591562271\n",
      "tensor([[855]]) tensor(681.5056, grad_fn=<SubBackward0>)\n",
      "loss: 0.20291748642921448\n",
      "tensor([[855]]) tensor(682.9927, grad_fn=<SubBackward0>)\n",
      "loss: 0.20117813348770142\n",
      "tensor([[855]]) tensor(678.4822, grad_fn=<SubBackward0>)\n",
      "loss: 0.20645351707935333\n",
      "tensor([[855]]) tensor(684.6998, grad_fn=<SubBackward0>)\n",
      "loss: 0.19918155670166016\n",
      "tensor([[855]]) tensor(686.0241, grad_fn=<SubBackward0>)\n",
      "loss: 0.19763262569904327\n",
      "tensor([[855]]) tensor(682.4009, grad_fn=<SubBackward0>)\n",
      "loss: 0.20187032222747803\n",
      "tensor([[855]]) tensor(683.4656, grad_fn=<SubBackward0>)\n",
      "loss: 0.2006249725818634\n",
      "tensor([[855]]) tensor(683.5201, grad_fn=<SubBackward0>)\n",
      "loss: 0.20056132972240448\n",
      "tensor([[855]]) tensor(686.4166, grad_fn=<SubBackward0>)\n",
      "loss: 0.19717353582382202\n",
      "tensor([[855]]) tensor(683.8687, grad_fn=<SubBackward0>)\n",
      "loss: 0.20015352964401245\n",
      "tensor([[855]]) tensor(677.6374, grad_fn=<SubBackward0>)\n",
      "loss: 0.20744164288043976\n",
      "tensor([[855]]) tensor(683.8932, grad_fn=<SubBackward0>)\n",
      "loss: 0.20012490451335907\n",
      "tensor([[855]]) tensor(688.7460, grad_fn=<SubBackward0>)\n",
      "loss: 0.19444908201694489\n",
      "tensor([[855]]) tensor(678.2640, grad_fn=<SubBackward0>)\n",
      "loss: 0.20670877397060394\n",
      "tensor([[855]]) tensor(686.4888, grad_fn=<SubBackward0>)\n",
      "loss: 0.19708912074565887\n",
      "tensor([[855]]) tensor(684.8799, grad_fn=<SubBackward0>)\n",
      "loss: 0.19897083938121796\n",
      "tensor([[855]]) tensor(682.6927, grad_fn=<SubBackward0>)\n",
      "loss: 0.20152899622917175\n",
      "tensor([[855]]) tensor(682.5150, grad_fn=<SubBackward0>)\n",
      "loss: 0.20173688232898712\n",
      "tensor([[855]]) tensor(681.5676, grad_fn=<SubBackward0>)\n",
      "loss: 0.20284494757652283\n",
      "tensor([[855]]) tensor(684.7434, grad_fn=<SubBackward0>)\n",
      "loss: 0.19913052022457123\n",
      "tensor([[855]]) tensor(687.2700, grad_fn=<SubBackward0>)\n",
      "loss: 0.19617541134357452\n",
      "tensor([[855]]) tensor(693.3606, grad_fn=<SubBackward0>)\n",
      "loss: 0.18905194103717804\n",
      "tensor([[855]]) tensor(694.0162, grad_fn=<SubBackward0>)\n",
      "loss: 0.18828512728214264\n",
      "tensor([[855]]) tensor(687.7678, grad_fn=<SubBackward0>)\n",
      "loss: 0.1955931931734085\n",
      "tensor([[855]]) tensor(696.3015, grad_fn=<SubBackward0>)\n",
      "loss: 0.18561230599880219\n",
      "tensor([[855]]) tensor(692.9558, grad_fn=<SubBackward0>)\n",
      "loss: 0.18952538073062897\n",
      "tensor([[855]]) tensor(690.3307, grad_fn=<SubBackward0>)\n",
      "loss: 0.1925956904888153\n",
      "tensor([[855]]) tensor(690.0646, grad_fn=<SubBackward0>)\n",
      "loss: 0.1929069608449936\n",
      "tensor([[855]]) tensor(690.9377, grad_fn=<SubBackward0>)\n",
      "loss: 0.19188566505908966\n",
      "tensor([[855]]) tensor(695.5454, grad_fn=<SubBackward0>)\n",
      "loss: 0.18649660050868988\n",
      "tensor([[855]]) tensor(698.1777, grad_fn=<SubBackward0>)\n",
      "loss: 0.1834178864955902\n",
      "tensor([[855]]) tensor(699.4298, grad_fn=<SubBackward0>)\n",
      "loss: 0.18195341527462006\n",
      "tensor([[855]]) tensor(695.8678, grad_fn=<SubBackward0>)\n",
      "loss: 0.18611957132816315\n",
      "tensor([[855]]) tensor(699.3929, grad_fn=<SubBackward0>)\n",
      "loss: 0.18199662864208221\n",
      "tensor([[855]]) tensor(698.2452, grad_fn=<SubBackward0>)\n",
      "loss: 0.18333888053894043\n",
      "tensor([[855]]) tensor(699.4166, grad_fn=<SubBackward0>)\n",
      "loss: 0.1819688230752945\n",
      "tensor([[855]]) tensor(696.0082, grad_fn=<SubBackward0>)\n",
      "loss: 0.18595533072948456\n",
      "tensor([[855]]) tensor(701.6079, grad_fn=<SubBackward0>)\n",
      "loss: 0.17940598726272583\n",
      "tensor([[855]]) tensor(701.9475, grad_fn=<SubBackward0>)\n",
      "loss: 0.17900876700878143\n",
      "tensor([[855]]) tensor(698.4919, grad_fn=<SubBackward0>)\n",
      "loss: 0.18305036425590515\n",
      "tensor([[855]]) tensor(704.4630, grad_fn=<SubBackward0>)\n",
      "loss: 0.17606671154499054\n",
      "tensor([[855]]) tensor(704.2624, grad_fn=<SubBackward0>)\n",
      "loss: 0.17630130052566528\n",
      "tensor([[855]]) tensor(705.3199, grad_fn=<SubBackward0>)\n",
      "loss: 0.17506444454193115\n",
      "tensor([[855]]) tensor(706.4158, grad_fn=<SubBackward0>)\n",
      "loss: 0.17378263175487518\n",
      "tensor([[855]]) tensor(705.3308, grad_fn=<SubBackward0>)\n",
      "loss: 0.17505165934562683\n",
      "tensor([[855]]) tensor(708.0664, grad_fn=<SubBackward0>)\n",
      "loss: 0.17185212671756744\n",
      "tensor([[855]]) tensor(705.1134, grad_fn=<SubBackward0>)\n",
      "loss: 0.17530594766139984\n",
      "tensor([[855]]) tensor(706.7109, grad_fn=<SubBackward0>)\n",
      "loss: 0.17343750596046448\n",
      "tensor([[855]]) tensor(704.7336, grad_fn=<SubBackward0>)\n",
      "loss: 0.17575012147426605\n",
      "tensor([[855]]) tensor(705.7178, grad_fn=<SubBackward0>)\n",
      "loss: 0.17459911108016968\n",
      "tensor([[855]]) tensor(711.3966, grad_fn=<SubBackward0>)\n",
      "loss: 0.16795720160007477\n",
      "tensor([[855]]) tensor(705.0061, grad_fn=<SubBackward0>)\n",
      "loss: 0.175431489944458\n",
      "tensor([[855]]) tensor(711.9832, grad_fn=<SubBackward0>)\n",
      "loss: 0.16727116703987122\n",
      "tensor([[855]]) tensor(712.2684, grad_fn=<SubBackward0>)\n",
      "loss: 0.1669374704360962\n",
      "tensor([[855]]) tensor(712.5560, grad_fn=<SubBackward0>)\n",
      "loss: 0.16660118103027344\n",
      "tensor([[855]]) tensor(714.0883, grad_fn=<SubBackward0>)\n",
      "loss: 0.1648089736700058\n",
      "tensor([[855]]) tensor(713.8075, grad_fn=<SubBackward0>)\n",
      "loss: 0.1651373952627182\n",
      "tensor([[855]]) tensor(707.4368, grad_fn=<SubBackward0>)\n",
      "loss: 0.17258857190608978\n",
      "tensor([[855]]) tensor(713.9320, grad_fn=<SubBackward0>)\n",
      "loss: 0.16499178111553192\n",
      "tensor([[855]]) tensor(698.4783, grad_fn=<SubBackward0>)\n",
      "loss: 0.18306630849838257\n",
      "tensor([[855]]) tensor(700.5679, grad_fn=<SubBackward0>)\n",
      "loss: 0.1806223839521408\n",
      "tensor([[855]]) tensor(717.0873, grad_fn=<SubBackward0>)\n",
      "loss: 0.1613014042377472\n",
      "tensor([[855]]) tensor(714.5148, grad_fn=<SubBackward0>)\n",
      "loss: 0.16431015729904175\n",
      "tensor([[855]]) tensor(717.9115, grad_fn=<SubBackward0>)\n",
      "loss: 0.16033746302127838\n",
      "tensor([[855]]) tensor(719.9866, grad_fn=<SubBackward0>)\n",
      "loss: 0.15791046619415283\n",
      "tensor([[855]]) tensor(710.0547, grad_fn=<SubBackward0>)\n",
      "loss: 0.16952668130397797\n",
      "tensor([[855]]) tensor(718.0209, grad_fn=<SubBackward0>)\n",
      "loss: 0.1602095365524292\n",
      "tensor([[855]]) tensor(708.6613, grad_fn=<SubBackward0>)\n",
      "loss: 0.17115642130374908\n",
      "tensor([[855]]) tensor(720.3171, grad_fn=<SubBackward0>)\n",
      "loss: 0.15752388536930084\n",
      "tensor([[855]]) tensor(708.0531, grad_fn=<SubBackward0>)\n",
      "loss: 0.1718677431344986\n",
      "tensor([[855]]) tensor(721.4275, grad_fn=<SubBackward0>)\n",
      "loss: 0.15622515976428986\n",
      "tensor([[855]]) tensor(707.2689, grad_fn=<SubBackward0>)\n",
      "loss: 0.1727849245071411\n",
      "tensor([[855]]) tensor(712.1569, grad_fn=<SubBackward0>)\n",
      "loss: 0.16706791520118713\n",
      "tensor([[855]]) tensor(710.0018, grad_fn=<SubBackward0>)\n",
      "loss: 0.16958852112293243\n",
      "tensor([[855]]) tensor(712.0344, grad_fn=<SubBackward0>)\n",
      "loss: 0.16721121966838837\n",
      "tensor([[855]]) tensor(715.8937, grad_fn=<SubBackward0>)\n",
      "loss: 0.1626974493265152\n",
      "tensor([[855]]) tensor(720.6079, grad_fn=<SubBackward0>)\n",
      "loss: 0.1571836918592453\n",
      "tensor([[855]]) tensor(722.8047, grad_fn=<SubBackward0>)\n",
      "loss: 0.15461431443691254\n",
      "tensor([[855]]) tensor(715.2054, grad_fn=<SubBackward0>)\n",
      "loss: 0.16350243985652924\n",
      "tensor([[855]]) tensor(722.8915, grad_fn=<SubBackward0>)\n",
      "loss: 0.15451282262802124\n",
      "tensor([[855]]) tensor(713.6334, grad_fn=<SubBackward0>)\n",
      "loss: 0.16534101963043213\n",
      "tensor([[855]]) tensor(724.1163, grad_fn=<SubBackward0>)\n",
      "loss: 0.15308035910129547\n",
      "tensor([[855]]) tensor(719.9570, grad_fn=<SubBackward0>)\n",
      "loss: 0.15794506669044495\n",
      "tensor([[855]]) tensor(721.3920, grad_fn=<SubBackward0>)\n",
      "loss: 0.1562667042016983\n",
      "tensor([[855]]) tensor(725.3588, grad_fn=<SubBackward0>)\n",
      "loss: 0.15162712335586548\n",
      "tensor([[855]]) tensor(716.6663, grad_fn=<SubBackward0>)\n",
      "loss: 0.1617937833070755\n",
      "tensor([[855]]) tensor(723.5444, grad_fn=<SubBackward0>)\n",
      "loss: 0.1537492722272873\n",
      "tensor([[855]]) tensor(722.1526, grad_fn=<SubBackward0>)\n",
      "loss: 0.15537701547145844\n",
      "tensor([[855]]) tensor(720.8782, grad_fn=<SubBackward0>)\n",
      "loss: 0.15686757862567902\n",
      "tensor([[855]]) tensor(728.2693, grad_fn=<SubBackward0>)\n",
      "loss: 0.14822307229042053\n",
      "tensor([[855]]) tensor(725.3181, grad_fn=<SubBackward0>)\n",
      "loss: 0.1516747921705246\n",
      "tensor([[855]]) tensor(729.1181, grad_fn=<SubBackward0>)\n",
      "loss: 0.14723028242588043\n",
      "tensor([[855]]) tensor(730.2589, grad_fn=<SubBackward0>)\n",
      "loss: 0.1458960473537445\n",
      "tensor([[855]]) tensor(713.9926, grad_fn=<SubBackward0>)\n",
      "loss: 0.16492097079753876\n",
      "tensor([[855]]) tensor(729.8596, grad_fn=<SubBackward0>)\n",
      "loss: 0.14636299014091492\n",
      "tensor([[855]]) tensor(730.8663, grad_fn=<SubBackward0>)\n",
      "loss: 0.14518554508686066\n",
      "tensor([[855]]) tensor(728.7496, grad_fn=<SubBackward0>)\n",
      "loss: 0.1476612091064453\n",
      "tensor([[855]]) tensor(723.0400, grad_fn=<SubBackward0>)\n",
      "loss: 0.15433911979198456\n",
      "tensor([[855]]) tensor(721.7361, grad_fn=<SubBackward0>)\n",
      "loss: 0.15586426854133606\n",
      "tensor([[855]]) tensor(721.6002, grad_fn=<SubBackward0>)\n",
      "loss: 0.15602311491966248\n",
      "tensor([[855]]) tensor(727.9481, grad_fn=<SubBackward0>)\n",
      "loss: 0.14859865605831146\n",
      "tensor([[855]]) tensor(709.3619, grad_fn=<SubBackward0>)\n",
      "loss: 0.17033694684505463\n",
      "tensor([[855]]) tensor(708.9962, grad_fn=<SubBackward0>)\n",
      "loss: 0.1707647293806076\n",
      "tensor([[855]]) tensor(729.2772, grad_fn=<SubBackward0>)\n",
      "loss: 0.14704425632953644\n",
      "tensor([[855]]) tensor(705.4970, grad_fn=<SubBackward0>)\n",
      "loss: 0.17485731840133667\n",
      "tensor([[855]]) tensor(710.1489, grad_fn=<SubBackward0>)\n",
      "loss: 0.16941645741462708\n",
      "tensor([[855]]) tensor(726.0059, grad_fn=<SubBackward0>)\n",
      "loss: 0.15087029337882996\n",
      "tensor([[855]]) tensor(715.8743, grad_fn=<SubBackward0>)\n",
      "loss: 0.162720188498497\n",
      "tensor([[855]]) tensor(726.9582, grad_fn=<SubBackward0>)\n",
      "loss: 0.1497565060853958\n",
      "tensor([[855]]) tensor(707.3861, grad_fn=<SubBackward0>)\n",
      "loss: 0.17264778912067413\n",
      "tensor([[855]]) tensor(708.6279, grad_fn=<SubBackward0>)\n",
      "loss: 0.171195387840271\n",
      "tensor([[855]]) tensor(733.6639, grad_fn=<SubBackward0>)\n",
      "loss: 0.1419135183095932\n",
      "tensor([[855]]) tensor(724.1805, grad_fn=<SubBackward0>)\n",
      "loss: 0.15300527215003967\n",
      "tensor([[855]]) tensor(730.3364, grad_fn=<SubBackward0>)\n",
      "loss: 0.14580534398555756\n",
      "tensor([[855]]) tensor(728.2714, grad_fn=<SubBackward0>)\n",
      "loss: 0.14822061359882355\n",
      "tensor([[855]]) tensor(726.5510, grad_fn=<SubBackward0>)\n",
      "loss: 0.15023273229599\n",
      "tensor([[855]]) tensor(729.5649, grad_fn=<SubBackward0>)\n",
      "loss: 0.14670763909816742\n",
      "tensor([[855]]) tensor(722.9072, grad_fn=<SubBackward0>)\n",
      "loss: 0.1544945389032364\n",
      "tensor([[855]]) tensor(725.1446, grad_fn=<SubBackward0>)\n",
      "loss: 0.15187768638134003\n",
      "tensor([[855]]) tensor(724.1019, grad_fn=<SubBackward0>)\n",
      "loss: 0.15309712290763855\n",
      "tensor([[855]]) tensor(729.0178, grad_fn=<SubBackward0>)\n",
      "loss: 0.1473475694656372\n",
      "tensor([[855]]) tensor(721.7908, grad_fn=<SubBackward0>)\n",
      "loss: 0.15580026805400848\n",
      "tensor([[855]]) tensor(727.8549, grad_fn=<SubBackward0>)\n",
      "loss: 0.14870776236057281\n",
      "tensor([[855]]) tensor(718.8907, grad_fn=<SubBackward0>)\n",
      "loss: 0.15919211506843567\n",
      "tensor([[855]]) tensor(732.4695, grad_fn=<SubBackward0>)\n",
      "loss: 0.1433105319738388\n",
      "tensor([[855]]) tensor(719.0276, grad_fn=<SubBackward0>)\n",
      "loss: 0.15903198719024658\n",
      "tensor([[855]]) tensor(732.1165, grad_fn=<SubBackward0>)\n",
      "loss: 0.14372342824935913\n",
      "tensor([[855]]) tensor(720.4077, grad_fn=<SubBackward0>)\n",
      "loss: 0.15741784870624542\n",
      "tensor([[855]]) tensor(721.9539, grad_fn=<SubBackward0>)\n",
      "loss: 0.15560942888259888\n",
      "tensor([[855]]) tensor(733.7533, grad_fn=<SubBackward0>)\n",
      "loss: 0.14180901646614075\n",
      "tensor([[855]]) tensor(712.2249, grad_fn=<SubBackward0>)\n",
      "loss: 0.16698847711086273\n",
      "tensor([[855]]) tensor(717.2328, grad_fn=<SubBackward0>)\n",
      "loss: 0.16113115847110748\n",
      "tensor([[855]]) tensor(730.0323, grad_fn=<SubBackward0>)\n",
      "loss: 0.14616096019744873\n",
      "tensor([[855]]) tensor(722.6682, grad_fn=<SubBackward0>)\n",
      "loss: 0.15477411448955536\n",
      "tensor([[855]]) tensor(724.2991, grad_fn=<SubBackward0>)\n",
      "loss: 0.15286654233932495\n",
      "tensor([[855]]) tensor(722.7314, grad_fn=<SubBackward0>)\n",
      "loss: 0.15470010042190552\n",
      "tensor([[855]]) tensor(729.5078, grad_fn=<SubBackward0>)\n",
      "loss: 0.14677447080612183\n",
      "tensor([[855]]) tensor(723.8906, grad_fn=<SubBackward0>)\n",
      "loss: 0.1533443033695221\n",
      "tensor([[855]]) tensor(718.3213, grad_fn=<SubBackward0>)\n",
      "loss: 0.1598581075668335\n",
      "tensor([[855]]) tensor(726.0382, grad_fn=<SubBackward0>)\n",
      "loss: 0.15083247423171997\n",
      "tensor([[855]]) tensor(723.1827, grad_fn=<SubBackward0>)\n",
      "loss: 0.15417230129241943\n",
      "tensor([[855]]) tensor(734.6125, grad_fn=<SubBackward0>)\n",
      "loss: 0.1408040076494217\n",
      "tensor([[855]]) tensor(721.5647, grad_fn=<SubBackward0>)\n",
      "loss: 0.1560647189617157\n",
      "tensor([[855]]) tensor(730.9620, grad_fn=<SubBackward0>)\n",
      "loss: 0.14507372677326202\n",
      "tensor([[855]]) tensor(716.2529, grad_fn=<SubBackward0>)\n",
      "loss: 0.16227729618549347\n",
      "tensor([[855]]) tensor(724.4242, grad_fn=<SubBackward0>)\n",
      "loss: 0.15272025763988495\n",
      "tensor([[855]]) tensor(714.2277, grad_fn=<SubBackward0>)\n",
      "loss: 0.16464604437351227\n",
      "tensor([[855]]) tensor(718.9429, grad_fn=<SubBackward0>)\n",
      "loss: 0.15913118422031403\n",
      "tensor([[855]]) tensor(731.0632, grad_fn=<SubBackward0>)\n",
      "loss: 0.1449553221464157\n",
      "tensor([[855]]) tensor(723.3830, grad_fn=<SubBackward0>)\n",
      "loss: 0.15393801033496857\n",
      "tensor([[855]]) tensor(735.7554, grad_fn=<SubBackward0>)\n",
      "loss: 0.13946743309497833\n",
      "tensor([[855]]) tensor(729.8613, grad_fn=<SubBackward0>)\n",
      "loss: 0.1463610976934433\n",
      "tensor([[855]]) tensor(730.5122, grad_fn=<SubBackward0>)\n",
      "loss: 0.14559979736804962\n",
      "tensor([[855]]) tensor(728.8312, grad_fn=<SubBackward0>)\n",
      "loss: 0.14756585657596588\n",
      "tensor([[855]]) tensor(730.3507, grad_fn=<SubBackward0>)\n",
      "loss: 0.14578866958618164\n",
      "tensor([[855]]) tensor(725.6013, grad_fn=<SubBackward0>)\n",
      "loss: 0.1513434648513794\n",
      "tensor([[855]]) tensor(730.3654, grad_fn=<SubBackward0>)\n",
      "loss: 0.14577144384384155\n",
      "tensor([[855]]) tensor(722.0394, grad_fn=<SubBackward0>)\n",
      "loss: 0.15550942718982697\n",
      "tensor([[855]]) tensor(732.2256, grad_fn=<SubBackward0>)\n",
      "loss: 0.1435958445072174\n",
      "tensor([[855]]) tensor(716.3921, grad_fn=<SubBackward0>)\n",
      "loss: 0.1621144860982895\n",
      "tensor([[855]]) tensor(713.4486, grad_fn=<SubBackward0>)\n",
      "loss: 0.1655571460723877\n",
      "tensor([[855]]) tensor(735.5925, grad_fn=<SubBackward0>)\n",
      "loss: 0.13965792953968048\n",
      "tensor([[855]]) tensor(721.0428, grad_fn=<SubBackward0>)\n",
      "loss: 0.15667510032653809\n",
      "tensor([[855]]) tensor(733.1302, grad_fn=<SubBackward0>)\n",
      "loss: 0.14253780245780945\n",
      "tensor([[855]]) tensor(718.7452, grad_fn=<SubBackward0>)\n",
      "loss: 0.1593622863292694\n",
      "tensor([[855]]) tensor(717.1987, grad_fn=<SubBackward0>)\n",
      "loss: 0.161171093583107\n",
      "tensor([[855]]) tensor(732.0779, grad_fn=<SubBackward0>)\n",
      "loss: 0.14376859366893768\n",
      "tensor([[855]]) tensor(715.6061, grad_fn=<SubBackward0>)\n",
      "loss: 0.16303378343582153\n",
      "tensor([[855]]) tensor(712.2444, grad_fn=<SubBackward0>)\n",
      "loss: 0.1669655740261078\n",
      "tensor([[855]]) tensor(738.0895, grad_fn=<SubBackward0>)\n",
      "loss: 0.1367373764514923\n",
      "tensor([[855]]) tensor(709.2382, grad_fn=<SubBackward0>)\n",
      "loss: 0.17048168182373047\n",
      "tensor([[855]]) tensor(706.9329, grad_fn=<SubBackward0>)\n",
      "loss: 0.17317789793014526\n",
      "tensor([[855]]) tensor(727.1981, grad_fn=<SubBackward0>)\n",
      "loss: 0.14947588741779327\n",
      "tensor([[855]]) tensor(714.0644, grad_fn=<SubBackward0>)\n",
      "loss: 0.16483698785305023\n",
      "tensor([[855]]) tensor(708.2206, grad_fn=<SubBackward0>)\n",
      "loss: 0.1716717630624771\n",
      "tensor([[855]]) tensor(730.1376, grad_fn=<SubBackward0>)\n",
      "loss: 0.14603792130947113\n",
      "tensor([[855]]) tensor(715.1628, grad_fn=<SubBackward0>)\n",
      "loss: 0.16355231404304504\n",
      "tensor([[855]]) tensor(702.7220, grad_fn=<SubBackward0>)\n",
      "loss: 0.17810291051864624\n",
      "tensor([[855]]) tensor(710.9920, grad_fn=<SubBackward0>)\n",
      "loss: 0.1684304177761078\n",
      "tensor([[855]]) tensor(731.2039, grad_fn=<SubBackward0>)\n",
      "loss: 0.14479073882102966\n",
      "tensor([[855]]) tensor(704.9528, grad_fn=<SubBackward0>)\n",
      "loss: 0.17549385130405426\n",
      "tensor([[855]]) tensor(691.4835, grad_fn=<SubBackward0>)\n",
      "loss: 0.19124743342399597\n",
      "tensor([[855]]) tensor(711.7445, grad_fn=<SubBackward0>)\n",
      "loss: 0.16755026578903198\n",
      "tensor([[855]]) tensor(729.8622, grad_fn=<SubBackward0>)\n",
      "loss: 0.14635995030403137\n",
      "tensor([[855]]) tensor(714.2714, grad_fn=<SubBackward0>)\n",
      "loss: 0.1645948588848114\n",
      "tensor([[855]]) tensor(716.4752, grad_fn=<SubBackward0>)\n",
      "loss: 0.1620173156261444\n",
      "tensor([[855]]) tensor(736.1636, grad_fn=<SubBackward0>)\n",
      "loss: 0.1389898955821991\n",
      "tensor([[855]]) tensor(708.4049, grad_fn=<SubBackward0>)\n",
      "loss: 0.1714562475681305\n",
      "tensor([[855]]) tensor(699.4406, grad_fn=<SubBackward0>)\n",
      "loss: 0.18194080889225006\n",
      "tensor([[855]]) tensor(722.2880, grad_fn=<SubBackward0>)\n",
      "loss: 0.1552186906337738\n",
      "tensor([[855]]) tensor(728.4558, grad_fn=<SubBackward0>)\n",
      "loss: 0.1480049043893814\n",
      "tensor([[855]]) tensor(709.0986, grad_fn=<SubBackward0>)\n",
      "loss: 0.1706448346376419\n",
      "tensor([[855]]) tensor(717.5444, grad_fn=<SubBackward0>)\n",
      "loss: 0.16076679527759552\n",
      "tensor([[855]]) tensor(737.3568, grad_fn=<SubBackward0>)\n",
      "loss: 0.13759437203407288\n",
      "tensor([[855]]) tensor(698.9583, grad_fn=<SubBackward0>)\n",
      "loss: 0.18250495195388794\n",
      "tensor([[855]]) tensor(687.6417, grad_fn=<SubBackward0>)\n",
      "loss: 0.19574064016342163\n",
      "tensor([[855]]) tensor(711.7159, grad_fn=<SubBackward0>)\n",
      "loss: 0.1675836741924286\n",
      "tensor([[855]]) tensor(730.3918, grad_fn=<SubBackward0>)\n",
      "loss: 0.1457405835390091\n",
      "tensor([[855]]) tensor(713.0983, grad_fn=<SubBackward0>)\n",
      "loss: 0.1659669280052185\n",
      "tensor([[855]]) tensor(715.0227, grad_fn=<SubBackward0>)\n",
      "loss: 0.1637161374092102\n",
      "tensor([[855]]) tensor(734.2269, grad_fn=<SubBackward0>)\n",
      "loss: 0.14125502109527588\n",
      "tensor([[855]]) tensor(716.4699, grad_fn=<SubBackward0>)\n",
      "loss: 0.16202351450920105\n",
      "tensor([[855]]) tensor(710.2219, grad_fn=<SubBackward0>)\n",
      "loss: 0.1693311333656311\n",
      "tensor([[855]]) tensor(731.6552, grad_fn=<SubBackward0>)\n",
      "loss: 0.14426301419734955\n",
      "tensor([[855]]) tensor(715.5466, grad_fn=<SubBackward0>)\n",
      "loss: 0.16310334205627441\n",
      "tensor([[855]]) tensor(702.6805, grad_fn=<SubBackward0>)\n",
      "loss: 0.17815138399600983\n",
      "tensor([[855]]) tensor(722.3080, grad_fn=<SubBackward0>)\n",
      "loss: 0.15519531071186066\n",
      "tensor([[855]]) tensor(732.4414, grad_fn=<SubBackward0>)\n",
      "loss: 0.14334340393543243\n",
      "tensor([[855]]) tensor(720.2518, grad_fn=<SubBackward0>)\n",
      "loss: 0.15760023891925812\n",
      "tensor([[855]]) tensor(732.6885, grad_fn=<SubBackward0>)\n",
      "loss: 0.1430543214082718\n",
      "tensor([[855]]) tensor(724.1814, grad_fn=<SubBackward0>)\n",
      "loss: 0.15300418436527252\n",
      "tensor([[855]]) tensor(712.6806, grad_fn=<SubBackward0>)\n",
      "loss: 0.1664554476737976\n",
      "tensor([[855]]) tensor(719.1700, grad_fn=<SubBackward0>)\n",
      "loss: 0.15886545181274414\n",
      "tensor([[855]]) tensor(733.3808, grad_fn=<SubBackward0>)\n",
      "loss: 0.14224469661712646\n",
      "tensor([[855]]) tensor(720.1025, grad_fn=<SubBackward0>)\n",
      "loss: 0.15777488052845\n",
      "tensor([[855]]) tensor(713.7547, grad_fn=<SubBackward0>)\n",
      "loss: 0.1651991605758667\n",
      "tensor([[855]]) tensor(736.5796, grad_fn=<SubBackward0>)\n",
      "loss: 0.13850340247154236\n",
      "tensor([[855]]) tensor(724.3933, grad_fn=<SubBackward0>)\n",
      "loss: 0.15275634825229645\n",
      "tensor([[855]]) tensor(719.0338, grad_fn=<SubBackward0>)\n",
      "loss: 0.15902483463287354\n",
      "tensor([[855]]) tensor(734.4017, grad_fn=<SubBackward0>)\n",
      "loss: 0.14105063676834106\n",
      "tensor([[855]]) tensor(722.3871, grad_fn=<SubBackward0>)\n",
      "loss: 0.15510281920433044\n",
      "tensor([[855]]) tensor(718.4280, grad_fn=<SubBackward0>)\n",
      "loss: 0.1597333550453186\n",
      "tensor([[855]]) tensor(736.3177, grad_fn=<SubBackward0>)\n",
      "loss: 0.13880963623523712\n",
      "tensor([[855]]) tensor(729.3976, grad_fn=<SubBackward0>)\n",
      "loss: 0.1469034105539322\n",
      "tensor([[855]]) tensor(726.6655, grad_fn=<SubBackward0>)\n",
      "loss: 0.15009889006614685\n",
      "tensor([[855]]) tensor(734.7920, grad_fn=<SubBackward0>)\n",
      "loss: 0.14059419929981232\n",
      "tensor([[855]]) tensor(734.2718, grad_fn=<SubBackward0>)\n",
      "loss: 0.14120259881019592\n",
      "tensor([[855]]) tensor(728.7411, grad_fn=<SubBackward0>)\n",
      "loss: 0.14767120778560638\n",
      "tensor([[855]]) tensor(743.1475, grad_fn=<SubBackward0>)\n",
      "loss: 0.13082171976566315\n",
      "tensor([[855]]) tensor(719.5554, grad_fn=<SubBackward0>)\n",
      "loss: 0.15841473639011383\n",
      "tensor([[855]]) tensor(723.2195, grad_fn=<SubBackward0>)\n",
      "loss: 0.15412920713424683\n",
      "tensor([[855]]) tensor(740.3563, grad_fn=<SubBackward0>)\n",
      "loss: 0.13408617675304413\n",
      "tensor([[855]]) tensor(732.2826, grad_fn=<SubBackward0>)\n",
      "loss: 0.14352914690971375\n",
      "tensor([[855]]) tensor(742.5723, grad_fn=<SubBackward0>)\n",
      "loss: 0.1314944326877594\n",
      "tensor([[855]]) tensor(739.3358, grad_fn=<SubBackward0>)\n",
      "loss: 0.1352798044681549\n",
      "tensor([[855]]) tensor(741.6812, grad_fn=<SubBackward0>)\n",
      "loss: 0.13253659009933472\n",
      "tensor([[855]]) tensor(735.7092, grad_fn=<SubBackward0>)\n",
      "loss: 0.13952134549617767\n",
      "tensor([[855]]) tensor(730.9208, grad_fn=<SubBackward0>)\n",
      "loss: 0.14512185752391815\n",
      "tensor([[855]]) tensor(740.1837, grad_fn=<SubBackward0>)\n",
      "loss: 0.134288027882576\n",
      "tensor([[855]]) tensor(730.3585, grad_fn=<SubBackward0>)\n",
      "loss: 0.145779550075531\n",
      "tensor([[855]]) tensor(734.1976, grad_fn=<SubBackward0>)\n",
      "loss: 0.14128939807415009\n",
      "tensor([[855]]) tensor(741.5466, grad_fn=<SubBackward0>)\n",
      "loss: 0.1326940357685089\n",
      "tensor([[855]]) tensor(728.8305, grad_fn=<SubBackward0>)\n",
      "loss: 0.14756666123867035\n",
      "tensor([[855]]) tensor(740.4437, grad_fn=<SubBackward0>)\n",
      "loss: 0.13398398458957672\n",
      "tensor([[855]]) tensor(738.0340, grad_fn=<SubBackward0>)\n",
      "loss: 0.13680236041545868\n",
      "tensor([[855]]) tensor(738.0445, grad_fn=<SubBackward0>)\n",
      "loss: 0.13679005205631256\n",
      "tensor([[855]]) tensor(741.5885, grad_fn=<SubBackward0>)\n",
      "loss: 0.13264502584934235\n",
      "tensor([[855]]) tensor(739.8932, grad_fn=<SubBackward0>)\n",
      "loss: 0.13462787866592407\n",
      "tensor([[855]]) tensor(744.5526, grad_fn=<SubBackward0>)\n",
      "loss: 0.1291782110929489\n",
      "tensor([[855]]) tensor(743.6556, grad_fn=<SubBackward0>)\n",
      "loss: 0.13022734224796295\n",
      "tensor([[855]]) tensor(744.4603, grad_fn=<SubBackward0>)\n",
      "loss: 0.1292862445116043\n",
      "tensor([[855]]) tensor(745.2889, grad_fn=<SubBackward0>)\n",
      "loss: 0.12831711769104004\n",
      "tensor([[855]]) tensor(739.1420, grad_fn=<SubBackward0>)\n",
      "loss: 0.13550643622875214\n",
      "tensor([[855]]) tensor(744.7014, grad_fn=<SubBackward0>)\n",
      "loss: 0.12900426983833313\n",
      "tensor([[855]]) tensor(745.1703, grad_fn=<SubBackward0>)\n",
      "loss: 0.12845578789710999\n",
      "tensor([[855]]) tensor(742.4313, grad_fn=<SubBackward0>)\n",
      "loss: 0.13165931403636932\n",
      "tensor([[855]]) tensor(744.4536, grad_fn=<SubBackward0>)\n",
      "loss: 0.1292940378189087\n",
      "tensor([[855]]) tensor(733.1979, grad_fn=<SubBackward0>)\n",
      "loss: 0.14245860278606415\n",
      "tensor([[855]]) tensor(744.3528, grad_fn=<SubBackward0>)\n",
      "loss: 0.12941193580627441\n",
      "tensor([[855]]) tensor(726.2683, grad_fn=<SubBackward0>)\n",
      "loss: 0.15056341886520386\n",
      "tensor([[855]]) tensor(724.8671, grad_fn=<SubBackward0>)\n",
      "loss: 0.1522022932767868\n",
      "tensor([[855]]) tensor(743.3970, grad_fn=<SubBackward0>)\n",
      "loss: 0.13052988052368164\n",
      "tensor([[855]]) tensor(729.1116, grad_fn=<SubBackward0>)\n",
      "loss: 0.14723795652389526\n",
      "tensor([[855]]) tensor(727.4291, grad_fn=<SubBackward0>)\n",
      "loss: 0.14920568466186523\n",
      "tensor([[855]]) tensor(739.4157, grad_fn=<SubBackward0>)\n",
      "loss: 0.1351862996816635\n",
      "tensor([[855]]) tensor(718.8669, grad_fn=<SubBackward0>)\n",
      "loss: 0.15921998023986816\n",
      "tensor([[855]]) tensor(716.3270, grad_fn=<SubBackward0>)\n",
      "loss: 0.16219066083431244\n",
      "tensor([[855]]) tensor(740.5000, grad_fn=<SubBackward0>)\n",
      "loss: 0.13391809165477753\n",
      "tensor([[855]]) tensor(732.5648, grad_fn=<SubBackward0>)\n",
      "loss: 0.14319907128810883\n",
      "tensor([[855]]) tensor(717.1611, grad_fn=<SubBackward0>)\n",
      "loss: 0.16121505200862885\n",
      "tensor([[855]]) tensor(729.7153, grad_fn=<SubBackward0>)\n",
      "loss: 0.1465318351984024\n",
      "tensor([[855]]) tensor(747.6470, grad_fn=<SubBackward0>)\n",
      "loss: 0.12555906176567078\n",
      "tensor([[855]]) tensor(733.7040, grad_fn=<SubBackward0>)\n",
      "loss: 0.14186659455299377\n",
      "tensor([[855]]) tensor(745.9950, grad_fn=<SubBackward0>)\n",
      "loss: 0.12749119102954865\n",
      "tensor([[855]]) tensor(741.0048, grad_fn=<SubBackward0>)\n",
      "loss: 0.1333276927471161\n",
      "tensor([[855]]) tensor(746.8293, grad_fn=<SubBackward0>)\n",
      "loss: 0.1265154778957367\n",
      "tensor([[855]]) tensor(737.7814, grad_fn=<SubBackward0>)\n",
      "loss: 0.13709771633148193\n",
      "tensor([[855]]) tensor(741.9821, grad_fn=<SubBackward0>)\n",
      "loss: 0.13218466937541962\n",
      "tensor([[855]]) tensor(732.3420, grad_fn=<SubBackward0>)\n",
      "loss: 0.14345963299274445\n",
      "tensor([[855]]) tensor(733.9365, grad_fn=<SubBackward0>)\n",
      "loss: 0.1415947824716568\n",
      "tensor([[855]]) tensor(744.9309, grad_fn=<SubBackward0>)\n",
      "loss: 0.12873575091362\n",
      "tensor([[855]]) tensor(737.2756, grad_fn=<SubBackward0>)\n",
      "loss: 0.13768938183784485\n",
      "tensor([[855]]) tensor(739.1655, grad_fn=<SubBackward0>)\n",
      "loss: 0.13547898828983307\n",
      "tensor([[855]]) tensor(744.1713, grad_fn=<SubBackward0>)\n",
      "loss: 0.12962429225444794\n",
      "tensor([[855]]) tensor(745.2095, grad_fn=<SubBackward0>)\n",
      "loss: 0.12840993702411652\n",
      "tensor([[855]]) tensor(739.8817, grad_fn=<SubBackward0>)\n",
      "loss: 0.13464130461215973\n",
      "tensor([[855]]) tensor(737.2005, grad_fn=<SubBackward0>)\n",
      "loss: 0.1377771943807602\n",
      "tensor([[855]]) tensor(744.4662, grad_fn=<SubBackward0>)\n",
      "loss: 0.12927930057048798\n",
      "tensor([[855]]) tensor(744.7311, grad_fn=<SubBackward0>)\n",
      "loss: 0.12896950542926788\n",
      "tensor([[855]]) tensor(743.7649, grad_fn=<SubBackward0>)\n",
      "loss: 0.1300995796918869\n",
      "tensor([[855]]) tensor(746.4518, grad_fn=<SubBackward0>)\n",
      "loss: 0.1269569844007492\n",
      "tensor([[855]]) tensor(740.0780, grad_fn=<SubBackward0>)\n",
      "loss: 0.13441166281700134\n",
      "tensor([[855]]) tensor(748.8453, grad_fn=<SubBackward0>)\n",
      "loss: 0.12415753304958344\n",
      "tensor([[855]]) tensor(739.6228, grad_fn=<SubBackward0>)\n",
      "loss: 0.1349440962076187\n",
      "tensor([[855]]) tensor(745.0851, grad_fn=<SubBackward0>)\n",
      "loss: 0.12855547666549683\n",
      "tensor([[855]]) tensor(744.4418, grad_fn=<SubBackward0>)\n",
      "loss: 0.1293077915906906\n",
      "tensor([[855]]) tensor(750.4794, grad_fn=<SubBackward0>)\n",
      "loss: 0.12224625796079636\n",
      "tensor([[855]]) tensor(748.9996, grad_fn=<SubBackward0>)\n",
      "loss: 0.12397703528404236\n",
      "tensor([[855]]) tensor(747.9512, grad_fn=<SubBackward0>)\n",
      "loss: 0.12520332634449005\n",
      "tensor([[855]]) tensor(749.9738, grad_fn=<SubBackward0>)\n",
      "loss: 0.12283766269683838\n",
      "tensor([[855]]) tensor(739.8975, grad_fn=<SubBackward0>)\n",
      "loss: 0.13462278246879578\n",
      "tensor([[855]]) tensor(750.1584, grad_fn=<SubBackward0>)\n",
      "loss: 0.12262166291475296\n",
      "tensor([[855]]) tensor(729.2236, grad_fn=<SubBackward0>)\n",
      "loss: 0.14710694551467896\n",
      "tensor([[855]]) tensor(728.1866, grad_fn=<SubBackward0>)\n",
      "loss: 0.14831975102424622\n",
      "tensor([[855]]) tensor(747.2179, grad_fn=<SubBackward0>)\n",
      "loss: 0.12606094777584076\n",
      "tensor([[855]]) tensor(720.3506, grad_fn=<SubBackward0>)\n",
      "loss: 0.1574847251176834\n",
      "tensor([[855]]) tensor(710.4015, grad_fn=<SubBackward0>)\n",
      "loss: 0.16912110149860382\n",
      "tensor([[855]]) tensor(732.3920, grad_fn=<SubBackward0>)\n",
      "loss: 0.14340117573738098\n",
      "tensor([[855]]) tensor(742.0087, grad_fn=<SubBackward0>)\n",
      "loss: 0.13215357065200806\n",
      "tensor([[855]]) tensor(731.1572, grad_fn=<SubBackward0>)\n",
      "loss: 0.14484542608261108\n",
      "tensor([[855]]) tensor(746.9119, grad_fn=<SubBackward0>)\n",
      "loss: 0.12641878426074982\n",
      "tensor([[855]]) tensor(735.5853, grad_fn=<SubBackward0>)\n",
      "loss: 0.139666348695755\n",
      "tensor([[855]]) tensor(729.1417, grad_fn=<SubBackward0>)\n",
      "loss: 0.14720262587070465\n",
      "tensor([[855]]) tensor(733.6177, grad_fn=<SubBackward0>)\n",
      "loss: 0.14196766912937164\n",
      "tensor([[855]]) tensor(745.6879, grad_fn=<SubBackward0>)\n",
      "loss: 0.12785041332244873\n",
      "tensor([[855]]) tensor(730.4484, grad_fn=<SubBackward0>)\n",
      "loss: 0.1456744521856308\n",
      "tensor([[855]]) tensor(727.6156, grad_fn=<SubBackward0>)\n",
      "loss: 0.1489875614643097\n",
      "tensor([[855]]) tensor(745.4171, grad_fn=<SubBackward0>)\n",
      "loss: 0.12816712260246277\n",
      "tensor([[855]]) tensor(735.1814, grad_fn=<SubBackward0>)\n",
      "loss: 0.1401386857032776\n",
      "tensor([[855]]) tensor(743.2831, grad_fn=<SubBackward0>)\n",
      "loss: 0.13066306710243225\n",
      "tensor([[855]]) tensor(739.7247, grad_fn=<SubBackward0>)\n",
      "loss: 0.1348249465227127\n",
      "tensor([[855]]) tensor(744.1371, grad_fn=<SubBackward0>)\n",
      "loss: 0.12966425716876984\n",
      "tensor([[855]]) tensor(744.4075, grad_fn=<SubBackward0>)\n",
      "loss: 0.12934795022010803\n",
      "tensor([[855]]) tensor(738.1096, grad_fn=<SubBackward0>)\n",
      "loss: 0.13671396672725677\n",
      "tensor([[855]]) tensor(748.3490, grad_fn=<SubBackward0>)\n",
      "loss: 0.12473804503679276\n",
      "tensor([[855]]) tensor(730.0981, grad_fn=<SubBackward0>)\n",
      "loss: 0.1460840255022049\n",
      "tensor([[855]]) tensor(732.3210, grad_fn=<SubBackward0>)\n",
      "loss: 0.1434842348098755\n",
      "tensor([[855]]) tensor(746.5905, grad_fn=<SubBackward0>)\n",
      "loss: 0.1267947554588318\n",
      "tensor([[855]]) tensor(744.5818, grad_fn=<SubBackward0>)\n",
      "loss: 0.1291441023349762\n",
      "tensor([[855]]) tensor(751.4855, grad_fn=<SubBackward0>)\n",
      "loss: 0.12106965482234955\n",
      "tensor([[855]]) tensor(731.2524, grad_fn=<SubBackward0>)\n",
      "loss: 0.1447339802980423\n",
      "tensor([[855]]) tensor(738.6031, grad_fn=<SubBackward0>)\n",
      "loss: 0.13613666594028473\n",
      "tensor([[855]]) tensor(744.4033, grad_fn=<SubBackward0>)\n",
      "loss: 0.12935280799865723\n",
      "tensor([[855]]) tensor(736.4436, grad_fn=<SubBackward0>)\n",
      "loss: 0.1386624574661255\n",
      "tensor([[855]]) tensor(750.0582, grad_fn=<SubBackward0>)\n",
      "loss: 0.12273897230625153\n",
      "tensor([[855]]) tensor(745.3804, grad_fn=<SubBackward0>)\n",
      "loss: 0.12821006774902344\n",
      "tensor([[855]]) tensor(754.3342, grad_fn=<SubBackward0>)\n",
      "loss: 0.1177377998828888\n",
      "tensor([[855]]) tensor(749.3442, grad_fn=<SubBackward0>)\n",
      "loss: 0.12357395142316818\n",
      "tensor([[855]]) tensor(750.7952, grad_fn=<SubBackward0>)\n",
      "loss: 0.1218770369887352\n",
      "tensor([[855]]) tensor(751.2168, grad_fn=<SubBackward0>)\n",
      "loss: 0.121383897960186\n",
      "tensor([[855]]) tensor(742.4135, grad_fn=<SubBackward0>)\n",
      "loss: 0.13168013095855713\n",
      "tensor([[855]]) tensor(753.4476, grad_fn=<SubBackward0>)\n",
      "loss: 0.11877473443746567\n",
      "tensor([[855]]) tensor(740.3851, grad_fn=<SubBackward0>)\n",
      "loss: 0.13405245542526245\n",
      "tensor([[855]]) tensor(750.7183, grad_fn=<SubBackward0>)\n",
      "loss: 0.12196698039770126\n",
      "tensor([[855]]) tensor(740.1955, grad_fn=<SubBackward0>)\n",
      "loss: 0.13427427411079407\n",
      "tensor([[855]]) tensor(740.3606, grad_fn=<SubBackward0>)\n",
      "loss: 0.1340811401605606\n",
      "tensor([[855]]) tensor(751.5331, grad_fn=<SubBackward0>)\n",
      "loss: 0.12101388722658157\n",
      "tensor([[855]]) tensor(738.8874, grad_fn=<SubBackward0>)\n",
      "loss: 0.13580422103405\n",
      "tensor([[855]]) tensor(747.0551, grad_fn=<SubBackward0>)\n",
      "loss: 0.12625139951705933\n",
      "tensor([[855]]) tensor(746.8572, grad_fn=<SubBackward0>)\n",
      "loss: 0.12648282945156097\n",
      "tensor([[855]]) tensor(746.6082, grad_fn=<SubBackward0>)\n",
      "loss: 0.12677399814128876\n",
      "tensor([[855]]) tensor(751.9648, grad_fn=<SubBackward0>)\n",
      "loss: 0.12050904333591461\n",
      "tensor([[855]]) tensor(749.3812, grad_fn=<SubBackward0>)\n",
      "loss: 0.1235307827591896\n",
      "tensor([[855]]) tensor(750.8904, grad_fn=<SubBackward0>)\n",
      "loss: 0.12176567316055298\n",
      "tensor([[855]]) tensor(754.7390, grad_fn=<SubBackward0>)\n",
      "loss: 0.1172642931342125\n",
      "tensor([[855]]) tensor(749.4009, grad_fn=<SubBackward0>)\n",
      "loss: 0.1235077828168869\n",
      "tensor([[855]]) tensor(747.4664, grad_fn=<SubBackward0>)\n",
      "loss: 0.12577033042907715\n",
      "tensor([[855]]) tensor(748.2081, grad_fn=<SubBackward0>)\n",
      "loss: 0.12490279227495193\n",
      "tensor([[855]]) tensor(742.5070, grad_fn=<SubBackward0>)\n",
      "loss: 0.13157078623771667\n",
      "tensor([[855]]) tensor(750.4581, grad_fn=<SubBackward0>)\n",
      "loss: 0.12227124720811844\n",
      "tensor([[855]]) tensor(748.1576, grad_fn=<SubBackward0>)\n",
      "loss: 0.12496188282966614\n",
      "tensor([[855]]) tensor(750.8297, grad_fn=<SubBackward0>)\n",
      "loss: 0.12183663249015808\n",
      "tensor([[855]]) tensor(750.7747, grad_fn=<SubBackward0>)\n",
      "loss: 0.12190094590187073\n",
      "tensor([[855]]) tensor(750.7852, grad_fn=<SubBackward0>)\n",
      "loss: 0.12188874185085297\n",
      "tensor([[855]]) tensor(749.4766, grad_fn=<SubBackward0>)\n",
      "loss: 0.12341924011707306\n",
      "tensor([[855]]) tensor(751.8574, grad_fn=<SubBackward0>)\n",
      "loss: 0.12063463032245636\n",
      "tensor([[855]]) tensor(755.7146, grad_fn=<SubBackward0>)\n",
      "loss: 0.1161232739686966\n",
      "tensor([[855]]) tensor(753.8115, grad_fn=<SubBackward0>)\n",
      "loss: 0.1183491125702858\n",
      "tensor([[855]]) tensor(750.1860, grad_fn=<SubBackward0>)\n",
      "loss: 0.12258943170309067\n",
      "tensor([[855]]) tensor(749.1593, grad_fn=<SubBackward0>)\n",
      "loss: 0.12379029393196106\n",
      "tensor([[855]]) tensor(749.8491, grad_fn=<SubBackward0>)\n",
      "loss: 0.12298357486724854\n",
      "tensor([[855]]) tensor(750.9933, grad_fn=<SubBackward0>)\n",
      "loss: 0.12164527922868729\n",
      "tensor([[855]]) tensor(753.5235, grad_fn=<SubBackward0>)\n",
      "loss: 0.11868598312139511\n",
      "tensor([[855]]) tensor(754.2856, grad_fn=<SubBackward0>)\n",
      "loss: 0.11779455095529556\n",
      "tensor([[855]]) tensor(754.2303, grad_fn=<SubBackward0>)\n",
      "loss: 0.11785924434661865\n",
      "tensor([[855]]) tensor(751.0432, grad_fn=<SubBackward0>)\n",
      "loss: 0.12158695608377457\n",
      "tensor([[855]]) tensor(746.5474, grad_fn=<SubBackward0>)\n",
      "loss: 0.12684519588947296\n",
      "tensor([[855]]) tensor(753.0968, grad_fn=<SubBackward0>)\n",
      "loss: 0.11918506026268005\n",
      "tensor([[855]]) tensor(749.9318, grad_fn=<SubBackward0>)\n",
      "loss: 0.1228867918252945\n",
      "tensor([[855]]) tensor(755.9249, grad_fn=<SubBackward0>)\n",
      "loss: 0.11587726324796677\n",
      "tensor([[855]]) tensor(754.9829, grad_fn=<SubBackward0>)\n",
      "loss: 0.11697905510663986\n",
      "tensor([[855]]) tensor(753.5438, grad_fn=<SubBackward0>)\n",
      "loss: 0.11866217851638794\n",
      "tensor([[855]]) tensor(754.2654, grad_fn=<SubBackward0>)\n",
      "loss: 0.11781826615333557\n",
      "tensor([[855]]) tensor(752.3058, grad_fn=<SubBackward0>)\n",
      "loss: 0.1201101541519165\n",
      "tensor([[855]]) tensor(754.0419, grad_fn=<SubBackward0>)\n",
      "loss: 0.11807969957590103\n",
      "tensor([[855]]) tensor(754.9937, grad_fn=<SubBackward0>)\n",
      "loss: 0.11696648597717285\n",
      "tensor([[855]]) tensor(749.3749, grad_fn=<SubBackward0>)\n",
      "loss: 0.12353808432817459\n",
      "tensor([[855]]) tensor(758.4664, grad_fn=<SubBackward0>)\n",
      "loss: 0.11290472745895386\n",
      "tensor([[855]]) tensor(758.5530, grad_fn=<SubBackward0>)\n",
      "loss: 0.11280349642038345\n",
      "tensor([[855]]) tensor(757.1827, grad_fn=<SubBackward0>)\n",
      "loss: 0.11440611630678177\n",
      "tensor([[855]]) tensor(747.0948, grad_fn=<SubBackward0>)\n",
      "loss: 0.12620489299297333\n",
      "tensor([[855]]) tensor(754.9712, grad_fn=<SubBackward0>)\n",
      "loss: 0.11699271947145462\n",
      "tensor([[855]]) tensor(740.9824, grad_fn=<SubBackward0>)\n",
      "loss: 0.13335388898849487\n",
      "tensor([[855]]) tensor(743.4541, grad_fn=<SubBackward0>)\n",
      "loss: 0.13046301901340485\n",
      "tensor([[855]]) tensor(746.6042, grad_fn=<SubBackward0>)\n",
      "loss: 0.1267787218093872\n",
      "tensor([[855]]) tensor(740.4255, grad_fn=<SubBackward0>)\n",
      "loss: 0.13400518894195557\n",
      "tensor([[855]]) tensor(745.6744, grad_fn=<SubBackward0>)\n",
      "loss: 0.12786614894866943\n",
      "tensor([[855]]) tensor(749.3193, grad_fn=<SubBackward0>)\n",
      "loss: 0.12360313534736633\n",
      "tensor([[855]]) tensor(754.8607, grad_fn=<SubBackward0>)\n",
      "loss: 0.11712202429771423\n",
      "tensor([[855]]) tensor(748.1910, grad_fn=<SubBackward0>)\n",
      "loss: 0.12492279708385468\n",
      "tensor([[855]]) tensor(746.6962, grad_fn=<SubBackward0>)\n",
      "loss: 0.12667116522789001\n",
      "tensor([[855]]) tensor(752.6379, grad_fn=<SubBackward0>)\n",
      "loss: 0.11972176283597946\n",
      "tensor([[855]]) tensor(757.6202, grad_fn=<SubBackward0>)\n",
      "loss: 0.11389452964067459\n",
      "tensor([[855]]) tensor(755.7063, grad_fn=<SubBackward0>)\n",
      "loss: 0.11613298207521439\n",
      "tensor([[855]]) tensor(754.7805, grad_fn=<SubBackward0>)\n",
      "loss: 0.11721578985452652\n",
      "tensor([[855]]) tensor(749.2328, grad_fn=<SubBackward0>)\n",
      "loss: 0.12370425462722778\n",
      "tensor([[855]]) tensor(755.0096, grad_fn=<SubBackward0>)\n",
      "loss: 0.11694785952568054\n",
      "tensor([[855]]) tensor(743.5833, grad_fn=<SubBackward0>)\n",
      "loss: 0.130311980843544\n",
      "tensor([[855]]) tensor(749.3870, grad_fn=<SubBackward0>)\n",
      "loss: 0.12352405488491058\n",
      "tensor([[855]]) tensor(746.1475, grad_fn=<SubBackward0>)\n",
      "loss: 0.12731283903121948\n",
      "tensor([[855]]) tensor(743.7787, grad_fn=<SubBackward0>)\n",
      "loss: 0.13008339703083038\n",
      "tensor([[855]]) tensor(748.8318, grad_fn=<SubBackward0>)\n",
      "loss: 0.12417327612638474\n",
      "tensor([[855]]) tensor(737.7325, grad_fn=<SubBackward0>)\n",
      "loss: 0.13715487718582153\n",
      "tensor([[855]]) tensor(741.7584, grad_fn=<SubBackward0>)\n",
      "loss: 0.13244634866714478\n",
      "tensor([[855]]) tensor(746.7291, grad_fn=<SubBackward0>)\n",
      "loss: 0.1266326606273651\n",
      "tensor([[855]]) tensor(741.9910, grad_fn=<SubBackward0>)\n",
      "loss: 0.1321742832660675\n",
      "tensor([[855]]) tensor(752.7401, grad_fn=<SubBackward0>)\n",
      "loss: 0.11960218846797943\n",
      "tensor([[855]]) tensor(744.5102, grad_fn=<SubBackward0>)\n",
      "loss: 0.12922786176204681\n",
      "tensor([[855]]) tensor(749.8145, grad_fn=<SubBackward0>)\n",
      "loss: 0.12302406877279282\n",
      "tensor([[855]]) tensor(750.4971, grad_fn=<SubBackward0>)\n",
      "loss: 0.12222564965486526\n",
      "tensor([[855]]) tensor(755.1354, grad_fn=<SubBackward0>)\n",
      "loss: 0.11680076271295547\n",
      "tensor([[855]]) tensor(742.9758, grad_fn=<SubBackward0>)\n",
      "loss: 0.13102246820926666\n",
      "tensor([[855]]) tensor(744.2073, grad_fn=<SubBackward0>)\n",
      "loss: 0.12958209216594696\n",
      "tensor([[855]]) tensor(756.9483, grad_fn=<SubBackward0>)\n",
      "loss: 0.11468034982681274\n",
      "tensor([[855]]) tensor(757.5128, grad_fn=<SubBackward0>)\n",
      "loss: 0.11402018368244171\n",
      "tensor([[855]]) tensor(757.4841, grad_fn=<SubBackward0>)\n",
      "loss: 0.11405373364686966\n",
      "tensor([[855]]) tensor(760.3971, grad_fn=<SubBackward0>)\n",
      "loss: 0.11064670979976654\n",
      "tensor([[855]]) tensor(757.4788, grad_fn=<SubBackward0>)\n",
      "loss: 0.11405996233224869\n",
      "tensor([[855]]) tensor(755.0922, grad_fn=<SubBackward0>)\n",
      "loss: 0.11685125529766083\n",
      "tensor([[855]]) tensor(754.5687, grad_fn=<SubBackward0>)\n",
      "loss: 0.11746349930763245\n",
      "tensor([[855]]) tensor(758.0558, grad_fn=<SubBackward0>)\n",
      "loss: 0.11338508129119873\n",
      "tensor([[855]]) tensor(760.7180, grad_fn=<SubBackward0>)\n",
      "loss: 0.1102713942527771\n",
      "tensor([[855]]) tensor(754.0067, grad_fn=<SubBackward0>)\n",
      "loss: 0.11812084168195724\n",
      "tensor([[855]]) tensor(760.6238, grad_fn=<SubBackward0>)\n",
      "loss: 0.11038149148225784\n",
      "tensor([[855]]) tensor(744.3848, grad_fn=<SubBackward0>)\n",
      "loss: 0.12937448918819427\n",
      "tensor([[855]]) tensor(753.4044, grad_fn=<SubBackward0>)\n",
      "loss: 0.11882520467042923\n",
      "tensor([[855]]) tensor(739.7103, grad_fn=<SubBackward0>)\n",
      "loss: 0.13484175503253937\n",
      "tensor([[855]]) tensor(743.2753, grad_fn=<SubBackward0>)\n",
      "loss: 0.1306721717119217\n",
      "tensor([[855]]) tensor(757.6870, grad_fn=<SubBackward0>)\n",
      "loss: 0.11381639540195465\n",
      "tensor([[855]]) tensor(746.9694, grad_fn=<SubBackward0>)\n",
      "loss: 0.12635160982608795\n",
      "tensor([[855]]) tensor(754.0613, grad_fn=<SubBackward0>)\n",
      "loss: 0.11805690824985504\n",
      "tensor([[855]]) tensor(753.9357, grad_fn=<SubBackward0>)\n",
      "loss: 0.11820393055677414\n",
      "tensor([[855]]) tensor(751.4691, grad_fn=<SubBackward0>)\n",
      "loss: 0.12108875066041946\n",
      "tensor([[855]]) tensor(756.1387, grad_fn=<SubBackward0>)\n",
      "loss: 0.11562731862068176\n",
      "tensor([[855]]) tensor(752.1855, grad_fn=<SubBackward0>)\n",
      "loss: 0.12025082111358643\n",
      "tensor([[855]]) tensor(759.7486, grad_fn=<SubBackward0>)\n",
      "loss: 0.111405149102211\n",
      "tensor([[855]]) tensor(752.7598, grad_fn=<SubBackward0>)\n",
      "loss: 0.1195792555809021\n",
      "tensor([[855]]) tensor(758.7703, grad_fn=<SubBackward0>)\n",
      "loss: 0.11254941672086716\n",
      "tensor([[855]]) tensor(746.0228, grad_fn=<SubBackward0>)\n",
      "loss: 0.12745867669582367\n",
      "tensor([[855]]) tensor(755.0900, grad_fn=<SubBackward0>)\n",
      "loss: 0.1168537512421608\n",
      "tensor([[855]]) tensor(747.7551, grad_fn=<SubBackward0>)\n",
      "loss: 0.12543264031410217\n",
      "tensor([[855]]) tensor(758.1537, grad_fn=<SubBackward0>)\n",
      "loss: 0.11327050626277924\n",
      "tensor([[855]]) tensor(753.8005, grad_fn=<SubBackward0>)\n",
      "loss: 0.11836197972297668\n",
      "tensor([[855]]) tensor(751.4557, grad_fn=<SubBackward0>)\n",
      "loss: 0.1211044192314148\n",
      "tensor([[855]]) tensor(759.0223, grad_fn=<SubBackward0>)\n",
      "loss: 0.1122545599937439\n",
      "tensor([[855]]) tensor(747.8909, grad_fn=<SubBackward0>)\n",
      "loss: 0.12527376413345337\n",
      "tensor([[855]]) tensor(759.4166, grad_fn=<SubBackward0>)\n",
      "loss: 0.11179345846176147\n",
      "tensor([[855]]) tensor(761.5722, grad_fn=<SubBackward0>)\n",
      "loss: 0.10927227884531021\n",
      "tensor([[855]]) tensor(756.0728, grad_fn=<SubBackward0>)\n",
      "loss: 0.11570434272289276\n",
      "tensor([[855]]) tensor(763.5295, grad_fn=<SubBackward0>)\n",
      "loss: 0.1069829910993576\n",
      "tensor([[855]]) tensor(743.2867, grad_fn=<SubBackward0>)\n",
      "loss: 0.1306588500738144\n",
      "tensor([[855]]) tensor(745.5823, grad_fn=<SubBackward0>)\n",
      "loss: 0.12797391414642334\n",
      "tensor([[855]]) tensor(749.5148, grad_fn=<SubBackward0>)\n",
      "loss: 0.1233745738863945\n",
      "tensor([[855]]) tensor(752.2061, grad_fn=<SubBackward0>)\n",
      "loss: 0.12022680044174194\n",
      "tensor([[855]]) tensor(753.0742, grad_fn=<SubBackward0>)\n",
      "loss: 0.11921147257089615\n",
      "tensor([[855]]) tensor(757.7613, grad_fn=<SubBackward0>)\n",
      "loss: 0.11372949928045273\n",
      "tensor([[855]]) tensor(754.3567, grad_fn=<SubBackward0>)\n",
      "loss: 0.11771143972873688\n",
      "tensor([[855]]) tensor(754.0289, grad_fn=<SubBackward0>)\n",
      "loss: 0.11809481680393219\n",
      "tensor([[855]]) tensor(756.1589, grad_fn=<SubBackward0>)\n",
      "loss: 0.11560360342264175\n",
      "tensor([[855]]) tensor(755.0963, grad_fn=<SubBackward0>)\n",
      "loss: 0.1168464869260788\n",
      "tensor([[855]]) tensor(753.4630, grad_fn=<SubBackward0>)\n",
      "loss: 0.1187567487359047\n",
      "tensor([[855]]) tensor(753.6906, grad_fn=<SubBackward0>)\n",
      "loss: 0.11849058419466019\n",
      "tensor([[855]]) tensor(754.4691, grad_fn=<SubBackward0>)\n",
      "loss: 0.11757994443178177\n",
      "tensor([[855]]) tensor(759.2526, grad_fn=<SubBackward0>)\n",
      "loss: 0.11198527365922928\n",
      "tensor([[855]]) tensor(755.9228, grad_fn=<SubBackward0>)\n",
      "loss: 0.11587975919246674\n",
      "tensor([[855]]) tensor(759.9871, grad_fn=<SubBackward0>)\n",
      "loss: 0.11112624406814575\n",
      "tensor([[855]]) tensor(751.1071, grad_fn=<SubBackward0>)\n",
      "loss: 0.12151214480400085\n",
      "tensor([[855]]) tensor(759.3150, grad_fn=<SubBackward0>)\n",
      "loss: 0.11191229522228241\n",
      "tensor([[855]]) tensor(744.6536, grad_fn=<SubBackward0>)\n",
      "loss: 0.12906016409397125\n",
      "tensor([[855]]) tensor(749.6525, grad_fn=<SubBackward0>)\n",
      "loss: 0.12321349233388901\n",
      "tensor([[855]]) tensor(747.1127, grad_fn=<SubBackward0>)\n",
      "loss: 0.12618398666381836\n",
      "tensor([[855]]) tensor(750.2648, grad_fn=<SubBackward0>)\n",
      "loss: 0.1224973052740097\n",
      "tensor([[855]]) tensor(756.0265, grad_fn=<SubBackward0>)\n",
      "loss: 0.11575853079557419\n",
      "tensor([[855]]) tensor(743.0255, grad_fn=<SubBackward0>)\n",
      "loss: 0.13096435368061066\n",
      "tensor([[855]]) tensor(753.7853, grad_fn=<SubBackward0>)\n",
      "loss: 0.11837975680828094\n",
      "tensor([[855]]) tensor(744.1368, grad_fn=<SubBackward0>)\n",
      "loss: 0.1296645849943161\n",
      "tensor([[855]]) tensor(733.6553, grad_fn=<SubBackward0>)\n",
      "loss: 0.14192356169223785\n",
      "tensor([[855]]) tensor(736.5208, grad_fn=<SubBackward0>)\n",
      "loss: 0.13857220113277435\n",
      "tensor([[855]]) tensor(752.1365, grad_fn=<SubBackward0>)\n",
      "loss: 0.12030825018882751\n",
      "tensor([[855]]) tensor(746.0281, grad_fn=<SubBackward0>)\n",
      "loss: 0.12745247781276703\n",
      "tensor([[855]]) tensor(740.9969, grad_fn=<SubBackward0>)\n",
      "loss: 0.13333693146705627\n",
      "tensor([[855]]) tensor(756.9538, grad_fn=<SubBackward0>)\n",
      "loss: 0.1146739199757576\n",
      "tensor([[855]]) tensor(754.0850, grad_fn=<SubBackward0>)\n",
      "loss: 0.11802928894758224\n",
      "tensor([[855]]) tensor(756.8286, grad_fn=<SubBackward0>)\n",
      "loss: 0.11482033878564835\n",
      "tensor([[855]]) tensor(764.4485, grad_fn=<SubBackward0>)\n",
      "loss: 0.10590822249650955\n",
      "tensor([[855]]) tensor(765.8738, grad_fn=<SubBackward0>)\n",
      "loss: 0.10424122959375381\n",
      "tensor([[855]]) tensor(756.2928, grad_fn=<SubBackward0>)\n",
      "loss: 0.11544696241617203\n",
      "tensor([[855]]) tensor(763.1507, grad_fn=<SubBackward0>)\n",
      "loss: 0.10742610692977905\n",
      "tensor([[855]]) tensor(748.6069, grad_fn=<SubBackward0>)\n",
      "loss: 0.1244363859295845\n",
      "tensor([[855]]) tensor(756.8873, grad_fn=<SubBackward0>)\n",
      "loss: 0.11475162953138351\n",
      "tensor([[855]]) tensor(742.1599, grad_fn=<SubBackward0>)\n",
      "loss: 0.13197672367095947\n",
      "tensor([[855]]) tensor(751.2787, grad_fn=<SubBackward0>)\n",
      "loss: 0.1213114932179451\n",
      "tensor([[855]]) tensor(758.8035, grad_fn=<SubBackward0>)\n",
      "loss: 0.11251053214073181\n",
      "tensor([[855]]) tensor(757.1111, grad_fn=<SubBackward0>)\n",
      "loss: 0.11448990553617477\n",
      "tensor([[855]]) tensor(760.7719, grad_fn=<SubBackward0>)\n",
      "loss: 0.11020832508802414\n",
      "tensor([[855]]) tensor(762.7457, grad_fn=<SubBackward0>)\n",
      "loss: 0.10789980739355087\n",
      "tensor([[855]]) tensor(758.1097, grad_fn=<SubBackward0>)\n",
      "loss: 0.11332197487354279\n",
      "tensor([[855]]) tensor(765.6155, grad_fn=<SubBackward0>)\n",
      "loss: 0.10454323142766953\n",
      "tensor([[855]]) tensor(758.0081, grad_fn=<SubBackward0>)\n",
      "loss: 0.11344081908464432\n",
      "tensor([[855]]) tensor(762.7378, grad_fn=<SubBackward0>)\n",
      "loss: 0.10790897905826569\n",
      "tensor([[855]]) tensor(765.9517, grad_fn=<SubBackward0>)\n",
      "loss: 0.10415012389421463\n",
      "tensor([[855]]) tensor(763.0544, grad_fn=<SubBackward0>)\n",
      "loss: 0.1075386255979538\n",
      "tensor([[855]]) tensor(760.3627, grad_fn=<SubBackward0>)\n",
      "loss: 0.11068697273731232\n",
      "tensor([[855]]) tensor(760.9788, grad_fn=<SubBackward0>)\n",
      "loss: 0.10996634513139725\n",
      "tensor([[855]]) tensor(761.6320, grad_fn=<SubBackward0>)\n",
      "loss: 0.1092023178935051\n",
      "tensor([[855]]) tensor(756.4832, grad_fn=<SubBackward0>)\n",
      "loss: 0.11522438377141953\n",
      "tensor([[855]]) tensor(767.5972, grad_fn=<SubBackward0>)\n",
      "loss: 0.10222551971673965\n",
      "tensor([[855]]) tensor(749.9830, grad_fn=<SubBackward0>)\n",
      "loss: 0.12282691895961761\n",
      "tensor([[855]]) tensor(751.2964, grad_fn=<SubBackward0>)\n",
      "loss: 0.12129074335098267\n",
      "tensor([[855]]) tensor(767.2849, grad_fn=<SubBackward0>)\n",
      "loss: 0.10259081423282623\n",
      "tensor([[855]]) tensor(737.8007, grad_fn=<SubBackward0>)\n",
      "loss: 0.13707518577575684\n",
      "tensor([[855]]) tensor(735.6174, grad_fn=<SubBackward0>)\n",
      "loss: 0.13962878286838531\n",
      "tensor([[855]]) tensor(759.1696, grad_fn=<SubBackward0>)\n",
      "loss: 0.11208231747150421\n",
      "tensor([[855]]) tensor(740.5472, grad_fn=<SubBackward0>)\n",
      "loss: 0.13386285305023193\n",
      "tensor([[855]]) tensor(732.8986, grad_fn=<SubBackward0>)\n",
      "loss: 0.14280864596366882\n",
      "tensor([[855]]) tensor(744.5728, grad_fn=<SubBackward0>)\n",
      "loss: 0.12915466725826263\n",
      "tensor([[855]]) tensor(759.0609, grad_fn=<SubBackward0>)\n",
      "loss: 0.1122094914317131\n",
      "tensor([[855]]) tensor(738.5695, grad_fn=<SubBackward0>)\n",
      "loss: 0.1361759901046753\n",
      "tensor([[855]]) tensor(739.1298, grad_fn=<SubBackward0>)\n",
      "loss: 0.13552069664001465\n",
      "tensor([[855]]) tensor(761.2974, grad_fn=<SubBackward0>)\n",
      "loss: 0.10959372669458389\n",
      "tensor([[855]]) tensor(756.5887, grad_fn=<SubBackward0>)\n",
      "loss: 0.11510086804628372\n",
      "tensor([[855]]) tensor(761.3123, grad_fn=<SubBackward0>)\n",
      "loss: 0.10957624018192291\n",
      "tensor([[855]]) tensor(748.1523, grad_fn=<SubBackward0>)\n",
      "loss: 0.1249680370092392\n",
      "tensor([[855]]) tensor(758.2783, grad_fn=<SubBackward0>)\n",
      "loss: 0.1131247729063034\n",
      "tensor([[855]]) tensor(747.9236, grad_fn=<SubBackward0>)\n",
      "loss: 0.12523561716079712\n",
      "tensor([[855]]) tensor(747.6465, grad_fn=<SubBackward0>)\n",
      "loss: 0.12555964291095734\n",
      "tensor([[855]]) tensor(763.0611, grad_fn=<SubBackward0>)\n",
      "loss: 0.10753088444471359\n",
      "tensor([[855]]) tensor(758.2521, grad_fn=<SubBackward0>)\n",
      "loss: 0.11315539479255676\n",
      "tensor([[855]]) tensor(765.8909, grad_fn=<SubBackward0>)\n",
      "loss: 0.10422118753194809\n",
      "tensor([[855]]) tensor(760.3398, grad_fn=<SubBackward0>)\n",
      "loss: 0.1107136532664299\n",
      "tensor([[855]]) tensor(761.0717, grad_fn=<SubBackward0>)\n",
      "loss: 0.10985764116048813\n",
      "tensor([[855]]) tensor(756.4116, grad_fn=<SubBackward0>)\n",
      "loss: 0.11530811339616776\n",
      "tensor([[855]]) tensor(760.9714, grad_fn=<SubBackward0>)\n",
      "loss: 0.1099749282002449\n",
      "tensor([[855]]) tensor(765.9631, grad_fn=<SubBackward0>)\n",
      "loss: 0.1041366457939148\n",
      "tensor([[855]]) tensor(762.9668, grad_fn=<SubBackward0>)\n",
      "loss: 0.10764117538928986\n",
      "tensor([[855]]) tensor(766.1660, grad_fn=<SubBackward0>)\n",
      "loss: 0.10389941185712814\n",
      "tensor([[855]]) tensor(755.4565, grad_fn=<SubBackward0>)\n",
      "loss: 0.11642513424158096\n",
      "tensor([[855]]) tensor(767.2561, grad_fn=<SubBackward0>)\n",
      "loss: 0.10262447595596313\n",
      "tensor([[855]]) tensor(740.9205, grad_fn=<SubBackward0>)\n",
      "loss: 0.13342636823654175\n",
      "tensor([[855]]) tensor(745.3266, grad_fn=<SubBackward0>)\n",
      "loss: 0.12827299535274506\n",
      "tensor([[855]]) tensor(767.1410, grad_fn=<SubBackward0>)\n",
      "loss: 0.10275909304618835\n",
      "tensor([[855]]) tensor(759.7479, grad_fn=<SubBackward0>)\n",
      "loss: 0.11140595376491547\n",
      "tensor([[855]]) tensor(765.4066, grad_fn=<SubBackward0>)\n",
      "loss: 0.10478755086660385\n",
      "tensor([[855]]) tensor(756.6137, grad_fn=<SubBackward0>)\n",
      "loss: 0.11507166922092438\n",
      "tensor([[855]]) tensor(758.5616, grad_fn=<SubBackward0>)\n",
      "loss: 0.11279341578483582\n",
      "tensor([[855]]) tensor(768.5100, grad_fn=<SubBackward0>)\n",
      "loss: 0.10115784406661987\n",
      "tensor([[855]]) tensor(768.5711, grad_fn=<SubBackward0>)\n",
      "loss: 0.10108644515275955\n",
      "tensor([[855]]) tensor(766.7598, grad_fn=<SubBackward0>)\n",
      "loss: 0.10320493578910828\n",
      "tensor([[855]]) tensor(768.0342, grad_fn=<SubBackward0>)\n",
      "loss: 0.1017143577337265\n",
      "tensor([[855]]) tensor(764.1289, grad_fn=<SubBackward0>)\n",
      "loss: 0.10628201812505722\n",
      "tensor([[855]]) tensor(767.0259, grad_fn=<SubBackward0>)\n",
      "loss: 0.1028936356306076\n",
      "tensor([[855]]) tensor(766.8700, grad_fn=<SubBackward0>)\n",
      "loss: 0.10307604819536209\n",
      "tensor([[855]]) tensor(767.5295, grad_fn=<SubBackward0>)\n",
      "loss: 0.10230470448732376\n",
      "tensor([[855]]) tensor(766.9623, grad_fn=<SubBackward0>)\n",
      "loss: 0.10296805948019028\n",
      "tensor([[855]]) tensor(761.4056, grad_fn=<SubBackward0>)\n",
      "loss: 0.109467051923275\n",
      "tensor([[855]]) tensor(765.6813, grad_fn=<SubBackward0>)\n",
      "loss: 0.10446631163358688\n",
      "tensor([[855]]) tensor(752.8120, grad_fn=<SubBackward0>)\n",
      "loss: 0.11951815336942673\n",
      "tensor([[855]]) tensor(760.8211, grad_fn=<SubBackward0>)\n",
      "loss: 0.1101507693529129\n",
      "tensor([[855]]) tensor(753.9521, grad_fn=<SubBackward0>)\n",
      "loss: 0.1181846410036087\n",
      "tensor([[855]]) tensor(747.9131, grad_fn=<SubBackward0>)\n",
      "loss: 0.1252478063106537\n",
      "tensor([[855]]) tensor(762.3247, grad_fn=<SubBackward0>)\n",
      "loss: 0.10839219391345978\n",
      "tensor([[855]]) tensor(757.2419, grad_fn=<SubBackward0>)\n",
      "loss: 0.11433689296245575\n",
      "tensor([[855]]) tensor(757.9753, grad_fn=<SubBackward0>)\n",
      "loss: 0.11347910016775131\n",
      "tensor([[855]]) tensor(766.2239, grad_fn=<SubBackward0>)\n",
      "loss: 0.10383163392543793\n",
      "tensor([[855]]) tensor(763.3316, grad_fn=<SubBackward0>)\n",
      "loss: 0.10721451789140701\n",
      "tensor([[855]]) tensor(769.3027, grad_fn=<SubBackward0>)\n",
      "loss: 0.10023080557584763\n",
      "tensor([[855]]) tensor(763.9032, grad_fn=<SubBackward0>)\n",
      "loss: 0.10654598474502563\n",
      "tensor([[855]]) tensor(769.7527, grad_fn=<SubBackward0>)\n",
      "loss: 0.09970445930957794\n",
      "tensor([[855]]) tensor(771.4639, grad_fn=<SubBackward0>)\n",
      "loss: 0.09770311415195465\n",
      "tensor([[855]]) tensor(761.7104, grad_fn=<SubBackward0>)\n",
      "loss: 0.10911065340042114\n",
      "tensor([[855]]) tensor(772.0653, grad_fn=<SubBackward0>)\n",
      "loss: 0.09699966013431549\n",
      "tensor([[855]]) tensor(757.1064, grad_fn=<SubBackward0>)\n",
      "loss: 0.1144954189658165\n",
      "tensor([[855]]) tensor(765.8597, grad_fn=<SubBackward0>)\n",
      "loss: 0.10425770282745361\n",
      "tensor([[855]]) tensor(759.1969, grad_fn=<SubBackward0>)\n",
      "loss: 0.1120503768324852\n",
      "tensor([[855]]) tensor(762.8821, grad_fn=<SubBackward0>)\n",
      "loss: 0.10774027556180954\n",
      "tensor([[855]]) tensor(759.6906, grad_fn=<SubBackward0>)\n",
      "loss: 0.11147303879261017\n",
      "tensor([[855]]) tensor(760.8007, grad_fn=<SubBackward0>)\n",
      "loss: 0.11017464846372604\n",
      "tensor([[855]]) tensor(768.4725, grad_fn=<SubBackward0>)\n",
      "loss: 0.10120171308517456\n",
      "tensor([[855]]) tensor(756.3693, grad_fn=<SubBackward0>)\n",
      "loss: 0.11535762250423431\n",
      "tensor([[855]]) tensor(766.2065, grad_fn=<SubBackward0>)\n",
      "loss: 0.10385195910930634\n",
      "tensor([[855]]) tensor(759.7238, grad_fn=<SubBackward0>)\n",
      "loss: 0.1114342212677002\n",
      "tensor([[855]]) tensor(756.8452, grad_fn=<SubBackward0>)\n",
      "loss: 0.11480100452899933\n",
      "tensor([[855]]) tensor(767.9609, grad_fn=<SubBackward0>)\n",
      "loss: 0.1018001064658165\n",
      "tensor([[855]]) tensor(755.6509, grad_fn=<SubBackward0>)\n",
      "loss: 0.11619783937931061\n",
      "tensor([[855]]) tensor(756.5674, grad_fn=<SubBackward0>)\n",
      "loss: 0.11512579768896103\n",
      "tensor([[855]]) tensor(766.6825, grad_fn=<SubBackward0>)\n",
      "loss: 0.10329532623291016\n",
      "tensor([[855]]) tensor(766.2181, grad_fn=<SubBackward0>)\n",
      "loss: 0.10383845120668411\n",
      "tensor([[855]]) tensor(769.3976, grad_fn=<SubBackward0>)\n",
      "loss: 0.10011978447437286\n",
      "tensor([[855]]) tensor(771.6935, grad_fn=<SubBackward0>)\n",
      "loss: 0.09743443876504898\n",
      "tensor([[855]]) tensor(767.6460, grad_fn=<SubBackward0>)\n",
      "loss: 0.10216841101646423\n",
      "tensor([[855]]) tensor(770.0820, grad_fn=<SubBackward0>)\n",
      "loss: 0.09931924194097519\n",
      "tensor([[855]]) tensor(767.2637, grad_fn=<SubBackward0>)\n",
      "loss: 0.10261553525924683\n",
      "tensor([[855]]) tensor(769.7596, grad_fn=<SubBackward0>)\n",
      "loss: 0.09969639778137207\n",
      "tensor([[855]]) tensor(766.1863, grad_fn=<SubBackward0>)\n",
      "loss: 0.10387573391199112\n",
      "tensor([[855]]) tensor(768.2192, grad_fn=<SubBackward0>)\n",
      "loss: 0.10149793326854706\n",
      "tensor([[855]]) tensor(769.2133, grad_fn=<SubBackward0>)\n",
      "loss: 0.10033528506755829\n",
      "tensor([[855]]) tensor(772.9084, grad_fn=<SubBackward0>)\n",
      "loss: 0.09601347893476486\n",
      "tensor([[855]]) tensor(759.2040, grad_fn=<SubBackward0>)\n",
      "loss: 0.11204205453395844\n",
      "tensor([[855]]) tensor(770.7726, grad_fn=<SubBackward0>)\n",
      "loss: 0.09851163625717163\n",
      "tensor([[855]]) tensor(761.4145, grad_fn=<SubBackward0>)\n",
      "loss: 0.10945675522089005\n",
      "tensor([[855]]) tensor(767.0918, grad_fn=<SubBackward0>)\n",
      "loss: 0.10281659662723541\n",
      "tensor([[855]]) tensor(744.0118, grad_fn=<SubBackward0>)\n",
      "loss: 0.12981070578098297\n",
      "tensor([[855]]) tensor(746.1680, grad_fn=<SubBackward0>)\n",
      "loss: 0.12728896737098694\n",
      "tensor([[855]]) tensor(761.2557, grad_fn=<SubBackward0>)\n",
      "loss: 0.10964249819517136\n",
      "tensor([[855]]) tensor(750.7255, grad_fn=<SubBackward0>)\n",
      "loss: 0.12195848673582077\n",
      "tensor([[855]]) tensor(746.2066, grad_fn=<SubBackward0>)\n",
      "loss: 0.1272437423467636\n",
      "tensor([[855]]) tensor(758.9372, grad_fn=<SubBackward0>)\n",
      "loss: 0.11235415935516357\n",
      "tensor([[855]]) tensor(752.2469, grad_fn=<SubBackward0>)\n",
      "loss: 0.12017899006605148\n",
      "tensor([[855]]) tensor(749.9539, grad_fn=<SubBackward0>)\n",
      "loss: 0.12286091595888138\n",
      "tensor([[855]]) tensor(757.9884, grad_fn=<SubBackward0>)\n",
      "loss: 0.11346381902694702\n",
      "tensor([[855]]) tensor(753.2806, grad_fn=<SubBackward0>)\n",
      "loss: 0.11897005140781403\n",
      "tensor([[855]]) tensor(757.0720, grad_fn=<SubBackward0>)\n",
      "loss: 0.11453568190336227\n",
      "tensor([[855]]) tensor(763.8782, grad_fn=<SubBackward0>)\n",
      "loss: 0.10657527297735214\n",
      "tensor([[855]]) tensor(759.6212, grad_fn=<SubBackward0>)\n",
      "loss: 0.11155420541763306\n",
      "tensor([[855]]) tensor(764.5869, grad_fn=<SubBackward0>)\n",
      "loss: 0.10574628412723541\n",
      "tensor([[855]]) tensor(768.8547, grad_fn=<SubBackward0>)\n",
      "loss: 0.1007547676563263\n",
      "tensor([[855]]) tensor(768.5036, grad_fn=<SubBackward0>)\n",
      "loss: 0.10116539895534515\n",
      "tensor([[855]]) tensor(766.9783, grad_fn=<SubBackward0>)\n",
      "loss: 0.10294932126998901\n",
      "tensor([[855]]) tensor(771.1832, grad_fn=<SubBackward0>)\n",
      "loss: 0.09803134948015213\n",
      "tensor([[855]]) tensor(769.8269, grad_fn=<SubBackward0>)\n",
      "loss: 0.09961765259504318\n",
      "tensor([[855]]) tensor(760.4155, grad_fn=<SubBackward0>)\n",
      "loss: 0.11062517017126083\n",
      "tensor([[855]]) tensor(758.3057, grad_fn=<SubBackward0>)\n",
      "loss: 0.11309278756380081\n",
      "tensor([[855]]) tensor(770.7524, grad_fn=<SubBackward0>)\n",
      "loss: 0.09853515774011612\n",
      "tensor([[855]]) tensor(759.8268, grad_fn=<SubBackward0>)\n",
      "loss: 0.11131367087364197\n",
      "tensor([[855]]) tensor(771.0623, grad_fn=<SubBackward0>)\n",
      "loss: 0.09817276149988174\n",
      "tensor([[855]]) tensor(763.5261, grad_fn=<SubBackward0>)\n",
      "loss: 0.10698699206113815\n",
      "tensor([[855]]) tensor(756.5692, grad_fn=<SubBackward0>)\n",
      "loss: 0.11512377858161926\n",
      "tensor([[855]]) tensor(767.0168, grad_fn=<SubBackward0>)\n",
      "loss: 0.10290434211492538\n",
      "tensor([[855]]) tensor(763.3926, grad_fn=<SubBackward0>)\n",
      "loss: 0.10714321583509445\n",
      "tensor([[855]]) tensor(766.8948, grad_fn=<SubBackward0>)\n",
      "loss: 0.10304708033800125\n",
      "tensor([[855]]) tensor(759.4901, grad_fn=<SubBackward0>)\n",
      "loss: 0.11170745640993118\n",
      "tensor([[855]]) tensor(753.2067, grad_fn=<SubBackward0>)\n",
      "loss: 0.11905649304389954\n",
      "tensor([[855]]) tensor(774.1532, grad_fn=<SubBackward0>)\n",
      "loss: 0.09455769509077072\n",
      "tensor([[855]]) tensor(751.9739, grad_fn=<SubBackward0>)\n",
      "loss: 0.1204984039068222\n",
      "tensor([[855]]) tensor(748.4554, grad_fn=<SubBackward0>)\n",
      "loss: 0.12461351603269577\n",
      "tensor([[855]]) tensor(769.2570, grad_fn=<SubBackward0>)\n",
      "loss: 0.10028424113988876\n",
      "tensor([[855]]) tensor(748.0310, grad_fn=<SubBackward0>)\n",
      "loss: 0.1251099407672882\n",
      "tensor([[855]]) tensor(739.9592, grad_fn=<SubBackward0>)\n",
      "loss: 0.13455067574977875\n",
      "tensor([[855]]) tensor(758.6302, grad_fn=<SubBackward0>)\n",
      "loss: 0.11271321028470993\n",
      "tensor([[855]]) tensor(765.6550, grad_fn=<SubBackward0>)\n",
      "loss: 0.10449711233377457\n",
      "tensor([[855]]) tensor(758.0532, grad_fn=<SubBackward0>)\n",
      "loss: 0.11338813602924347\n",
      "tensor([[855]]) tensor(775.0627, grad_fn=<SubBackward0>)\n",
      "loss: 0.09349383413791656\n",
      "tensor([[855]]) tensor(754.0537, grad_fn=<SubBackward0>)\n",
      "loss: 0.11806579679250717\n",
      "tensor([[855]]) tensor(753.8190, grad_fn=<SubBackward0>)\n",
      "loss: 0.11834035068750381\n",
      "tensor([[855]]) tensor(766.5123, grad_fn=<SubBackward0>)\n",
      "loss: 0.10349435359239578\n",
      "tensor([[855]]) tensor(757.8246, grad_fn=<SubBackward0>)\n",
      "loss: 0.1136554554104805\n",
      "tensor([[855]]) tensor(757.9672, grad_fn=<SubBackward0>)\n",
      "loss: 0.11348868161439896\n",
      "tensor([[855]]) tensor(771.0388, grad_fn=<SubBackward0>)\n",
      "loss: 0.09820026904344559\n",
      "tensor([[855]]) tensor(765.5151, grad_fn=<SubBackward0>)\n",
      "loss: 0.10466063767671585\n",
      "tensor([[855]]) tensor(769.4860, grad_fn=<SubBackward0>)\n",
      "loss: 0.10001641511917114\n",
      "tensor([[855]]) tensor(764.2335, grad_fn=<SubBackward0>)\n",
      "loss: 0.10615969449281693\n",
      "tensor([[855]]) tensor(769.3965, grad_fn=<SubBackward0>)\n",
      "loss: 0.10012099891901016\n",
      "tensor([[855]]) tensor(772.5599, grad_fn=<SubBackward0>)\n",
      "loss: 0.09642110764980316\n",
      "tensor([[855]]) tensor(770.2828, grad_fn=<SubBackward0>)\n",
      "loss: 0.09908447414636612\n",
      "tensor([[855]]) tensor(771.3926, grad_fn=<SubBackward0>)\n",
      "loss: 0.09778649359941483\n",
      "tensor([[855]]) tensor(773.1214, grad_fn=<SubBackward0>)\n",
      "loss: 0.09576442837715149\n",
      "tensor([[855]]) tensor(772.7793, grad_fn=<SubBackward0>)\n",
      "loss: 0.0961645320057869\n",
      "tensor([[855]]) tensor(771.8112, grad_fn=<SubBackward0>)\n",
      "loss: 0.0972968190908432\n",
      "tensor([[855]]) tensor(768.2366, grad_fn=<SubBackward0>)\n",
      "loss: 0.10147763788700104\n",
      "tensor([[855]]) tensor(774.2675, grad_fn=<SubBackward0>)\n",
      "loss: 0.0944240465760231\n",
      "tensor([[855]]) tensor(764.7152, grad_fn=<SubBackward0>)\n",
      "loss: 0.10559626668691635\n",
      "tensor([[855]]) tensor(767.0273, grad_fn=<SubBackward0>)\n",
      "loss: 0.1028919592499733\n",
      "tensor([[855]]) tensor(775.7952, grad_fn=<SubBackward0>)\n",
      "loss: 0.09263721853494644\n",
      "tensor([[855]]) tensor(763.6217, grad_fn=<SubBackward0>)\n",
      "loss: 0.1068752184510231\n",
      "tensor([[855]]) tensor(773.8309, grad_fn=<SubBackward0>)\n",
      "loss: 0.09493456035852432\n",
      "tensor([[855]]) tensor(769.3571, grad_fn=<SubBackward0>)\n",
      "loss: 0.1001671701669693\n",
      "tensor([[855]]) tensor(764.5894, grad_fn=<SubBackward0>)\n",
      "loss: 0.10574348270893097\n",
      "tensor([[855]]) tensor(776.2153, grad_fn=<SubBackward0>)\n",
      "loss: 0.09214584529399872\n",
      "tensor([[855]]) tensor(775.3273, grad_fn=<SubBackward0>)\n",
      "loss: 0.0931844413280487\n",
      "tensor([[855]]) tensor(775.7805, grad_fn=<SubBackward0>)\n",
      "loss: 0.09265436232089996\n",
      "tensor([[855]]) tensor(778.4337, grad_fn=<SubBackward0>)\n",
      "loss: 0.08955127745866776\n",
      "tensor([[855]]) tensor(776.0035, grad_fn=<SubBackward0>)\n",
      "loss: 0.09239355474710464\n",
      "tensor([[855]]) tensor(773.4705, grad_fn=<SubBackward0>)\n",
      "loss: 0.09535618871450424\n",
      "tensor([[855]]) tensor(771.6711, grad_fn=<SubBackward0>)\n",
      "loss: 0.09746070206165314\n",
      "tensor([[855]]) tensor(778.6806, grad_fn=<SubBackward0>)\n",
      "loss: 0.08926243335008621\n",
      "tensor([[855]]) tensor(780.3280, grad_fn=<SubBackward0>)\n",
      "loss: 0.08733570575714111\n",
      "tensor([[855]]) tensor(767.3237, grad_fn=<SubBackward0>)\n",
      "loss: 0.10254530608654022\n",
      "tensor([[855]]) tensor(774.2579, grad_fn=<SubBackward0>)\n",
      "loss: 0.0944352000951767\n",
      "tensor([[855]]) tensor(768.9586, grad_fn=<SubBackward0>)\n",
      "loss: 0.1006331592798233\n",
      "tensor([[855]]) tensor(771.6158, grad_fn=<SubBackward0>)\n",
      "loss: 0.09752541780471802\n",
      "tensor([[855]]) tensor(773.0746, grad_fn=<SubBackward0>)\n",
      "loss: 0.0958191454410553\n",
      "tensor([[855]]) tensor(772.1897, grad_fn=<SubBackward0>)\n",
      "loss: 0.09685418754816055\n",
      "tensor([[855]]) tensor(774.7781, grad_fn=<SubBackward0>)\n",
      "loss: 0.0938267931342125\n",
      "tensor([[855]]) tensor(775.2844, grad_fn=<SubBackward0>)\n",
      "loss: 0.0932345911860466\n",
      "tensor([[855]]) tensor(775.5187, grad_fn=<SubBackward0>)\n",
      "loss: 0.09296061098575592\n",
      "tensor([[855]]) tensor(777.9204, grad_fn=<SubBackward0>)\n",
      "loss: 0.09015153348445892\n",
      "tensor([[855]]) tensor(765.5233, grad_fn=<SubBackward0>)\n",
      "loss: 0.10465114563703537\n",
      "tensor([[855]]) tensor(775.6509, grad_fn=<SubBackward0>)\n",
      "loss: 0.0928058996796608\n",
      "tensor([[855]]) tensor(764.3272, grad_fn=<SubBackward0>)\n",
      "loss: 0.106050044298172\n",
      "tensor([[855]]) tensor(778.0493, grad_fn=<SubBackward0>)\n",
      "loss: 0.09000089019536972\n",
      "tensor([[855]]) tensor(758.5610, grad_fn=<SubBackward0>)\n",
      "loss: 0.11279407888650894\n",
      "tensor([[855]]) tensor(766.4292, grad_fn=<SubBackward0>)\n",
      "loss: 0.10359157621860504\n",
      "tensor([[855]]) tensor(764.7566, grad_fn=<SubBackward0>)\n",
      "loss: 0.10554784536361694\n",
      "tensor([[855]]) tensor(768.3906, grad_fn=<SubBackward0>)\n",
      "loss: 0.10129751265048981\n",
      "tensor([[855]]) tensor(773.0652, grad_fn=<SubBackward0>)\n",
      "loss: 0.09583015739917755\n",
      "tensor([[855]]) tensor(767.2435, grad_fn=<SubBackward0>)\n",
      "loss: 0.1026391088962555\n",
      "tensor([[855]]) tensor(770.1815, grad_fn=<SubBackward0>)\n",
      "loss: 0.09920292347669601\n",
      "tensor([[855]]) tensor(767.5369, grad_fn=<SubBackward0>)\n",
      "loss: 0.10229609906673431\n",
      "tensor([[855]]) tensor(770.4179, grad_fn=<SubBackward0>)\n",
      "loss: 0.09892642498016357\n",
      "tensor([[855]]) tensor(770.9661, grad_fn=<SubBackward0>)\n",
      "loss: 0.09828521311283112\n",
      "tensor([[855]]) tensor(772.2792, grad_fn=<SubBackward0>)\n",
      "loss: 0.09674941748380661\n",
      "tensor([[855]]) tensor(774.2278, grad_fn=<SubBackward0>)\n",
      "loss: 0.09447035938501358\n",
      "tensor([[855]]) tensor(769.4140, grad_fn=<SubBackward0>)\n",
      "loss: 0.10010059922933578\n",
      "tensor([[855]]) tensor(770.5487, grad_fn=<SubBackward0>)\n",
      "loss: 0.09877346456050873\n",
      "tensor([[855]]) tensor(769.1254, grad_fn=<SubBackward0>)\n",
      "loss: 0.10043813288211823\n",
      "tensor([[855]]) tensor(768.6906, grad_fn=<SubBackward0>)\n",
      "loss: 0.10094663500785828\n",
      "tensor([[855]]) tensor(771.0723, grad_fn=<SubBackward0>)\n",
      "loss: 0.09816107153892517\n",
      "tensor([[855]]) tensor(776.2510, grad_fn=<SubBackward0>)\n",
      "loss: 0.09210403263568878\n",
      "tensor([[855]]) tensor(760.3660, grad_fn=<SubBackward0>)\n",
      "loss: 0.11068306118249893\n",
      "tensor([[855]]) tensor(762.9792, grad_fn=<SubBackward0>)\n",
      "loss: 0.10762659460306168\n",
      "tensor([[855]]) tensor(770.7614, grad_fn=<SubBackward0>)\n",
      "loss: 0.09852469712495804\n",
      "tensor([[855]]) tensor(762.5488, grad_fn=<SubBackward0>)\n",
      "loss: 0.10813002288341522\n",
      "tensor([[855]]) tensor(775.4890, grad_fn=<SubBackward0>)\n",
      "loss: 0.09299532324075699\n",
      "tensor([[855]]) tensor(768.6389, grad_fn=<SubBackward0>)\n",
      "loss: 0.1010071337223053\n",
      "tensor([[855]]) tensor(768.2278, grad_fn=<SubBackward0>)\n",
      "loss: 0.1014879047870636\n",
      "tensor([[855]]) tensor(772.7803, grad_fn=<SubBackward0>)\n",
      "loss: 0.09616336971521378\n",
      "tensor([[855]]) tensor(764.2384, grad_fn=<SubBackward0>)\n",
      "loss: 0.1061539500951767\n",
      "tensor([[855]]) tensor(776.1924, grad_fn=<SubBackward0>)\n",
      "loss: 0.09217257797718048\n",
      "tensor([[855]]) tensor(774.3921, grad_fn=<SubBackward0>)\n",
      "loss: 0.09427829086780548\n",
      "tensor([[855]]) tensor(777.9854, grad_fn=<SubBackward0>)\n",
      "loss: 0.0900755375623703\n",
      "tensor([[855]]) tensor(778.5682, grad_fn=<SubBackward0>)\n",
      "loss: 0.08939387649297714\n",
      "tensor([[855]]) tensor(777.3782, grad_fn=<SubBackward0>)\n",
      "loss: 0.09078577905893326\n",
      "tensor([[855]]) tensor(774.8637, grad_fn=<SubBackward0>)\n",
      "loss: 0.09372664242982864\n",
      "tensor([[855]]) tensor(773.6422, grad_fn=<SubBackward0>)\n",
      "loss: 0.095155268907547\n",
      "tensor([[855]]) tensor(776.1561, grad_fn=<SubBackward0>)\n",
      "loss: 0.09221507608890533\n",
      "tensor([[855]]) tensor(781.5693, grad_fn=<SubBackward0>)\n",
      "loss: 0.08588378131389618\n",
      "tensor([[855]]) tensor(776.1908, grad_fn=<SubBackward0>)\n",
      "loss: 0.09217449277639389\n",
      "tensor([[855]]) tensor(778.5109, grad_fn=<SubBackward0>)\n",
      "loss: 0.08946090936660767\n",
      "tensor([[855]]) tensor(775.3724, grad_fn=<SubBackward0>)\n",
      "loss: 0.09313161671161652\n",
      "tensor([[855]]) tensor(776.7590, grad_fn=<SubBackward0>)\n",
      "loss: 0.09150990098714828\n",
      "tensor([[855]]) tensor(771.8381, grad_fn=<SubBackward0>)\n",
      "loss: 0.0972653180360794\n",
      "tensor([[855]]) tensor(779.3892, grad_fn=<SubBackward0>)\n",
      "loss: 0.08843367546796799\n",
      "tensor([[855]]) tensor(767.2864, grad_fn=<SubBackward0>)\n",
      "loss: 0.10258899629116058\n",
      "tensor([[855]]) tensor(769.8044, grad_fn=<SubBackward0>)\n",
      "loss: 0.09964389353990555\n",
      "tensor([[855]]) tensor(778.6326, grad_fn=<SubBackward0>)\n",
      "loss: 0.0893186703324318\n",
      "tensor([[855]]) tensor(776.8922, grad_fn=<SubBackward0>)\n",
      "loss: 0.0913541167974472\n",
      "tensor([[855]]) tensor(776.8777, grad_fn=<SubBackward0>)\n",
      "loss: 0.091371089220047\n",
      "tensor([[855]]) tensor(774.7128, grad_fn=<SubBackward0>)\n",
      "loss: 0.09390322864055634\n",
      "tensor([[855]]) tensor(779.1526, grad_fn=<SubBackward0>)\n",
      "loss: 0.08871041983366013\n",
      "tensor([[855]]) tensor(777.6031, grad_fn=<SubBackward0>)\n",
      "loss: 0.0905226320028305\n",
      "tensor([[855]]) tensor(779.2499, grad_fn=<SubBackward0>)\n",
      "loss: 0.08859659731388092\n",
      "tensor([[855]]) tensor(780.5209, grad_fn=<SubBackward0>)\n",
      "loss: 0.08711010962724686\n",
      "tensor([[855]]) tensor(781.3872, grad_fn=<SubBackward0>)\n",
      "loss: 0.08609680086374283\n",
      "tensor([[855]]) tensor(774.7148, grad_fn=<SubBackward0>)\n",
      "loss: 0.09390076994895935\n",
      "tensor([[855]]) tensor(782.3531, grad_fn=<SubBackward0>)\n",
      "loss: 0.08496715128421783\n",
      "tensor([[855]]) tensor(772.4497, grad_fn=<SubBackward0>)\n",
      "loss: 0.09655004739761353\n",
      "tensor([[855]]) tensor(777.9036, grad_fn=<SubBackward0>)\n",
      "loss: 0.0901711955666542\n",
      "tensor([[855]]) tensor(774.5060, grad_fn=<SubBackward0>)\n",
      "loss: 0.09414508938789368\n",
      "tensor([[855]]) tensor(782.0154, grad_fn=<SubBackward0>)\n",
      "loss: 0.08536205440759659\n",
      "tensor([[855]]) tensor(782.1494, grad_fn=<SubBackward0>)\n",
      "loss: 0.08520542085170746\n",
      "tensor([[855]]) tensor(776.2443, grad_fn=<SubBackward0>)\n",
      "loss: 0.09211193770170212\n",
      "tensor([[855]]) tensor(779.6251, grad_fn=<SubBackward0>)\n",
      "loss: 0.0881577879190445\n",
      "tensor([[855]]) tensor(779.0406, grad_fn=<SubBackward0>)\n",
      "loss: 0.08884137868881226\n",
      "tensor([[855]]) tensor(781.8137, grad_fn=<SubBackward0>)\n",
      "loss: 0.08559807389974594\n",
      "tensor([[855]]) tensor(778.9229, grad_fn=<SubBackward0>)\n",
      "loss: 0.08897915482521057\n",
      "tensor([[855]]) tensor(784.9761, grad_fn=<SubBackward0>)\n",
      "loss: 0.08189927786588669\n",
      "tensor([[855]]) tensor(777.6235, grad_fn=<SubBackward0>)\n",
      "loss: 0.09049876779317856\n",
      "tensor([[855]]) tensor(775.4229, grad_fn=<SubBackward0>)\n",
      "loss: 0.09307272732257843\n",
      "tensor([[855]]) tensor(777.0388, grad_fn=<SubBackward0>)\n",
      "loss: 0.09118273854255676\n",
      "tensor([[855]]) tensor(770.0662, grad_fn=<SubBackward0>)\n",
      "loss: 0.0993378609418869\n",
      "tensor([[855]]) tensor(774.5262, grad_fn=<SubBackward0>)\n",
      "loss: 0.09412140399217606\n",
      "tensor([[855]]) tensor(764.6157, grad_fn=<SubBackward0>)\n",
      "loss: 0.10571258515119553\n",
      "tensor([[855]]) tensor(764.6160, grad_fn=<SubBackward0>)\n",
      "loss: 0.10571231693029404\n",
      "tensor([[855]]) tensor(781.5579, grad_fn=<SubBackward0>)\n",
      "loss: 0.08589714765548706\n",
      "tensor([[855]]) tensor(750.9182, grad_fn=<SubBackward0>)\n",
      "loss: 0.121733158826828\n",
      "tensor([[855]]) tensor(743.5076, grad_fn=<SubBackward0>)\n",
      "loss: 0.13040044903755188\n",
      "tensor([[855]]) tensor(767.5291, grad_fn=<SubBackward0>)\n",
      "loss: 0.10230523347854614\n",
      "tensor([[855]]) tensor(766.3182, grad_fn=<SubBackward0>)\n",
      "loss: 0.10372138023376465\n",
      "tensor([[855]]) tensor(748.6143, grad_fn=<SubBackward0>)\n",
      "loss: 0.12442776560783386\n",
      "tensor([[855]]) tensor(769.1237, grad_fn=<SubBackward0>)\n",
      "loss: 0.10044015198945999\n",
      "tensor([[855]]) tensor(775.4539, grad_fn=<SubBackward0>)\n",
      "loss: 0.09303639084100723\n",
      "tensor([[855]]) tensor(760.5560, grad_fn=<SubBackward0>)\n",
      "loss: 0.11046081781387329\n",
      "tensor([[855]]) tensor(773.0846, grad_fn=<SubBackward0>)\n",
      "loss: 0.09580749273300171\n",
      "tensor([[855]]) tensor(761.2181, grad_fn=<SubBackward0>)\n",
      "loss: 0.109686478972435\n",
      "tensor([[855]]) tensor(750.8702, grad_fn=<SubBackward0>)\n",
      "loss: 0.12178923189640045\n",
      "tensor([[855]]) tensor(753.9656, grad_fn=<SubBackward0>)\n",
      "loss: 0.11816883087158203\n",
      "tensor([[855]]) tensor(765.2817, grad_fn=<SubBackward0>)\n",
      "loss: 0.10493360459804535\n",
      "tensor([[855]]) tensor(776.8477, grad_fn=<SubBackward0>)\n",
      "loss: 0.09140618145465851\n",
      "tensor([[855]]) tensor(777.6766, grad_fn=<SubBackward0>)\n",
      "loss: 0.09043664485216141\n",
      "tensor([[855]]) tensor(777.3728, grad_fn=<SubBackward0>)\n",
      "loss: 0.09079204499721527\n",
      "tensor([[855]]) tensor(772.3049, grad_fn=<SubBackward0>)\n",
      "loss: 0.09671945124864578\n",
      "tensor([[855]]) tensor(779.9240, grad_fn=<SubBackward0>)\n",
      "loss: 0.08780824393033981\n",
      "tensor([[855]]) tensor(769.7958, grad_fn=<SubBackward0>)\n",
      "loss: 0.09965402632951736\n",
      "tensor([[855]]) tensor(770.7408, grad_fn=<SubBackward0>)\n",
      "loss: 0.09854871779680252\n",
      "tensor([[855]]) tensor(778.8428, grad_fn=<SubBackward0>)\n",
      "loss: 0.08907276391983032\n",
      "tensor([[855]]) tensor(782.8982, grad_fn=<SubBackward0>)\n",
      "loss: 0.08432961255311966\n",
      "tensor([[855]]) tensor(780.7947, grad_fn=<SubBackward0>)\n",
      "loss: 0.08678986877202988\n",
      "tensor([[855]]) tensor(780.9392, grad_fn=<SubBackward0>)\n",
      "loss: 0.0866207703948021\n",
      "tensor([[855]]) tensor(779.0076, grad_fn=<SubBackward0>)\n",
      "loss: 0.0888800397515297\n",
      "tensor([[855]]) tensor(786.7133, grad_fn=<SubBackward0>)\n",
      "loss: 0.07986755669116974\n",
      "tensor([[855]]) tensor(767.5667, grad_fn=<SubBackward0>)\n",
      "loss: 0.10226120799779892\n",
      "tensor([[855]]) tensor(769.4365, grad_fn=<SubBackward0>)\n",
      "loss: 0.10007420927286148\n",
      "tensor([[855]]) tensor(782.2173, grad_fn=<SubBackward0>)\n",
      "loss: 0.08512598276138306\n",
      "tensor([[855]]) tensor(777.8546, grad_fn=<SubBackward0>)\n",
      "loss: 0.09022855758666992\n",
      "tensor([[855]]) tensor(785.1433, grad_fn=<SubBackward0>)\n",
      "loss: 0.08170376718044281\n",
      "tensor([[855]]) tensor(777.3217, grad_fn=<SubBackward0>)\n",
      "loss: 0.09085177630186081\n",
      "tensor([[855]]) tensor(780.2652, grad_fn=<SubBackward0>)\n",
      "loss: 0.0874091237783432\n",
      "tensor([[855]]) tensor(783.9294, grad_fn=<SubBackward0>)\n",
      "loss: 0.08312342315912247\n",
      "tensor([[855]]) tensor(785.0262, grad_fn=<SubBackward0>)\n",
      "loss: 0.08184073865413666\n",
      "tensor([[855]]) tensor(782.3460, grad_fn=<SubBackward0>)\n",
      "loss: 0.08497542887926102\n",
      "tensor([[855]]) tensor(781.5304, grad_fn=<SubBackward0>)\n",
      "loss: 0.08592936396598816\n",
      "tensor([[855]]) tensor(782.8221, grad_fn=<SubBackward0>)\n",
      "loss: 0.0844186320900917\n",
      "tensor([[855]]) tensor(778.3354, grad_fn=<SubBackward0>)\n",
      "loss: 0.08966614305973053\n",
      "tensor([[855]]) tensor(776.6036, grad_fn=<SubBackward0>)\n",
      "loss: 0.09169172495603561\n",
      "tensor([[855]]) tensor(786.0309, grad_fn=<SubBackward0>)\n",
      "loss: 0.08066555857658386\n",
      "tensor([[855]]) tensor(785.4667, grad_fn=<SubBackward0>)\n",
      "loss: 0.08132552355527878\n",
      "tensor([[855]]) tensor(782.4810, grad_fn=<SubBackward0>)\n",
      "loss: 0.08481759577989578\n",
      "tensor([[855]]) tensor(787.1912, grad_fn=<SubBackward0>)\n",
      "loss: 0.07930849492549896\n",
      "tensor([[855]]) tensor(785.6804, grad_fn=<SubBackward0>)\n",
      "loss: 0.08107562363147736\n",
      "tensor([[855]]) tensor(786.3281, grad_fn=<SubBackward0>)\n",
      "loss: 0.08031800389289856\n",
      "tensor([[855]]) tensor(789.2369, grad_fn=<SubBackward0>)\n",
      "loss: 0.0769159346818924\n",
      "tensor([[855]]) tensor(786.9827, grad_fn=<SubBackward0>)\n",
      "loss: 0.07955238223075867\n",
      "tensor([[855]]) tensor(787.6256, grad_fn=<SubBackward0>)\n",
      "loss: 0.07880041748285294\n",
      "tensor([[855]]) tensor(775.5869, grad_fn=<SubBackward0>)\n",
      "loss: 0.09288078546524048\n",
      "tensor([[855]]) tensor(785.6163, grad_fn=<SubBackward0>)\n",
      "loss: 0.08115056157112122\n",
      "tensor([[855]]) tensor(764.1477, grad_fn=<SubBackward0>)\n",
      "loss: 0.1062600314617157\n",
      "tensor([[855]]) tensor(763.6129, grad_fn=<SubBackward0>)\n",
      "loss: 0.10688547790050507\n",
      "tensor([[855]]) tensor(784.4522, grad_fn=<SubBackward0>)\n",
      "loss: 0.0825120359659195\n",
      "tensor([[855]]) tensor(761.7820, grad_fn=<SubBackward0>)\n",
      "loss: 0.10902684926986694\n",
      "tensor([[855]]) tensor(752.9308, grad_fn=<SubBackward0>)\n",
      "loss: 0.11937911063432693\n",
      "tensor([[855]]) tensor(772.0995, grad_fn=<SubBackward0>)\n",
      "loss: 0.09695959091186523\n",
      "tensor([[855]]) tensor(782.1452, grad_fn=<SubBackward0>)\n",
      "loss: 0.08521030843257904\n",
      "tensor([[855]]) tensor(774.6461, grad_fn=<SubBackward0>)\n",
      "loss: 0.09398114681243896\n",
      "tensor([[855]]) tensor(782.2057, grad_fn=<SubBackward0>)\n",
      "loss: 0.08513951301574707\n",
      "tensor([[855]]) tensor(776.0619, grad_fn=<SubBackward0>)\n",
      "loss: 0.09232529252767563\n",
      "tensor([[855]]) tensor(775.4701, grad_fn=<SubBackward0>)\n",
      "loss: 0.09301747381687164\n",
      "tensor([[855]]) tensor(783.1788, grad_fn=<SubBackward0>)\n",
      "loss: 0.08400138467550278\n",
      "tensor([[855]]) tensor(774.3776, grad_fn=<SubBackward0>)\n",
      "loss: 0.09429524838924408\n",
      "tensor([[855]]) tensor(786.7708, grad_fn=<SubBackward0>)\n",
      "loss: 0.07980021834373474\n",
      "tensor([[855]]) tensor(775.7163, grad_fn=<SubBackward0>)\n",
      "loss: 0.09272947907447815\n",
      "tensor([[855]]) tensor(776.7914, grad_fn=<SubBackward0>)\n",
      "loss: 0.09147210419178009\n",
      "tensor([[855]]) tensor(788.9877, grad_fn=<SubBackward0>)\n",
      "loss: 0.07720733433961868\n",
      "tensor([[855]]) tensor(755.3508, grad_fn=<SubBackward0>)\n",
      "loss: 0.11654873937368393\n",
      "tensor([[855]]) tensor(752.8725, grad_fn=<SubBackward0>)\n",
      "loss: 0.11944738775491714\n",
      "tensor([[855]]) tensor(778.8134, grad_fn=<SubBackward0>)\n",
      "loss: 0.0891072228550911\n",
      "tensor([[855]]) tensor(762.1880, grad_fn=<SubBackward0>)\n",
      "loss: 0.1085520088672638\n",
      "tensor([[855]]) tensor(746.8701, grad_fn=<SubBackward0>)\n",
      "loss: 0.12646766006946564\n",
      "tensor([[855]]) tensor(760.8263, grad_fn=<SubBackward0>)\n",
      "loss: 0.11014468222856522\n",
      "tensor([[855]]) tensor(785.2584, grad_fn=<SubBackward0>)\n",
      "loss: 0.08156915009021759\n",
      "tensor([[855]]) tensor(751.7798, grad_fn=<SubBackward0>)\n",
      "loss: 0.12072543054819107\n",
      "tensor([[855]]) tensor(736.0853, grad_fn=<SubBackward0>)\n",
      "loss: 0.13908149302005768\n",
      "tensor([[855]]) tensor(748.3837, grad_fn=<SubBackward0>)\n",
      "loss: 0.12469737976789474\n",
      "tensor([[855]]) tensor(776.1058, grad_fn=<SubBackward0>)\n",
      "loss: 0.09227387607097626\n",
      "tensor([[855]]) tensor(762.3563, grad_fn=<SubBackward0>)\n",
      "loss: 0.10835526883602142\n",
      "tensor([[855]]) tensor(759.3167, grad_fn=<SubBackward0>)\n",
      "loss: 0.11191026121377945\n",
      "tensor([[855]]) tensor(767.4297, grad_fn=<SubBackward0>)\n",
      "loss: 0.10242145508527756\n",
      "tensor([[855]]) tensor(778.8590, grad_fn=<SubBackward0>)\n",
      "loss: 0.08905378729104996\n",
      "tensor([[855]]) tensor(758.3051, grad_fn=<SubBackward0>)\n",
      "loss: 0.11309346556663513\n",
      "tensor([[855]]) tensor(750.9387, grad_fn=<SubBackward0>)\n",
      "loss: 0.12170916795730591\n",
      "tensor([[855]]) tensor(772.1300, grad_fn=<SubBackward0>)\n",
      "loss: 0.09692400693893433\n",
      "tensor([[855]]) tensor(767.2367, grad_fn=<SubBackward0>)\n",
      "loss: 0.10264710336923599\n",
      "tensor([[855]]) tensor(752.5009, grad_fn=<SubBackward0>)\n",
      "loss: 0.11988197267055511\n",
      "tensor([[855]]) tensor(757.9435, grad_fn=<SubBackward0>)\n",
      "loss: 0.11351632326841354\n",
      "tensor([[855]]) tensor(780.0092, grad_fn=<SubBackward0>)\n",
      "loss: 0.08770859241485596\n",
      "tensor([[855]]) tensor(780.2955, grad_fn=<SubBackward0>)\n",
      "loss: 0.08737364411354065\n",
      "tensor([[855]]) tensor(779.2634, grad_fn=<SubBackward0>)\n",
      "loss: 0.08858085423707962\n",
      "tensor([[855]]) tensor(773.1280, grad_fn=<SubBackward0>)\n",
      "loss: 0.09575675427913666\n",
      "tensor([[855]]) tensor(777.2797, grad_fn=<SubBackward0>)\n",
      "loss: 0.09090101718902588\n",
      "tensor([[855]]) tensor(783.2021, grad_fn=<SubBackward0>)\n",
      "loss: 0.08397411555051804\n",
      "tensor([[855]]) tensor(775.9274, grad_fn=<SubBackward0>)\n",
      "loss: 0.09248258918523788\n",
      "tensor([[855]]) tensor(776.1709, grad_fn=<SubBackward0>)\n",
      "loss: 0.09219774603843689\n",
      "tensor([[855]]) tensor(782.9960, grad_fn=<SubBackward0>)\n",
      "loss: 0.08421523869037628\n",
      "tensor([[855]]) tensor(780.4753, grad_fn=<SubBackward0>)\n",
      "loss: 0.08716341108083725\n",
      "tensor([[855]]) tensor(783.8860, grad_fn=<SubBackward0>)\n",
      "loss: 0.0831741988658905\n",
      "tensor([[855]]) tensor(784.4951, grad_fn=<SubBackward0>)\n",
      "loss: 0.08246183395385742\n",
      "tensor([[855]]) tensor(778.0362, grad_fn=<SubBackward0>)\n",
      "loss: 0.09001614898443222\n",
      "tensor([[855]]) tensor(783.5316, grad_fn=<SubBackward0>)\n",
      "loss: 0.08358871936798096\n",
      "tensor([[855]]) tensor(774.6588, grad_fn=<SubBackward0>)\n",
      "loss: 0.09396633505821228\n",
      "tensor([[855]]) tensor(787.5067, grad_fn=<SubBackward0>)\n",
      "loss: 0.0789395123720169\n",
      "tensor([[855]]) tensor(784.4381, grad_fn=<SubBackward0>)\n",
      "loss: 0.08252856135368347\n",
      "tensor([[855]]) tensor(786.8710, grad_fn=<SubBackward0>)\n",
      "loss: 0.0796830952167511\n",
      "tensor([[855]]) tensor(785.9470, grad_fn=<SubBackward0>)\n",
      "loss: 0.08076371997594833\n",
      "tensor([[855]]) tensor(790.2418, grad_fn=<SubBackward0>)\n",
      "loss: 0.07574056088924408\n",
      "tensor([[855]]) tensor(788.4667, grad_fn=<SubBackward0>)\n",
      "loss: 0.07781675457954407\n",
      "tensor([[855]]) tensor(788.6874, grad_fn=<SubBackward0>)\n",
      "loss: 0.07755862176418304\n",
      "tensor([[855]]) tensor(790.9529, grad_fn=<SubBackward0>)\n",
      "loss: 0.07490887492895126\n",
      "tensor([[855]]) tensor(789.2866, grad_fn=<SubBackward0>)\n",
      "loss: 0.07685782760381699\n",
      "tensor([[855]]) tensor(784.0212, grad_fn=<SubBackward0>)\n",
      "loss: 0.08301616460084915\n",
      "tensor([[855]]) tensor(786.6579, grad_fn=<SubBackward0>)\n",
      "loss: 0.07993226498365402\n",
      "tensor([[855]]) tensor(788.7274, grad_fn=<SubBackward0>)\n",
      "loss: 0.07751186192035675\n",
      "tensor([[855]]) tensor(784.1235, grad_fn=<SubBackward0>)\n",
      "loss: 0.0828964114189148\n",
      "tensor([[855]]) tensor(791.2209, grad_fn=<SubBackward0>)\n",
      "loss: 0.07459543645381927\n",
      "tensor([[855]]) tensor(794.0966, grad_fn=<SubBackward0>)\n",
      "loss: 0.0712321326136589\n",
      "tensor([[855]]) tensor(794.4034, grad_fn=<SubBackward0>)\n",
      "loss: 0.0708732008934021\n",
      "tensor([[855]]) tensor(787.0746, grad_fn=<SubBackward0>)\n",
      "loss: 0.07944484055042267\n",
      "tensor([[855]]) tensor(792.7897, grad_fn=<SubBackward0>)\n",
      "loss: 0.07276058197021484\n",
      "tensor([[855]]) tensor(781.6241, grad_fn=<SubBackward0>)\n",
      "loss: 0.08581976592540741\n",
      "tensor([[855]]) tensor(787.6248, grad_fn=<SubBackward0>)\n",
      "loss: 0.07880138605833054\n",
      "tensor([[855]]) tensor(781.4342, grad_fn=<SubBackward0>)\n",
      "loss: 0.0860419049859047\n",
      "tensor([[855]]) tensor(779.8331, grad_fn=<SubBackward0>)\n",
      "loss: 0.08791450411081314\n",
      "tensor([[855]]) tensor(793.0721, grad_fn=<SubBackward0>)\n",
      "loss: 0.07243027538061142\n",
      "tensor([[855]]) tensor(792.1505, grad_fn=<SubBackward0>)\n",
      "loss: 0.07350821048021317\n",
      "tensor([[855]]) tensor(790.0121, grad_fn=<SubBackward0>)\n",
      "loss: 0.07600925862789154\n",
      "tensor([[855]]) tensor(791.2751, grad_fn=<SubBackward0>)\n",
      "loss: 0.07453206181526184\n",
      "tensor([[855]]) tensor(792.2148, grad_fn=<SubBackward0>)\n",
      "loss: 0.07343295216560364\n",
      "tensor([[855]]) tensor(794.2417, grad_fn=<SubBackward0>)\n",
      "loss: 0.07106234133243561\n",
      "tensor([[855]]) tensor(794.7729, grad_fn=<SubBackward0>)\n",
      "loss: 0.07044105231761932\n",
      "tensor([[855]]) tensor(792.6342, grad_fn=<SubBackward0>)\n",
      "loss: 0.07294247299432755\n",
      "tensor([[855]]) tensor(783.7348, grad_fn=<SubBackward0>)\n",
      "loss: 0.08335110545158386\n",
      "tensor([[855]]) tensor(792.9896, grad_fn=<SubBackward0>)\n",
      "loss: 0.07252682745456696\n",
      "tensor([[855]]) tensor(783.9586, grad_fn=<SubBackward0>)\n",
      "loss: 0.0830894261598587\n",
      "tensor([[855]]) tensor(794.4285, grad_fn=<SubBackward0>)\n",
      "loss: 0.0708438977599144\n",
      "tensor([[855]]) tensor(791.3237, grad_fn=<SubBackward0>)\n",
      "loss: 0.0744752436876297\n",
      "tensor([[855]]) tensor(793.1520, grad_fn=<SubBackward0>)\n",
      "loss: 0.07233677804470062\n",
      "tensor([[855]]) tensor(794.1643, grad_fn=<SubBackward0>)\n",
      "loss: 0.07115282118320465\n",
      "tensor([[855]]) tensor(786.8761, grad_fn=<SubBackward0>)\n",
      "loss: 0.0796770453453064\n",
      "tensor([[855]]) tensor(795.1383, grad_fn=<SubBackward0>)\n",
      "loss: 0.07001364231109619\n",
      "tensor([[855]]) tensor(792.2212, grad_fn=<SubBackward0>)\n",
      "loss: 0.07342550903558731\n",
      "tensor([[855]]) tensor(784.9204, grad_fn=<SubBackward0>)\n",
      "loss: 0.08196444809436798\n",
      "tensor([[855]]) tensor(794.2149, grad_fn=<SubBackward0>)\n",
      "loss: 0.07109369337558746\n",
      "tensor([[855]]) tensor(783.0204, grad_fn=<SubBackward0>)\n",
      "loss: 0.08418665081262589\n",
      "tensor([[855]]) tensor(790.0461, grad_fn=<SubBackward0>)\n",
      "loss: 0.07596942037343979\n",
      "tensor([[855]]) tensor(781.2244, grad_fn=<SubBackward0>)\n",
      "loss: 0.08628722280263901\n",
      "tensor([[855]]) tensor(782.3071, grad_fn=<SubBackward0>)\n",
      "loss: 0.08502086251974106\n",
      "tensor([[855]]) tensor(785.8444, grad_fn=<SubBackward0>)\n",
      "loss: 0.08088382333517075\n",
      "tensor([[855]]) tensor(782.1093, grad_fn=<SubBackward0>)\n",
      "loss: 0.08525237441062927\n",
      "tensor([[855]]) tensor(784.5305, grad_fn=<SubBackward0>)\n",
      "loss: 0.08242053538560867\n",
      "tensor([[855]]) tensor(789.8017, grad_fn=<SubBackward0>)\n",
      "loss: 0.07625530660152435\n",
      "tensor([[855]]) tensor(786.0498, grad_fn=<SubBackward0>)\n",
      "loss: 0.08064346760511398\n",
      "tensor([[855]]) tensor(788.4795, grad_fn=<SubBackward0>)\n",
      "loss: 0.07780180126428604\n",
      "tensor([[855]]) tensor(788.4726, grad_fn=<SubBackward0>)\n",
      "loss: 0.07780983299016953\n",
      "tensor([[855]]) tensor(791.6646, grad_fn=<SubBackward0>)\n",
      "loss: 0.0740765854716301\n",
      "tensor([[855]]) tensor(795.1081, grad_fn=<SubBackward0>)\n",
      "loss: 0.07004901021718979\n",
      "tensor([[855]]) tensor(786.2421, grad_fn=<SubBackward0>)\n",
      "loss: 0.0804186761379242\n",
      "tensor([[855]]) tensor(795.8649, grad_fn=<SubBackward0>)\n",
      "loss: 0.06916388124227524\n",
      "tensor([[855]]) tensor(793.1516, grad_fn=<SubBackward0>)\n",
      "loss: 0.07233729958534241\n",
      "tensor([[855]]) tensor(792.2635, grad_fn=<SubBackward0>)\n",
      "loss: 0.07337605208158493\n",
      "tensor([[855]]) tensor(796.1796, grad_fn=<SubBackward0>)\n",
      "loss: 0.06879575550556183\n",
      "tensor([[855]]) tensor(788.5379, grad_fn=<SubBackward0>)\n",
      "loss: 0.07773344963788986\n",
      "tensor([[855]]) tensor(789.0084, grad_fn=<SubBackward0>)\n",
      "loss: 0.07718314975500107\n",
      "tensor([[855]]) tensor(790.0441, grad_fn=<SubBackward0>)\n",
      "loss: 0.07597178220748901\n",
      "tensor([[855]]) tensor(792.2025, grad_fn=<SubBackward0>)\n",
      "loss: 0.0734473168849945\n",
      "tensor([[855]]) tensor(796.1403, grad_fn=<SubBackward0>)\n",
      "loss: 0.06884173303842545\n",
      "tensor([[855]]) tensor(796.2094, grad_fn=<SubBackward0>)\n",
      "loss: 0.06876101344823837\n",
      "tensor([[855]]) tensor(792.8129, grad_fn=<SubBackward0>)\n",
      "loss: 0.07273349165916443\n",
      "tensor([[855]]) tensor(796.8285, grad_fn=<SubBackward0>)\n",
      "loss: 0.06803689152002335\n",
      "tensor([[855]]) tensor(785.1711, grad_fn=<SubBackward0>)\n",
      "loss: 0.08167125284671783\n",
      "tensor([[855]]) tensor(791.1233, grad_fn=<SubBackward0>)\n",
      "loss: 0.07470956444740295\n",
      "tensor([[855]]) tensor(786.3182, grad_fn=<SubBackward0>)\n",
      "loss: 0.08032956719398499\n",
      "tensor([[855]]) tensor(790.7125, grad_fn=<SubBackward0>)\n",
      "loss: 0.0751899927854538\n",
      "tensor([[855]]) tensor(786.2356, grad_fn=<SubBackward0>)\n",
      "loss: 0.08042620122432709\n",
      "tensor([[855]]) tensor(787.8716, grad_fn=<SubBackward0>)\n",
      "loss: 0.0785127729177475\n",
      "tensor([[855]]) tensor(785.3116, grad_fn=<SubBackward0>)\n",
      "loss: 0.0815068855881691\n",
      "tensor([[855]]) tensor(781.6025, grad_fn=<SubBackward0>)\n",
      "loss: 0.08584500104188919\n",
      "tensor([[855]]) tensor(792.8502, grad_fn=<SubBackward0>)\n",
      "loss: 0.07268983870744705\n",
      "tensor([[855]]) tensor(774.1981, grad_fn=<SubBackward0>)\n",
      "loss: 0.09450512379407883\n",
      "tensor([[855]]) tensor(771.6696, grad_fn=<SubBackward0>)\n",
      "loss: 0.09746243804693222\n",
      "tensor([[855]]) tensor(796.0298, grad_fn=<SubBackward0>)\n",
      "loss: 0.06897097826004028\n",
      "tensor([[855]]) tensor(787.8379, grad_fn=<SubBackward0>)\n",
      "loss: 0.07855220884084702\n",
      "tensor([[855]]) tensor(790.0948, grad_fn=<SubBackward0>)\n",
      "loss: 0.0759124606847763\n",
      "tensor([[855]]) tensor(795.8818, grad_fn=<SubBackward0>)\n",
      "loss: 0.06914408504962921\n",
      "tensor([[855]]) tensor(791.7016, grad_fn=<SubBackward0>)\n",
      "loss: 0.07403320074081421\n",
      "tensor([[855]]) tensor(793.0469, grad_fn=<SubBackward0>)\n",
      "loss: 0.07245983183383942\n",
      "tensor([[855]]) tensor(792.6215, grad_fn=<SubBackward0>)\n",
      "loss: 0.07295737415552139\n",
      "tensor([[855]]) tensor(796.0713, grad_fn=<SubBackward0>)\n",
      "loss: 0.0689225047826767\n",
      "tensor([[855]]) tensor(796.9547, grad_fn=<SubBackward0>)\n",
      "loss: 0.0678892582654953\n",
      "tensor([[855]]) tensor(798.4315, grad_fn=<SubBackward0>)\n",
      "loss: 0.06616196781396866\n",
      "tensor([[855]]) tensor(790.9761, grad_fn=<SubBackward0>)\n",
      "loss: 0.07488171011209488\n",
      "tensor([[855]]) tensor(799.0283, grad_fn=<SubBackward0>)\n",
      "loss: 0.06546391546726227\n",
      "tensor([[855]]) tensor(795.1804, grad_fn=<SubBackward0>)\n",
      "loss: 0.06996447592973709\n",
      "tensor([[855]]) tensor(794.2281, grad_fn=<SubBackward0>)\n",
      "loss: 0.07107820361852646\n",
      "tensor([[855]]) tensor(792.6427, grad_fn=<SubBackward0>)\n",
      "loss: 0.07293248176574707\n",
      "tensor([[855]]) tensor(797.8428, grad_fn=<SubBackward0>)\n",
      "loss: 0.06685050576925278\n",
      "tensor([[855]]) tensor(794.1819, grad_fn=<SubBackward0>)\n",
      "loss: 0.07113222777843475\n",
      "tensor([[855]]) tensor(792.3612, grad_fn=<SubBackward0>)\n",
      "loss: 0.07326170802116394\n",
      "tensor([[855]]) tensor(795.8361, grad_fn=<SubBackward0>)\n",
      "loss: 0.06919752061367035\n",
      "tensor([[855]]) tensor(789.6503, grad_fn=<SubBackward0>)\n",
      "loss: 0.07643246650695801\n",
      "tensor([[855]]) tensor(793.6241, grad_fn=<SubBackward0>)\n",
      "loss: 0.0717846229672432\n",
      "tensor([[855]]) tensor(790.3143, grad_fn=<SubBackward0>)\n",
      "loss: 0.07565582543611526\n",
      "tensor([[855]]) tensor(792.6442, grad_fn=<SubBackward0>)\n",
      "loss: 0.07293079793453217\n",
      "tensor([[855]]) tensor(789.3117, grad_fn=<SubBackward0>)\n",
      "loss: 0.07682841271162033\n",
      "tensor([[855]]) tensor(795.1897, grad_fn=<SubBackward0>)\n",
      "loss: 0.0699535384774208\n",
      "tensor([[855]]) tensor(785.4576, grad_fn=<SubBackward0>)\n",
      "loss: 0.08133608847856522\n",
      "tensor([[855]]) tensor(781.7935, grad_fn=<SubBackward0>)\n",
      "loss: 0.08562172204256058\n",
      "tensor([[855]]) tensor(798.6903, grad_fn=<SubBackward0>)\n",
      "loss: 0.06585928797721863\n",
      "tensor([[855]]) tensor(774.3069, grad_fn=<SubBackward0>)\n",
      "loss: 0.09437791258096695\n",
      "tensor([[855]]) tensor(770.5609, grad_fn=<SubBackward0>)\n",
      "loss: 0.09875912964344025\n",
      "tensor([[855]]) tensor(794.3461, grad_fn=<SubBackward0>)\n",
      "loss: 0.07094019651412964\n",
      "tensor([[855]]) tensor(768.3834, grad_fn=<SubBackward0>)\n",
      "loss: 0.10130590200424194\n",
      "tensor([[855]]) tensor(765.7977, grad_fn=<SubBackward0>)\n",
      "loss: 0.10433019697666168\n",
      "tensor([[855]]) tensor(781.3201, grad_fn=<SubBackward0>)\n",
      "loss: 0.08617532253265381\n",
      "tensor([[855]]) tensor(794.6935, grad_fn=<SubBackward0>)\n",
      "loss: 0.0705338716506958\n",
      "tensor([[855]]) tensor(771.3398, grad_fn=<SubBackward0>)\n",
      "loss: 0.09784820675849915\n",
      "tensor([[855]]) tensor(771.3502, grad_fn=<SubBackward0>)\n",
      "loss: 0.09783606976270676\n",
      "tensor([[855]]) tensor(794.5192, grad_fn=<SubBackward0>)\n",
      "loss: 0.07073774933815002\n",
      "tensor([[855]]) tensor(785.9935, grad_fn=<SubBackward0>)\n",
      "loss: 0.08070939034223557\n",
      "tensor([[855]]) tensor(787.2368, grad_fn=<SubBackward0>)\n",
      "loss: 0.07925514876842499\n",
      "tensor([[855]]) tensor(792.2936, grad_fn=<SubBackward0>)\n",
      "loss: 0.0733407512307167\n",
      "tensor([[855]]) tensor(789.9681, grad_fn=<SubBackward0>)\n",
      "loss: 0.07606074213981628\n",
      "tensor([[855]]) tensor(791.6006, grad_fn=<SubBackward0>)\n",
      "loss: 0.07415132224559784\n",
      "tensor([[855]]) tensor(787.6406, grad_fn=<SubBackward0>)\n",
      "loss: 0.07878289371728897\n",
      "tensor([[855]]) tensor(786.1337, grad_fn=<SubBackward0>)\n",
      "loss: 0.08054541796445847\n",
      "tensor([[855]]) tensor(797.8311, grad_fn=<SubBackward0>)\n",
      "loss: 0.06686422973871231\n",
      "tensor([[855]]) tensor(778.5623, grad_fn=<SubBackward0>)\n",
      "loss: 0.08940088748931885\n",
      "tensor([[855]]) tensor(776.7344, grad_fn=<SubBackward0>)\n",
      "loss: 0.09153875708580017\n",
      "tensor([[855]]) tensor(794.0624, grad_fn=<SubBackward0>)\n",
      "loss: 0.07127209007740021\n",
      "tensor([[855]]) tensor(778.2086, grad_fn=<SubBackward0>)\n",
      "loss: 0.08981457352638245\n",
      "tensor([[855]]) tensor(777.1310, grad_fn=<SubBackward0>)\n",
      "loss: 0.09107483923435211\n",
      "tensor([[855]]) tensor(794.7268, grad_fn=<SubBackward0>)\n",
      "loss: 0.07049500197172165\n",
      "tensor([[855]]) tensor(769.2324, grad_fn=<SubBackward0>)\n",
      "loss: 0.10031291842460632\n",
      "tensor([[855]]) tensor(761.4214, grad_fn=<SubBackward0>)\n",
      "loss: 0.1094486340880394\n",
      "tensor([[855]]) tensor(780.5256, grad_fn=<SubBackward0>)\n",
      "loss: 0.08710457384586334\n",
      "tensor([[855]]) tensor(789.5018, grad_fn=<SubBackward0>)\n",
      "loss: 0.07660606503486633\n",
      "tensor([[855]]) tensor(775.7915, grad_fn=<SubBackward0>)\n",
      "loss: 0.09264148026704788\n",
      "tensor([[855]]) tensor(785.1810, grad_fn=<SubBackward0>)\n",
      "loss: 0.08165957778692245\n",
      "tensor([[855]]) tensor(793.9380, grad_fn=<SubBackward0>)\n",
      "loss: 0.07141752541065216\n",
      "tensor([[855]]) tensor(781.2094, grad_fn=<SubBackward0>)\n",
      "loss: 0.08630485087633133\n",
      "tensor([[855]]) tensor(793.4523, grad_fn=<SubBackward0>)\n",
      "loss: 0.07198558002710342\n",
      "tensor([[855]]) tensor(791.2639, grad_fn=<SubBackward0>)\n",
      "loss: 0.07454514503479004\n",
      "tensor([[855]]) tensor(790.3143, grad_fn=<SubBackward0>)\n",
      "loss: 0.07565577328205109\n",
      "tensor([[855]]) tensor(791.1726, grad_fn=<SubBackward0>)\n",
      "loss: 0.07465188205242157\n",
      "tensor([[855]]) tensor(788.7256, grad_fn=<SubBackward0>)\n",
      "loss: 0.07751397043466568\n",
      "tensor([[855]]) tensor(791.4147, grad_fn=<SubBackward0>)\n",
      "loss: 0.07436876744031906\n",
      "tensor([[855]]) tensor(791.3150, grad_fn=<SubBackward0>)\n",
      "loss: 0.07448537647724152\n",
      "tensor([[855]]) tensor(788.0624, grad_fn=<SubBackward0>)\n",
      "loss: 0.07828958332538605\n",
      "tensor([[855]]) tensor(792.2952, grad_fn=<SubBackward0>)\n",
      "loss: 0.07333894819021225\n",
      "tensor([[855]]) tensor(795.5450, grad_fn=<SubBackward0>)\n",
      "loss: 0.06953801214694977\n",
      "tensor([[855]]) tensor(794.4789, grad_fn=<SubBackward0>)\n",
      "loss: 0.07078497111797333\n",
      "tensor([[855]]) tensor(796.6084, grad_fn=<SubBackward0>)\n",
      "loss: 0.0682942345738411\n",
      "tensor([[855]]) tensor(794.8387, grad_fn=<SubBackward0>)\n",
      "loss: 0.0703640729188919\n",
      "tensor([[855]]) tensor(793.2749, grad_fn=<SubBackward0>)\n",
      "loss: 0.07219313085079193\n",
      "tensor([[855]]) tensor(797.6930, grad_fn=<SubBackward0>)\n",
      "loss: 0.06702577322721481\n",
      "tensor([[855]]) tensor(793.5875, grad_fn=<SubBackward0>)\n",
      "loss: 0.0718274936079979\n",
      "tensor([[855]]) tensor(795.8771, grad_fn=<SubBackward0>)\n",
      "loss: 0.06914958357810974\n",
      "tensor([[855]]) tensor(796.5049, grad_fn=<SubBackward0>)\n",
      "loss: 0.06841530650854111\n",
      "tensor([[855]]) tensor(789.3119, grad_fn=<SubBackward0>)\n",
      "loss: 0.07682819664478302\n",
      "tensor([[855]]) tensor(792.5957, grad_fn=<SubBackward0>)\n",
      "loss: 0.07298748195171356\n",
      "tensor([[855]]) tensor(786.0281, grad_fn=<SubBackward0>)\n",
      "loss: 0.08066888153553009\n",
      "tensor([[855]]) tensor(793.0826, grad_fn=<SubBackward0>)\n",
      "loss: 0.0724179819226265\n",
      "tensor([[855]]) tensor(800.9183, grad_fn=<SubBackward0>)\n",
      "loss: 0.06325337290763855\n",
      "tensor([[855]]) tensor(794.6143, grad_fn=<SubBackward0>)\n",
      "loss: 0.07062661647796631\n",
      "tensor([[855]]) tensor(798.7972, grad_fn=<SubBackward0>)\n",
      "loss: 0.06573428958654404\n",
      "tensor([[855]]) tensor(796.9819, grad_fn=<SubBackward0>)\n",
      "loss: 0.06785738468170166\n",
      "tensor([[855]]) tensor(799.9000, grad_fn=<SubBackward0>)\n",
      "loss: 0.06444448977708817\n",
      "tensor([[855]]) tensor(783.5300, grad_fn=<SubBackward0>)\n",
      "loss: 0.08359070122241974\n",
      "tensor([[855]]) tensor(786.1559, grad_fn=<SubBackward0>)\n",
      "loss: 0.08051936328411102\n",
      "tensor([[855]]) tensor(792.2913, grad_fn=<SubBackward0>)\n",
      "loss: 0.07334355264902115\n",
      "tensor([[855]]) tensor(798.7806, grad_fn=<SubBackward0>)\n",
      "loss: 0.06575370579957962\n",
      "tensor([[855]]) tensor(789.3975, grad_fn=<SubBackward0>)\n",
      "loss: 0.07672809809446335\n",
      "tensor([[855]]) tensor(792.8370, grad_fn=<SubBackward0>)\n",
      "loss: 0.07270518690347672\n",
      "tensor([[855]]) tensor(791.7611, grad_fn=<SubBackward0>)\n",
      "loss: 0.07396361231803894\n",
      "tensor([[855]]) tensor(785.6616, grad_fn=<SubBackward0>)\n",
      "loss: 0.08109752088785172\n",
      "tensor([[855]]) tensor(794.4658, grad_fn=<SubBackward0>)\n",
      "loss: 0.07080017775297165\n",
      "tensor([[855]]) tensor(794.3350, grad_fn=<SubBackward0>)\n",
      "loss: 0.07095319032669067\n",
      "tensor([[855]]) tensor(794.8447, grad_fn=<SubBackward0>)\n",
      "loss: 0.07035704702138901\n",
      "tensor([[855]]) tensor(789.2350, grad_fn=<SubBackward0>)\n",
      "loss: 0.07691807299852371\n",
      "tensor([[855]]) tensor(785.4792, grad_fn=<SubBackward0>)\n",
      "loss: 0.08131082355976105\n",
      "tensor([[855]]) tensor(795.9767, grad_fn=<SubBackward0>)\n",
      "loss: 0.06903307884931564\n",
      "tensor([[855]]) tensor(792.6227, grad_fn=<SubBackward0>)\n",
      "loss: 0.07295592874288559\n",
      "tensor([[855]]) tensor(794.9897, grad_fn=<SubBackward0>)\n",
      "loss: 0.07018744945526123\n",
      "tensor([[855]]) tensor(792.8801, grad_fn=<SubBackward0>)\n",
      "loss: 0.07265489548444748\n",
      "tensor([[855]]) tensor(784.7584, grad_fn=<SubBackward0>)\n",
      "loss: 0.08215385675430298\n",
      "tensor([[855]]) tensor(800.2952, grad_fn=<SubBackward0>)\n",
      "loss: 0.06398230046033859\n",
      "tensor([[855]]) tensor(776.9023, grad_fn=<SubBackward0>)\n",
      "loss: 0.09134230762720108\n",
      "tensor([[855]]) tensor(769.3973, grad_fn=<SubBackward0>)\n",
      "loss: 0.10012014210224152\n",
      "tensor([[855]]) tensor(791.5948, grad_fn=<SubBackward0>)\n",
      "loss: 0.07415816187858582\n",
      "tensor([[855]]) tensor(779.1166, grad_fn=<SubBackward0>)\n",
      "loss: 0.08875247091054916\n",
      "tensor([[855]]) tensor(763.7505, grad_fn=<SubBackward0>)\n",
      "loss: 0.10672453790903091\n",
      "tensor([[855]]) tensor(775.3582, grad_fn=<SubBackward0>)\n",
      "loss: 0.09314834326505661\n",
      "tensor([[855]]) tensor(799.0404, grad_fn=<SubBackward0>)\n",
      "loss: 0.06544983386993408\n",
      "tensor([[855]]) tensor(771.0947, grad_fn=<SubBackward0>)\n",
      "loss: 0.09813482314348221\n",
      "tensor([[855]]) tensor(757.8943, grad_fn=<SubBackward0>)\n",
      "loss: 0.11357387900352478\n",
      "tensor([[855]]) tensor(774.3064, grad_fn=<SubBackward0>)\n",
      "loss: 0.09437848627567291\n",
      "tensor([[855]]) tensor(796.6904, grad_fn=<SubBackward0>)\n",
      "loss: 0.06819839775562286\n",
      "tensor([[855]]) tensor(785.1802, grad_fn=<SubBackward0>)\n",
      "loss: 0.08166056126356125\n",
      "tensor([[855]]) tensor(792.5806, grad_fn=<SubBackward0>)\n",
      "loss: 0.07300520688295364\n",
      "tensor([[855]]) tensor(799.6562, grad_fn=<SubBackward0>)\n",
      "loss: 0.06472957134246826\n",
      "tensor([[855]]) tensor(792.3121, grad_fn=<SubBackward0>)\n",
      "loss: 0.07331917434930801\n",
      "tensor([[855]]) tensor(794.2062, grad_fn=<SubBackward0>)\n",
      "loss: 0.07110384851694107\n",
      "tensor([[855]]) tensor(803.5264, grad_fn=<SubBackward0>)\n",
      "loss: 0.06020309776067734\n",
      "tensor([[855]]) tensor(790.8815, grad_fn=<SubBackward0>)\n",
      "loss: 0.07499241828918457\n",
      "tensor([[855]]) tensor(788.7030, grad_fn=<SubBackward0>)\n",
      "loss: 0.0775403082370758\n",
      "tensor([[855]]) tensor(800.9124, grad_fn=<SubBackward0>)\n",
      "loss: 0.06326044350862503\n",
      "tensor([[855]]) tensor(783.8378, grad_fn=<SubBackward0>)\n",
      "loss: 0.0832306444644928\n",
      "tensor([[855]]) tensor(791.0732, grad_fn=<SubBackward0>)\n",
      "loss: 0.07476814091205597\n",
      "tensor([[855]]) tensor(794.8925, grad_fn=<SubBackward0>)\n",
      "loss: 0.07030125707387924\n",
      "tensor([[855]]) tensor(791.0935, grad_fn=<SubBackward0>)\n",
      "loss: 0.07474447041749954\n",
      "tensor([[855]]) tensor(800.9138, grad_fn=<SubBackward0>)\n",
      "loss: 0.06325872987508774\n",
      "tensor([[855]]) tensor(781.5176, grad_fn=<SubBackward0>)\n",
      "loss: 0.08594436943531036\n",
      "tensor([[855]]) tensor(783.5371, grad_fn=<SubBackward0>)\n",
      "loss: 0.0835823267698288\n",
      "tensor([[855]]) tensor(800.1667, grad_fn=<SubBackward0>)\n",
      "loss: 0.064132459461689\n",
      "tensor([[855]]) tensor(784.8897, grad_fn=<SubBackward0>)\n",
      "loss: 0.08200033754110336\n",
      "tensor([[855]]) tensor(784.3422, grad_fn=<SubBackward0>)\n",
      "loss: 0.08264078199863434\n",
      "tensor([[855]]) tensor(797.9971, grad_fn=<SubBackward0>)\n",
      "loss: 0.0666700005531311\n",
      "tensor([[855]]) tensor(788.6191, grad_fn=<SubBackward0>)\n",
      "loss: 0.07763844728469849\n",
      "tensor([[855]]) tensor(785.2629, grad_fn=<SubBackward0>)\n",
      "loss: 0.08156383037567139\n",
      "tensor([[855]]) tensor(799.9702, grad_fn=<SubBackward0>)\n",
      "loss: 0.0643622875213623\n",
      "tensor([[855]]) tensor(794.0249, grad_fn=<SubBackward0>)\n",
      "loss: 0.07131586968898773\n",
      "tensor([[855]]) tensor(793.1574, grad_fn=<SubBackward0>)\n",
      "loss: 0.07233049720525742\n",
      "tensor([[855]]) tensor(802.3165, grad_fn=<SubBackward0>)\n",
      "loss: 0.0616181306540966\n",
      "tensor([[855]]) tensor(791.1088, grad_fn=<SubBackward0>)\n",
      "loss: 0.07472655177116394\n",
      "tensor([[855]]) tensor(792.7334, grad_fn=<SubBackward0>)\n",
      "loss: 0.07282641530036926\n",
      "tensor([[855]]) tensor(802.2811, grad_fn=<SubBackward0>)\n",
      "loss: 0.06165948137640953\n",
      "tensor([[855]]) tensor(785.2001, grad_fn=<SubBackward0>)\n",
      "loss: 0.08163730800151825\n",
      "tensor([[855]]) tensor(795.5994, grad_fn=<SubBackward0>)\n",
      "loss: 0.06947435438632965\n",
      "tensor([[855]]) tensor(794.5439, grad_fn=<SubBackward0>)\n",
      "loss: 0.07070880383253098\n",
      "tensor([[855]]) tensor(782.8202, grad_fn=<SubBackward0>)\n",
      "loss: 0.0844208151102066\n",
      "tensor([[855]]) tensor(796.1652, grad_fn=<SubBackward0>)\n",
      "loss: 0.06881263852119446\n",
      "tensor([[855]]) tensor(800.5164, grad_fn=<SubBackward0>)\n",
      "loss: 0.06372351944446564\n",
      "tensor([[855]]) tensor(797.6653, grad_fn=<SubBackward0>)\n",
      "loss: 0.06705814599990845\n",
      "tensor([[855]]) tensor(802.2281, grad_fn=<SubBackward0>)\n",
      "loss: 0.061721500009298325\n",
      "tensor([[855]]) tensor(799.7291, grad_fn=<SubBackward0>)\n",
      "loss: 0.06464435160160065\n",
      "tensor([[855]]) tensor(802.0323, grad_fn=<SubBackward0>)\n",
      "loss: 0.061950452625751495\n",
      "tensor([[855]]) tensor(800.5856, grad_fn=<SubBackward0>)\n",
      "loss: 0.06364264339208603\n",
      "tensor([[855]]) tensor(798.5793, grad_fn=<SubBackward0>)\n",
      "loss: 0.06598905473947525\n",
      "tensor([[855]]) tensor(797.1315, grad_fn=<SubBackward0>)\n",
      "loss: 0.06768252700567245\n",
      "tensor([[855]]) tensor(801.0099, grad_fn=<SubBackward0>)\n",
      "loss: 0.06314636766910553\n",
      "tensor([[855]]) tensor(803.3858, grad_fn=<SubBackward0>)\n",
      "loss: 0.06036747992038727\n",
      "tensor([[855]]) tensor(805.7631, grad_fn=<SubBackward0>)\n",
      "loss: 0.05758706107735634\n",
      "tensor([[855]]) tensor(804.6151, grad_fn=<SubBackward0>)\n",
      "loss: 0.05892973020672798\n",
      "tensor([[855]]) tensor(805.5940, grad_fn=<SubBackward0>)\n",
      "loss: 0.057784803211688995\n",
      "tensor([[855]]) tensor(800.7621, grad_fn=<SubBackward0>)\n",
      "loss: 0.06343619525432587\n",
      "tensor([[855]]) tensor(807.6816, grad_fn=<SubBackward0>)\n",
      "loss: 0.055343110114336014\n",
      "tensor([[855]]) tensor(806.3237, grad_fn=<SubBackward0>)\n",
      "loss: 0.05693134665489197\n",
      "tensor([[855]]) tensor(806.5800, grad_fn=<SubBackward0>)\n",
      "loss: 0.056631557643413544\n",
      "tensor([[855]]) tensor(808.1838, grad_fn=<SubBackward0>)\n",
      "loss: 0.05475571006536484\n",
      "tensor([[855]]) tensor(801.2463, grad_fn=<SubBackward0>)\n",
      "loss: 0.06286981701850891\n",
      "tensor([[855]]) tensor(805.7499, grad_fn=<SubBackward0>)\n",
      "loss: 0.057602409273386\n",
      "tensor([[855]]) tensor(804.6295, grad_fn=<SubBackward0>)\n",
      "loss: 0.05891288071870804\n",
      "tensor([[855]]) tensor(808.6779, grad_fn=<SubBackward0>)\n",
      "loss: 0.05417798087000847\n",
      "tensor([[855]]) tensor(806.6195, grad_fn=<SubBackward0>)\n",
      "loss: 0.05658533796668053\n",
      "tensor([[855]]) tensor(808.8879, grad_fn=<SubBackward0>)\n",
      "loss: 0.05393219739198685\n",
      "tensor([[855]]) tensor(804.9474, grad_fn=<SubBackward0>)\n",
      "loss: 0.05854102969169617\n",
      "tensor([[855]]) tensor(803.4012, grad_fn=<SubBackward0>)\n",
      "loss: 0.06034945696592331\n",
      "tensor([[855]]) tensor(806.4868, grad_fn=<SubBackward0>)\n",
      "loss: 0.05674063786864281\n",
      "tensor([[855]]) tensor(796.6473, grad_fn=<SubBackward0>)\n",
      "loss: 0.06824876368045807\n",
      "tensor([[855]]) tensor(801.0496, grad_fn=<SubBackward0>)\n",
      "loss: 0.0630999505519867\n",
      "tensor([[855]]) tensor(798.6166, grad_fn=<SubBackward0>)\n",
      "loss: 0.06594550609588623\n",
      "tensor([[855]]) tensor(794.4932, grad_fn=<SubBackward0>)\n",
      "loss: 0.07076817750930786\n",
      "tensor([[855]]) tensor(806.8025, grad_fn=<SubBackward0>)\n",
      "loss: 0.05637133866548538\n",
      "tensor([[855]]) tensor(794.3676, grad_fn=<SubBackward0>)\n",
      "loss: 0.07091514021158218\n",
      "tensor([[855]]) tensor(794.5522, grad_fn=<SubBackward0>)\n",
      "loss: 0.07069916278123856\n",
      "tensor([[855]]) tensor(805.5275, grad_fn=<SubBackward0>)\n",
      "loss: 0.057862650603055954\n",
      "tensor([[855]]) tensor(789.0135, grad_fn=<SubBackward0>)\n",
      "loss: 0.07717709988355637\n",
      "tensor([[855]]) tensor(798.5687, grad_fn=<SubBackward0>)\n",
      "loss: 0.06600148975849152\n",
      "tensor([[855]]) tensor(801.0269, grad_fn=<SubBackward0>)\n",
      "loss: 0.06312646716833115\n",
      "tensor([[855]]) tensor(787.8483, grad_fn=<SubBackward0>)\n",
      "loss: 0.07854004204273224\n",
      "tensor([[855]]) tensor(800.7581, grad_fn=<SubBackward0>)\n",
      "loss: 0.06344088912010193\n",
      "tensor([[855]]) tensor(789.6660, grad_fn=<SubBackward0>)\n",
      "loss: 0.0764140859246254\n",
      "tensor([[855]]) tensor(777.1613, grad_fn=<SubBackward0>)\n",
      "loss: 0.09103943407535553\n",
      "tensor([[855]]) tensor(794.6542, grad_fn=<SubBackward0>)\n",
      "loss: 0.0705798789858818\n",
      "tensor([[855]]) tensor(796.8370, grad_fn=<SubBackward0>)\n",
      "loss: 0.06802693009376526\n",
      "tensor([[855]]) tensor(790.5154, grad_fn=<SubBackward0>)\n",
      "loss: 0.07542064040899277\n",
      "tensor([[855]]) tensor(803.6201, grad_fn=<SubBackward0>)\n",
      "loss: 0.06009351834654808\n",
      "tensor([[855]]) tensor(792.0408, grad_fn=<SubBackward0>)\n",
      "loss: 0.0736364871263504\n",
      "tensor([[855]]) tensor(788.5067, grad_fn=<SubBackward0>)\n",
      "loss: 0.07776999473571777\n",
      "tensor([[855]]) tensor(796.1074, grad_fn=<SubBackward0>)\n",
      "loss: 0.06888017058372498\n",
      "tensor([[855]]) tensor(804.5326, grad_fn=<SubBackward0>)\n",
      "loss: 0.05902622640132904\n",
      "tensor([[855]]) tensor(789.5387, grad_fn=<SubBackward0>)\n",
      "loss: 0.07656288892030716\n",
      "tensor([[855]]) tensor(803.5114, grad_fn=<SubBackward0>)\n",
      "loss: 0.060220640152692795\n",
      "tensor([[855]]) tensor(795.5710, grad_fn=<SubBackward0>)\n",
      "loss: 0.06950756907463074\n",
      "tensor([[855]]) tensor(791.0515, grad_fn=<SubBackward0>)\n",
      "loss: 0.07479355484247208\n",
      "tensor([[855]]) tensor(793.2706, grad_fn=<SubBackward0>)\n",
      "loss: 0.07219809293746948\n",
      "tensor([[855]]) tensor(803.8981, grad_fn=<SubBackward0>)\n",
      "loss: 0.059768300503492355\n",
      "tensor([[855]]) tensor(790.1947, grad_fn=<SubBackward0>)\n",
      "loss: 0.07579567283391953\n",
      "tensor([[855]]) tensor(793.3632, grad_fn=<SubBackward0>)\n",
      "loss: 0.0720897987484932\n",
      "tensor([[855]]) tensor(807.7855, grad_fn=<SubBackward0>)\n",
      "loss: 0.05522157624363899\n",
      "tensor([[855]]) tensor(800.0284, grad_fn=<SubBackward0>)\n",
      "loss: 0.0642942562699318\n",
      "tensor([[855]]) tensor(809.9331, grad_fn=<SubBackward0>)\n",
      "loss: 0.052709855139255524\n",
      "tensor([[855]]) tensor(805.7900, grad_fn=<SubBackward0>)\n",
      "loss: 0.05755556374788284\n",
      "tensor([[855]]) tensor(806.8325, grad_fn=<SubBackward0>)\n",
      "loss: 0.05633632466197014\n",
      "tensor([[855]]) tensor(806.6766, grad_fn=<SubBackward0>)\n",
      "loss: 0.056518517434597015\n",
      "tensor([[855]]) tensor(807.9419, grad_fn=<SubBackward0>)\n",
      "loss: 0.0550387017428875\n",
      "tensor([[855]]) tensor(809.1443, grad_fn=<SubBackward0>)\n",
      "loss: 0.053632378578186035\n",
      "tensor([[855]]) tensor(798.7755, grad_fn=<SubBackward0>)\n",
      "loss: 0.06575963646173477\n",
      "tensor([[855]]) tensor(802.0970, grad_fn=<SubBackward0>)\n",
      "loss: 0.06187479943037033\n",
      "tensor([[855]]) tensor(793.6351, grad_fn=<SubBackward0>)\n",
      "loss: 0.07177183032035828\n",
      "tensor([[855]]) tensor(788.9803, grad_fn=<SubBackward0>)\n",
      "loss: 0.0772160068154335\n",
      "tensor([[855]]) tensor(804.9139, grad_fn=<SubBackward0>)\n",
      "loss: 0.0585801862180233\n",
      "tensor([[855]]) tensor(795.4935, grad_fn=<SubBackward0>)\n",
      "loss: 0.06959817558526993\n",
      "tensor([[855]]) tensor(799.9231, grad_fn=<SubBackward0>)\n",
      "loss: 0.06441739946603775\n",
      "tensor([[855]]) tensor(799.9292, grad_fn=<SubBackward0>)\n",
      "loss: 0.06441032886505127\n",
      "tensor([[855]]) tensor(795.5820, grad_fn=<SubBackward0>)\n",
      "loss: 0.06949475407600403\n",
      "tensor([[855]]) tensor(797.5411, grad_fn=<SubBackward0>)\n",
      "loss: 0.0672033503651619\n",
      "tensor([[855]]) tensor(803.7466, grad_fn=<SubBackward0>)\n",
      "loss: 0.05994551628828049\n",
      "tensor([[855]]) tensor(802.6976, grad_fn=<SubBackward0>)\n",
      "loss: 0.061172325164079666\n",
      "tensor([[855]]) tensor(804.6321, grad_fn=<SubBackward0>)\n",
      "loss: 0.05890977755188942\n",
      "tensor([[855]]) tensor(803.5369, grad_fn=<SubBackward0>)\n",
      "loss: 0.0601908378303051\n",
      "tensor([[855]]) tensor(802.8314, grad_fn=<SubBackward0>)\n",
      "loss: 0.06101595237851143\n",
      "tensor([[855]]) tensor(806.4567, grad_fn=<SubBackward0>)\n",
      "loss: 0.05677583068609238\n",
      "tensor([[855]]) tensor(801.8453, grad_fn=<SubBackward0>)\n",
      "loss: 0.06216919794678688\n",
      "tensor([[855]]) tensor(804.0931, grad_fn=<SubBackward0>)\n",
      "loss: 0.05954015254974365\n",
      "tensor([[855]]) tensor(808.5803, grad_fn=<SubBackward0>)\n",
      "loss: 0.05429210886359215\n",
      "tensor([[855]]) tensor(810.1545, grad_fn=<SubBackward0>)\n",
      "loss: 0.052450794726610184\n",
      "tensor([[855]]) tensor(799.4299, grad_fn=<SubBackward0>)\n",
      "loss: 0.06499426811933517\n",
      "tensor([[855]]) tensor(803.0167, grad_fn=<SubBackward0>)\n",
      "loss: 0.060799118131399155\n",
      "tensor([[855]]) tensor(810.1344, grad_fn=<SubBackward0>)\n",
      "loss: 0.05247434973716736\n",
      "tensor([[855]]) tensor(809.3941, grad_fn=<SubBackward0>)\n",
      "loss: 0.053340230137109756\n",
      "tensor([[855]]) tensor(806.5307, grad_fn=<SubBackward0>)\n",
      "loss: 0.056689221411943436\n",
      "tensor([[855]]) tensor(807.6969, grad_fn=<SubBackward0>)\n",
      "loss: 0.05532524734735489\n",
      "tensor([[855]]) tensor(811.0193, grad_fn=<SubBackward0>)\n",
      "loss: 0.05143946781754494\n",
      "tensor([[855]]) tensor(810.8655, grad_fn=<SubBackward0>)\n",
      "loss: 0.051619235426187515\n",
      "tensor([[855]]) tensor(813.0120, grad_fn=<SubBackward0>)\n",
      "loss: 0.04910874366760254\n",
      "tensor([[855]]) tensor(812.5098, grad_fn=<SubBackward0>)\n",
      "loss: 0.04969611018896103\n",
      "tensor([[855]]) tensor(815.0980, grad_fn=<SubBackward0>)\n",
      "loss: 0.04666898027062416\n",
      "tensor([[855]]) tensor(813.9990, grad_fn=<SubBackward0>)\n",
      "loss: 0.047954410314559937\n",
      "tensor([[855]]) tensor(811.6871, grad_fn=<SubBackward0>)\n",
      "loss: 0.05065836012363434\n",
      "tensor([[855]]) tensor(806.1538, grad_fn=<SubBackward0>)\n",
      "loss: 0.057130083441734314\n",
      "tensor([[855]]) tensor(811.2201, grad_fn=<SubBackward0>)\n",
      "loss: 0.05120456963777542\n",
      "tensor([[855]]) tensor(800.8031, grad_fn=<SubBackward0>)\n",
      "loss: 0.06338822096586227\n",
      "tensor([[855]]) tensor(805.2874, grad_fn=<SubBackward0>)\n",
      "loss: 0.058143410831689835\n",
      "tensor([[855]]) tensor(802.4171, grad_fn=<SubBackward0>)\n",
      "loss: 0.06150052323937416\n",
      "tensor([[855]]) tensor(804.8772, grad_fn=<SubBackward0>)\n",
      "loss: 0.05862316116690636\n",
      "tensor([[855]]) tensor(796.5646, grad_fn=<SubBackward0>)\n",
      "loss: 0.06834554672241211\n",
      "tensor([[855]]) tensor(790.3323, grad_fn=<SubBackward0>)\n",
      "loss: 0.07563469558954239\n",
      "tensor([[855]]) tensor(794.3994, grad_fn=<SubBackward0>)\n",
      "loss: 0.07087796926498413\n",
      "tensor([[855]]) tensor(807.7625, grad_fn=<SubBackward0>)\n",
      "loss: 0.055248524993658066\n",
      "tensor([[855]]) tensor(795.4465, grad_fn=<SubBackward0>)\n",
      "loss: 0.06965317577123642\n",
      "tensor([[855]]) tensor(791.5424, grad_fn=<SubBackward0>)\n",
      "loss: 0.07421950250864029\n",
      "tensor([[855]]) tensor(809.9057, grad_fn=<SubBackward0>)\n",
      "loss: 0.052741870284080505\n",
      "tensor([[855]]) tensor(795.7836, grad_fn=<SubBackward0>)\n",
      "loss: 0.06925895065069199\n",
      "tensor([[855]]) tensor(812.8282, grad_fn=<SubBackward0>)\n",
      "loss: 0.049323670566082\n",
      "tensor([[855]]) tensor(799.7010, grad_fn=<SubBackward0>)\n",
      "loss: 0.0646771714091301\n",
      "tensor([[855]]) tensor(797.9964, grad_fn=<SubBackward0>)\n",
      "loss: 0.06667087972164154\n",
      "tensor([[855]]) tensor(809.9218, grad_fn=<SubBackward0>)\n",
      "loss: 0.05272309482097626\n",
      "tensor([[855]]) tensor(803.5550, grad_fn=<SubBackward0>)\n",
      "loss: 0.06016959995031357\n",
      "tensor([[855]]) tensor(808.7170, grad_fn=<SubBackward0>)\n",
      "loss: 0.05413215234875679\n",
      "tensor([[855]]) tensor(802.1481, grad_fn=<SubBackward0>)\n",
      "loss: 0.061815086752176285\n",
      "tensor([[855]]) tensor(810.9082, grad_fn=<SubBackward0>)\n",
      "loss: 0.051569387316703796\n",
      "tensor([[855]]) tensor(804.6551, grad_fn=<SubBackward0>)\n",
      "loss: 0.05888291820883751\n",
      "tensor([[855]]) tensor(799.6448, grad_fn=<SubBackward0>)\n",
      "loss: 0.06474296748638153\n",
      "tensor([[855]]) tensor(813.9592, grad_fn=<SubBackward0>)\n",
      "loss: 0.048000939190387726\n",
      "tensor([[855]]) tensor(790.9382, grad_fn=<SubBackward0>)\n",
      "loss: 0.07492613047361374\n",
      "tensor([[855]]) tensor(789.3579, grad_fn=<SubBackward0>)\n",
      "loss: 0.07677441090345383\n",
      "tensor([[855]]) tensor(812.6810, grad_fn=<SubBackward0>)\n",
      "loss: 0.049495942890644073\n",
      "tensor([[855]]) tensor(802.9509, grad_fn=<SubBackward0>)\n",
      "loss: 0.06087610870599747\n",
      "tensor([[855]]) tensor(800.3902, grad_fn=<SubBackward0>)\n",
      "loss: 0.0638711154460907\n",
      "tensor([[855]]) tensor(807.5515, grad_fn=<SubBackward0>)\n",
      "loss: 0.05549526959657669\n",
      "tensor([[855]]) tensor(808.2468, grad_fn=<SubBackward0>)\n",
      "loss: 0.05468207597732544\n",
      "tensor([[855]]) tensor(807.6495, grad_fn=<SubBackward0>)\n",
      "loss: 0.05538066104054451\n",
      "tensor([[855]]) tensor(805.0894, grad_fn=<SubBackward0>)\n",
      "loss: 0.058374933898448944\n",
      "tensor([[855]]) tensor(806.1653, grad_fn=<SubBackward0>)\n",
      "loss: 0.05711662769317627\n",
      "tensor([[855]]) tensor(806.3372, grad_fn=<SubBackward0>)\n",
      "loss: 0.05691555142402649\n",
      "tensor([[855]]) tensor(810.5884, grad_fn=<SubBackward0>)\n",
      "loss: 0.051943451166152954\n",
      "tensor([[855]]) tensor(807.0417, grad_fn=<SubBackward0>)\n",
      "loss: 0.056091487407684326\n",
      "tensor([[855]]) tensor(810.9747, grad_fn=<SubBackward0>)\n",
      "loss: 0.051491525024175644\n",
      "tensor([[855]]) tensor(802.6321, grad_fn=<SubBackward0>)\n",
      "loss: 0.06124906614422798\n",
      "tensor([[855]]) tensor(811.8481, grad_fn=<SubBackward0>)\n",
      "loss: 0.05047004297375679\n",
      "tensor([[855]]) tensor(797.3482, grad_fn=<SubBackward0>)\n",
      "loss: 0.06742899864912033\n",
      "tensor([[855]]) tensor(799.9677, grad_fn=<SubBackward0>)\n",
      "loss: 0.06436531990766525\n",
      "tensor([[855]]) tensor(816.2917, grad_fn=<SubBackward0>)\n",
      "loss: 0.04527287930250168\n",
      "tensor([[855]]) tensor(796.9266, grad_fn=<SubBackward0>)\n",
      "loss: 0.06792213767766953\n",
      "tensor([[855]]) tensor(803.3001, grad_fn=<SubBackward0>)\n",
      "loss: 0.060467708855867386\n",
      "tensor([[855]]) tensor(811.0442, grad_fn=<SubBackward0>)\n",
      "loss: 0.05141032114624977\n",
      "tensor([[855]]) tensor(804.0776, grad_fn=<SubBackward0>)\n",
      "loss: 0.05955835431814194\n",
      "tensor([[855]]) tensor(812.2229, grad_fn=<SubBackward0>)\n",
      "loss: 0.05003165826201439\n",
      "tensor([[855]]) tensor(806.7060, grad_fn=<SubBackward0>)\n",
      "loss: 0.05648421868681908\n",
      "tensor([[855]]) tensor(810.6481, grad_fn=<SubBackward0>)\n",
      "loss: 0.05187363550066948\n",
      "tensor([[855]]) tensor(809.4437, grad_fn=<SubBackward0>)\n",
      "loss: 0.053282156586647034\n",
      "tensor([[855]]) tensor(800.5937, grad_fn=<SubBackward0>)\n",
      "loss: 0.06363312900066376\n",
      "tensor([[855]]) tensor(810.7285, grad_fn=<SubBackward0>)\n",
      "loss: 0.05177949741482735\n",
      "tensor([[855]]) tensor(804.6329, grad_fn=<SubBackward0>)\n",
      "loss: 0.0589088499546051\n",
      "tensor([[855]]) tensor(800.7992, grad_fn=<SubBackward0>)\n",
      "loss: 0.06339278817176819\n",
      "tensor([[855]]) tensor(816.2712, grad_fn=<SubBackward0>)\n",
      "loss: 0.04529688507318497\n",
      "tensor([[855]]) tensor(810.2703, grad_fn=<SubBackward0>)\n",
      "loss: 0.05231548100709915\n",
      "tensor([[855]]) tensor(818.2645, grad_fn=<SubBackward0>)\n",
      "loss: 0.042965468019247055\n",
      "tensor([[855]]) tensor(802.2791, grad_fn=<SubBackward0>)\n",
      "loss: 0.06166191026568413\n",
      "tensor([[855]]) tensor(805.8365, grad_fn=<SubBackward0>)\n",
      "loss: 0.05750120431184769\n",
      "tensor([[855]]) tensor(809.6519, grad_fn=<SubBackward0>)\n",
      "loss: 0.05303878337144852\n",
      "tensor([[855]]) tensor(810.7821, grad_fn=<SubBackward0>)\n",
      "loss: 0.051716871559619904\n",
      "tensor([[855]]) tensor(815.0297, grad_fn=<SubBackward0>)\n",
      "loss: 0.04674895107746124\n",
      "tensor([[855]]) tensor(813.1947, grad_fn=<SubBackward0>)\n",
      "loss: 0.04889504984021187\n",
      "tensor([[855]]) tensor(814.7336, grad_fn=<SubBackward0>)\n",
      "loss: 0.04709520936012268\n",
      "tensor([[855]]) tensor(814.2346, grad_fn=<SubBackward0>)\n",
      "loss: 0.047678880393505096\n",
      "tensor([[855]]) tensor(815.4514, grad_fn=<SubBackward0>)\n",
      "loss: 0.04625565558671951\n",
      "tensor([[855]]) tensor(812.6536, grad_fn=<SubBackward0>)\n",
      "loss: 0.04952799528837204\n",
      "tensor([[855]]) tensor(815.3067, grad_fn=<SubBackward0>)\n",
      "loss: 0.04642491042613983\n",
      "tensor([[855]]) tensor(817.5690, grad_fn=<SubBackward0>)\n",
      "loss: 0.04377889260649681\n",
      "tensor([[855]]) tensor(808.6814, grad_fn=<SubBackward0>)\n",
      "loss: 0.05417384207248688\n",
      "tensor([[855]]) tensor(814.5348, grad_fn=<SubBackward0>)\n",
      "loss: 0.04732776805758476\n",
      "tensor([[855]]) tensor(803.4081, grad_fn=<SubBackward0>)\n",
      "loss: 0.06034133583307266\n",
      "tensor([[855]]) tensor(813.6759, grad_fn=<SubBackward0>)\n",
      "loss: 0.04833231121301651\n",
      "tensor([[855]]) tensor(803.5688, grad_fn=<SubBackward0>)\n",
      "loss: 0.060153428465127945\n",
      "tensor([[855]]) tensor(799.0856, grad_fn=<SubBackward0>)\n",
      "loss: 0.06539697200059891\n",
      "tensor([[855]]) tensor(813.7580, grad_fn=<SubBackward0>)\n",
      "loss: 0.048236243426799774\n",
      "tensor([[855]]) tensor(796.2704, grad_fn=<SubBackward0>)\n",
      "loss: 0.06868962198495865\n",
      "tensor([[855]]) tensor(790.3272, grad_fn=<SubBackward0>)\n",
      "loss: 0.07564069330692291\n",
      "tensor([[855]]) tensor(812.6817, grad_fn=<SubBackward0>)\n",
      "loss: 0.049495067447423935\n",
      "tensor([[855]]) tensor(793.0044, grad_fn=<SubBackward0>)\n",
      "loss: 0.07250946015119553\n",
      "tensor([[855]]) tensor(776.9249, grad_fn=<SubBackward0>)\n",
      "loss: 0.0913158431649208\n",
      "tensor([[855]]) tensor(796.4926, grad_fn=<SubBackward0>)\n",
      "loss: 0.06842970848083496\n",
      "tensor([[855]]) tensor(814.0399, grad_fn=<SubBackward0>)\n",
      "loss: 0.047906599938869476\n",
      "tensor([[855]]) tensor(796.2137, grad_fn=<SubBackward0>)\n",
      "loss: 0.06875592470169067\n",
      "tensor([[855]]) tensor(804.7676, grad_fn=<SubBackward0>)\n",
      "loss: 0.05875128135085106\n",
      "tensor([[855]]) tensor(803.9048, grad_fn=<SubBackward0>)\n",
      "loss: 0.059760432690382004\n",
      "tensor([[855]]) tensor(796.7569, grad_fn=<SubBackward0>)\n",
      "loss: 0.06812059134244919\n",
      "tensor([[855]]) tensor(797.0662, grad_fn=<SubBackward0>)\n",
      "loss: 0.06775887310504913\n",
      "tensor([[855]]) tensor(801.9638, grad_fn=<SubBackward0>)\n",
      "loss: 0.06203063577413559\n",
      "tensor([[855]]) tensor(804.7640, grad_fn=<SubBackward0>)\n",
      "loss: 0.058755528181791306\n",
      "tensor([[855]]) tensor(809.7515, grad_fn=<SubBackward0>)\n",
      "loss: 0.052922192960977554\n",
      "tensor([[855]]) tensor(807.9470, grad_fn=<SubBackward0>)\n",
      "loss: 0.055032722651958466\n",
      "tensor([[855]]) tensor(796.9812, grad_fn=<SubBackward0>)\n",
      "loss: 0.0678582638502121\n",
      "tensor([[855]]) tensor(802.8870, grad_fn=<SubBackward0>)\n",
      "loss: 0.06095088645815849\n",
      "tensor([[855]]) tensor(816.7270, grad_fn=<SubBackward0>)\n",
      "loss: 0.044763773679733276\n",
      "tensor([[855]]) tensor(809.8938, grad_fn=<SubBackward0>)\n",
      "loss: 0.05275575444102287\n",
      "tensor([[855]]) tensor(815.5940, grad_fn=<SubBackward0>)\n",
      "loss: 0.04608885943889618\n",
      "tensor([[855]]) tensor(816.5920, grad_fn=<SubBackward0>)\n",
      "loss: 0.04492158815264702\n",
      "tensor([[855]]) tensor(816.9119, grad_fn=<SubBackward0>)\n",
      "loss: 0.04454747214913368\n",
      "tensor([[855]]) tensor(814.5151, grad_fn=<SubBackward0>)\n",
      "loss: 0.04735071584582329\n",
      "tensor([[855]]) tensor(816.7382, grad_fn=<SubBackward0>)\n",
      "loss: 0.04475070908665657\n",
      "tensor([[855]]) tensor(809.6366, grad_fn=<SubBackward0>)\n",
      "loss: 0.05305664613842964\n",
      "tensor([[855]]) tensor(818.1223, grad_fn=<SubBackward0>)\n",
      "loss: 0.043131761252880096\n",
      "tensor([[855]]) tensor(801.0356, grad_fn=<SubBackward0>)\n",
      "loss: 0.06311620771884918\n",
      "tensor([[855]]) tensor(804.2270, grad_fn=<SubBackward0>)\n",
      "loss: 0.059383638203144073\n",
      "tensor([[855]]) tensor(816.5533, grad_fn=<SubBackward0>)\n",
      "loss: 0.04496688395738602\n",
      "tensor([[855]]) tensor(810.4897, grad_fn=<SubBackward0>)\n",
      "loss: 0.05205884948372841\n",
      "tensor([[855]]) tensor(815.7327, grad_fn=<SubBackward0>)\n",
      "loss: 0.04592663422226906\n",
      "tensor([[855]]) tensor(802.7021, grad_fn=<SubBackward0>)\n",
      "loss: 0.06116706132888794\n",
      "tensor([[855]]) tensor(808.3118, grad_fn=<SubBackward0>)\n",
      "loss: 0.0546061210334301\n",
      "tensor([[855]]) tensor(805.3284, grad_fn=<SubBackward0>)\n",
      "loss: 0.05809551104903221\n",
      "tensor([[855]]) tensor(801.0283, grad_fn=<SubBackward0>)\n",
      "loss: 0.06312480568885803\n",
      "tensor([[855]]) tensor(815.0255, grad_fn=<SubBackward0>)\n",
      "loss: 0.046753786504268646\n",
      "tensor([[855]]) tensor(795.2874, grad_fn=<SubBackward0>)\n",
      "loss: 0.06983935087919235\n",
      "tensor([[855]]) tensor(795.4400, grad_fn=<SubBackward0>)\n",
      "loss: 0.06966083496809006\n",
      "tensor([[855]]) tensor(815.1457, grad_fn=<SubBackward0>)\n",
      "loss: 0.04661322757601738\n",
      "tensor([[855]]) tensor(795.2754, grad_fn=<SubBackward0>)\n",
      "loss: 0.06985334306955338\n",
      "tensor([[855]]) tensor(787.1234, grad_fn=<SubBackward0>)\n",
      "loss: 0.07938782125711441\n",
      "tensor([[855]]) tensor(804.4398, grad_fn=<SubBackward0>)\n",
      "loss: 0.059134677052497864\n",
      "tensor([[855]]) tensor(805.1982, grad_fn=<SubBackward0>)\n",
      "loss: 0.05824768915772438\n",
      "tensor([[855]]) tensor(795.7546, grad_fn=<SubBackward0>)\n",
      "loss: 0.06929285824298859\n",
      "tensor([[855]]) tensor(810.5663, grad_fn=<SubBackward0>)\n",
      "loss: 0.051969293504953384\n",
      "tensor([[855]]) tensor(792.2934, grad_fn=<SubBackward0>)\n",
      "loss: 0.07334107160568237\n",
      "tensor([[855]]) tensor(778.5043, grad_fn=<SubBackward0>)\n",
      "loss: 0.08946859836578369\n",
      "tensor([[855]]) tensor(790.6047, grad_fn=<SubBackward0>)\n",
      "loss: 0.07531606405973434\n",
      "tensor([[855]]) tensor(810.5969, grad_fn=<SubBackward0>)\n",
      "loss: 0.051933422684669495\n",
      "tensor([[855]]) tensor(784.7599, grad_fn=<SubBackward0>)\n",
      "loss: 0.08215218037366867\n",
      "tensor([[855]]) tensor(772.2237, grad_fn=<SubBackward0>)\n",
      "loss: 0.09681439399719238\n",
      "tensor([[855]]) tensor(786.0864, grad_fn=<SubBackward0>)\n",
      "loss: 0.08060065656900406\n",
      "tensor([[855]]) tensor(811.2798, grad_fn=<SubBackward0>)\n",
      "loss: 0.05113477259874344\n",
      "tensor([[855]]) tensor(801.0328, grad_fn=<SubBackward0>)\n",
      "loss: 0.06311947107315063\n",
      "tensor([[855]]) tensor(799.4390, grad_fn=<SubBackward0>)\n",
      "loss: 0.06498366594314575\n",
      "tensor([[855]]) tensor(803.3525, grad_fn=<SubBackward0>)\n",
      "loss: 0.060406457632780075\n",
      "tensor([[855]]) tensor(808.1857, grad_fn=<SubBackward0>)\n",
      "loss: 0.05475356802344322\n",
      "tensor([[855]]) tensor(794.9030, grad_fn=<SubBackward0>)\n",
      "loss: 0.07028894126415253\n",
      "tensor([[855]]) tensor(807.0544, grad_fn=<SubBackward0>)\n",
      "loss: 0.05607670918107033\n",
      "tensor([[855]]) tensor(799.0516, grad_fn=<SubBackward0>)\n",
      "loss: 0.06543677300214767\n",
      "tensor([[855]]) tensor(793.8753, grad_fn=<SubBackward0>)\n",
      "loss: 0.07149089127779007\n",
      "tensor([[855]]) tensor(805.6118, grad_fn=<SubBackward0>)\n",
      "loss: 0.05776393786072731\n",
      "tensor([[855]]) tensor(803.8877, grad_fn=<SubBackward0>)\n",
      "loss: 0.05978045612573624\n",
      "tensor([[855]]) tensor(798.2360, grad_fn=<SubBackward0>)\n",
      "loss: 0.06639068573713303\n",
      "tensor([[855]]) tensor(817.4999, grad_fn=<SubBackward0>)\n",
      "loss: 0.04385970160365105\n",
      "tensor([[855]]) tensor(801.2417, grad_fn=<SubBackward0>)\n",
      "loss: 0.06287520378828049\n",
      "tensor([[855]]) tensor(798.0347, grad_fn=<SubBackward0>)\n",
      "loss: 0.06662602722644806\n",
      "tensor([[855]]) tensor(818.7733, grad_fn=<SubBackward0>)\n",
      "loss: 0.042370427399873734\n",
      "tensor([[855]]) tensor(794.1324, grad_fn=<SubBackward0>)\n",
      "loss: 0.07119008898735046\n",
      "tensor([[855]]) tensor(783.2960, grad_fn=<SubBackward0>)\n",
      "loss: 0.08386433869600296\n",
      "tensor([[855]]) tensor(800.8630, grad_fn=<SubBackward0>)\n",
      "loss: 0.0633181557059288\n",
      "tensor([[855]]) tensor(811.7236, grad_fn=<SubBackward0>)\n",
      "loss: 0.05061563476920128\n",
      "tensor([[855]]) tensor(794.3777, grad_fn=<SubBackward0>)\n",
      "loss: 0.0709032416343689\n",
      "tensor([[855]]) tensor(799.0594, grad_fn=<SubBackward0>)\n",
      "loss: 0.06542760133743286\n",
      "tensor([[855]]) tensor(816.4479, grad_fn=<SubBackward0>)\n",
      "loss: 0.045090239495038986\n",
      "tensor([[855]]) tensor(795.6406, grad_fn=<SubBackward0>)\n",
      "loss: 0.06942623853683472\n",
      "tensor([[855]]) tensor(786.3649, grad_fn=<SubBackward0>)\n",
      "loss: 0.08027495443820953\n",
      "tensor([[855]]) tensor(806.1356, grad_fn=<SubBackward0>)\n",
      "loss: 0.05715135857462883\n",
      "tensor([[855]]) tensor(808.5757, grad_fn=<SubBackward0>)\n",
      "loss: 0.05429737642407417\n",
      "tensor([[855]]) tensor(787.8536, grad_fn=<SubBackward0>)\n",
      "loss: 0.07853373885154724\n",
      "tensor([[855]]) tensor(789.7737, grad_fn=<SubBackward0>)\n",
      "loss: 0.07628807425498962\n",
      "tensor([[855]]) tensor(812.1556, grad_fn=<SubBackward0>)\n",
      "loss: 0.050110433250665665\n",
      "tensor([[855]]) tensor(803.2928, grad_fn=<SubBackward0>)\n",
      "loss: 0.06047622114419937\n",
      "tensor([[855]]) tensor(794.7274, grad_fn=<SubBackward0>)\n",
      "loss: 0.07049428671598434\n",
      "tensor([[855]]) tensor(813.9439, grad_fn=<SubBackward0>)\n",
      "loss: 0.04801882058382034\n",
      "tensor([[855]]) tensor(807.8376, grad_fn=<SubBackward0>)\n",
      "loss: 0.05516066402196884\n",
      "tensor([[855]]) tensor(801.7877, grad_fn=<SubBackward0>)\n",
      "loss: 0.062236636877059937\n",
      "tensor([[855]]) tensor(810.4441, grad_fn=<SubBackward0>)\n",
      "loss: 0.05211217328906059\n",
      "tensor([[855]]) tensor(814.0121, grad_fn=<SubBackward0>)\n",
      "loss: 0.04793911799788475\n",
      "tensor([[855]]) tensor(805.3979, grad_fn=<SubBackward0>)\n",
      "loss: 0.05801411345601082\n",
      "tensor([[855]]) tensor(820.5798, grad_fn=<SubBackward0>)\n",
      "loss: 0.04025757685303688\n",
      "tensor([[855]]) tensor(805.8397, grad_fn=<SubBackward0>)\n",
      "loss: 0.057497456669807434\n",
      "tensor([[855]]) tensor(801.5107, grad_fn=<SubBackward0>)\n",
      "loss: 0.06256061047315598\n",
      "tensor([[855]]) tensor(811.8066, grad_fn=<SubBackward0>)\n",
      "loss: 0.05051851272583008\n",
      "tensor([[855]]) tensor(805.4924, grad_fn=<SubBackward0>)\n",
      "loss: 0.05790365859866142\n",
      "tensor([[855]]) tensor(801.1619, grad_fn=<SubBackward0>)\n",
      "loss: 0.06296861171722412\n",
      "tensor([[855]]) tensor(821.4739, grad_fn=<SubBackward0>)\n",
      "loss: 0.03921176865696907\n",
      "tensor([[855]]) tensor(809.1927, grad_fn=<SubBackward0>)\n",
      "loss: 0.053575802594423294\n",
      "tensor([[855]]) tensor(812.2594, grad_fn=<SubBackward0>)\n",
      "loss: 0.049988970160484314\n",
      "tensor([[855]]) tensor(820.9534, grad_fn=<SubBackward0>)\n",
      "loss: 0.039820656180381775\n",
      "tensor([[855]]) tensor(801.8646, grad_fn=<SubBackward0>)\n",
      "loss: 0.06214660406112671\n",
      "tensor([[855]]) tensor(803.1224, grad_fn=<SubBackward0>)\n",
      "loss: 0.060675475746393204\n",
      "tensor([[855]]) tensor(817.4408, grad_fn=<SubBackward0>)\n",
      "loss: 0.043928928673267365\n",
      "tensor([[855]]) tensor(817.0349, grad_fn=<SubBackward0>)\n",
      "loss: 0.04440368339419365\n",
      "tensor([[855]]) tensor(817.6896, grad_fn=<SubBackward0>)\n",
      "loss: 0.04363790526986122\n",
      "tensor([[855]]) tensor(814.8353, grad_fn=<SubBackward0>)\n",
      "loss: 0.046976227313280106\n",
      "tensor([[855]]) tensor(818.2625, grad_fn=<SubBackward0>)\n",
      "loss: 0.04296785593032837\n",
      "tensor([[855]]) tensor(809.2137, grad_fn=<SubBackward0>)\n",
      "loss: 0.05355121195316315\n",
      "tensor([[855]]) tensor(818.5155, grad_fn=<SubBackward0>)\n",
      "loss: 0.042671963572502136\n",
      "tensor([[855]]) tensor(803.2897, grad_fn=<SubBackward0>)\n",
      "loss: 0.060479916632175446\n",
      "tensor([[855]]) tensor(801.3615, grad_fn=<SubBackward0>)\n",
      "loss: 0.06273507326841354\n",
      "tensor([[855]]) tensor(821.3569, grad_fn=<SubBackward0>)\n",
      "loss: 0.03934870660305023\n",
      "tensor([[855]]) tensor(807.0154, grad_fn=<SubBackward0>)\n",
      "loss: 0.056122343987226486\n",
      "tensor([[855]]) tensor(816.2271, grad_fn=<SubBackward0>)\n",
      "loss: 0.04534844309091568\n",
      "tensor([[855]]) tensor(809.2570, grad_fn=<SubBackward0>)\n",
      "loss: 0.05350056290626526\n",
      "tensor([[855]]) tensor(810.6761, grad_fn=<SubBackward0>)\n",
      "loss: 0.05184074491262436\n",
      "tensor([[855]]) tensor(816.9527, grad_fn=<SubBackward0>)\n",
      "loss: 0.04449976980686188\n",
      "tensor([[855]]) tensor(810.3163, grad_fn=<SubBackward0>)\n",
      "loss: 0.052261654287576675\n",
      "tensor([[855]]) tensor(822.7405, grad_fn=<SubBackward0>)\n",
      "loss: 0.03773036226630211\n",
      "tensor([[855]]) tensor(797.3014, grad_fn=<SubBackward0>)\n",
      "loss: 0.06748371571302414\n",
      "tensor([[855]]) tensor(793.8738, grad_fn=<SubBackward0>)\n",
      "loss: 0.07149261981248856\n",
      "tensor([[855]]) tensor(818.8740, grad_fn=<SubBackward0>)\n",
      "loss: 0.04225260391831398\n",
      "tensor([[855]]) tensor(799.2530, grad_fn=<SubBackward0>)\n",
      "loss: 0.06520116329193115\n",
      "tensor([[855]]) tensor(800.3208, grad_fn=<SubBackward0>)\n",
      "loss: 0.06395231187343597\n",
      "tensor([[855]]) tensor(816.4046, grad_fn=<SubBackward0>)\n",
      "loss: 0.045140817761421204\n",
      "tensor([[855]]) tensor(800.3485, grad_fn=<SubBackward0>)\n",
      "loss: 0.06391990929841995\n",
      "tensor([[855]]) tensor(794.0825, grad_fn=<SubBackward0>)\n",
      "loss: 0.07124855369329453\n",
      "tensor([[855]]) tensor(812.1932, grad_fn=<SubBackward0>)\n",
      "loss: 0.05006638914346695\n",
      "tensor([[855]]) tensor(803.4792, grad_fn=<SubBackward0>)\n",
      "loss: 0.060258153825998306\n",
      "tensor([[855]]) tensor(789.0236, grad_fn=<SubBackward0>)\n",
      "loss: 0.07716537266969681\n",
      "tensor([[855]]) tensor(799.8256, grad_fn=<SubBackward0>)\n",
      "loss: 0.06453143805265427\n",
      "tensor([[855]]) tensor(814.8366, grad_fn=<SubBackward0>)\n",
      "loss: 0.04697470739483833\n",
      "tensor([[855]]) tensor(794.8337, grad_fn=<SubBackward0>)\n",
      "loss: 0.07036996632814407\n",
      "tensor([[855]]) tensor(784.6216, grad_fn=<SubBackward0>)\n",
      "loss: 0.08231393992900848\n",
      "tensor([[855]]) tensor(802.3232, grad_fn=<SubBackward0>)\n",
      "loss: 0.06161022558808327\n",
      "tensor([[855]]) tensor(808.1451, grad_fn=<SubBackward0>)\n",
      "loss: 0.05480096861720085\n",
      "tensor([[855]]) tensor(795.9180, grad_fn=<SubBackward0>)\n",
      "loss: 0.06910182535648346\n",
      "tensor([[855]]) tensor(788.9885, grad_fn=<SubBackward0>)\n",
      "loss: 0.07720636576414108\n",
      "tensor([[855]]) tensor(801.1827, grad_fn=<SubBackward0>)\n",
      "loss: 0.06294416636228561\n",
      "tensor([[855]]) tensor(815.0139, grad_fn=<SubBackward0>)\n",
      "loss: 0.04676736891269684\n",
      "tensor([[855]]) tensor(792.8923, grad_fn=<SubBackward0>)\n",
      "loss: 0.07264053076505661\n",
      "tensor([[855]]) tensor(784.9763, grad_fn=<SubBackward0>)\n",
      "loss: 0.08189907670021057\n",
      "tensor([[855]]) tensor(800.7432, grad_fn=<SubBackward0>)\n",
      "loss: 0.06345821917057037\n",
      "tensor([[855]]) tensor(808.9257, grad_fn=<SubBackward0>)\n",
      "loss: 0.053888119757175446\n",
      "tensor([[855]]) tensor(791.3544, grad_fn=<SubBackward0>)\n",
      "loss: 0.07443936914205551\n",
      "tensor([[855]]) tensor(798.4132, grad_fn=<SubBackward0>)\n",
      "loss: 0.0661834180355072\n",
      "tensor([[855]]) tensor(819.1932, grad_fn=<SubBackward0>)\n",
      "loss: 0.0418793261051178\n",
      "tensor([[855]]) tensor(791.6354, grad_fn=<SubBackward0>)\n",
      "loss: 0.07411063462495804\n",
      "tensor([[855]]) tensor(776.7166, grad_fn=<SubBackward0>)\n",
      "loss: 0.09155955165624619\n",
      "tensor([[855]]) tensor(788.9637, grad_fn=<SubBackward0>)\n",
      "loss: 0.07723542302846909\n",
      "tensor([[855]]) tensor(822.5591, grad_fn=<SubBackward0>)\n",
      "loss: 0.03794259577989578\n",
      "tensor([[855]]) tensor(793.9936, grad_fn=<SubBackward0>)\n",
      "loss: 0.0713525265455246\n",
      "tensor([[855]]) tensor(776.8242, grad_fn=<SubBackward0>)\n",
      "loss: 0.09143369644880295\n",
      "tensor([[855]]) tensor(791.0160, grad_fn=<SubBackward0>)\n",
      "loss: 0.07483506202697754\n",
      "tensor([[855]]) tensor(817.8887, grad_fn=<SubBackward0>)\n",
      "loss: 0.04340509697794914\n",
      "tensor([[855]]) tensor(785.8431, grad_fn=<SubBackward0>)\n",
      "loss: 0.08088521659374237\n",
      "tensor([[855]]) tensor(772.6346, grad_fn=<SubBackward0>)\n",
      "loss: 0.0963338240981102\n",
      "tensor([[855]]) tensor(788.7471, grad_fn=<SubBackward0>)\n",
      "loss: 0.07748877257108688\n",
      "tensor([[855]]) tensor(817.5402, grad_fn=<SubBackward0>)\n",
      "loss: 0.04381271451711655\n",
      "tensor([[855]]) tensor(801.3186, grad_fn=<SubBackward0>)\n",
      "loss: 0.06278522312641144\n",
      "tensor([[855]]) tensor(789.3770, grad_fn=<SubBackward0>)\n",
      "loss: 0.07675206661224365\n",
      "tensor([[855]]) tensor(800.1630, grad_fn=<SubBackward0>)\n",
      "loss: 0.06413687020540237\n",
      "tensor([[855]]) tensor(815.8124, grad_fn=<SubBackward0>)\n",
      "loss: 0.04583345726132393\n",
      "tensor([[855]]) tensor(794.2074, grad_fn=<SubBackward0>)\n",
      "loss: 0.07110242545604706\n",
      "tensor([[855]]) tensor(784.2347, grad_fn=<SubBackward0>)\n",
      "loss: 0.08276638388633728\n",
      "tensor([[855]]) tensor(800.5911, grad_fn=<SubBackward0>)\n",
      "loss: 0.0636361613869667\n",
      "tensor([[855]]) tensor(818.6502, grad_fn=<SubBackward0>)\n",
      "loss: 0.04251435771584511\n",
      "tensor([[855]]) tensor(810.5626, grad_fn=<SubBackward0>)\n",
      "loss: 0.0519736111164093\n",
      "tensor([[855]]) tensor(804.1189, grad_fn=<SubBackward0>)\n",
      "loss: 0.05951002612709999\n",
      "tensor([[855]]) tensor(816.3376, grad_fn=<SubBackward0>)\n",
      "loss: 0.04521908983588219\n",
      "tensor([[855]]) tensor(805.1037, grad_fn=<SubBackward0>)\n",
      "loss: 0.05835826322436333\n",
      "tensor([[855]]) tensor(803.3030, grad_fn=<SubBackward0>)\n",
      "loss: 0.06046431511640549\n",
      "tensor([[855]]) tensor(813.5166, grad_fn=<SubBackward0>)\n",
      "loss: 0.04851863160729408\n",
      "tensor([[855]]) tensor(806.2533, grad_fn=<SubBackward0>)\n",
      "loss: 0.057013723999261856\n",
      "tensor([[855]]) tensor(811.0547, grad_fn=<SubBackward0>)\n",
      "loss: 0.05139799043536186\n",
      "tensor([[855]]) tensor(815.1188, grad_fn=<SubBackward0>)\n",
      "loss: 0.046644654124975204\n",
      "tensor([[855]]) tensor(807.3693, grad_fn=<SubBackward0>)\n",
      "loss: 0.05570850148797035\n",
      "tensor([[855]]) tensor(817.8802, grad_fn=<SubBackward0>)\n",
      "loss: 0.0434148795902729\n",
      "tensor([[855]]) tensor(818.8666, grad_fn=<SubBackward0>)\n",
      "loss: 0.04226124286651611\n",
      "tensor([[855]]) tensor(808.1312, grad_fn=<SubBackward0>)\n",
      "loss: 0.0548173151910305\n",
      "tensor([[855]]) tensor(813.1054, grad_fn=<SubBackward0>)\n",
      "loss: 0.048999521881341934\n",
      "tensor([[855]]) tensor(818.4595, grad_fn=<SubBackward0>)\n",
      "loss: 0.042737387120723724\n",
      "tensor([[855]]) tensor(817.0180, grad_fn=<SubBackward0>)\n",
      "loss: 0.04442340508103371\n",
      "tensor([[855]]) tensor(822.6119, grad_fn=<SubBackward0>)\n",
      "loss: 0.03788077458739281\n",
      "tensor([[855]]) tensor(824.7646, grad_fn=<SubBackward0>)\n",
      "loss: 0.03536307439208031\n",
      "tensor([[855]]) tensor(821.7281, grad_fn=<SubBackward0>)\n",
      "loss: 0.03891449794173241\n",
      "tensor([[855]]) tensor(821.3525, grad_fn=<SubBackward0>)\n",
      "loss: 0.03935382515192032\n",
      "tensor([[855]]) tensor(825.8239, grad_fn=<SubBackward0>)\n",
      "loss: 0.034124113619327545\n",
      "tensor([[855]]) tensor(817.4772, grad_fn=<SubBackward0>)\n",
      "loss: 0.04388631135225296\n",
      "tensor([[855]]) tensor(825.8841, grad_fn=<SubBackward0>)\n",
      "loss: 0.03405369073152542\n",
      "tensor([[855]]) tensor(819.2173, grad_fn=<SubBackward0>)\n",
      "loss: 0.04185107350349426\n",
      "tensor([[855]]) tensor(827.1835, grad_fn=<SubBackward0>)\n",
      "loss: 0.03253398835659027\n",
      "tensor([[855]]) tensor(821.0320, grad_fn=<SubBackward0>)\n",
      "loss: 0.039728712290525436\n",
      "tensor([[855]]) tensor(827.9675, grad_fn=<SubBackward0>)\n",
      "loss: 0.03161690756678581\n",
      "tensor([[855]]) tensor(814.0712, grad_fn=<SubBackward0>)\n",
      "loss: 0.04786992818117142\n",
      "tensor([[855]]) tensor(824.9237, grad_fn=<SubBackward0>)\n",
      "loss: 0.03517695143818855\n",
      "tensor([[855]]) tensor(824.7780, grad_fn=<SubBackward0>)\n",
      "loss: 0.03534742072224617\n",
      "tensor([[855]]) tensor(825.8695, grad_fn=<SubBackward0>)\n",
      "loss: 0.03407075256109238\n",
      "tensor([[855]]) tensor(825.3161, grad_fn=<SubBackward0>)\n",
      "loss: 0.03471801057457924\n",
      "tensor([[855]]) tensor(827.3064, grad_fn=<SubBackward0>)\n",
      "loss: 0.032390180975198746\n",
      "tensor([[855]]) tensor(826.4794, grad_fn=<SubBackward0>)\n",
      "loss: 0.03335749730467796\n",
      "tensor([[855]]) tensor(825.1510, grad_fn=<SubBackward0>)\n",
      "loss: 0.03491111099720001\n",
      "tensor([[855]]) tensor(817.0774, grad_fn=<SubBackward0>)\n",
      "loss: 0.04435392841696739\n",
      "tensor([[855]]) tensor(824.7786, grad_fn=<SubBackward0>)\n",
      "loss: 0.03534665331244469\n",
      "tensor([[855]]) tensor(818.2493, grad_fn=<SubBackward0>)\n",
      "loss: 0.04298333078622818\n",
      "tensor([[855]]) tensor(828.0135, grad_fn=<SubBackward0>)\n",
      "loss: 0.031563080847263336\n",
      "tensor([[855]]) tensor(823.9228, grad_fn=<SubBackward0>)\n",
      "loss: 0.036347631365060806\n",
      "tensor([[855]]) tensor(822.9187, grad_fn=<SubBackward0>)\n",
      "loss: 0.03752198815345764\n",
      "tensor([[855]]) tensor(826.3136, grad_fn=<SubBackward0>)\n",
      "loss: 0.03355138376355171\n",
      "tensor([[855]]) tensor(823.7488, grad_fn=<SubBackward0>)\n",
      "loss: 0.03655117005109787\n",
      "tensor([[855]]) tensor(825.8595, grad_fn=<SubBackward0>)\n",
      "loss: 0.03408242389559746\n",
      "tensor([[855]]) tensor(822.9022, grad_fn=<SubBackward0>)\n",
      "loss: 0.037541262805461884\n",
      "tensor([[855]]) tensor(825.8547, grad_fn=<SubBackward0>)\n",
      "loss: 0.03408806398510933\n",
      "tensor([[855]]) tensor(824.7703, grad_fn=<SubBackward0>)\n",
      "loss: 0.03535638004541397\n",
      "tensor([[855]]) tensor(822.6580, grad_fn=<SubBackward0>)\n",
      "loss: 0.03782687708735466\n",
      "tensor([[855]]) tensor(823.6223, grad_fn=<SubBackward0>)\n",
      "loss: 0.03669901192188263\n",
      "tensor([[855]]) tensor(820.1078, grad_fn=<SubBackward0>)\n",
      "loss: 0.04080953449010849\n",
      "tensor([[855]]) tensor(826.7908, grad_fn=<SubBackward0>)\n",
      "loss: 0.03299328684806824\n",
      "tensor([[855]]) tensor(825.3805, grad_fn=<SubBackward0>)\n",
      "loss: 0.03464273363351822\n",
      "tensor([[855]]) tensor(824.1774, grad_fn=<SubBackward0>)\n",
      "loss: 0.03604989871382713\n",
      "tensor([[855]]) tensor(824.2599, grad_fn=<SubBackward0>)\n",
      "loss: 0.03595331311225891\n",
      "tensor([[855]]) tensor(824.1758, grad_fn=<SubBackward0>)\n",
      "loss: 0.036051683127880096\n",
      "tensor([[855]]) tensor(825.4460, grad_fn=<SubBackward0>)\n",
      "loss: 0.034566063433885574\n",
      "tensor([[855]]) tensor(825.3708, grad_fn=<SubBackward0>)\n",
      "loss: 0.03465397655963898\n",
      "tensor([[855]]) tensor(821.8947, grad_fn=<SubBackward0>)\n",
      "loss: 0.03871973976492882\n",
      "tensor([[855]]) tensor(830.0358, grad_fn=<SubBackward0>)\n",
      "loss: 0.029197916388511658\n",
      "tensor([[855]]) tensor(825.7424, grad_fn=<SubBackward0>)\n",
      "loss: 0.03421937674283981\n",
      "tensor([[855]]) tensor(832.4503, grad_fn=<SubBackward0>)\n",
      "loss: 0.026373861357569695\n",
      "tensor([[855]]) tensor(816.1149, grad_fn=<SubBackward0>)\n",
      "loss: 0.045479703694581985\n",
      "tensor([[855]]) tensor(824.8202, grad_fn=<SubBackward0>)\n",
      "loss: 0.03529798611998558\n",
      "tensor([[855]]) tensor(803.7598, grad_fn=<SubBackward0>)\n",
      "loss: 0.05993009731173515\n",
      "tensor([[855]]) tensor(799.5243, grad_fn=<SubBackward0>)\n",
      "loss: 0.06488383561372757\n",
      "tensor([[855]]) tensor(817.3814, grad_fn=<SubBackward0>)\n",
      "loss: 0.04399837180972099\n",
      "tensor([[855]]) tensor(814.2783, grad_fn=<SubBackward0>)\n",
      "loss: 0.047627732157707214\n",
      "tensor([[855]]) tensor(812.5695, grad_fn=<SubBackward0>)\n",
      "loss: 0.04962638393044472\n",
      "tensor([[855]]) tensor(822.7734, grad_fn=<SubBackward0>)\n",
      "loss: 0.03769185021519661\n",
      "tensor([[855]]) tensor(820.0042, grad_fn=<SubBackward0>)\n",
      "loss: 0.04093072935938835\n",
      "tensor([[855]]) tensor(825.8678, grad_fn=<SubBackward0>)\n",
      "loss: 0.03407278656959534\n",
      "tensor([[855]]) tensor(824.3881, grad_fn=<SubBackward0>)\n",
      "loss: 0.03580334782600403\n",
      "tensor([[855]]) tensor(823.0242, grad_fn=<SubBackward0>)\n",
      "loss: 0.03739859536290169\n",
      "tensor([[855]]) tensor(820.8636, grad_fn=<SubBackward0>)\n",
      "loss: 0.03992556035518646\n",
      "tensor([[855]]) tensor(824.9218, grad_fn=<SubBackward0>)\n",
      "loss: 0.03517916426062584\n",
      "tensor([[855]]) tensor(818.4772, grad_fn=<SubBackward0>)\n",
      "loss: 0.04271668568253517\n",
      "tensor([[855]]) tensor(822.8279, grad_fn=<SubBackward0>)\n",
      "loss: 0.037628211081027985\n",
      "tensor([[855]]) tensor(815.1217, grad_fn=<SubBackward0>)\n",
      "loss: 0.04664124548435211\n",
      "tensor([[855]]) tensor(823.2718, grad_fn=<SubBackward0>)\n",
      "loss: 0.03710901737213135\n",
      "tensor([[855]]) tensor(808.5942, grad_fn=<SubBackward0>)\n",
      "loss: 0.05427583307027817\n",
      "tensor([[855]]) tensor(808.2837, grad_fn=<SubBackward0>)\n",
      "loss: 0.05463899299502373\n",
      "tensor([[855]]) tensor(819.6246, grad_fn=<SubBackward0>)\n",
      "loss: 0.04137476906180382\n",
      "tensor([[855]]) tensor(816.2738, grad_fn=<SubBackward0>)\n",
      "loss: 0.04529383406043053\n",
      "tensor([[855]]) tensor(821.8456, grad_fn=<SubBackward0>)\n",
      "loss: 0.03877713531255722\n",
      "tensor([[855]]) tensor(820.6997, grad_fn=<SubBackward0>)\n",
      "loss: 0.0401173010468483\n",
      "tensor([[855]]) tensor(813.7274, grad_fn=<SubBackward0>)\n",
      "loss: 0.048272062093019485\n",
      "tensor([[855]]) tensor(814.5938, grad_fn=<SubBackward0>)\n",
      "loss: 0.04725870117545128\n",
      "tensor([[855]]) tensor(823.9783, grad_fn=<SubBackward0>)\n",
      "loss: 0.03628275915980339\n",
      "tensor([[855]]) tensor(813.4920, grad_fn=<SubBackward0>)\n",
      "loss: 0.04854737967252731\n",
      "tensor([[855]]) tensor(825.6702, grad_fn=<SubBackward0>)\n",
      "loss: 0.034303899854421616\n",
      "tensor([[855]]) tensor(815.6063, grad_fn=<SubBackward0>)\n",
      "loss: 0.04607447609305382\n",
      "tensor([[855]]) tensor(810.7133, grad_fn=<SubBackward0>)\n",
      "loss: 0.05179730802774429\n",
      "tensor([[855]]) tensor(826.2479, grad_fn=<SubBackward0>)\n",
      "loss: 0.033628158271312714\n",
      "tensor([[855]]) tensor(825.8872, grad_fn=<SubBackward0>)\n",
      "loss: 0.03405001387000084\n",
      "tensor([[855]]) tensor(826.0498, grad_fn=<SubBackward0>)\n",
      "loss: 0.03385984152555466\n",
      "tensor([[855]]) tensor(821.7152, grad_fn=<SubBackward0>)\n",
      "loss: 0.03892957791686058\n",
      "tensor([[855]]) tensor(825.5448, grad_fn=<SubBackward0>)\n",
      "loss: 0.03445052728056908\n",
      "tensor([[855]]) tensor(825.7028, grad_fn=<SubBackward0>)\n",
      "loss: 0.034265708178281784\n",
      "tensor([[855]]) tensor(825.9655, grad_fn=<SubBackward0>)\n",
      "loss: 0.033958498388528824\n",
      "tensor([[855]]) tensor(828.9508, grad_fn=<SubBackward0>)\n",
      "loss: 0.03046685829758644\n",
      "tensor([[855]]) tensor(825.3013, grad_fn=<SubBackward0>)\n",
      "loss: 0.03473532199859619\n",
      "tensor([[855]]) tensor(829.2079, grad_fn=<SubBackward0>)\n",
      "loss: 0.030166197568178177\n",
      "tensor([[855]]) tensor(813.0168, grad_fn=<SubBackward0>)\n",
      "loss: 0.049103159457445145\n",
      "tensor([[855]]) tensor(818.3836, grad_fn=<SubBackward0>)\n",
      "loss: 0.04282619059085846\n",
      "tensor([[855]]) tensor(813.7333, grad_fn=<SubBackward0>)\n",
      "loss: 0.04826510325074196\n",
      "tensor([[855]]) tensor(813.8094, grad_fn=<SubBackward0>)\n",
      "loss: 0.048176173120737076\n",
      "tensor([[855]]) tensor(828.0577, grad_fn=<SubBackward0>)\n",
      "loss: 0.03151141479611397\n",
      "tensor([[855]]) tensor(822.7184, grad_fn=<SubBackward0>)\n",
      "loss: 0.037756241858005524\n",
      "tensor([[855]]) tensor(824.6293, grad_fn=<SubBackward0>)\n",
      "loss: 0.03552131727337837\n",
      "tensor([[855]]) tensor(827.8065, grad_fn=<SubBackward0>)\n",
      "loss: 0.03180525824427605\n",
      "tensor([[855]]) tensor(817.0872, grad_fn=<SubBackward0>)\n",
      "loss: 0.044342540204524994\n",
      "tensor([[855]]) tensor(823.4788, grad_fn=<SubBackward0>)\n",
      "loss: 0.03686698153614998\n",
      "tensor([[855]]) tensor(818.3011, grad_fn=<SubBackward0>)\n",
      "loss: 0.04292268678545952\n",
      "tensor([[855]]) tensor(815.6829, grad_fn=<SubBackward0>)\n",
      "loss: 0.045984938740730286\n",
      "tensor([[855]]) tensor(825.5967, grad_fn=<SubBackward0>)\n",
      "loss: 0.034389812499284744\n",
      "tensor([[855]]) tensor(813.8054, grad_fn=<SubBackward0>)\n",
      "loss: 0.04818082973361015\n",
      "tensor([[855]]) tensor(817.2698, grad_fn=<SubBackward0>)\n",
      "loss: 0.04412895441055298\n",
      "tensor([[855]]) tensor(823.3323, grad_fn=<SubBackward0>)\n",
      "loss: 0.037038203328847885\n",
      "tensor([[855]]) tensor(817.3239, grad_fn=<SubBackward0>)\n",
      "loss: 0.04406566917896271\n",
      "tensor([[855]]) tensor(820.4918, grad_fn=<SubBackward0>)\n",
      "loss: 0.04036042466759682\n",
      "tensor([[855]]) tensor(827.8723, grad_fn=<SubBackward0>)\n",
      "loss: 0.03172837570309639\n",
      "tensor([[855]]) tensor(828.8386, grad_fn=<SubBackward0>)\n",
      "loss: 0.03059815615415573\n",
      "tensor([[855]]) tensor(811.6550, grad_fn=<SubBackward0>)\n",
      "loss: 0.05069587379693985\n",
      "tensor([[855]]) tensor(810.7743, grad_fn=<SubBackward0>)\n",
      "loss: 0.05172593891620636\n",
      "tensor([[855]]) tensor(828.5325, grad_fn=<SubBackward0>)\n",
      "loss: 0.03095615655183792\n",
      "tensor([[855]]) tensor(802.3698, grad_fn=<SubBackward0>)\n",
      "loss: 0.06155586615204811\n",
      "tensor([[855]]) tensor(799.3782, grad_fn=<SubBackward0>)\n",
      "loss: 0.06505467742681503\n",
      "tensor([[855]]) tensor(815.1529, grad_fn=<SubBackward0>)\n",
      "loss: 0.046604786068201065\n",
      "tensor([[855]]) tensor(810.0143, grad_fn=<SubBackward0>)\n",
      "loss: 0.052614785730838776\n",
      "tensor([[855]]) tensor(796.1603, grad_fn=<SubBackward0>)\n",
      "loss: 0.06881840527057648\n",
      "tensor([[855]]) tensor(810.3168, grad_fn=<SubBackward0>)\n",
      "loss: 0.05226101353764534\n",
      "tensor([[855]]) tensor(826.4417, grad_fn=<SubBackward0>)\n",
      "loss: 0.03340161591768265\n",
      "tensor([[855]]) tensor(813.4686, grad_fn=<SubBackward0>)\n",
      "loss: 0.04857466742396355\n",
      "tensor([[855]]) tensor(824.1754, grad_fn=<SubBackward0>)\n",
      "loss: 0.03605223447084427\n",
      "tensor([[855]]) tensor(807.3530, grad_fn=<SubBackward0>)\n",
      "loss: 0.05572741851210594\n",
      "tensor([[855]]) tensor(800.0002, grad_fn=<SubBackward0>)\n",
      "loss: 0.06432729214429855\n",
      "tensor([[855]]) tensor(809.3889, grad_fn=<SubBackward0>)\n",
      "loss: 0.05334628000855446\n",
      "tensor([[855]]) tensor(820.5668, grad_fn=<SubBackward0>)\n",
      "loss: 0.040272779762744904\n",
      "tensor([[855]]) tensor(807.1135, grad_fn=<SubBackward0>)\n",
      "loss: 0.05600760877132416\n",
      "tensor([[855]]) tensor(820.1600, grad_fn=<SubBackward0>)\n",
      "loss: 0.040748462080955505\n",
      "tensor([[855]]) tensor(821.3414, grad_fn=<SubBackward0>)\n",
      "loss: 0.0393667109310627\n",
      "tensor([[855]]) tensor(820.0747, grad_fn=<SubBackward0>)\n",
      "loss: 0.04084833338856697\n",
      "tensor([[855]]) tensor(823.1837, grad_fn=<SubBackward0>)\n",
      "loss: 0.0372120626270771\n",
      "tensor([[855]]) tensor(816.7644, grad_fn=<SubBackward0>)\n",
      "loss: 0.044719960540533066\n",
      "tensor([[855]]) tensor(827.8027, grad_fn=<SubBackward0>)\n",
      "loss: 0.03180975839495659\n",
      "tensor([[855]]) tensor(810.0854, grad_fn=<SubBackward0>)\n",
      "loss: 0.05253167450428009\n",
      "tensor([[855]]) tensor(801.6097, grad_fn=<SubBackward0>)\n",
      "loss: 0.062444817274808884\n",
      "tensor([[855]]) tensor(819.8342, grad_fn=<SubBackward0>)\n",
      "loss: 0.04112961143255234\n",
      "tensor([[855]]) tensor(819.3256, grad_fn=<SubBackward0>)\n",
      "loss: 0.04172447323799133\n",
      "tensor([[855]]) tensor(810.1702, grad_fn=<SubBackward0>)\n",
      "loss: 0.05243253707885742\n",
      "tensor([[855]]) tensor(828.6517, grad_fn=<SubBackward0>)\n",
      "loss: 0.03081665001809597\n",
      "tensor([[855]]) tensor(821.4149, grad_fn=<SubBackward0>)\n",
      "loss: 0.039280835539102554\n",
      "tensor([[855]]) tensor(822.8149, grad_fn=<SubBackward0>)\n",
      "loss: 0.03764338046312332\n",
      "tensor([[855]]) tensor(825.7036, grad_fn=<SubBackward0>)\n",
      "loss: 0.03426479920744896\n",
      "tensor([[855]]) tensor(815.7762, grad_fn=<SubBackward0>)\n",
      "loss: 0.04587577283382416\n",
      "tensor([[855]]) tensor(828.8533, grad_fn=<SubBackward0>)\n",
      "loss: 0.030580950900912285\n",
      "tensor([[855]]) tensor(826.2162, grad_fn=<SubBackward0>)\n",
      "loss: 0.03366522490978241\n",
      "tensor([[855]]) tensor(832.4662, grad_fn=<SubBackward0>)\n",
      "loss: 0.026355266571044922\n",
      "tensor([[855]]) tensor(807.4811, grad_fn=<SubBackward0>)\n",
      "loss: 0.0555775947868824\n",
      "tensor([[855]]) tensor(810.8373, grad_fn=<SubBackward0>)\n",
      "loss: 0.05165230482816696\n",
      "tensor([[855]]) tensor(830.3427, grad_fn=<SubBackward0>)\n",
      "loss: 0.02883896790444851\n",
      "tensor([[855]]) tensor(821.0886, grad_fn=<SubBackward0>)\n",
      "loss: 0.039662428200244904\n",
      "tensor([[855]]) tensor(824.4733, grad_fn=<SubBackward0>)\n",
      "loss: 0.03570378199219704\n",
      "tensor([[855]]) tensor(830.0792, grad_fn=<SubBackward0>)\n",
      "loss: 0.02914712391793728\n",
      "tensor([[855]]) tensor(826.0308, grad_fn=<SubBackward0>)\n",
      "loss: 0.03388213366270065\n",
      "tensor([[855]]) tensor(822.3612, grad_fn=<SubBackward0>)\n",
      "loss: 0.03817404434084892\n",
      "tensor([[855]]) tensor(824.0616, grad_fn=<SubBackward0>)\n",
      "loss: 0.03618524596095085\n",
      "tensor([[855]]) tensor(829.6346, grad_fn=<SubBackward0>)\n",
      "loss: 0.029667066410183907\n",
      "tensor([[855]]) tensor(821.1935, grad_fn=<SubBackward0>)\n",
      "loss: 0.03953976929187775\n",
      "tensor([[855]]) tensor(828.0975, grad_fn=<SubBackward0>)\n",
      "loss: 0.031464871019124985\n",
      "tensor([[855]]) tensor(818.2173, grad_fn=<SubBackward0>)\n",
      "loss: 0.04302064701914787\n",
      "tensor([[855]]) tensor(822.3776, grad_fn=<SubBackward0>)\n",
      "loss: 0.03815482556819916\n",
      "tensor([[855]]) tensor(819.8787, grad_fn=<SubBackward0>)\n",
      "loss: 0.04107755422592163\n",
      "tensor([[855]]) tensor(816.7553, grad_fn=<SubBackward0>)\n",
      "loss: 0.04473062977194786\n",
      "tensor([[855]]) tensor(823.3364, grad_fn=<SubBackward0>)\n",
      "loss: 0.037033457309007645\n",
      "tensor([[855]]) tensor(818.1093, grad_fn=<SubBackward0>)\n",
      "loss: 0.043147001415491104\n",
      "tensor([[855]]) tensor(822.1155, grad_fn=<SubBackward0>)\n",
      "loss: 0.038461409509181976\n",
      "tensor([[855]]) tensor(823.1655, grad_fn=<SubBackward0>)\n",
      "loss: 0.03723335638642311\n",
      "tensor([[855]]) tensor(821.5676, grad_fn=<SubBackward0>)\n",
      "loss: 0.03910226374864578\n",
      "tensor([[855]]) tensor(829.8131, grad_fn=<SubBackward0>)\n",
      "loss: 0.029458386823534966\n",
      "tensor([[855]]) tensor(826.5612, grad_fn=<SubBackward0>)\n",
      "loss: 0.0332617312669754\n",
      "tensor([[855]]) tensor(824.7098, grad_fn=<SubBackward0>)\n",
      "loss: 0.03542708978056908\n",
      "tensor([[855]]) tensor(822.4689, grad_fn=<SubBackward0>)\n",
      "loss: 0.038048047572374344\n",
      "tensor([[855]]) tensor(833.7388, grad_fn=<SubBackward0>)\n",
      "loss: 0.024866847321391106\n",
      "tensor([[855]]) tensor(815.3071, grad_fn=<SubBackward0>)\n",
      "loss: 0.04642441123723984\n",
      "tensor([[855]]) tensor(826.2805, grad_fn=<SubBackward0>)\n",
      "loss: 0.03359000384807587\n",
      "tensor([[855]]) tensor(814.9005, grad_fn=<SubBackward0>)\n",
      "loss: 0.04690001904964447\n",
      "tensor([[855]]) tensor(806.1056, grad_fn=<SubBackward0>)\n",
      "loss: 0.057186443358659744\n",
      "tensor([[855]]) tensor(823.6509, grad_fn=<SubBackward0>)\n",
      "loss: 0.03666556626558304\n",
      "tensor([[855]]) tensor(809.1855, grad_fn=<SubBackward0>)\n",
      "loss: 0.05358417332172394\n",
      "tensor([[855]]) tensor(799.3875, grad_fn=<SubBackward0>)\n",
      "loss: 0.06504393368959427\n",
      "tensor([[855]]) tensor(813.4955, grad_fn=<SubBackward0>)\n",
      "loss: 0.04854322224855423\n",
      "tensor([[855]]) tensor(813.6947, grad_fn=<SubBackward0>)\n",
      "loss: 0.0483102910220623\n",
      "tensor([[855]]) tensor(802.7405, grad_fn=<SubBackward0>)\n",
      "loss: 0.061122264713048935\n",
      "tensor([[855]]) tensor(807.7020, grad_fn=<SubBackward0>)\n",
      "loss: 0.05531923100352287\n",
      "tensor([[855]]) tensor(825.4393, grad_fn=<SubBackward0>)\n",
      "loss: 0.034573864191770554\n",
      "tensor([[855]]) tensor(802.4099, grad_fn=<SubBackward0>)\n",
      "loss: 0.06150887534022331\n",
      "tensor([[855]]) tensor(797.1517, grad_fn=<SubBackward0>)\n",
      "loss: 0.06765887886285782\n",
      "tensor([[855]]) tensor(821.5931, grad_fn=<SubBackward0>)\n",
      "loss: 0.03907231613993645\n",
      "tensor([[855]]) tensor(801.1017, grad_fn=<SubBackward0>)\n",
      "loss: 0.06303887814283371\n",
      "tensor([[855]]) tensor(781.2064, grad_fn=<SubBackward0>)\n",
      "loss: 0.0863083153963089\n",
      "tensor([[855]]) tensor(789.1798, grad_fn=<SubBackward0>)\n",
      "loss: 0.07698263972997665\n",
      "tensor([[855]]) tensor(813.9583, grad_fn=<SubBackward0>)\n",
      "loss: 0.0480019748210907\n",
      "tensor([[855]]) tensor(795.3517, grad_fn=<SubBackward0>)\n",
      "loss: 0.069764144718647\n",
      "tensor([[855]]) tensor(780.1070, grad_fn=<SubBackward0>)\n",
      "loss: 0.0875941589474678\n",
      "tensor([[855]]) tensor(795.9033, grad_fn=<SubBackward0>)\n",
      "loss: 0.0691189244389534\n",
      "tensor([[855]]) tensor(829.6705, grad_fn=<SubBackward0>)\n",
      "loss: 0.029625143855810165\n",
      "tensor([[855]]) tensor(809.4286, grad_fn=<SubBackward0>)\n",
      "loss: 0.05329989641904831\n",
      "tensor([[855]]) tensor(824.2609, grad_fn=<SubBackward0>)\n",
      "loss: 0.035952240228652954\n",
      "tensor([[855]]) tensor(826.7174, grad_fn=<SubBackward0>)\n",
      "loss: 0.03307907283306122\n",
      "tensor([[855]]) tensor(820.0436, grad_fn=<SubBackward0>)\n",
      "loss: 0.04088473692536354\n",
      "tensor([[855]]) tensor(819.5568, grad_fn=<SubBackward0>)\n",
      "loss: 0.04145408049225807\n",
      "tensor([[855]]) tensor(821.5028, grad_fn=<SubBackward0>)\n",
      "loss: 0.03917800262570381\n",
      "tensor([[855]]) tensor(831.9709, grad_fn=<SubBackward0>)\n",
      "loss: 0.02693459950387478\n",
      "tensor([[855]]) tensor(812.2584, grad_fn=<SubBackward0>)\n",
      "loss: 0.04999018460512161\n",
      "tensor([[855]]) tensor(806.3595, grad_fn=<SubBackward0>)\n",
      "loss: 0.05688951164484024\n",
      "tensor([[855]]) tensor(811.8596, grad_fn=<SubBackward0>)\n",
      "loss: 0.05045662075281143\n",
      "tensor([[855]]) tensor(813.3219, grad_fn=<SubBackward0>)\n",
      "loss: 0.048746317625045776\n",
      "tensor([[855]]) tensor(823.3136, grad_fn=<SubBackward0>)\n",
      "loss: 0.03706011921167374\n",
      "tensor([[855]]) tensor(811.6375, grad_fn=<SubBackward0>)\n",
      "loss: 0.05071642994880676\n",
      "tensor([[855]]) tensor(821.0275, grad_fn=<SubBackward0>)\n",
      "loss: 0.03973386809229851\n",
      "tensor([[855]]) tensor(807.1523, grad_fn=<SubBackward0>)\n",
      "loss: 0.05596226081252098\n",
      "tensor([[855]]) tensor(814.3478, grad_fn=<SubBackward0>)\n",
      "loss: 0.04754636809229851\n",
      "tensor([[855]]) tensor(822.7489, grad_fn=<SubBackward0>)\n",
      "loss: 0.03772062063217163\n",
      "tensor([[855]]) tensor(826.4774, grad_fn=<SubBackward0>)\n",
      "loss: 0.03335971012711525\n",
      "tensor([[855]]) tensor(809.7318, grad_fn=<SubBackward0>)\n",
      "loss: 0.05294523015618324\n",
      "tensor([[855]]) tensor(814.8273, grad_fn=<SubBackward0>)\n",
      "loss: 0.046985648572444916\n",
      "tensor([[855]]) tensor(821.7773, grad_fn=<SubBackward0>)\n",
      "loss: 0.03885696083307266\n",
      "tensor([[855]]) tensor(803.1891, grad_fn=<SubBackward0>)\n",
      "loss: 0.060597486793994904\n",
      "tensor([[855]]) tensor(801.1202, grad_fn=<SubBackward0>)\n",
      "loss: 0.06301726400852203\n",
      "tensor([[855]]) tensor(813.3898, grad_fn=<SubBackward0>)\n",
      "loss: 0.04866684600710869\n",
      "tensor([[855]]) tensor(805.0225, grad_fn=<SubBackward0>)\n",
      "loss: 0.058453209698200226\n",
      "tensor([[855]]) tensor(808.4202, grad_fn=<SubBackward0>)\n",
      "loss: 0.054479338228702545\n",
      "tensor([[855]]) tensor(822.5782, grad_fn=<SubBackward0>)\n",
      "loss: 0.03792021423578262\n",
      "tensor([[855]]) tensor(805.8976, grad_fn=<SubBackward0>)\n",
      "loss: 0.05742969363927841\n",
      "tensor([[855]]) tensor(809.2775, grad_fn=<SubBackward0>)\n",
      "loss: 0.05347668379545212\n",
      "tensor([[855]]) tensor(830.9568, grad_fn=<SubBackward0>)\n",
      "loss: 0.028120698407292366\n",
      "tensor([[855]]) tensor(826.1676, grad_fn=<SubBackward0>)\n",
      "loss: 0.03372206538915634\n",
      "tensor([[855]]) tensor(830.0157, grad_fn=<SubBackward0>)\n",
      "loss: 0.029221419245004654\n",
      "tensor([[855]]) tensor(816.5090, grad_fn=<SubBackward0>)\n",
      "loss: 0.04501863941550255\n",
      "tensor([[855]]) tensor(821.1599, grad_fn=<SubBackward0>)\n",
      "loss: 0.039579104632139206\n",
      "tensor([[855]]) tensor(817.9328, grad_fn=<SubBackward0>)\n",
      "loss: 0.043353430926799774\n",
      "tensor([[855]]) tensor(814.5746, grad_fn=<SubBackward0>)\n",
      "loss: 0.0472811684012413\n",
      "tensor([[855]]) tensor(825.9226, grad_fn=<SubBackward0>)\n",
      "loss: 0.03400866314768791\n",
      "tensor([[855]]) tensor(825.4868, grad_fn=<SubBackward0>)\n",
      "loss: 0.03451837971806526\n",
      "tensor([[855]]) tensor(825.5918, grad_fn=<SubBackward0>)\n",
      "loss: 0.03439556062221527\n",
      "tensor([[855]]) tensor(830.1508, grad_fn=<SubBackward0>)\n",
      "loss: 0.02906337007880211\n",
      "tensor([[855]]) tensor(815.9383, grad_fn=<SubBackward0>)\n",
      "loss: 0.045686207711696625\n",
      "tensor([[855]]) tensor(822.2205, grad_fn=<SubBackward0>)\n",
      "loss: 0.03833864629268646\n",
      "tensor([[855]]) tensor(825.2280, grad_fn=<SubBackward0>)\n",
      "loss: 0.0348210372030735\n",
      "tensor([[855]]) tensor(816.5706, grad_fn=<SubBackward0>)\n",
      "loss: 0.04494662955403328\n",
      "tensor([[855]]) tensor(822.4330, grad_fn=<SubBackward0>)\n",
      "loss: 0.038090113550424576\n",
      "tensor([[855]]) tensor(814.1872, grad_fn=<SubBackward0>)\n",
      "loss: 0.047734275460243225\n",
      "tensor([[855]]) tensor(820.5092, grad_fn=<SubBackward0>)\n",
      "loss: 0.040340203791856766\n",
      "tensor([[855]]) tensor(821.0504, grad_fn=<SubBackward0>)\n",
      "loss: 0.039707206189632416\n",
      "tensor([[855]]) tensor(818.8760, grad_fn=<SubBackward0>)\n",
      "loss: 0.042250264436006546\n",
      "tensor([[855]]) tensor(827.6246, grad_fn=<SubBackward0>)\n",
      "loss: 0.03201800957322121\n",
      "tensor([[855]]) tensor(805.8986, grad_fn=<SubBackward0>)\n",
      "loss: 0.05742858350276947\n",
      "tensor([[855]]) tensor(806.0526, grad_fn=<SubBackward0>)\n",
      "loss: 0.057248372584581375\n",
      "tensor([[855]]) tensor(831.3528, grad_fn=<SubBackward0>)\n",
      "loss: 0.027657581493258476\n",
      "tensor([[855]]) tensor(821.6736, grad_fn=<SubBackward0>)\n",
      "loss: 0.03897826373577118\n",
      "tensor([[855]]) tensor(821.5067, grad_fn=<SubBackward0>)\n",
      "loss: 0.03917339816689491\n",
      "tensor([[855]]) tensor(821.5723, grad_fn=<SubBackward0>)\n",
      "loss: 0.03909669443964958\n",
      "tensor([[855]]) tensor(825.8162, grad_fn=<SubBackward0>)\n",
      "loss: 0.034133180975914\n",
      "tensor([[855]]) tensor(815.3901, grad_fn=<SubBackward0>)\n",
      "loss: 0.0463273786008358\n",
      "tensor([[855]]) tensor(811.4915, grad_fn=<SubBackward0>)\n",
      "loss: 0.050887152552604675\n",
      "tensor([[855]]) tensor(824.2833, grad_fn=<SubBackward0>)\n",
      "loss: 0.035925935953855515\n",
      "tensor([[855]]) tensor(816.5056, grad_fn=<SubBackward0>)\n",
      "loss: 0.04502267390489578\n",
      "tensor([[855]]) tensor(813.1041, grad_fn=<SubBackward0>)\n",
      "loss: 0.04900100454688072\n",
      "tensor([[855]]) tensor(834.9896, grad_fn=<SubBackward0>)\n",
      "loss: 0.023404037579894066\n",
      "tensor([[855]]) tensor(819.9830, grad_fn=<SubBackward0>)\n",
      "loss: 0.040955498814582825\n",
      "tensor([[855]]) tensor(823.8654, grad_fn=<SubBackward0>)\n",
      "loss: 0.036414697766304016\n",
      "tensor([[855]]) tensor(828.9111, grad_fn=<SubBackward0>)\n",
      "loss: 0.03051336668431759\n",
      "tensor([[855]]) tensor(827.1527, grad_fn=<SubBackward0>)\n",
      "loss: 0.03256992995738983\n",
      "tensor([[855]]) tensor(829.8287, grad_fn=<SubBackward0>)\n",
      "loss: 0.029440129175782204\n",
      "tensor([[855]]) tensor(825.8610, grad_fn=<SubBackward0>)\n",
      "loss: 0.034080710262060165\n",
      "tensor([[855]]) tensor(832.8908, grad_fn=<SubBackward0>)\n",
      "loss: 0.02585870400071144\n",
      "tensor([[855]]) tensor(826.1470, grad_fn=<SubBackward0>)\n",
      "loss: 0.03374619409441948\n",
      "tensor([[855]]) tensor(833.0516, grad_fn=<SubBackward0>)\n",
      "loss: 0.025670601055026054\n",
      "tensor([[855]]) tensor(836.8928, grad_fn=<SubBackward0>)\n",
      "loss: 0.02117805741727352\n",
      "tensor([[855]]) tensor(836.1132, grad_fn=<SubBackward0>)\n",
      "loss: 0.022089801728725433\n",
      "tensor([[855]]) tensor(827.2551, grad_fn=<SubBackward0>)\n",
      "loss: 0.03245014324784279\n",
      "tensor([[855]]) tensor(835.0396, grad_fn=<SubBackward0>)\n",
      "loss: 0.023345518857240677\n",
      "tensor([[855]]) tensor(832.5331, grad_fn=<SubBackward0>)\n",
      "loss: 0.026277044788002968\n",
      "tensor([[855]]) tensor(823.8568, grad_fn=<SubBackward0>)\n",
      "loss: 0.036424871534109116\n",
      "tensor([[855]]) tensor(828.8532, grad_fn=<SubBackward0>)\n",
      "loss: 0.03058105893433094\n",
      "tensor([[855]]) tensor(831.3978, grad_fn=<SubBackward0>)\n",
      "loss: 0.0276048444211483\n",
      "tensor([[855]]) tensor(832.5686, grad_fn=<SubBackward0>)\n",
      "loss: 0.026235533878207207\n",
      "tensor([[855]]) tensor(825.4905, grad_fn=<SubBackward0>)\n",
      "loss: 0.03451397269964218\n",
      "tensor([[855]]) tensor(823.8813, grad_fn=<SubBackward0>)\n",
      "loss: 0.03639613837003708\n",
      "tensor([[855]]) tensor(829.4810, grad_fn=<SubBackward0>)\n",
      "loss: 0.02984679862856865\n",
      "tensor([[855]]) tensor(825.4117, grad_fn=<SubBackward0>)\n",
      "loss: 0.0346062034368515\n",
      "tensor([[855]]) tensor(827.7819, grad_fn=<SubBackward0>)\n",
      "loss: 0.03183408081531525\n",
      "tensor([[855]]) tensor(823.3501, grad_fn=<SubBackward0>)\n",
      "loss: 0.03701743111014366\n",
      "tensor([[855]]) tensor(818.2366, grad_fn=<SubBackward0>)\n",
      "loss: 0.04299812391400337\n",
      "tensor([[855]]) tensor(834.2064, grad_fn=<SubBackward0>)\n",
      "loss: 0.024320047348737717\n",
      "tensor([[855]]) tensor(809.5549, grad_fn=<SubBackward0>)\n",
      "loss: 0.05315211042761803\n",
      "tensor([[855]]) tensor(804.0419, grad_fn=<SubBackward0>)\n",
      "loss: 0.05960017070174217\n",
      "tensor([[855]]) tensor(822.2236, grad_fn=<SubBackward0>)\n",
      "loss: 0.03833496943116188\n",
      "tensor([[855]]) tensor(817.5539, grad_fn=<SubBackward0>)\n",
      "loss: 0.0437965989112854\n",
      "tensor([[855]]) tensor(807.5236, grad_fn=<SubBackward0>)\n",
      "loss: 0.05552801862359047\n",
      "tensor([[855]]) tensor(822.4973, grad_fn=<SubBackward0>)\n",
      "loss: 0.03801492601633072\n",
      "tensor([[855]]) tensor(820.1570, grad_fn=<SubBackward0>)\n",
      "loss: 0.040751997381448746\n",
      "tensor([[855]]) tensor(814.8075, grad_fn=<SubBackward0>)\n",
      "loss: 0.04700879380106926\n",
      "tensor([[855]]) tensor(830.0678, grad_fn=<SubBackward0>)\n",
      "loss: 0.029160473495721817\n",
      "tensor([[855]]) tensor(805.9122, grad_fn=<SubBackward0>)\n",
      "loss: 0.05741257593035698\n",
      "tensor([[855]]) tensor(802.4555, grad_fn=<SubBackward0>)\n",
      "loss: 0.06145556643605232\n",
      "tensor([[855]]) tensor(812.7235, grad_fn=<SubBackward0>)\n",
      "loss: 0.049446187913417816\n",
      "tensor([[855]]) tensor(817.9218, grad_fn=<SubBackward0>)\n",
      "loss: 0.04336629807949066\n",
      "tensor([[855]]) tensor(811.3931, grad_fn=<SubBackward0>)\n",
      "loss: 0.051002297550439835\n",
      "tensor([[855]]) tensor(827.7689, grad_fn=<SubBackward0>)\n",
      "loss: 0.03184928745031357\n",
      "tensor([[855]]) tensor(828.2656, grad_fn=<SubBackward0>)\n",
      "loss: 0.03126830980181694\n",
      "tensor([[855]]) tensor(816.5029, grad_fn=<SubBackward0>)\n",
      "loss: 0.0450257770717144\n",
      "tensor([[855]]) tensor(830.4846, grad_fn=<SubBackward0>)\n",
      "loss: 0.028672995045781136\n",
      "tensor([[855]]) tensor(834.3491, grad_fn=<SubBackward0>)\n",
      "loss: 0.02415303885936737\n",
      "tensor([[855]]) tensor(827.0358, grad_fn=<SubBackward0>)\n",
      "loss: 0.032706670463085175\n",
      "tensor([[855]]) tensor(825.5877, grad_fn=<SubBackward0>)\n",
      "loss: 0.034400343894958496\n",
      "tensor([[855]]) tensor(827.1960, grad_fn=<SubBackward0>)\n",
      "loss: 0.032519299536943436\n",
      "tensor([[855]]) tensor(835.1119, grad_fn=<SubBackward0>)\n",
      "loss: 0.023260891437530518\n",
      "tensor([[855]]) tensor(824.8340, grad_fn=<SubBackward0>)\n",
      "loss: 0.03528192639350891\n",
      "tensor([[855]]) tensor(833.4588, grad_fn=<SubBackward0>)\n",
      "loss: 0.025194384157657623\n",
      "tensor([[855]]) tensor(834.4779, grad_fn=<SubBackward0>)\n",
      "loss: 0.024002468213438988\n",
      "tensor([[855]]) tensor(832.7968, grad_fn=<SubBackward0>)\n",
      "loss: 0.0259686391800642\n",
      "tensor([[855]]) tensor(835.0029, grad_fn=<SubBackward0>)\n",
      "loss: 0.023388385772705078\n",
      "tensor([[855]]) tensor(830.0019, grad_fn=<SubBackward0>)\n",
      "loss: 0.029237553477287292\n",
      "tensor([[855]]) tensor(832.4458, grad_fn=<SubBackward0>)\n",
      "loss: 0.02637919783592224\n",
      "tensor([[855]]) tensor(827.8526, grad_fn=<SubBackward0>)\n",
      "loss: 0.0317513644695282\n",
      "tensor([[855]]) tensor(830.4003, grad_fn=<SubBackward0>)\n",
      "loss: 0.028771651908755302\n",
      "tensor([[855]]) tensor(820.1873, grad_fn=<SubBackward0>)\n",
      "loss: 0.04071669653058052\n",
      "tensor([[855]]) tensor(817.6070, grad_fn=<SubBackward0>)\n",
      "loss: 0.043734509497880936\n",
      "tensor([[855]]) tensor(833.6748, grad_fn=<SubBackward0>)\n",
      "loss: 0.024941785261034966\n",
      "tensor([[855]]) tensor(813.6537, grad_fn=<SubBackward0>)\n",
      "loss: 0.04835820943117142\n",
      "tensor([[855]]) tensor(807.1310, grad_fn=<SubBackward0>)\n",
      "loss: 0.05598708614706993\n",
      "tensor([[855]]) tensor(831.5798, grad_fn=<SubBackward0>)\n",
      "loss: 0.02739209681749344\n",
      "tensor([[855]]) tensor(809.2222, grad_fn=<SubBackward0>)\n",
      "loss: 0.05354134365916252\n",
      "tensor([[855]]) tensor(791.1653, grad_fn=<SubBackward0>)\n",
      "loss: 0.07466041296720505\n",
      "tensor([[855]]) tensor(804.5330, grad_fn=<SubBackward0>)\n",
      "loss: 0.05902576074004173\n",
      "tensor([[855]]) tensor(830.5016, grad_fn=<SubBackward0>)\n",
      "loss: 0.02865302562713623\n",
      "tensor([[855]]) tensor(797.8447, grad_fn=<SubBackward0>)\n",
      "loss: 0.06684830784797668\n",
      "tensor([[855]]) tensor(786.0017, grad_fn=<SubBackward0>)\n",
      "loss: 0.08069975674152374\n",
      "tensor([[855]]) tensor(795.8240, grad_fn=<SubBackward0>)\n",
      "loss: 0.06921175867319107\n",
      "tensor([[855]]) tensor(834.2629, grad_fn=<SubBackward0>)\n",
      "loss: 0.024253925308585167\n",
      "tensor([[855]]) tensor(792.9567, grad_fn=<SubBackward0>)\n",
      "loss: 0.07256530225276947\n",
      "tensor([[855]]) tensor(763.1681, grad_fn=<SubBackward0>)\n",
      "loss: 0.10740574449300766\n",
      "tensor([[855]]) tensor(766.5044, grad_fn=<SubBackward0>)\n",
      "loss: 0.10350362956523895\n",
      "tensor([[855]]) tensor(796.7129, grad_fn=<SubBackward0>)\n",
      "loss: 0.06817202270030975\n",
      "tensor([[855]]) tensor(815.4124, grad_fn=<SubBackward0>)\n",
      "loss: 0.04630126804113388\n",
      "tensor([[855]]) tensor(787.4495, grad_fn=<SubBackward0>)\n",
      "loss: 0.07900642603635788\n",
      "tensor([[855]]) tensor(787.8745, grad_fn=<SubBackward0>)\n",
      "loss: 0.07850939780473709\n",
      "tensor([[855]]) tensor(815.9505, grad_fn=<SubBackward0>)\n",
      "loss: 0.04567191004753113\n",
      "tensor([[855]]) tensor(812.9858, grad_fn=<SubBackward0>)\n",
      "loss: 0.049139369279146194\n",
      "tensor([[855]]) tensor(787.8203, grad_fn=<SubBackward0>)\n",
      "loss: 0.07857277244329453\n",
      "tensor([[855]]) tensor(804.0286, grad_fn=<SubBackward0>)\n",
      "loss: 0.05961574986577034\n",
      "tensor([[855]]) tensor(823.9039, grad_fn=<SubBackward0>)\n",
      "loss: 0.03636967018246651\n",
      "tensor([[855]]) tensor(808.7947, grad_fn=<SubBackward0>)\n",
      "loss: 0.05404127761721611\n",
      "tensor([[855]]) tensor(799.4106, grad_fn=<SubBackward0>)\n",
      "loss: 0.06501682847738266\n",
      "tensor([[855]]) tensor(818.2937, grad_fn=<SubBackward0>)\n",
      "loss: 0.04293130710721016\n",
      "tensor([[855]]) tensor(822.4279, grad_fn=<SubBackward0>)\n",
      "loss: 0.038096074014902115\n",
      "tensor([[855]]) tensor(800.2588, grad_fn=<SubBackward0>)\n",
      "loss: 0.06402479112148285\n",
      "tensor([[855]]) tensor(809.1138, grad_fn=<SubBackward0>)\n",
      "loss: 0.053668033331632614\n",
      "tensor([[855]]) tensor(831.1216, grad_fn=<SubBackward0>)\n",
      "loss: 0.027927903458476067\n",
      "tensor([[855]]) tensor(811.7267, grad_fn=<SubBackward0>)\n",
      "loss: 0.050612010061740875\n",
      "tensor([[855]]) tensor(813.4769, grad_fn=<SubBackward0>)\n",
      "loss: 0.04856506735086441\n",
      "tensor([[855]]) tensor(834.5544, grad_fn=<SubBackward0>)\n",
      "loss: 0.02391296811401844\n",
      "tensor([[855]]) tensor(823.8042, grad_fn=<SubBackward0>)\n",
      "loss: 0.036486316472291946\n",
      "tensor([[855]]) tensor(828.1303, grad_fn=<SubBackward0>)\n",
      "loss: 0.03142653778195381\n",
      "tensor([[855]]) tensor(828.2918, grad_fn=<SubBackward0>)\n",
      "loss: 0.031237632036209106\n",
      "tensor([[855]]) tensor(828.2272, grad_fn=<SubBackward0>)\n",
      "loss: 0.031313229352235794\n",
      "tensor([[855]]) tensor(828.2187, grad_fn=<SubBackward0>)\n",
      "loss: 0.03132318705320358\n",
      "tensor([[855]]) tensor(829.4559, grad_fn=<SubBackward0>)\n",
      "loss: 0.02987617440521717\n",
      "tensor([[855]]) tensor(829.9716, grad_fn=<SubBackward0>)\n",
      "loss: 0.02927306853234768\n",
      "tensor([[855]]) tensor(835.5559, grad_fn=<SubBackward0>)\n",
      "loss: 0.022741610184311867\n",
      "tensor([[855]]) tensor(831.1035, grad_fn=<SubBackward0>)\n",
      "loss: 0.027949122712016106\n",
      "tensor([[855]]) tensor(839.1809, grad_fn=<SubBackward0>)\n",
      "loss: 0.01850186102092266\n",
      "tensor([[855]]) tensor(835.0035, grad_fn=<SubBackward0>)\n",
      "loss: 0.023387691006064415\n",
      "tensor([[855]]) tensor(830.7059, grad_fn=<SubBackward0>)\n",
      "loss: 0.028414132073521614\n",
      "tensor([[855]]) tensor(831.7850, grad_fn=<SubBackward0>)\n",
      "loss: 0.027152007445693016\n",
      "tensor([[855]]) tensor(833.4462, grad_fn=<SubBackward0>)\n",
      "loss: 0.025209197774529457\n",
      "tensor([[855]]) tensor(835.1002, grad_fn=<SubBackward0>)\n",
      "loss: 0.02327461540699005\n",
      "tensor([[855]]) tensor(835.9450, grad_fn=<SubBackward0>)\n",
      "loss: 0.022286541759967804\n",
      "tensor([[855]]) tensor(833.1466, grad_fn=<SubBackward0>)\n",
      "loss: 0.025559524074196815\n",
      "tensor([[855]]) tensor(838.9569, grad_fn=<SubBackward0>)\n",
      "loss: 0.018763814121484756\n",
      "tensor([[855]]) tensor(836.6280, grad_fn=<SubBackward0>)\n",
      "loss: 0.021487729623913765\n",
      "tensor([[855]]) tensor(823.2715, grad_fn=<SubBackward0>)\n",
      "loss: 0.03710935637354851\n",
      "tensor([[855]]) tensor(828.0682, grad_fn=<SubBackward0>)\n",
      "loss: 0.031499192118644714\n",
      "tensor([[855]]) tensor(827.0393, grad_fn=<SubBackward0>)\n",
      "loss: 0.03270256519317627\n",
      "tensor([[855]]) tensor(826.1580, grad_fn=<SubBackward0>)\n",
      "loss: 0.033733416348695755\n",
      "tensor([[855]]) tensor(833.4850, grad_fn=<SubBackward0>)\n",
      "loss: 0.025163760408759117\n",
      "tensor([[855]]) tensor(831.5736, grad_fn=<SubBackward0>)\n",
      "loss: 0.027399323880672455\n",
      "tensor([[855]]) tensor(830.7000, grad_fn=<SubBackward0>)\n",
      "loss: 0.02842102013528347\n",
      "tensor([[855]]) tensor(835.5057, grad_fn=<SubBackward0>)\n",
      "loss: 0.022800378501415253\n",
      "tensor([[855]]) tensor(838.9450, grad_fn=<SubBackward0>)\n",
      "loss: 0.018777787685394287\n",
      "tensor([[855]]) tensor(832.4191, grad_fn=<SubBackward0>)\n",
      "loss: 0.026410482823848724\n",
      "tensor([[855]]) tensor(836.7319, grad_fn=<SubBackward0>)\n",
      "loss: 0.021366123110055923\n",
      "tensor([[855]]) tensor(828.6197, grad_fn=<SubBackward0>)\n",
      "loss: 0.03085416369140148\n",
      "tensor([[855]]) tensor(836.9434, grad_fn=<SubBackward0>)\n",
      "loss: 0.021118806675076485\n",
      "tensor([[855]]) tensor(827.2354, grad_fn=<SubBackward0>)\n",
      "loss: 0.032473307102918625\n",
      "tensor([[855]]) tensor(832.5978, grad_fn=<SubBackward0>)\n",
      "loss: 0.026201428845524788\n",
      "tensor([[855]]) tensor(821.3814, grad_fn=<SubBackward0>)\n",
      "loss: 0.03932000696659088\n",
      "tensor([[855]]) tensor(817.0161, grad_fn=<SubBackward0>)\n",
      "loss: 0.0444255992770195\n",
      "tensor([[855]]) tensor(837.5001, grad_fn=<SubBackward0>)\n",
      "loss: 0.020467692986130714\n",
      "tensor([[855]]) tensor(825.0529, grad_fn=<SubBackward0>)\n",
      "loss: 0.03502587974071503\n",
      "tensor([[855]]) tensor(826.1112, grad_fn=<SubBackward0>)\n",
      "loss: 0.03378806263208389\n",
      "tensor([[855]]) tensor(830.9122, grad_fn=<SubBackward0>)\n",
      "loss: 0.028172828257083893\n",
      "tensor([[855]]) tensor(822.8788, grad_fn=<SubBackward0>)\n",
      "loss: 0.03756863623857498\n",
      "tensor([[855]]) tensor(830.2822, grad_fn=<SubBackward0>)\n",
      "loss: 0.028909675776958466\n",
      "tensor([[855]]) tensor(816.5151, grad_fn=<SubBackward0>)\n",
      "loss: 0.04501151666045189\n",
      "tensor([[855]]) tensor(820.3718, grad_fn=<SubBackward0>)\n",
      "loss: 0.04050087556242943\n",
      "tensor([[855]]) tensor(831.8823, grad_fn=<SubBackward0>)\n",
      "loss: 0.027038181200623512\n",
      "tensor([[855]]) tensor(813.7383, grad_fn=<SubBackward0>)\n",
      "loss: 0.048259321600198746\n",
      "tensor([[855]]) tensor(825.9487, grad_fn=<SubBackward0>)\n",
      "loss: 0.03397805616259575\n",
      "tensor([[855]]) tensor(820.1595, grad_fn=<SubBackward0>)\n",
      "loss: 0.040749069303274155\n",
      "tensor([[855]]) tensor(815.5404, grad_fn=<SubBackward0>)\n",
      "loss: 0.04615160822868347\n",
      "tensor([[855]]) tensor(823.6766, grad_fn=<SubBackward0>)\n",
      "loss: 0.036635514348745346\n",
      "tensor([[855]]) tensor(821.2748, grad_fn=<SubBackward0>)\n",
      "loss: 0.039444699883461\n",
      "tensor([[855]]) tensor(817.1697, grad_fn=<SubBackward0>)\n",
      "loss: 0.044245973229408264\n",
      "tensor([[855]]) tensor(831.6752, grad_fn=<SubBackward0>)\n",
      "loss: 0.027280466631054878\n",
      "tensor([[855]]) tensor(828.8938, grad_fn=<SubBackward0>)\n",
      "loss: 0.030533568933606148\n",
      "tensor([[855]]) tensor(834.8902, grad_fn=<SubBackward0>)\n",
      "loss: 0.023520253598690033\n",
      "tensor([[855]]) tensor(822.6010, grad_fn=<SubBackward0>)\n",
      "loss: 0.03789358586072922\n",
      "tensor([[855]]) tensor(828.0344, grad_fn=<SubBackward0>)\n",
      "loss: 0.031538669019937515\n",
      "tensor([[855]]) tensor(817.5125, grad_fn=<SubBackward0>)\n",
      "loss: 0.04384512081742287\n",
      "tensor([[855]]) tensor(815.0941, grad_fn=<SubBackward0>)\n",
      "loss: 0.04667358472943306\n",
      "tensor([[855]]) tensor(836.9306, grad_fn=<SubBackward0>)\n",
      "loss: 0.021133797243237495\n",
      "tensor([[855]]) tensor(819.9743, grad_fn=<SubBackward0>)\n",
      "loss: 0.0409657247364521\n",
      "tensor([[855]]) tensor(821.8687, grad_fn=<SubBackward0>)\n",
      "loss: 0.038750097155570984\n",
      "tensor([[855]]) tensor(835.9392, grad_fn=<SubBackward0>)\n",
      "loss: 0.02229328639805317\n",
      "tensor([[855]]) tensor(819.3599, grad_fn=<SubBackward0>)\n",
      "loss: 0.04168431833386421\n",
      "tensor([[855]]) tensor(826.2287, grad_fn=<SubBackward0>)\n",
      "loss: 0.03365064412355423\n",
      "tensor([[855]]) tensor(836.9980, grad_fn=<SubBackward0>)\n",
      "loss: 0.021054880693554878\n",
      "tensor([[855]]) tensor(832.9694, grad_fn=<SubBackward0>)\n",
      "loss: 0.025766830891370773\n",
      "tensor([[855]]) tensor(836.0839, grad_fn=<SubBackward0>)\n",
      "loss: 0.022124066948890686\n",
      "tensor([[855]]) tensor(842.5944, grad_fn=<SubBackward0>)\n",
      "loss: 0.014509448781609535\n",
      "tensor([[855]]) tensor(822.9229, grad_fn=<SubBackward0>)\n",
      "loss: 0.03751704469323158\n",
      "tensor([[855]]) tensor(825.5343, grad_fn=<SubBackward0>)\n",
      "loss: 0.03446283936500549\n",
      "tensor([[855]]) tensor(837.0642, grad_fn=<SubBackward0>)\n",
      "loss: 0.020977497100830078\n",
      "tensor([[855]]) tensor(831.1155, grad_fn=<SubBackward0>)\n",
      "loss: 0.027935095131397247\n",
      "tensor([[855]]) tensor(838.2051, grad_fn=<SubBackward0>)\n",
      "loss: 0.01964321918785572\n",
      "tensor([[855]]) tensor(837.0117, grad_fn=<SubBackward0>)\n",
      "loss: 0.021038996055722237\n",
      "tensor([[855]]) tensor(831.3110, grad_fn=<SubBackward0>)\n",
      "loss: 0.027706392109394073\n",
      "tensor([[855]]) tensor(835.1077, grad_fn=<SubBackward0>)\n",
      "loss: 0.02326585166156292\n",
      "tensor([[855]]) tensor(830.0360, grad_fn=<SubBackward0>)\n",
      "loss: 0.02919764816761017\n",
      "tensor([[855]]) tensor(832.2946, grad_fn=<SubBackward0>)\n",
      "loss: 0.026556039229035378\n",
      "tensor([[855]]) tensor(830.7417, grad_fn=<SubBackward0>)\n",
      "loss: 0.0283722635358572\n",
      "tensor([[855]]) tensor(830.8034, grad_fn=<SubBackward0>)\n",
      "loss: 0.028300128877162933\n",
      "tensor([[855]]) tensor(833.2775, grad_fn=<SubBackward0>)\n",
      "loss: 0.02540649101138115\n",
      "tensor([[855]]) tensor(834.3945, grad_fn=<SubBackward0>)\n",
      "loss: 0.024099962785840034\n",
      "tensor([[855]]) tensor(833.1729, grad_fn=<SubBackward0>)\n",
      "loss: 0.025528864935040474\n",
      "tensor([[855]]) tensor(828.3186, grad_fn=<SubBackward0>)\n",
      "loss: 0.03120633028447628\n",
      "tensor([[855]]) tensor(838.3226, grad_fn=<SubBackward0>)\n",
      "loss: 0.019505783915519714\n",
      "tensor([[855]]) tensor(829.5394, grad_fn=<SubBackward0>)\n",
      "loss: 0.029778463765978813\n",
      "tensor([[855]]) tensor(836.3596, grad_fn=<SubBackward0>)\n",
      "loss: 0.021801650524139404\n",
      "tensor([[855]]) tensor(825.6068, grad_fn=<SubBackward0>)\n",
      "loss: 0.03437803313136101\n",
      "tensor([[855]]) tensor(823.9338, grad_fn=<SubBackward0>)\n",
      "loss: 0.03633465617895126\n",
      "tensor([[855]]) tensor(832.2094, grad_fn=<SubBackward0>)\n",
      "loss: 0.026655729860067368\n",
      "tensor([[855]]) tensor(831.2227, grad_fn=<SubBackward0>)\n",
      "loss: 0.027809740975499153\n",
      "tensor([[855]]) tensor(835.1062, grad_fn=<SubBackward0>)\n",
      "loss: 0.023267636075615883\n",
      "tensor([[855]]) tensor(833.6995, grad_fn=<SubBackward0>)\n",
      "loss: 0.024912873283028603\n",
      "tensor([[855]]) tensor(831.6854, grad_fn=<SubBackward0>)\n",
      "loss: 0.027268581092357635\n",
      "tensor([[855]]) tensor(839.3149, grad_fn=<SubBackward0>)\n",
      "loss: 0.018345097079873085\n",
      "tensor([[855]]) tensor(824.1399, grad_fn=<SubBackward0>)\n",
      "loss: 0.03609367460012436\n",
      "tensor([[855]]) tensor(833.2584, grad_fn=<SubBackward0>)\n",
      "loss: 0.025428762659430504\n",
      "tensor([[855]]) tensor(829.1890, grad_fn=<SubBackward0>)\n",
      "loss: 0.030188273638486862\n",
      "tensor([[855]]) tensor(831.2233, grad_fn=<SubBackward0>)\n",
      "loss: 0.02780897356569767\n",
      "tensor([[855]]) tensor(830.2426, grad_fn=<SubBackward0>)\n",
      "loss: 0.028955988585948944\n",
      "tensor([[855]]) tensor(829.2523, grad_fn=<SubBackward0>)\n",
      "loss: 0.03011421114206314\n",
      "tensor([[855]]) tensor(834.4467, grad_fn=<SubBackward0>)\n",
      "loss: 0.02403891086578369\n",
      "tensor([[855]]) tensor(816.4417, grad_fn=<SubBackward0>)\n",
      "loss: 0.04509752243757248\n",
      "tensor([[855]]) tensor(814.4319, grad_fn=<SubBackward0>)\n",
      "loss: 0.047448016703128815\n",
      "tensor([[855]]) tensor(830.0201, grad_fn=<SubBackward0>)\n",
      "loss: 0.02921617217361927\n",
      "tensor([[855]]) tensor(802.0844, grad_fn=<SubBackward0>)\n",
      "loss: 0.0618896484375\n",
      "tensor([[855]]) tensor(790.7753, grad_fn=<SubBackward0>)\n",
      "loss: 0.07511664181947708\n",
      "tensor([[855]]) tensor(813.9625, grad_fn=<SubBackward0>)\n",
      "loss: 0.047997117042541504\n",
      "tensor([[855]]) tensor(840.8304, grad_fn=<SubBackward0>)\n",
      "loss: 0.016572579741477966\n",
      "tensor([[855]]) tensor(816.3458, grad_fn=<SubBackward0>)\n",
      "loss: 0.04520954191684723\n",
      "tensor([[855]]) tensor(825.0942, grad_fn=<SubBackward0>)\n",
      "loss: 0.03497753292322159\n",
      "tensor([[855]]) tensor(828.1403, grad_fn=<SubBackward0>)\n",
      "loss: 0.03141491860151291\n",
      "tensor([[855]]) tensor(812.6837, grad_fn=<SubBackward0>)\n",
      "loss: 0.049492694437503815\n",
      "tensor([[855]]) tensor(816.2521, grad_fn=<SubBackward0>)\n",
      "loss: 0.045319244265556335\n",
      "tensor([[855]]) tensor(826.2476, grad_fn=<SubBackward0>)\n",
      "loss: 0.033628515899181366\n",
      "tensor([[855]]) tensor(820.2999, grad_fn=<SubBackward0>)\n",
      "loss: 0.040584880858659744\n",
      "tensor([[855]]) tensor(828.0388, grad_fn=<SubBackward0>)\n",
      "loss: 0.0315336175262928\n",
      "tensor([[855]]) tensor(824.8350, grad_fn=<SubBackward0>)\n",
      "loss: 0.035280730575323105\n",
      "tensor([[855]]) tensor(817.0687, grad_fn=<SubBackward0>)\n",
      "loss: 0.04436415433883667\n",
      "tensor([[855]]) tensor(836.6648, grad_fn=<SubBackward0>)\n",
      "loss: 0.021444648504257202\n",
      "tensor([[855]]) tensor(824.7192, grad_fn=<SubBackward0>)\n",
      "loss: 0.035416167229413986\n",
      "tensor([[855]]) tensor(831.4791, grad_fn=<SubBackward0>)\n",
      "loss: 0.02750982902944088\n",
      "tensor([[855]]) tensor(819.8078, grad_fn=<SubBackward0>)\n",
      "loss: 0.04116048663854599\n",
      "tensor([[855]]) tensor(814.1874, grad_fn=<SubBackward0>)\n",
      "loss: 0.04773402586579323\n",
      "tensor([[855]]) tensor(833.3168, grad_fn=<SubBackward0>)\n",
      "loss: 0.025360481813549995\n",
      "tensor([[855]]) tensor(808.0562, grad_fn=<SubBackward0>)\n",
      "loss: 0.054905086755752563\n",
      "tensor([[855]]) tensor(797.8465, grad_fn=<SubBackward0>)\n",
      "loss: 0.06684619933366776\n",
      "tensor([[855]]) tensor(812.6776, grad_fn=<SubBackward0>)\n",
      "loss: 0.04949990287423134\n",
      "tensor([[855]]) tensor(828.8954, grad_fn=<SubBackward0>)\n",
      "loss: 0.03053174912929535\n",
      "tensor([[855]]) tensor(814.8000, grad_fn=<SubBackward0>)\n",
      "loss: 0.047017574310302734\n",
      "tensor([[855]]) tensor(822.7936, grad_fn=<SubBackward0>)\n",
      "loss: 0.03766823932528496\n",
      "tensor([[855]]) tensor(834.9422, grad_fn=<SubBackward0>)\n",
      "loss: 0.02345941588282585\n",
      "tensor([[855]]) tensor(836.4796, grad_fn=<SubBackward0>)\n",
      "loss: 0.021661287173628807\n",
      "tensor([[855]]) tensor(829.6982, grad_fn=<SubBackward0>)\n",
      "loss: 0.02959268167614937\n",
      "tensor([[855]]) tensor(824.2564, grad_fn=<SubBackward0>)\n",
      "loss: 0.03595743328332901\n",
      "tensor([[855]]) tensor(831.6653, grad_fn=<SubBackward0>)\n",
      "loss: 0.02729199454188347\n",
      "tensor([[855]]) tensor(817.3612, grad_fn=<SubBackward0>)\n",
      "loss: 0.044021982699632645\n",
      "tensor([[855]]) tensor(824.2830, grad_fn=<SubBackward0>)\n",
      "loss: 0.03592636436223984\n",
      "tensor([[855]]) tensor(827.1504, grad_fn=<SubBackward0>)\n",
      "loss: 0.032572608441114426\n",
      "tensor([[855]]) tensor(832.5602, grad_fn=<SubBackward0>)\n",
      "loss: 0.026245366781949997\n",
      "tensor([[855]]) tensor(837.7027, grad_fn=<SubBackward0>)\n",
      "loss: 0.02023078128695488\n",
      "tensor([[855]]) tensor(827.3521, grad_fn=<SubBackward0>)\n",
      "loss: 0.032336801290512085\n",
      "tensor([[855]]) tensor(828.2578, grad_fn=<SubBackward0>)\n",
      "loss: 0.03127741068601608\n",
      "tensor([[855]]) tensor(833.4214, grad_fn=<SubBackward0>)\n",
      "loss: 0.02523810788989067\n",
      "tensor([[855]]) tensor(829.3339, grad_fn=<SubBackward0>)\n",
      "loss: 0.03001878596842289\n",
      "tensor([[855]]) tensor(841.1388, grad_fn=<SubBackward0>)\n",
      "loss: 0.016211900860071182\n",
      "tensor([[855]]) tensor(820.6008, grad_fn=<SubBackward0>)\n",
      "loss: 0.040232911705970764\n",
      "tensor([[855]]) tensor(821.3738, grad_fn=<SubBackward0>)\n",
      "loss: 0.03932887688279152\n",
      "tensor([[855]]) tensor(842.2031, grad_fn=<SubBackward0>)\n",
      "loss: 0.014967105351388454\n",
      "tensor([[855]]) tensor(829.7061, grad_fn=<SubBackward0>)\n",
      "loss: 0.02958359755575657\n",
      "tensor([[855]]) tensor(839.6051, grad_fn=<SubBackward0>)\n",
      "loss: 0.018005728721618652\n",
      "tensor([[855]]) tensor(835.5055, grad_fn=<SubBackward0>)\n",
      "loss: 0.02280062809586525\n",
      "tensor([[855]]) tensor(831.2458, grad_fn=<SubBackward0>)\n",
      "loss: 0.02778266742825508\n",
      "tensor([[855]]) tensor(838.3167, grad_fn=<SubBackward0>)\n",
      "loss: 0.019512725993990898\n",
      "tensor([[855]]) tensor(838.7998, grad_fn=<SubBackward0>)\n",
      "loss: 0.018947632983326912\n",
      "tensor([[855]]) tensor(834.4668, grad_fn=<SubBackward0>)\n",
      "loss: 0.02401542477309704\n",
      "tensor([[855]]) tensor(840.3176, grad_fn=<SubBackward0>)\n",
      "loss: 0.0171724371612072\n",
      "tensor([[855]]) tensor(833.0181, grad_fn=<SubBackward0>)\n",
      "loss: 0.02570982836186886\n",
      "tensor([[855]]) tensor(839.0392, grad_fn=<SubBackward0>)\n",
      "loss: 0.018667656928300858\n",
      "tensor([[855]]) tensor(841.9080, grad_fn=<SubBackward0>)\n",
      "loss: 0.015312292613089085\n",
      "tensor([[855]]) tensor(834.7269, grad_fn=<SubBackward0>)\n",
      "loss: 0.023711157962679863\n",
      "tensor([[855]]) tensor(836.9978, grad_fn=<SubBackward0>)\n",
      "loss: 0.02105523645877838\n",
      "tensor([[855]]) tensor(836.9709, grad_fn=<SubBackward0>)\n",
      "loss: 0.021086575463414192\n",
      "tensor([[855]]) tensor(835.4513, grad_fn=<SubBackward0>)\n",
      "loss: 0.022864000871777534\n",
      "tensor([[855]]) tensor(836.2104, grad_fn=<SubBackward0>)\n",
      "loss: 0.02197611890733242\n",
      "tensor([[855]]) tensor(843.6389, grad_fn=<SubBackward0>)\n",
      "loss: 0.013287781737744808\n",
      "tensor([[855]]) tensor(827.0656, grad_fn=<SubBackward0>)\n",
      "loss: 0.03267186880111694\n",
      "tensor([[855]]) tensor(839.1556, grad_fn=<SubBackward0>)\n",
      "loss: 0.018531380221247673\n",
      "tensor([[855]]) tensor(824.9670, grad_fn=<SubBackward0>)\n",
      "loss: 0.03512632101774216\n",
      "tensor([[855]]) tensor(824.0225, grad_fn=<SubBackward0>)\n",
      "loss: 0.03623107448220253\n",
      "tensor([[855]]) tensor(840.8174, grad_fn=<SubBackward0>)\n",
      "loss: 0.0165878739207983\n",
      "tensor([[855]]) tensor(835.0426, grad_fn=<SubBackward0>)\n",
      "loss: 0.023341966792941093\n",
      "tensor([[855]]) tensor(841.1160, grad_fn=<SubBackward0>)\n",
      "loss: 0.016238654032349586\n",
      "tensor([[855]]) tensor(832.0834, grad_fn=<SubBackward0>)\n",
      "loss: 0.02680303528904915\n",
      "tensor([[855]]) tensor(843.5750, grad_fn=<SubBackward0>)\n",
      "loss: 0.01336266566067934\n",
      "tensor([[855]]) tensor(825.6458, grad_fn=<SubBackward0>)\n",
      "loss: 0.03433247283101082\n",
      "tensor([[855]]) tensor(832.4069, grad_fn=<SubBackward0>)\n",
      "loss: 0.026424670591950417\n",
      "tensor([[855]]) tensor(829.8066, grad_fn=<SubBackward0>)\n",
      "loss: 0.02946595288813114\n",
      "tensor([[855]]) tensor(827.7854, grad_fn=<SubBackward0>)\n",
      "loss: 0.03182997554540634\n",
      "tensor([[855]]) tensor(842.7278, grad_fn=<SubBackward0>)\n",
      "loss: 0.01435346994549036\n",
      "tensor([[855]]) tensor(831.0164, grad_fn=<SubBackward0>)\n",
      "loss: 0.028051026165485382\n",
      "tensor([[855]]) tensor(839.0269, grad_fn=<SubBackward0>)\n",
      "loss: 0.018681950867176056\n",
      "tensor([[855]]) tensor(834.7067, grad_fn=<SubBackward0>)\n",
      "loss: 0.023734895512461662\n",
      "tensor([[855]]) tensor(834.4547, grad_fn=<SubBackward0>)\n",
      "loss: 0.02402954176068306\n",
      "tensor([[855]]) tensor(838.4331, grad_fn=<SubBackward0>)\n",
      "loss: 0.01937648467719555\n",
      "tensor([[855]]) tensor(831.4662, grad_fn=<SubBackward0>)\n",
      "loss: 0.027524856850504875\n",
      "tensor([[855]]) tensor(833.6675, grad_fn=<SubBackward0>)\n",
      "loss: 0.02495022676885128\n",
      "tensor([[855]]) tensor(830.0267, grad_fn=<SubBackward0>)\n",
      "loss: 0.029208535328507423\n",
      "tensor([[855]]) tensor(835.0691, grad_fn=<SubBackward0>)\n",
      "loss: 0.023311004042625427\n",
      "tensor([[855]]) tensor(834.1072, grad_fn=<SubBackward0>)\n",
      "loss: 0.02443595975637436\n",
      "tensor([[855]]) tensor(838.2463, grad_fn=<SubBackward0>)\n",
      "loss: 0.019594961777329445\n",
      "tensor([[855]]) tensor(828.6663, grad_fn=<SubBackward0>)\n",
      "loss: 0.030799731612205505\n",
      "tensor([[855]]) tensor(829.0195, grad_fn=<SubBackward0>)\n",
      "loss: 0.03038647770881653\n",
      "tensor([[855]]) tensor(839.3683, grad_fn=<SubBackward0>)\n",
      "loss: 0.01828274130821228\n",
      "tensor([[855]]) tensor(832.7198, grad_fn=<SubBackward0>)\n",
      "loss: 0.026058746501803398\n",
      "tensor([[855]]) tensor(840.3370, grad_fn=<SubBackward0>)\n",
      "loss: 0.0171496644616127\n",
      "tensor([[855]]) tensor(836.5864, grad_fn=<SubBackward0>)\n",
      "loss: 0.021536415442824364\n",
      "tensor([[855]]) tensor(843.2281, grad_fn=<SubBackward0>)\n",
      "loss: 0.01376824639737606\n",
      "tensor([[855]]) tensor(840.2747, grad_fn=<SubBackward0>)\n",
      "loss: 0.01722262240946293\n",
      "tensor([[855]]) tensor(835.3185, grad_fn=<SubBackward0>)\n",
      "loss: 0.02301928400993347\n",
      "tensor([[855]]) tensor(842.8109, grad_fn=<SubBackward0>)\n",
      "loss: 0.014256241731345654\n",
      "tensor([[855]]) tensor(836.0417, grad_fn=<SubBackward0>)\n",
      "loss: 0.022173358127474785\n",
      "tensor([[855]]) tensor(832.7579, grad_fn=<SubBackward0>)\n",
      "loss: 0.026014147326350212\n",
      "tensor([[855]]) tensor(838.7180, grad_fn=<SubBackward0>)\n",
      "loss: 0.019043218344449997\n",
      "tensor([[855]]) tensor(832.3665, grad_fn=<SubBackward0>)\n",
      "loss: 0.026471929624676704\n",
      "tensor([[855]]) tensor(841.4144, grad_fn=<SubBackward0>)\n",
      "loss: 0.015889646485447884\n",
      "tensor([[855]]) tensor(834.5045, grad_fn=<SubBackward0>)\n",
      "loss: 0.023971397429704666\n",
      "tensor([[855]]) tensor(837.8899, grad_fn=<SubBackward0>)\n",
      "loss: 0.020011821761727333\n",
      "tensor([[855]]) tensor(828.4290, grad_fn=<SubBackward0>)\n",
      "loss: 0.031077280640602112\n",
      "tensor([[855]]) tensor(828.5408, grad_fn=<SubBackward0>)\n",
      "loss: 0.030946465209126472\n",
      "tensor([[855]]) tensor(833.9500, grad_fn=<SubBackward0>)\n",
      "loss: 0.02461995743215084\n",
      "tensor([[855]]) tensor(835.0846, grad_fn=<SubBackward0>)\n",
      "loss: 0.0232929065823555\n",
      "tensor([[855]]) tensor(833.9360, grad_fn=<SubBackward0>)\n",
      "loss: 0.024636216461658478\n",
      "tensor([[855]]) tensor(840.7887, grad_fn=<SubBackward0>)\n",
      "loss: 0.01662137173116207\n",
      "tensor([[855]]) tensor(820.2023, grad_fn=<SubBackward0>)\n",
      "loss: 0.04069900885224342\n",
      "tensor([[855]]) tensor(819.9337, grad_fn=<SubBackward0>)\n",
      "loss: 0.04101323336362839\n",
      "tensor([[855]]) tensor(836.3348, grad_fn=<SubBackward0>)\n",
      "loss: 0.021830562502145767\n",
      "tensor([[855]]) tensor(815.1589, grad_fn=<SubBackward0>)\n",
      "loss: 0.046597808599472046\n",
      "tensor([[855]]) tensor(811.7363, grad_fn=<SubBackward0>)\n",
      "loss: 0.050600823014974594\n",
      "tensor([[855]]) tensor(834.5365, grad_fn=<SubBackward0>)\n",
      "loss: 0.023933883756399155\n",
      "tensor([[855]]) tensor(815.2773, grad_fn=<SubBackward0>)\n",
      "loss: 0.046459246426820755\n",
      "tensor([[855]]) tensor(798.1144, grad_fn=<SubBackward0>)\n",
      "loss: 0.06653282046318054\n",
      "tensor([[855]]) tensor(807.9470, grad_fn=<SubBackward0>)\n",
      "loss: 0.055032722651958466\n",
      "tensor([[855]]) tensor(835.2759, grad_fn=<SubBackward0>)\n",
      "loss: 0.02306913025677204\n",
      "tensor([[855]]) tensor(807.7720, grad_fn=<SubBackward0>)\n",
      "loss: 0.05523742362856865\n",
      "tensor([[855]]) tensor(798.2905, grad_fn=<SubBackward0>)\n",
      "loss: 0.06632683426141739\n",
      "tensor([[855]]) tensor(814.7802, grad_fn=<SubBackward0>)\n",
      "loss: 0.04704075679183006\n",
      "tensor([[855]]) tensor(837.1201, grad_fn=<SubBackward0>)\n",
      "loss: 0.02091219648718834\n",
      "tensor([[855]]) tensor(817.0450, grad_fn=<SubBackward0>)\n",
      "loss: 0.04439179599285126\n",
      "tensor([[855]]) tensor(828.9770, grad_fn=<SubBackward0>)\n",
      "loss: 0.03043626993894577\n",
      "tensor([[855]]) tensor(831.8252, grad_fn=<SubBackward0>)\n",
      "loss: 0.027104999870061874\n",
      "tensor([[855]]) tensor(825.9715, grad_fn=<SubBackward0>)\n",
      "loss: 0.03395148366689682\n",
      "tensor([[855]]) tensor(831.3995, grad_fn=<SubBackward0>)\n",
      "loss: 0.02760288119316101\n",
      "tensor([[855]]) tensor(833.5377, grad_fn=<SubBackward0>)\n",
      "loss: 0.025102099403738976\n",
      "tensor([[855]]) tensor(839.4844, grad_fn=<SubBackward0>)\n",
      "loss: 0.018146876245737076\n",
      "tensor([[855]]) tensor(827.4318, grad_fn=<SubBackward0>)\n",
      "loss: 0.03224358707666397\n",
      "tensor([[855]]) tensor(841.1656, grad_fn=<SubBackward0>)\n",
      "loss: 0.01618054509162903\n",
      "tensor([[855]]) tensor(835.4913, grad_fn=<SubBackward0>)\n",
      "loss: 0.02281724289059639\n",
      "tensor([[855]]) tensor(834.3232, grad_fn=<SubBackward0>)\n",
      "loss: 0.02418334223330021\n",
      "tensor([[855]]) tensor(833.3055, grad_fn=<SubBackward0>)\n",
      "loss: 0.025373706594109535\n",
      "tensor([[855]]) tensor(838.4469, grad_fn=<SubBackward0>)\n",
      "loss: 0.019360333681106567\n",
      "tensor([[855]]) tensor(843.8572, grad_fn=<SubBackward0>)\n",
      "loss: 0.013032451272010803\n",
      "tensor([[855]]) tensor(834.6049, grad_fn=<SubBackward0>)\n",
      "loss: 0.023853931576013565\n",
      "tensor([[855]]) tensor(843.5934, grad_fn=<SubBackward0>)\n",
      "loss: 0.01334100030362606\n",
      "tensor([[855]]) tensor(837.4988, grad_fn=<SubBackward0>)\n",
      "loss: 0.020469175651669502\n",
      "tensor([[855]]) tensor(836.7821, grad_fn=<SubBackward0>)\n",
      "loss: 0.02130751498043537\n",
      "tensor([[855]]) tensor(840.3304, grad_fn=<SubBackward0>)\n",
      "loss: 0.01715739257633686\n",
      "tensor([[855]]) tensor(841.6684, grad_fn=<SubBackward0>)\n",
      "loss: 0.015592501498758793\n",
      "tensor([[855]]) tensor(837.4223, grad_fn=<SubBackward0>)\n",
      "loss: 0.020558727905154228\n",
      "tensor([[855]]) tensor(833.0110, grad_fn=<SubBackward0>)\n",
      "loss: 0.025718091055750847\n",
      "tensor([[855]]) tensor(836.0549, grad_fn=<SubBackward0>)\n",
      "loss: 0.02215793915092945\n",
      "tensor([[855]]) tensor(833.1665, grad_fn=<SubBackward0>)\n",
      "loss: 0.02553621679544449\n",
      "tensor([[855]]) tensor(835.3228, grad_fn=<SubBackward0>)\n",
      "loss: 0.023014340549707413\n",
      "tensor([[855]]) tensor(836.6499, grad_fn=<SubBackward0>)\n",
      "loss: 0.02146213874220848\n",
      "tensor([[855]]) tensor(834.1589, grad_fn=<SubBackward0>)\n",
      "loss: 0.024375567212700844\n",
      "tensor([[855]]) tensor(837.2479, grad_fn=<SubBackward0>)\n",
      "loss: 0.020762626081705093\n",
      "tensor([[855]]) tensor(837.3441, grad_fn=<SubBackward0>)\n",
      "loss: 0.02065015584230423\n",
      "tensor([[855]]) tensor(834.9291, grad_fn=<SubBackward0>)\n",
      "loss: 0.023474764078855515\n",
      "tensor([[855]]) tensor(837.1796, grad_fn=<SubBackward0>)\n",
      "loss: 0.02084263227880001\n",
      "tensor([[855]]) tensor(833.0140, grad_fn=<SubBackward0>)\n",
      "loss: 0.025714611634612083\n",
      "tensor([[855]]) tensor(835.0674, grad_fn=<SubBackward0>)\n",
      "loss: 0.023313038051128387\n",
      "tensor([[855]]) tensor(830.5654, grad_fn=<SubBackward0>)\n",
      "loss: 0.028578445315361023\n",
      "tensor([[855]]) tensor(830.0842, grad_fn=<SubBackward0>)\n",
      "loss: 0.029141271486878395\n",
      "tensor([[855]]) tensor(845.4755, grad_fn=<SubBackward0>)\n",
      "loss: 0.011139843612909317\n",
      "tensor([[855]]) tensor(838.8615, grad_fn=<SubBackward0>)\n",
      "loss: 0.018875425681471825\n",
      "tensor([[855]]) tensor(840.6052, grad_fn=<SubBackward0>)\n",
      "loss: 0.016835959628224373\n",
      "tensor([[855]]) tensor(841.6302, grad_fn=<SubBackward0>)\n",
      "loss: 0.01563720777630806\n",
      "tensor([[855]]) tensor(842.8973, grad_fn=<SubBackward0>)\n",
      "loss: 0.014155123382806778\n",
      "tensor([[855]]) tensor(845.3999, grad_fn=<SubBackward0>)\n",
      "loss: 0.011228148825466633\n",
      "tensor([[855]]) tensor(840.2358, grad_fn=<SubBackward0>)\n",
      "loss: 0.01726800575852394\n",
      "tensor([[855]]) tensor(838.3050, grad_fn=<SubBackward0>)\n",
      "loss: 0.019526325166225433\n",
      "tensor([[855]]) tensor(836.3481, grad_fn=<SubBackward0>)\n",
      "loss: 0.02181510627269745\n",
      "tensor([[855]]) tensor(836.2496, grad_fn=<SubBackward0>)\n",
      "loss: 0.021930307149887085\n",
      "tensor([[855]]) tensor(842.6475, grad_fn=<SubBackward0>)\n",
      "loss: 0.01444732490926981\n",
      "tensor([[855]]) tensor(826.3763, grad_fn=<SubBackward0>)\n",
      "loss: 0.03347792476415634\n",
      "tensor([[855]]) tensor(840.7769, grad_fn=<SubBackward0>)\n",
      "loss: 0.01663525588810444\n",
      "tensor([[855]]) tensor(822.8055, grad_fn=<SubBackward0>)\n",
      "loss: 0.0376543365418911\n",
      "tensor([[855]]) tensor(817.9615, grad_fn=<SubBackward0>)\n",
      "loss: 0.043319810181856155\n",
      "tensor([[855]]) tensor(831.1146, grad_fn=<SubBackward0>)\n",
      "loss: 0.027936147525906563\n",
      "tensor([[855]]) tensor(831.8833, grad_fn=<SubBackward0>)\n",
      "loss: 0.027037039399147034\n",
      "tensor([[855]]) tensor(840.6646, grad_fn=<SubBackward0>)\n",
      "loss: 0.016766607761383057\n",
      "tensor([[855]]) tensor(825.0604, grad_fn=<SubBackward0>)\n",
      "loss: 0.035017117857933044\n",
      "tensor([[855]]) tensor(829.2437, grad_fn=<SubBackward0>)\n",
      "loss: 0.030124418437480927\n",
      "tensor([[855]]) tensor(825.6066, grad_fn=<SubBackward0>)\n",
      "loss: 0.03437826409935951\n",
      "tensor([[855]]) tensor(824.2678, grad_fn=<SubBackward0>)\n",
      "loss: 0.035944048315286636\n",
      "tensor([[855]]) tensor(829.3021, grad_fn=<SubBackward0>)\n",
      "loss: 0.03005608543753624\n",
      "tensor([[855]]) tensor(812.6027, grad_fn=<SubBackward0>)\n",
      "loss: 0.049587514251470566\n",
      "tensor([[855]]) tensor(816.9546, grad_fn=<SubBackward0>)\n",
      "loss: 0.044497571885585785\n",
      "tensor([[855]]) tensor(834.9628, grad_fn=<SubBackward0>)\n",
      "loss: 0.023435287177562714\n",
      "tensor([[855]]) tensor(818.0519, grad_fn=<SubBackward0>)\n",
      "loss: 0.043214213103055954\n",
      "tensor([[855]]) tensor(818.7105, grad_fn=<SubBackward0>)\n",
      "loss: 0.04244384914636612\n",
      "tensor([[855]]) tensor(837.5710, grad_fn=<SubBackward0>)\n",
      "loss: 0.020384831354022026\n",
      "tensor([[855]]) tensor(821.4945, grad_fn=<SubBackward0>)\n",
      "loss: 0.03918774798512459\n",
      "tensor([[855]]) tensor(825.8328, grad_fn=<SubBackward0>)\n",
      "loss: 0.03411370888352394\n",
      "tensor([[855]]) tensor(836.0233, grad_fn=<SubBackward0>)\n",
      "loss: 0.02219495363533497\n",
      "tensor([[855]]) tensor(830.4249, grad_fn=<SubBackward0>)\n",
      "loss: 0.028742864727973938\n",
      "tensor([[855]]) tensor(839.5390, grad_fn=<SubBackward0>)\n",
      "loss: 0.018083039671182632\n",
      "tensor([[855]]) tensor(837.3247, grad_fn=<SubBackward0>)\n",
      "loss: 0.02067282237112522\n",
      "tensor([[855]]) tensor(829.3633, grad_fn=<SubBackward0>)\n",
      "loss: 0.02998446673154831\n",
      "tensor([[855]]) tensor(827.5639, grad_fn=<SubBackward0>)\n",
      "loss: 0.0320889838039875\n",
      "tensor([[855]]) tensor(842.5464, grad_fn=<SubBackward0>)\n",
      "loss: 0.014565665274858475\n",
      "tensor([[855]]) tensor(822.0752, grad_fn=<SubBackward0>)\n",
      "loss: 0.03850850835442543\n",
      "tensor([[855]]) tensor(828.2438, grad_fn=<SubBackward0>)\n",
      "loss: 0.03129386529326439\n",
      "tensor([[855]]) tensor(832.4397, grad_fn=<SubBackward0>)\n",
      "loss: 0.02638631872832775\n",
      "tensor([[855]]) tensor(825.6431, grad_fn=<SubBackward0>)\n",
      "loss: 0.03433561325073242\n",
      "tensor([[855]]) tensor(839.5659, grad_fn=<SubBackward0>)\n",
      "loss: 0.01805162988603115\n",
      "tensor([[855]]) tensor(817.2142, grad_fn=<SubBackward0>)\n",
      "loss: 0.04419393092393875\n",
      "tensor([[855]]) tensor(811.5766, grad_fn=<SubBackward0>)\n",
      "loss: 0.050787586718797684\n",
      "tensor([[855]]) tensor(826.1799, grad_fn=<SubBackward0>)\n",
      "loss: 0.03370768204331398\n",
      "tensor([[855]]) tensor(818.6526, grad_fn=<SubBackward0>)\n",
      "loss: 0.042511627078056335\n",
      "tensor([[855]]) tensor(814.5288, grad_fn=<SubBackward0>)\n",
      "loss: 0.047334689646959305\n",
      "tensor([[855]]) tensor(839.3987, grad_fn=<SubBackward0>)\n",
      "loss: 0.018247120082378387\n",
      "tensor([[855]]) tensor(820.7094, grad_fn=<SubBackward0>)\n",
      "loss: 0.04010598734021187\n",
      "tensor([[855]]) tensor(813.0195, grad_fn=<SubBackward0>)\n",
      "loss: 0.04910001531243324\n",
      "tensor([[855]]) tensor(829.6641, grad_fn=<SubBackward0>)\n",
      "loss: 0.02963271178305149\n",
      "tensor([[855]]) tensor(817.8508, grad_fn=<SubBackward0>)\n",
      "loss: 0.04344935715198517\n",
      "tensor([[855]]) tensor(800.9874, grad_fn=<SubBackward0>)\n",
      "loss: 0.06317266821861267\n",
      "tensor([[855]]) tensor(811.2115, grad_fn=<SubBackward0>)\n",
      "loss: 0.05121452733874321\n",
      "tensor([[855]]) tensor(835.5072, grad_fn=<SubBackward0>)\n",
      "loss: 0.02279859408736229\n",
      "tensor([[855]]) tensor(815.7763, grad_fn=<SubBackward0>)\n",
      "loss: 0.0458756648004055\n",
      "tensor([[855]]) tensor(807.1322, grad_fn=<SubBackward0>)\n",
      "loss: 0.05598573014140129\n",
      "tensor([[855]]) tensor(822.0610, grad_fn=<SubBackward0>)\n",
      "loss: 0.03852517530322075\n",
      "tensor([[855]]) tensor(832.4082, grad_fn=<SubBackward0>)\n",
      "loss: 0.026423119008541107\n",
      "tensor([[855]]) tensor(824.6760, grad_fn=<SubBackward0>)\n",
      "loss: 0.035466618835926056\n",
      "tensor([[855]]) tensor(832.2261, grad_fn=<SubBackward0>)\n",
      "loss: 0.026636099442839622\n",
      "tensor([[855]]) tensor(830.6104, grad_fn=<SubBackward0>)\n",
      "loss: 0.028525816276669502\n",
      "tensor([[855]]) tensor(831.4659, grad_fn=<SubBackward0>)\n",
      "loss: 0.027525195851922035\n",
      "tensor([[855]]) tensor(831.1694, grad_fn=<SubBackward0>)\n",
      "loss: 0.027872007340192795\n",
      "tensor([[855]]) tensor(825.2594, grad_fn=<SubBackward0>)\n",
      "loss: 0.03478432819247246\n",
      "tensor([[855]]) tensor(835.1232, grad_fn=<SubBackward0>)\n",
      "loss: 0.02324768342077732\n",
      "tensor([[855]]) tensor(832.7999, grad_fn=<SubBackward0>)\n",
      "loss: 0.025965087115764618\n",
      "tensor([[855]]) tensor(840.8593, grad_fn=<SubBackward0>)\n",
      "loss: 0.016538886353373528\n",
      "tensor([[855]]) tensor(840.6601, grad_fn=<SubBackward0>)\n",
      "loss: 0.016771817579865456\n",
      "tensor([[855]]) tensor(842.4703, grad_fn=<SubBackward0>)\n",
      "loss: 0.014654576778411865\n",
      "tensor([[855]]) tensor(828.6207, grad_fn=<SubBackward0>)\n",
      "loss: 0.030852951109409332\n",
      "tensor([[855]]) tensor(838.5560, grad_fn=<SubBackward0>)\n",
      "loss: 0.019232748076319695\n",
      "tensor([[855]]) tensor(831.6086, grad_fn=<SubBackward0>)\n",
      "loss: 0.027358312159776688\n",
      "tensor([[855]]) tensor(840.6786, grad_fn=<SubBackward0>)\n",
      "loss: 0.016750117763876915\n",
      "tensor([[855]]) tensor(829.9445, grad_fn=<SubBackward0>)\n",
      "loss: 0.029304727911949158\n",
      "tensor([[855]]) tensor(831.9396, grad_fn=<SubBackward0>)\n",
      "loss: 0.026971185579895973\n",
      "tensor([[855]]) tensor(827.4612, grad_fn=<SubBackward0>)\n",
      "loss: 0.03220914304256439\n",
      "tensor([[855]]) tensor(827.6583, grad_fn=<SubBackward0>)\n",
      "loss: 0.03197860345244408\n",
      "tensor([[855]]) tensor(835.1937, grad_fn=<SubBackward0>)\n",
      "loss: 0.023165233433246613\n",
      "tensor([[855]]) tensor(819.3054, grad_fn=<SubBackward0>)\n",
      "loss: 0.04174806550145149\n",
      "tensor([[855]]) tensor(815.1954, grad_fn=<SubBackward0>)\n",
      "loss: 0.04655510187149048\n",
      "tensor([[855]]) tensor(828.1243, grad_fn=<SubBackward0>)\n",
      "loss: 0.03143357113003731\n",
      "tensor([[855]]) tensor(826.8494, grad_fn=<SubBackward0>)\n",
      "loss: 0.03292475640773773\n",
      "tensor([[855]]) tensor(830.4131, grad_fn=<SubBackward0>)\n",
      "loss: 0.02875658869743347\n",
      "tensor([[855]]) tensor(828.9965, grad_fn=<SubBackward0>)\n",
      "loss: 0.030413426458835602\n",
      "tensor([[855]]) tensor(835.3825, grad_fn=<SubBackward0>)\n",
      "loss: 0.022944435477256775\n",
      "tensor([[855]]) tensor(834.9560, grad_fn=<SubBackward0>)\n",
      "loss: 0.023443300276994705\n",
      "tensor([[855]]) tensor(833.1768, grad_fn=<SubBackward0>)\n",
      "loss: 0.025524171069264412\n",
      "tensor([[855]]) tensor(831.7179, grad_fn=<SubBackward0>)\n",
      "loss: 0.027230530977249146\n",
      "tensor([[855]]) tensor(840.9097, grad_fn=<SubBackward0>)\n",
      "loss: 0.016479849815368652\n",
      "tensor([[855]]) tensor(828.1256, grad_fn=<SubBackward0>)\n",
      "loss: 0.03143206983804703\n",
      "tensor([[855]]) tensor(821.9399, grad_fn=<SubBackward0>)\n",
      "loss: 0.03866680711507797\n",
      "tensor([[855]]) tensor(833.9941, grad_fn=<SubBackward0>)\n",
      "loss: 0.0245683453977108\n",
      "tensor([[855]]) tensor(843.1492, grad_fn=<SubBackward0>)\n",
      "loss: 0.013860548846423626\n",
      "tensor([[855]]) tensor(838.3912, grad_fn=<SubBackward0>)\n",
      "loss: 0.01942552626132965\n",
      "tensor([[855]]) tensor(830.8139, grad_fn=<SubBackward0>)\n",
      "loss: 0.02828783169388771\n",
      "tensor([[855]]) tensor(834.2520, grad_fn=<SubBackward0>)\n",
      "loss: 0.024266650900244713\n",
      "tensor([[855]]) tensor(841.3538, grad_fn=<SubBackward0>)\n",
      "loss: 0.01596054993569851\n",
      "tensor([[855]]) tensor(828.6374, grad_fn=<SubBackward0>)\n",
      "loss: 0.030833479017019272\n",
      "tensor([[855]]) tensor(839.0317, grad_fn=<SubBackward0>)\n",
      "loss: 0.018676329404115677\n",
      "tensor([[855]]) tensor(816.7178, grad_fn=<SubBackward0>)\n",
      "loss: 0.04477455094456673\n",
      "tensor([[855]]) tensor(819.4872, grad_fn=<SubBackward0>)\n",
      "loss: 0.04153544083237648\n",
      "tensor([[855]]) tensor(829.2030, grad_fn=<SubBackward0>)\n",
      "loss: 0.03017192706465721\n",
      "tensor([[855]]) tensor(829.9744, grad_fn=<SubBackward0>)\n",
      "loss: 0.029269730672240257\n",
      "tensor([[855]]) tensor(841.9174, grad_fn=<SubBackward0>)\n",
      "loss: 0.015301316976547241\n",
      "tensor([[855]]) tensor(815.3088, grad_fn=<SubBackward0>)\n",
      "loss: 0.046422481536865234\n",
      "tensor([[855]]) tensor(817.8709, grad_fn=<SubBackward0>)\n",
      "loss: 0.04342583566904068\n",
      "tensor([[855]]) tensor(835.9471, grad_fn=<SubBackward0>)\n",
      "loss: 0.0222840066999197\n",
      "tensor([[855]]) tensor(833.9542, grad_fn=<SubBackward0>)\n",
      "loss: 0.024615032598376274\n",
      "tensor([[855]]) tensor(835.8796, grad_fn=<SubBackward0>)\n",
      "loss: 0.022362977266311646\n",
      "tensor([[855]]) tensor(837.0905, grad_fn=<SubBackward0>)\n",
      "loss: 0.020946748554706573\n",
      "tensor([[855]]) tensor(835.4556, grad_fn=<SubBackward0>)\n",
      "loss: 0.02285902202129364\n",
      "tensor([[855]]) tensor(833.1713, grad_fn=<SubBackward0>)\n",
      "loss: 0.025530613958835602\n",
      "tensor([[855]]) tensor(837.5386, grad_fn=<SubBackward0>)\n",
      "loss: 0.020422648638486862\n",
      "tensor([[855]]) tensor(840.3633, grad_fn=<SubBackward0>)\n",
      "loss: 0.017118897289037704\n",
      "tensor([[855]]) tensor(841.5466, grad_fn=<SubBackward0>)\n",
      "loss: 0.01573500595986843\n",
      "tensor([[855]]) tensor(838.9763, grad_fn=<SubBackward0>)\n",
      "loss: 0.018741220235824585\n",
      "tensor([[855]]) tensor(838.5181, grad_fn=<SubBackward0>)\n",
      "loss: 0.01927715167403221\n",
      "tensor([[855]]) tensor(843.0575, grad_fn=<SubBackward0>)\n",
      "loss: 0.013967877253890038\n",
      "tensor([[855]]) tensor(825.8107, grad_fn=<SubBackward0>)\n",
      "loss: 0.03413955122232437\n",
      "tensor([[855]]) tensor(828.9634, grad_fn=<SubBackward0>)\n",
      "loss: 0.030452188104391098\n",
      "tensor([[855]]) tensor(841.2306, grad_fn=<SubBackward0>)\n",
      "loss: 0.016104571521282196\n",
      "tensor([[855]]) tensor(837.3571, grad_fn=<SubBackward0>)\n",
      "loss: 0.020634986460208893\n",
      "tensor([[855]]) tensor(837.3215, grad_fn=<SubBackward0>)\n",
      "loss: 0.020676659420132637\n",
      "tensor([[855]]) tensor(833.5963, grad_fn=<SubBackward0>)\n",
      "loss: 0.025033587589859962\n",
      "tensor([[855]]) tensor(832.7189, grad_fn=<SubBackward0>)\n",
      "loss: 0.026059728115797043\n",
      "tensor([[855]]) tensor(835.6254, grad_fn=<SubBackward0>)\n",
      "loss: 0.02266031876206398\n",
      "tensor([[855]]) tensor(831.5431, grad_fn=<SubBackward0>)\n",
      "loss: 0.02743496373295784\n",
      "tensor([[855]]) tensor(832.5738, grad_fn=<SubBackward0>)\n",
      "loss: 0.026229484006762505\n",
      "tensor([[855]]) tensor(836.5554, grad_fn=<SubBackward0>)\n",
      "loss: 0.021572697907686234\n",
      "tensor([[855]]) tensor(832.8895, grad_fn=<SubBackward0>)\n",
      "loss: 0.025860274210572243\n",
      "tensor([[855]]) tensor(843.1806, grad_fn=<SubBackward0>)\n",
      "loss: 0.01382385566830635\n",
      "tensor([[855]]) tensor(831.6940, grad_fn=<SubBackward0>)\n",
      "loss: 0.027258479967713356\n",
      "tensor([[855]]) tensor(838.9144, grad_fn=<SubBackward0>)\n",
      "loss: 0.018813498318195343\n",
      "tensor([[855]]) tensor(839.1298, grad_fn=<SubBackward0>)\n",
      "loss: 0.018561629578471184\n",
      "tensor([[855]]) tensor(841.7991, grad_fn=<SubBackward0>)\n",
      "loss: 0.015439717099070549\n",
      "tensor([[855]]) tensor(841.5785, grad_fn=<SubBackward0>)\n",
      "loss: 0.015697671100497246\n",
      "tensor([[855]]) tensor(837.9296, grad_fn=<SubBackward0>)\n",
      "loss: 0.01996542140841484\n",
      "tensor([[855]]) tensor(839.3001, grad_fn=<SubBackward0>)\n",
      "loss: 0.018362443894147873\n",
      "tensor([[855]]) tensor(840.6233, grad_fn=<SubBackward0>)\n",
      "loss: 0.016814881935715675\n",
      "tensor([[855]]) tensor(833.4271, grad_fn=<SubBackward0>)\n",
      "loss: 0.025231415405869484\n",
      "tensor([[855]]) tensor(843.4506, grad_fn=<SubBackward0>)\n",
      "loss: 0.01350813265889883\n",
      "tensor([[855]]) tensor(831.0930, grad_fn=<SubBackward0>)\n",
      "loss: 0.027961382642388344\n",
      "tensor([[855]]) tensor(836.2376, grad_fn=<SubBackward0>)\n",
      "loss: 0.021944332867860794\n",
      "tensor([[855]]) tensor(824.5713, grad_fn=<SubBackward0>)\n",
      "loss: 0.03558911755681038\n",
      "tensor([[855]]) tensor(825.4562, grad_fn=<SubBackward0>)\n",
      "loss: 0.03455416113138199\n",
      "tensor([[855]]) tensor(841.7507, grad_fn=<SubBackward0>)\n",
      "loss: 0.015496272593736649\n",
      "tensor([[855]]) tensor(834.1555, grad_fn=<SubBackward0>)\n",
      "loss: 0.02437954768538475\n",
      "tensor([[855]]) tensor(840.2306, grad_fn=<SubBackward0>)\n",
      "loss: 0.01727418042719364\n",
      "tensor([[855]]) tensor(844.1068, grad_fn=<SubBackward0>)\n",
      "loss: 0.012740607373416424\n",
      "tensor([[855]]) tensor(839.5307, grad_fn=<SubBackward0>)\n",
      "loss: 0.018092747777700424\n",
      "tensor([[855]]) tensor(841.4838, grad_fn=<SubBackward0>)\n",
      "loss: 0.015808479860424995\n",
      "tensor([[855]]) tensor(842.6311, grad_fn=<SubBackward0>)\n",
      "loss: 0.014466545544564724\n",
      "tensor([[855]]) tensor(842.7703, grad_fn=<SubBackward0>)\n",
      "loss: 0.014303821139037609\n",
      "tensor([[855]]) tensor(839.2967, grad_fn=<SubBackward0>)\n",
      "loss: 0.018366442993283272\n",
      "tensor([[855]]) tensor(842.5746, grad_fn=<SubBackward0>)\n",
      "loss: 0.014532666653394699\n",
      "tensor([[855]]) tensor(841.9243, grad_fn=<SubBackward0>)\n",
      "loss: 0.015293268486857414\n",
      "tensor([[855]]) tensor(838.0394, grad_fn=<SubBackward0>)\n",
      "loss: 0.019837014377117157\n",
      "tensor([[855]]) tensor(842.2808, grad_fn=<SubBackward0>)\n",
      "loss: 0.014876230619847775\n",
      "tensor([[855]]) tensor(836.5665, grad_fn=<SubBackward0>)\n",
      "loss: 0.021559687331318855\n",
      "tensor([[855]]) tensor(838.3733, grad_fn=<SubBackward0>)\n",
      "loss: 0.01944640837609768\n",
      "tensor([[855]]) tensor(828.6484, grad_fn=<SubBackward0>)\n",
      "loss: 0.03082052245736122\n",
      "tensor([[855]]) tensor(834.4067, grad_fn=<SubBackward0>)\n",
      "loss: 0.024085668846964836\n",
      "tensor([[855]]) tensor(827.9596, grad_fn=<SubBackward0>)\n",
      "loss: 0.031626224517822266\n",
      "tensor([[855]]) tensor(823.8784, grad_fn=<SubBackward0>)\n",
      "loss: 0.03639950975775719\n",
      "tensor([[855]]) tensor(836.7349, grad_fn=<SubBackward0>)\n",
      "loss: 0.02136276848614216\n",
      "tensor([[855]]) tensor(818.9651, grad_fn=<SubBackward0>)\n",
      "loss: 0.042146023362874985\n",
      "tensor([[855]]) tensor(813.5579, grad_fn=<SubBackward0>)\n",
      "loss: 0.04847033694386482\n",
      "tensor([[855]]) tensor(831.2999, grad_fn=<SubBackward0>)\n",
      "loss: 0.027719365432858467\n",
      "tensor([[855]]) tensor(823.7260, grad_fn=<SubBackward0>)\n",
      "loss: 0.036577798426151276\n",
      "tensor([[855]]) tensor(818.2220, grad_fn=<SubBackward0>)\n",
      "loss: 0.04301515221595764\n",
      "tensor([[855]]) tensor(828.6710, grad_fn=<SubBackward0>)\n",
      "loss: 0.03079412877559662\n",
      "tensor([[855]]) tensor(824.2590, grad_fn=<SubBackward0>)\n",
      "loss: 0.0359543114900589\n",
      "tensor([[855]]) tensor(818.3743, grad_fn=<SubBackward0>)\n",
      "loss: 0.04283704236149788\n",
      "tensor([[855]]) tensor(830.2515, grad_fn=<SubBackward0>)\n",
      "loss: 0.028945619240403175\n",
      "tensor([[855]]) tensor(825.8231, grad_fn=<SubBackward0>)\n",
      "loss: 0.034124989062547684\n",
      "tensor([[855]]) tensor(830.4952, grad_fn=<SubBackward0>)\n",
      "loss: 0.028660574927926064\n",
      "tensor([[855]]) tensor(835.7075, grad_fn=<SubBackward0>)\n",
      "loss: 0.022564340382814407\n",
      "tensor([[855]]) tensor(832.3419, grad_fn=<SubBackward0>)\n",
      "loss: 0.026500733569264412\n",
      "tensor([[855]]) tensor(834.6040, grad_fn=<SubBackward0>)\n",
      "loss: 0.023854965344071388\n",
      "tensor([[855]]) tensor(835.2141, grad_fn=<SubBackward0>)\n",
      "loss: 0.023141425102949142\n",
      "tensor([[855]]) tensor(843.6237, grad_fn=<SubBackward0>)\n",
      "loss: 0.013305574655532837\n",
      "tensor([[855]]) tensor(831.8702, grad_fn=<SubBackward0>)\n",
      "loss: 0.02705233357846737\n",
      "tensor([[855]]) tensor(833.1739, grad_fn=<SubBackward0>)\n",
      "loss: 0.025527596473693848\n",
      "tensor([[855]]) tensor(834.2977, grad_fn=<SubBackward0>)\n",
      "loss: 0.024213271215558052\n",
      "tensor([[855]]) tensor(835.4426, grad_fn=<SubBackward0>)\n",
      "loss: 0.0228741392493248\n",
      "tensor([[855]]) tensor(831.2365, grad_fn=<SubBackward0>)\n",
      "loss: 0.027793554589152336\n",
      "tensor([[855]]) tensor(831.5925, grad_fn=<SubBackward0>)\n",
      "loss: 0.027377212420105934\n",
      "tensor([[855]]) tensor(836.5148, grad_fn=<SubBackward0>)\n",
      "loss: 0.021620187908411026\n",
      "tensor([[855]]) tensor(827.4415, grad_fn=<SubBackward0>)\n",
      "loss: 0.032232146710157394\n",
      "tensor([[855]]) tensor(833.9185, grad_fn=<SubBackward0>)\n",
      "loss: 0.024656811729073524\n",
      "tensor([[855]]) tensor(821.3937, grad_fn=<SubBackward0>)\n",
      "loss: 0.0393056757748127\n",
      "tensor([[855]]) tensor(819.4319, grad_fn=<SubBackward0>)\n",
      "loss: 0.04160015285015106\n",
      "tensor([[855]]) tensor(831.5104, grad_fn=<SubBackward0>)\n",
      "loss: 0.02747328020632267\n",
      "tensor([[855]]) tensor(819.9150, grad_fn=<SubBackward0>)\n",
      "loss: 0.04103509709239006\n",
      "tensor([[855]]) tensor(814.5204, grad_fn=<SubBackward0>)\n",
      "loss: 0.04734457656741142\n",
      "tensor([[855]]) tensor(835.6256, grad_fn=<SubBackward0>)\n",
      "loss: 0.02266010455787182\n",
      "tensor([[855]]) tensor(818.3203, grad_fn=<SubBackward0>)\n",
      "loss: 0.042900290340185165\n",
      "tensor([[855]]) tensor(801.0269, grad_fn=<SubBackward0>)\n",
      "loss: 0.06312641501426697\n",
      "tensor([[855]]) tensor(804.8052, grad_fn=<SubBackward0>)\n",
      "loss: 0.05870732665061951\n",
      "tensor([[855]]) tensor(822.8674, grad_fn=<SubBackward0>)\n",
      "loss: 0.037581916898489\n",
      "tensor([[855]]) tensor(817.9609, grad_fn=<SubBackward0>)\n",
      "loss: 0.04332050681114197\n",
      "tensor([[855]]) tensor(806.8076, grad_fn=<SubBackward0>)\n",
      "loss: 0.05636535957455635\n",
      "tensor([[855]]) tensor(821.1180, grad_fn=<SubBackward0>)\n",
      "loss: 0.03962809219956398\n",
      "tensor([[855]]) tensor(825.9813, grad_fn=<SubBackward0>)\n",
      "loss: 0.03393997251987457\n",
      "tensor([[855]]) tensor(823.5151, grad_fn=<SubBackward0>)\n",
      "loss: 0.03682440146803856\n",
      "tensor([[855]]) tensor(822.3423, grad_fn=<SubBackward0>)\n",
      "loss: 0.0381961390376091\n",
      "tensor([[855]]) tensor(828.0464, grad_fn=<SubBackward0>)\n",
      "loss: 0.03152463957667351\n",
      "tensor([[855]]) tensor(818.2112, grad_fn=<SubBackward0>)\n",
      "loss: 0.04302782192826271\n",
      "tensor([[855]]) tensor(833.9391, grad_fn=<SubBackward0>)\n",
      "loss: 0.02463264763355255\n",
      "tensor([[855]]) tensor(823.3364, grad_fn=<SubBackward0>)\n",
      "loss: 0.037033382803201675\n",
      "tensor([[855]]) tensor(805.6460, grad_fn=<SubBackward0>)\n",
      "loss: 0.05772398039698601\n",
      "tensor([[855]]) tensor(812.0890, grad_fn=<SubBackward0>)\n",
      "loss: 0.05018831789493561\n",
      "tensor([[855]]) tensor(827.8547, grad_fn=<SubBackward0>)\n",
      "loss: 0.03174886479973793\n",
      "tensor([[855]]) tensor(804.8907, grad_fn=<SubBackward0>)\n",
      "loss: 0.058607276529073715\n",
      "tensor([[855]]) tensor(796.1331, grad_fn=<SubBackward0>)\n",
      "loss: 0.06885026395320892\n",
      "tensor([[855]]) tensor(811.2156, grad_fn=<SubBackward0>)\n",
      "loss: 0.05120978131890297\n",
      "tensor([[855]]) tensor(826.9789, grad_fn=<SubBackward0>)\n",
      "loss: 0.03277323767542839\n",
      "tensor([[855]]) tensor(818.0386, grad_fn=<SubBackward0>)\n",
      "loss: 0.04322972148656845\n",
      "tensor([[855]]) tensor(819.1366, grad_fn=<SubBackward0>)\n",
      "loss: 0.041945502161979675\n",
      "tensor([[855]]) tensor(831.7537, grad_fn=<SubBackward0>)\n",
      "loss: 0.02718871645629406\n",
      "tensor([[855]]) tensor(824.4221, grad_fn=<SubBackward0>)\n",
      "loss: 0.03576363995671272\n",
      "tensor([[855]]) tensor(826.9233, grad_fn=<SubBackward0>)\n",
      "loss: 0.03283827006816864\n",
      "tensor([[855]]) tensor(841.8809, grad_fn=<SubBackward0>)\n",
      "loss: 0.015344042330980301\n",
      "tensor([[855]]) tensor(834.8172, grad_fn=<SubBackward0>)\n",
      "loss: 0.02360561490058899\n",
      "tensor([[855]]) tensor(838.9796, grad_fn=<SubBackward0>)\n",
      "loss: 0.01873725838959217\n",
      "tensor([[855]]) tensor(836.6756, grad_fn=<SubBackward0>)\n",
      "loss: 0.021432049572467804\n",
      "tensor([[855]]) tensor(842.8748, grad_fn=<SubBackward0>)\n",
      "loss: 0.0141815897077322\n",
      "tensor([[855]]) tensor(827.3387, grad_fn=<SubBackward0>)\n",
      "loss: 0.03235236182808876\n",
      "tensor([[855]]) tensor(823.3062, grad_fn=<SubBackward0>)\n",
      "loss: 0.03706882894039154\n",
      "tensor([[855]]) tensor(843.6088, grad_fn=<SubBackward0>)\n",
      "loss: 0.013323082588613033\n",
      "tensor([[855]]) tensor(816.6254, grad_fn=<SubBackward0>)\n",
      "loss: 0.044882647693157196\n",
      "tensor([[855]]) tensor(804.9067, grad_fn=<SubBackward0>)\n",
      "loss: 0.05858860909938812\n",
      "tensor([[855]]) tensor(820.7548, grad_fn=<SubBackward0>)\n",
      "loss: 0.04005291312932968\n",
      "tensor([[855]]) tensor(843.6276, grad_fn=<SubBackward0>)\n",
      "loss: 0.013301077298820019\n",
      "tensor([[855]]) tensor(831.9988, grad_fn=<SubBackward0>)\n",
      "loss: 0.026902012526988983\n",
      "tensor([[855]]) tensor(845.0209, grad_fn=<SubBackward0>)\n",
      "loss: 0.011671492829918861\n",
      "tensor([[855]]) tensor(831.9754, grad_fn=<SubBackward0>)\n",
      "loss: 0.026929371058940887\n",
      "tensor([[855]]) tensor(831.9175, grad_fn=<SubBackward0>)\n",
      "loss: 0.026997027918696404\n",
      "tensor([[855]]) tensor(830.6037, grad_fn=<SubBackward0>)\n",
      "loss: 0.028533685952425003\n",
      "tensor([[855]]) tensor(834.3337, grad_fn=<SubBackward0>)\n",
      "loss: 0.024171028286218643\n",
      "tensor([[855]]) tensor(841.5461, grad_fn=<SubBackward0>)\n",
      "loss: 0.015735577791929245\n",
      "tensor([[855]]) tensor(821.3050, grad_fn=<SubBackward0>)\n",
      "loss: 0.03940936550498009\n",
      "tensor([[855]]) tensor(826.5342, grad_fn=<SubBackward0>)\n",
      "loss: 0.033293284475803375\n",
      "tensor([[855]]) tensor(833.4341, grad_fn=<SubBackward0>)\n",
      "loss: 0.025223296135663986\n",
      "tensor([[855]]) tensor(819.0732, grad_fn=<SubBackward0>)\n",
      "loss: 0.04201958328485489\n",
      "tensor([[855]]) tensor(822.6901, grad_fn=<SubBackward0>)\n",
      "loss: 0.03778941556811333\n",
      "tensor([[855]]) tensor(843.2720, grad_fn=<SubBackward0>)\n",
      "loss: 0.013717008754611015\n",
      "tensor([[855]]) tensor(826.0107, grad_fn=<SubBackward0>)\n",
      "loss: 0.033905528485774994\n",
      "tensor([[855]]) tensor(832.4842, grad_fn=<SubBackward0>)\n",
      "loss: 0.026334278285503387\n",
      "tensor([[855]]) tensor(831.9970, grad_fn=<SubBackward0>)\n",
      "loss: 0.026904065161943436\n",
      "tensor([[855]]) tensor(828.4460, grad_fn=<SubBackward0>)\n",
      "loss: 0.031057292595505714\n",
      "tensor([[855]]) tensor(839.0651, grad_fn=<SubBackward0>)\n",
      "loss: 0.01863729953765869\n",
      "tensor([[855]]) tensor(834.0652, grad_fn=<SubBackward0>)\n",
      "loss: 0.02448519878089428\n",
      "tensor([[855]]) tensor(845.1194, grad_fn=<SubBackward0>)\n",
      "loss: 0.011556203477084637\n",
      "tensor([[855]]) tensor(831.5984, grad_fn=<SubBackward0>)\n",
      "loss: 0.02737027034163475\n",
      "tensor([[855]]) tensor(836.5408, grad_fn=<SubBackward0>)\n",
      "loss: 0.021589670330286026\n",
      "tensor([[855]]) tensor(832.2976, grad_fn=<SubBackward0>)\n",
      "loss: 0.026552541181445122\n",
      "tensor([[855]]) tensor(835.5430, grad_fn=<SubBackward0>)\n",
      "loss: 0.02275669015944004\n",
      "tensor([[855]]) tensor(830.5323, grad_fn=<SubBackward0>)\n",
      "loss: 0.02861715480685234\n",
      "tensor([[855]]) tensor(825.5367, grad_fn=<SubBackward0>)\n",
      "loss: 0.034460004419088364\n",
      "tensor([[855]]) tensor(836.2666, grad_fn=<SubBackward0>)\n",
      "loss: 0.0219104066491127\n",
      "tensor([[855]]) tensor(837.7250, grad_fn=<SubBackward0>)\n",
      "loss: 0.02020474337041378\n",
      "tensor([[855]]) tensor(832.8392, grad_fn=<SubBackward0>)\n",
      "loss: 0.025919007137417793\n",
      "tensor([[855]]) tensor(841.2186, grad_fn=<SubBackward0>)\n",
      "loss: 0.016118599101901054\n",
      "tensor([[855]]) tensor(836.2560, grad_fn=<SubBackward0>)\n",
      "loss: 0.02192273922264576\n",
      "tensor([[855]]) tensor(842.2936, grad_fn=<SubBackward0>)\n",
      "loss: 0.01486134622246027\n",
      "tensor([[855]]) tensor(834.9241, grad_fn=<SubBackward0>)\n",
      "loss: 0.02348063513636589\n",
      "tensor([[855]]) tensor(844.1741, grad_fn=<SubBackward0>)\n",
      "loss: 0.012661904096603394\n",
      "tensor([[855]]) tensor(835.6429, grad_fn=<SubBackward0>)\n",
      "loss: 0.022639885544776917\n",
      "tensor([[855]]) tensor(844.6082, grad_fn=<SubBackward0>)\n",
      "loss: 0.012154169380664825\n",
      "tensor([[855]]) tensor(822.6352, grad_fn=<SubBackward0>)\n",
      "loss: 0.03785359486937523\n",
      "tensor([[855]]) tensor(819.7679, grad_fn=<SubBackward0>)\n",
      "loss: 0.04120704531669617\n",
      "tensor([[855]]) tensor(840.4291, grad_fn=<SubBackward0>)\n",
      "loss: 0.017041943967342377\n",
      "tensor([[855]]) tensor(819.7544, grad_fn=<SubBackward0>)\n",
      "loss: 0.04122289642691612\n",
      "tensor([[855]]) tensor(805.3886, grad_fn=<SubBackward0>)\n",
      "loss: 0.058025017380714417\n",
      "tensor([[855]]) tensor(819.9294, grad_fn=<SubBackward0>)\n",
      "loss: 0.04101821407675743\n",
      "tensor([[855]]) tensor(842.3658, grad_fn=<SubBackward0>)\n",
      "loss: 0.014776789583265781\n",
      "tensor([[855]]) tensor(812.6404, grad_fn=<SubBackward0>)\n",
      "loss: 0.049543414264917374\n",
      "tensor([[855]]) tensor(812.1105, grad_fn=<SubBackward0>)\n",
      "loss: 0.05016311630606651\n",
      "tensor([[855]]) tensor(836.9962, grad_fn=<SubBackward0>)\n",
      "loss: 0.021057093515992165\n",
      "tensor([[855]]) tensor(812.7096, grad_fn=<SubBackward0>)\n",
      "loss: 0.049462463706731796\n",
      "tensor([[855]]) tensor(798.8190, grad_fn=<SubBackward0>)\n",
      "loss: 0.06570884585380554\n",
      "tensor([[855]]) tensor(817.3080, grad_fn=<SubBackward0>)\n",
      "loss: 0.04408426582813263\n",
      "tensor([[855]]) tensor(838.7186, grad_fn=<SubBackward0>)\n",
      "loss: 0.019042611122131348\n",
      "tensor([[855]]) tensor(802.6202, grad_fn=<SubBackward0>)\n",
      "loss: 0.06126287952065468\n",
      "tensor([[855]]) tensor(792.1033, grad_fn=<SubBackward0>)\n",
      "loss: 0.07356346398591995\n",
      "tensor([[855]]) tensor(808.4649, grad_fn=<SubBackward0>)\n",
      "loss: 0.05442703142762184\n",
      "tensor([[855]]) tensor(832.0737, grad_fn=<SubBackward0>)\n",
      "loss: 0.026814386248588562\n",
      "tensor([[855]]) tensor(818.0485, grad_fn=<SubBackward0>)\n",
      "loss: 0.04321817308664322\n",
      "tensor([[855]]) tensor(812.0712, grad_fn=<SubBackward0>)\n",
      "loss: 0.0502091608941555\n",
      "tensor([[855]]) tensor(823.1393, grad_fn=<SubBackward0>)\n",
      "loss: 0.0372639074921608\n",
      "tensor([[855]]) tensor(834.1614, grad_fn=<SubBackward0>)\n",
      "loss: 0.024372586980462074\n",
      "tensor([[855]]) tensor(806.0046, grad_fn=<SubBackward0>)\n",
      "loss: 0.057304516434669495\n",
      "tensor([[855]]) tensor(803.7885, grad_fn=<SubBackward0>)\n",
      "loss: 0.059896547347307205\n",
      "tensor([[855]]) tensor(824.6223, grad_fn=<SubBackward0>)\n",
      "loss: 0.03552952781319618\n",
      "tensor([[855]]) tensor(819.0599, grad_fn=<SubBackward0>)\n",
      "loss: 0.04203512519598007\n",
      "tensor([[855]]) tensor(803.1447, grad_fn=<SubBackward0>)\n",
      "loss: 0.060649458318948746\n",
      "tensor([[855]]) tensor(807.4944, grad_fn=<SubBackward0>)\n",
      "loss: 0.05556212365627289\n",
      "tensor([[855]]) tensor(834.5006, grad_fn=<SubBackward0>)\n",
      "loss: 0.023975858464837074\n",
      "tensor([[855]]) tensor(824.4919, grad_fn=<SubBackward0>)\n",
      "loss: 0.035681918263435364\n",
      "tensor([[855]]) tensor(813.5446, grad_fn=<SubBackward0>)\n",
      "loss: 0.04848584532737732\n",
      "tensor([[855]]) tensor(828.3180, grad_fn=<SubBackward0>)\n",
      "loss: 0.031207025051116943\n",
      "tensor([[855]]) tensor(829.0289, grad_fn=<SubBackward0>)\n",
      "loss: 0.030375609174370766\n",
      "tensor([[855]]) tensor(817.8649, grad_fn=<SubBackward0>)\n",
      "loss: 0.04343286529183388\n",
      "tensor([[855]]) tensor(832.3102, grad_fn=<SubBackward0>)\n",
      "loss: 0.026537729427218437\n",
      "tensor([[855]]) tensor(841.3639, grad_fn=<SubBackward0>)\n",
      "loss: 0.01594862900674343\n",
      "tensor([[855]]) tensor(828.1842, grad_fn=<SubBackward0>)\n",
      "loss: 0.03136353939771652\n",
      "tensor([[855]]) tensor(839.9816, grad_fn=<SubBackward0>)\n",
      "loss: 0.01756543666124344\n",
      "tensor([[855]]) tensor(835.6995, grad_fn=<SubBackward0>)\n",
      "loss: 0.022573692724108696\n",
      "tensor([[855]]) tensor(834.4714, grad_fn=<SubBackward0>)\n",
      "loss: 0.024009982123970985\n",
      "tensor([[855]]) tensor(843.3121, grad_fn=<SubBackward0>)\n",
      "loss: 0.013669983483850956\n",
      "tensor([[855]]) tensor(834.2178, grad_fn=<SubBackward0>)\n",
      "loss: 0.024306662380695343\n",
      "tensor([[855]]) tensor(841.5115, grad_fn=<SubBackward0>)\n",
      "loss: 0.0157760176807642\n",
      "tensor([[855]]) tensor(825.0962, grad_fn=<SubBackward0>)\n",
      "loss: 0.034975215792655945\n",
      "tensor([[855]]) tensor(825.0005, grad_fn=<SubBackward0>)\n",
      "loss: 0.035087112337350845\n",
      "tensor([[855]]) tensor(844.9934, grad_fn=<SubBackward0>)\n",
      "loss: 0.01170359831303358\n",
      "tensor([[855]]) tensor(827.7812, grad_fn=<SubBackward0>)\n",
      "loss: 0.03183486685156822\n",
      "tensor([[855]]) tensor(825.7448, grad_fn=<SubBackward0>)\n",
      "loss: 0.03421670198440552\n",
      "tensor([[855]]) tensor(836.7551, grad_fn=<SubBackward0>)\n",
      "loss: 0.021338997408747673\n",
      "tensor([[855]]) tensor(823.5240, grad_fn=<SubBackward0>)\n",
      "loss: 0.03681404888629913\n",
      "tensor([[855]]) tensor(829.5257, grad_fn=<SubBackward0>)\n",
      "loss: 0.02979452535510063\n",
      "tensor([[855]]) tensor(841.7200, grad_fn=<SubBackward0>)\n",
      "loss: 0.01553216204047203\n",
      "tensor([[855]]) tensor(826.2836, grad_fn=<SubBackward0>)\n",
      "loss: 0.033586468547582626\n",
      "tensor([[855]]) tensor(837.5844, grad_fn=<SubBackward0>)\n",
      "loss: 0.020369216799736023\n",
      "tensor([[855]]) tensor(824.3915, grad_fn=<SubBackward0>)\n",
      "loss: 0.03579936921596527\n",
      "tensor([[855]]) tensor(819.9165, grad_fn=<SubBackward0>)\n",
      "loss: 0.0410333126783371\n",
      "tensor([[855]]) tensor(839.8027, grad_fn=<SubBackward0>)\n",
      "loss: 0.017774544656276703\n",
      "tensor([[855]]) tensor(816.8945, grad_fn=<SubBackward0>)\n",
      "loss: 0.044567763805389404\n",
      "tensor([[855]]) tensor(807.1075, grad_fn=<SubBackward0>)\n",
      "loss: 0.056014638394117355\n",
      "tensor([[855]]) tensor(826.3925, grad_fn=<SubBackward0>)\n",
      "loss: 0.03345911577343941\n",
      "tensor([[855]]) tensor(827.8998, grad_fn=<SubBackward0>)\n",
      "loss: 0.03169609233736992\n",
      "tensor([[855]]) tensor(811.7191, grad_fn=<SubBackward0>)\n",
      "loss: 0.05062098801136017\n",
      "tensor([[855]]) tensor(816.5087, grad_fn=<SubBackward0>)\n",
      "loss: 0.04501910135149956\n",
      "tensor([[855]]) tensor(837.2370, grad_fn=<SubBackward0>)\n",
      "loss: 0.020775439217686653\n",
      "tensor([[855]]) tensor(824.3245, grad_fn=<SubBackward0>)\n",
      "loss: 0.03587773069739342\n",
      "tensor([[855]]) tensor(817.3175, grad_fn=<SubBackward0>)\n",
      "loss: 0.04407313093543053\n",
      "tensor([[855]]) tensor(835.7833, grad_fn=<SubBackward0>)\n",
      "loss: 0.02247566170990467\n",
      "tensor([[855]]) tensor(821.3515, grad_fn=<SubBackward0>)\n",
      "loss: 0.039354968816041946\n",
      "tensor([[855]]) tensor(820.4203, grad_fn=<SubBackward0>)\n",
      "loss: 0.040444035083055496\n",
      "tensor([[855]]) tensor(837.5106, grad_fn=<SubBackward0>)\n",
      "loss: 0.020455503836274147\n",
      "tensor([[855]]) tensor(826.4406, grad_fn=<SubBackward0>)\n",
      "loss: 0.03340289741754532\n",
      "tensor([[855]]) tensor(819.3541, grad_fn=<SubBackward0>)\n",
      "loss: 0.0416911356151104\n",
      "tensor([[855]]) tensor(833.4377, grad_fn=<SubBackward0>)\n",
      "loss: 0.025219012051820755\n",
      "tensor([[855]]) tensor(833.4384, grad_fn=<SubBackward0>)\n",
      "loss: 0.025218263268470764\n",
      "tensor([[855]]) tensor(831.3326, grad_fn=<SubBackward0>)\n",
      "loss: 0.027681156992912292\n",
      "tensor([[855]]) tensor(833.7012, grad_fn=<SubBackward0>)\n",
      "loss: 0.024910874664783478\n",
      "tensor([[855]]) tensor(833.3574, grad_fn=<SubBackward0>)\n",
      "loss: 0.02531297504901886\n",
      "tensor([[855]]) tensor(841.3608, grad_fn=<SubBackward0>)\n",
      "loss: 0.015952305868268013\n",
      "tensor([[855]]) tensor(824.1358, grad_fn=<SubBackward0>)\n",
      "loss: 0.03609847649931908\n",
      "tensor([[855]]) tensor(819.1388, grad_fn=<SubBackward0>)\n",
      "loss: 0.04194293171167374\n",
      "tensor([[855]]) tensor(842.2407, grad_fn=<SubBackward0>)\n",
      "loss: 0.01492320280522108\n",
      "tensor([[855]]) tensor(816.1576, grad_fn=<SubBackward0>)\n",
      "loss: 0.04542975127696991\n",
      "tensor([[855]]) tensor(811.2359, grad_fn=<SubBackward0>)\n",
      "loss: 0.051186081022024155\n",
      "tensor([[855]]) tensor(833.1260, grad_fn=<SubBackward0>)\n",
      "loss: 0.025583581998944283\n",
      "tensor([[855]]) tensor(826.1403, grad_fn=<SubBackward0>)\n",
      "loss: 0.03375401347875595\n",
      "tensor([[855]]) tensor(820.9399, grad_fn=<SubBackward0>)\n",
      "loss: 0.03983641415834427\n",
      "tensor([[855]]) tensor(828.9201, grad_fn=<SubBackward0>)\n",
      "loss: 0.03050280176103115\n",
      "tensor([[855]]) tensor(838.0414, grad_fn=<SubBackward0>)\n",
      "loss: 0.019834551960229874\n",
      "tensor([[855]]) tensor(827.1314, grad_fn=<SubBackward0>)\n",
      "loss: 0.032594844698905945\n",
      "tensor([[855]]) tensor(833.7231, grad_fn=<SubBackward0>)\n",
      "loss: 0.02488524653017521\n",
      "tensor([[855]]) tensor(829.1656, grad_fn=<SubBackward0>)\n",
      "loss: 0.03021557815372944\n",
      "tensor([[855]]) tensor(819.2899, grad_fn=<SubBackward0>)\n",
      "loss: 0.04176614433526993\n",
      "tensor([[855]]) tensor(832.4983, grad_fn=<SubBackward0>)\n",
      "loss: 0.026317788287997246\n",
      "tensor([[855]]) tensor(833.1924, grad_fn=<SubBackward0>)\n",
      "loss: 0.025506021454930305\n",
      "tensor([[855]]) tensor(824.5126, grad_fn=<SubBackward0>)\n",
      "loss: 0.0356578454375267\n",
      "tensor([[855]]) tensor(836.8569, grad_fn=<SubBackward0>)\n",
      "loss: 0.02121996134519577\n",
      "tensor([[855]]) tensor(828.3155, grad_fn=<SubBackward0>)\n",
      "loss: 0.031209953129291534\n",
      "tensor([[855]]) tensor(830.5001, grad_fn=<SubBackward0>)\n",
      "loss: 0.0286547914147377\n",
      "tensor([[855]]) tensor(841.7296, grad_fn=<SubBackward0>)\n",
      "loss: 0.015520954504609108\n",
      "tensor([[855]]) tensor(832.6564, grad_fn=<SubBackward0>)\n",
      "loss: 0.026132898405194283\n",
      "tensor([[855]]) tensor(841.7556, grad_fn=<SubBackward0>)\n",
      "loss: 0.015490508638322353\n",
      "tensor([[855]]) tensor(826.7027, grad_fn=<SubBackward0>)\n",
      "loss: 0.033096276223659515\n",
      "tensor([[855]]) tensor(821.9781, grad_fn=<SubBackward0>)\n",
      "loss: 0.03862211853265762\n",
      "tensor([[855]]) tensor(841.4752, grad_fn=<SubBackward0>)\n",
      "loss: 0.01581847481429577\n",
      "tensor([[855]]) tensor(825.0952, grad_fn=<SubBackward0>)\n",
      "loss: 0.03497644513845444\n",
      "tensor([[855]]) tensor(830.1304, grad_fn=<SubBackward0>)\n",
      "loss: 0.02908724918961525\n",
      "tensor([[855]]) tensor(837.8257, grad_fn=<SubBackward0>)\n",
      "loss: 0.020086849108338356\n",
      "tensor([[855]]) tensor(821.7260, grad_fn=<SubBackward0>)\n",
      "loss: 0.03891701623797417\n",
      "tensor([[855]]) tensor(837.2571, grad_fn=<SubBackward0>)\n",
      "loss: 0.020751934498548508\n",
      "tensor([[855]]) tensor(834.8652, grad_fn=<SubBackward0>)\n",
      "loss: 0.023549433797597885\n",
      "tensor([[855]]) tensor(832.1721, grad_fn=<SubBackward0>)\n",
      "loss: 0.026699312031269073\n",
      "tensor([[855]]) tensor(826.4784, grad_fn=<SubBackward0>)\n",
      "loss: 0.03335864096879959\n",
      "tensor([[855]]) tensor(827.2987, grad_fn=<SubBackward0>)\n",
      "loss: 0.03239917382597923\n",
      "tensor([[855]]) tensor(837.3925, grad_fn=<SubBackward0>)\n",
      "loss: 0.020593564957380295\n",
      "tensor([[855]]) tensor(836.5328, grad_fn=<SubBackward0>)\n",
      "loss: 0.021599056199193\n",
      "tensor([[855]]) tensor(825.8091, grad_fn=<SubBackward0>)\n",
      "loss: 0.03414135426282883\n",
      "tensor([[855]]) tensor(836.1240, grad_fn=<SubBackward0>)\n",
      "loss: 0.02207723632454872\n",
      "tensor([[855]]) tensor(834.6974, grad_fn=<SubBackward0>)\n",
      "loss: 0.023745745420455933\n",
      "tensor([[855]]) tensor(840.0295, grad_fn=<SubBackward0>)\n",
      "loss: 0.017509397119283676\n",
      "tensor([[855]]) tensor(820.4965, grad_fn=<SubBackward0>)\n",
      "loss: 0.040354982018470764\n",
      "tensor([[855]]) tensor(819.0667, grad_fn=<SubBackward0>)\n",
      "loss: 0.04202723875641823\n",
      "tensor([[855]]) tensor(834.0594, grad_fn=<SubBackward0>)\n",
      "loss: 0.02449183724820614\n",
      "tensor([[855]]) tensor(804.7032, grad_fn=<SubBackward0>)\n",
      "loss: 0.05882661044597626\n",
      "tensor([[855]]) tensor(796.2197, grad_fn=<SubBackward0>)\n",
      "loss: 0.0687488242983818\n",
      "tensor([[855]]) tensor(817.1555, grad_fn=<SubBackward0>)\n",
      "loss: 0.04426262527704239\n",
      "tensor([[855]]) tensor(825.6403, grad_fn=<SubBackward0>)\n",
      "loss: 0.03433889523148537\n",
      "tensor([[855]]) tensor(811.7248, grad_fn=<SubBackward0>)\n",
      "loss: 0.05061429738998413\n",
      "tensor([[855]]) tensor(819.7789, grad_fn=<SubBackward0>)\n",
      "loss: 0.04119425266981125\n",
      "tensor([[855]]) tensor(834.0494, grad_fn=<SubBackward0>)\n",
      "loss: 0.02450365200638771\n",
      "tensor([[855]]) tensor(816.4232, grad_fn=<SubBackward0>)\n",
      "loss: 0.0451190248131752\n",
      "tensor([[855]]) tensor(816.6227, grad_fn=<SubBackward0>)\n",
      "loss: 0.04488571733236313\n",
      "tensor([[855]]) tensor(820.1238, grad_fn=<SubBackward0>)\n",
      "loss: 0.04079082980751991\n",
      "tensor([[855]]) tensor(814.5558, grad_fn=<SubBackward0>)\n",
      "loss: 0.04730319231748581\n",
      "tensor([[855]]) tensor(823.3754, grad_fn=<SubBackward0>)\n",
      "loss: 0.036987803876399994\n",
      "tensor([[855]]) tensor(834.5564, grad_fn=<SubBackward0>)\n",
      "loss: 0.023910628631711006\n",
      "tensor([[855]]) tensor(821.2349, grad_fn=<SubBackward0>)\n",
      "loss: 0.03949137032032013\n",
      "tensor([[855]]) tensor(817.8800, grad_fn=<SubBackward0>)\n",
      "loss: 0.04341519996523857\n",
      "tensor([[855]]) tensor(829.3721, grad_fn=<SubBackward0>)\n",
      "loss: 0.02997415140271187\n",
      "tensor([[855]]) tensor(822.3577, grad_fn=<SubBackward0>)\n",
      "loss: 0.038178205490112305\n",
      "tensor([[855]]) tensor(825.5764, grad_fn=<SubBackward0>)\n",
      "loss: 0.03441356495022774\n",
      "tensor([[855]]) tensor(837.6266, grad_fn=<SubBackward0>)\n",
      "loss: 0.020319782197475433\n",
      "tensor([[855]]) tensor(827.8357, grad_fn=<SubBackward0>)\n",
      "loss: 0.03177111968398094\n",
      "tensor([[855]]) tensor(840.1095, grad_fn=<SubBackward0>)\n",
      "loss: 0.017415829002857208\n",
      "tensor([[855]]) tensor(833.9492, grad_fn=<SubBackward0>)\n",
      "loss: 0.024620868265628815\n",
      "tensor([[855]]) tensor(841.1661, grad_fn=<SubBackward0>)\n",
      "loss: 0.01617995649576187\n",
      "tensor([[855]]) tensor(826.8829, grad_fn=<SubBackward0>)\n",
      "loss: 0.03288542106747627\n",
      "tensor([[855]]) tensor(822.6064, grad_fn=<SubBackward0>)\n",
      "loss: 0.03788723424077034\n",
      "tensor([[855]]) tensor(841.4161, grad_fn=<SubBackward0>)\n",
      "loss: 0.015887629240751266\n",
      "tensor([[855]]) tensor(831.9674, grad_fn=<SubBackward0>)\n",
      "loss: 0.026938723400235176\n",
      "tensor([[855]]) tensor(832.6028, grad_fn=<SubBackward0>)\n",
      "loss: 0.026195522397756577\n",
      "tensor([[855]]) tensor(834.6028, grad_fn=<SubBackward0>)\n",
      "loss: 0.02385633997619152\n",
      "tensor([[855]]) tensor(836.8718, grad_fn=<SubBackward0>)\n",
      "loss: 0.021202577278017998\n",
      "tensor([[855]]) tensor(837.9233, grad_fn=<SubBackward0>)\n",
      "loss: 0.01997273787856102\n",
      "tensor([[855]]) tensor(830.9700, grad_fn=<SubBackward0>)\n",
      "loss: 0.028105244040489197\n",
      "tensor([[855]]) tensor(834.0074, grad_fn=<SubBackward0>)\n",
      "loss: 0.02455267682671547\n",
      "tensor([[855]]) tensor(831.7548, grad_fn=<SubBackward0>)\n",
      "loss: 0.027187395840883255\n",
      "tensor([[855]]) tensor(831.4652, grad_fn=<SubBackward0>)\n",
      "loss: 0.02752610668540001\n",
      "tensor([[855]]) tensor(838.8873, grad_fn=<SubBackward0>)\n",
      "loss: 0.018845301121473312\n",
      "tensor([[855]]) tensor(833.2443, grad_fn=<SubBackward0>)\n",
      "loss: 0.025445271283388138\n",
      "tensor([[855]]) tensor(840.1907, grad_fn=<SubBackward0>)\n",
      "loss: 0.017320794984698296\n",
      "tensor([[855]]) tensor(839.2567, grad_fn=<SubBackward0>)\n",
      "loss: 0.018413271754980087\n",
      "tensor([[855]]) tensor(840.5428, grad_fn=<SubBackward0>)\n",
      "loss: 0.01690896973013878\n",
      "tensor([[855]]) tensor(837.1581, grad_fn=<SubBackward0>)\n",
      "loss: 0.02086770534515381\n",
      "tensor([[855]]) tensor(843.8120, grad_fn=<SubBackward0>)\n",
      "loss: 0.013085402548313141\n",
      "tensor([[855]]) tensor(844.2826, grad_fn=<SubBackward0>)\n",
      "loss: 0.012534943409264088\n",
      "tensor([[855]]) tensor(843.0814, grad_fn=<SubBackward0>)\n",
      "loss: 0.01393985841423273\n",
      "tensor([[855]]) tensor(846.6913, grad_fn=<SubBackward0>)\n",
      "loss: 0.009717795997858047\n",
      "tensor([[855]]) tensor(840.7141, grad_fn=<SubBackward0>)\n",
      "loss: 0.016708677634596825\n",
      "tensor([[855]]) tensor(845.6133, grad_fn=<SubBackward0>)\n",
      "loss: 0.010978564620018005\n",
      "tensor([[855]]) tensor(841.3995, grad_fn=<SubBackward0>)\n",
      "loss: 0.015906939283013344\n",
      "tensor([[855]]) tensor(847.9377, grad_fn=<SubBackward0>)\n",
      "loss: 0.008260020054876804\n",
      "tensor([[855]]) tensor(844.8895, grad_fn=<SubBackward0>)\n",
      "loss: 0.011825150810182095\n",
      "tensor([[855]]) tensor(835.0840, grad_fn=<SubBackward0>)\n",
      "loss: 0.02329358644783497\n",
      "tensor([[855]]) tensor(840.7003, grad_fn=<SubBackward0>)\n",
      "loss: 0.016724810004234314\n",
      "tensor([[855]]) tensor(835.9969, grad_fn=<SubBackward0>)\n",
      "loss: 0.0222258809953928\n",
      "tensor([[855]]) tensor(841.9893, grad_fn=<SubBackward0>)\n",
      "loss: 0.015217278152704239\n",
      "tensor([[855]]) tensor(826.1926, grad_fn=<SubBackward0>)\n",
      "loss: 0.03369290381669998\n",
      "tensor([[855]]) tensor(825.1666, grad_fn=<SubBackward0>)\n",
      "loss: 0.03489285334944725\n",
      "tensor([[855]]) tensor(840.5396, grad_fn=<SubBackward0>)\n",
      "loss: 0.016912806779146194\n",
      "tensor([[855]]) tensor(820.7340, grad_fn=<SubBackward0>)\n",
      "loss: 0.04007718339562416\n",
      "tensor([[855]]) tensor(817.5847, grad_fn=<SubBackward0>)\n",
      "loss: 0.04376060143113136\n",
      "tensor([[855]]) tensor(838.8533, grad_fn=<SubBackward0>)\n",
      "loss: 0.018884990364313126\n",
      "tensor([[855]]) tensor(832.2538, grad_fn=<SubBackward0>)\n",
      "loss: 0.026603762060403824\n",
      "tensor([[855]]) tensor(834.6214, grad_fn=<SubBackward0>)\n",
      "loss: 0.02383463829755783\n",
      "tensor([[855]]) tensor(837.3467, grad_fn=<SubBackward0>)\n",
      "loss: 0.020647123456001282\n",
      "tensor([[855]]) tensor(843.7567, grad_fn=<SubBackward0>)\n",
      "loss: 0.013150078244507313\n",
      "tensor([[855]]) tensor(845.7847, grad_fn=<SubBackward0>)\n",
      "loss: 0.010778130032122135\n",
      "tensor([[855]]) tensor(843.6144, grad_fn=<SubBackward0>)\n",
      "loss: 0.0133164431899786\n",
      "tensor([[855]]) tensor(842.8328, grad_fn=<SubBackward0>)\n",
      "loss: 0.014230632223188877\n",
      "tensor([[855]]) tensor(832.2189, grad_fn=<SubBackward0>)\n",
      "loss: 0.026644594967365265\n",
      "tensor([[855]]) tensor(832.6738, grad_fn=<SubBackward0>)\n",
      "loss: 0.026112552732229233\n",
      "tensor([[855]]) tensor(828.5253, grad_fn=<SubBackward0>)\n",
      "loss: 0.030964508652687073\n",
      "tensor([[855]]) tensor(830.9252, grad_fn=<SubBackward0>)\n",
      "loss: 0.02815769426524639\n",
      "tensor([[855]]) tensor(839.0045, grad_fn=<SubBackward0>)\n",
      "loss: 0.01870816759765148\n",
      "tensor([[855]]) tensor(845.9242, grad_fn=<SubBackward0>)\n",
      "loss: 0.010615013539791107\n",
      "tensor([[855]]) tensor(830.4977, grad_fn=<SubBackward0>)\n",
      "loss: 0.028657646849751472\n",
      "tensor([[855]]) tensor(828.4538, grad_fn=<SubBackward0>)\n",
      "loss: 0.031048208475112915\n",
      "tensor([[855]]) tensor(841.0187, grad_fn=<SubBackward0>)\n",
      "loss: 0.016352443024516106\n",
      "tensor([[855]]) tensor(832.8550, grad_fn=<SubBackward0>)\n",
      "loss: 0.025900572538375854\n",
      "tensor([[855]]) tensor(836.1049, grad_fn=<SubBackward0>)\n",
      "loss: 0.022099491208791733\n",
      "tensor([[855]]) tensor(837.5573, grad_fn=<SubBackward0>)\n",
      "loss: 0.020400894805788994\n",
      "tensor([[855]]) tensor(842.6353, grad_fn=<SubBackward0>)\n",
      "loss: 0.0144616374745965\n",
      "tensor([[855]]) tensor(839.5015, grad_fn=<SubBackward0>)\n",
      "loss: 0.01812697760760784\n",
      "tensor([[855]]) tensor(841.6182, grad_fn=<SubBackward0>)\n",
      "loss: 0.015651216730475426\n",
      "tensor([[855]]) tensor(843.7264, grad_fn=<SubBackward0>)\n",
      "loss: 0.013185414485633373\n",
      "tensor([[855]]) tensor(841.7553, grad_fn=<SubBackward0>)\n",
      "loss: 0.015490865334868431\n",
      "tensor([[855]]) tensor(835.7242, grad_fn=<SubBackward0>)\n",
      "loss: 0.022544780746102333\n",
      "tensor([[855]]) tensor(846.6624, grad_fn=<SubBackward0>)\n",
      "loss: 0.009751544333994389\n",
      "tensor([[855]]) tensor(834.9415, grad_fn=<SubBackward0>)\n",
      "loss: 0.02346028946340084\n",
      "tensor([[855]]) tensor(839.7465, grad_fn=<SubBackward0>)\n",
      "loss: 0.01784036122262478\n",
      "tensor([[855]]) tensor(830.4261, grad_fn=<SubBackward0>)\n",
      "loss: 0.028741437941789627\n",
      "tensor([[855]]) tensor(835.5757, grad_fn=<SubBackward0>)\n",
      "loss: 0.02271849848330021\n",
      "tensor([[855]]) tensor(835.8167, grad_fn=<SubBackward0>)\n",
      "loss: 0.022436702623963356\n",
      "tensor([[855]]) tensor(837.6074, grad_fn=<SubBackward0>)\n",
      "loss: 0.02034226804971695\n",
      "tensor([[855]]) tensor(828.6694, grad_fn=<SubBackward0>)\n",
      "loss: 0.030796073377132416\n",
      "tensor([[855]]) tensor(825.7792, grad_fn=<SubBackward0>)\n",
      "loss: 0.034176405519247055\n",
      "tensor([[855]]) tensor(832.3529, grad_fn=<SubBackward0>)\n",
      "loss: 0.026487812399864197\n",
      "tensor([[855]]) tensor(838.9414, grad_fn=<SubBackward0>)\n",
      "loss: 0.01878201588988304\n",
      "tensor([[855]]) tensor(829.7009, grad_fn=<SubBackward0>)\n",
      "loss: 0.02958962880074978\n",
      "tensor([[855]]) tensor(842.7970, grad_fn=<SubBackward0>)\n",
      "loss: 0.014272499829530716\n",
      "tensor([[855]]) tensor(828.1945, grad_fn=<SubBackward0>)\n",
      "loss: 0.03135152906179428\n",
      "tensor([[855]]) tensor(819.3822, grad_fn=<SubBackward0>)\n",
      "loss: 0.04165827855467796\n",
      "tensor([[855]]) tensor(836.0453, grad_fn=<SubBackward0>)\n",
      "loss: 0.02216925285756588\n",
      "tensor([[855]]) tensor(827.0839, grad_fn=<SubBackward0>)\n",
      "loss: 0.032650452107191086\n",
      "tensor([[855]]) tensor(817.7656, grad_fn=<SubBackward0>)\n",
      "loss: 0.04354901239275932\n",
      "tensor([[855]]) tensor(833.3764, grad_fn=<SubBackward0>)\n",
      "loss: 0.02529073879122734\n",
      "tensor([[855]]) tensor(833.0754, grad_fn=<SubBackward0>)\n",
      "loss: 0.0256427600979805\n",
      "tensor([[855]]) tensor(831.0765, grad_fn=<SubBackward0>)\n",
      "loss: 0.027980728074908257\n",
      "tensor([[855]]) tensor(843.8876, grad_fn=<SubBackward0>)\n",
      "loss: 0.012996937148272991\n",
      "tensor([[855]]) tensor(829.1582, grad_fn=<SubBackward0>)\n",
      "loss: 0.030224323272705078\n",
      "tensor([[855]]) tensor(837.4603, grad_fn=<SubBackward0>)\n",
      "loss: 0.020514272153377533\n",
      "tensor([[855]]) tensor(828.6733, grad_fn=<SubBackward0>)\n",
      "loss: 0.03079148754477501\n",
      "tensor([[855]]) tensor(824.8266, grad_fn=<SubBackward0>)\n",
      "loss: 0.03529052808880806\n",
      "tensor([[855]]) tensor(836.9716, grad_fn=<SubBackward0>)\n",
      "loss: 0.021085843443870544\n",
      "tensor([[855]]) tensor(827.5439, grad_fn=<SubBackward0>)\n",
      "loss: 0.032112378627061844\n",
      "tensor([[855]]) tensor(829.3992, grad_fn=<SubBackward0>)\n",
      "loss: 0.029942454770207405\n",
      "tensor([[855]]) tensor(833.8248, grad_fn=<SubBackward0>)\n",
      "loss: 0.024766264483332634\n",
      "tensor([[855]]) tensor(829.0837, grad_fn=<SubBackward0>)\n",
      "loss: 0.030311379581689835\n",
      "tensor([[855]]) tensor(830.5485, grad_fn=<SubBackward0>)\n",
      "loss: 0.028598254546523094\n",
      "tensor([[855]]) tensor(839.0106, grad_fn=<SubBackward0>)\n",
      "loss: 0.0187011007219553\n",
      "tensor([[855]]) tensor(823.3221, grad_fn=<SubBackward0>)\n",
      "loss: 0.03705016151070595\n",
      "tensor([[855]]) tensor(827.5864, grad_fn=<SubBackward0>)\n",
      "loss: 0.03206264227628708\n",
      "tensor([[855]]) tensor(840.7854, grad_fn=<SubBackward0>)\n",
      "loss: 0.016625262796878815\n",
      "tensor([[855]]) tensor(840.7872, grad_fn=<SubBackward0>)\n",
      "loss: 0.016623085364699364\n",
      "tensor([[855]]) tensor(838.3726, grad_fn=<SubBackward0>)\n",
      "loss: 0.019447263330221176\n",
      "tensor([[855]]) tensor(833.9153, grad_fn=<SubBackward0>)\n",
      "loss: 0.024660486727952957\n",
      "tensor([[855]]) tensor(831.1830, grad_fn=<SubBackward0>)\n",
      "loss: 0.02785617671906948\n",
      "tensor([[855]]) tensor(832.7488, grad_fn=<SubBackward0>)\n",
      "loss: 0.026024820283055305\n",
      "tensor([[855]]) tensor(837.5807, grad_fn=<SubBackward0>)\n",
      "loss: 0.0203733928501606\n",
      "tensor([[855]]) tensor(831.5614, grad_fn=<SubBackward0>)\n",
      "loss: 0.02741360105574131\n",
      "tensor([[855]]) tensor(838.6134, grad_fn=<SubBackward0>)\n",
      "loss: 0.01916557364165783\n",
      "tensor([[855]]) tensor(823.1376, grad_fn=<SubBackward0>)\n",
      "loss: 0.037265997380018234\n",
      "tensor([[855]]) tensor(815.6956, grad_fn=<SubBackward0>)\n",
      "loss: 0.04597010836005211\n",
      "tensor([[855]]) tensor(827.0009, grad_fn=<SubBackward0>)\n",
      "loss: 0.032747555524110794\n",
      "tensor([[855]]) tensor(838.8529, grad_fn=<SubBackward0>)\n",
      "loss: 0.018885456025600433\n",
      "tensor([[855]]) tensor(816.2018, grad_fn=<SubBackward0>)\n",
      "loss: 0.04537801444530487\n",
      "tensor([[855]]) tensor(813.5121, grad_fn=<SubBackward0>)\n",
      "loss: 0.048523806035518646\n",
      "tensor([[855]]) tensor(839.1536, grad_fn=<SubBackward0>)\n",
      "loss: 0.018533842638134956\n",
      "tensor([[855]]) tensor(816.8206, grad_fn=<SubBackward0>)\n",
      "loss: 0.04465435445308685\n",
      "tensor([[855]]) tensor(796.7860, grad_fn=<SubBackward0>)\n",
      "loss: 0.06808653473854065\n",
      "tensor([[855]]) tensor(810.8381, grad_fn=<SubBackward0>)\n",
      "loss: 0.051651377230882645\n",
      "tensor([[855]]) tensor(833.0366, grad_fn=<SubBackward0>)\n",
      "loss: 0.025688162073493004\n",
      "tensor([[855]]) tensor(824.0684, grad_fn=<SubBackward0>)\n",
      "loss: 0.03617730364203453\n",
      "tensor([[855]]) tensor(812.4916, grad_fn=<SubBackward0>)\n",
      "loss: 0.04971741884946823\n",
      "tensor([[855]]) tensor(824.9225, grad_fn=<SubBackward0>)\n",
      "loss: 0.03517830744385719\n",
      "tensor([[855]]) tensor(830.0458, grad_fn=<SubBackward0>)\n",
      "loss: 0.02918626181781292\n",
      "tensor([[855]]) tensor(817.7811, grad_fn=<SubBackward0>)\n",
      "loss: 0.04353086277842522\n",
      "tensor([[855]]) tensor(821.4052, grad_fn=<SubBackward0>)\n",
      "loss: 0.039292220026254654\n",
      "tensor([[855]]) tensor(833.8376, grad_fn=<SubBackward0>)\n",
      "loss: 0.024751272052526474\n",
      "tensor([[855]]) tensor(827.1895, grad_fn=<SubBackward0>)\n",
      "loss: 0.032526955008506775\n",
      "tensor([[855]]) tensor(826.0767, grad_fn=<SubBackward0>)\n",
      "loss: 0.03382837772369385\n",
      "tensor([[855]]) tensor(842.9868, grad_fn=<SubBackward0>)\n",
      "loss: 0.014050578698515892\n",
      "tensor([[855]]) tensor(836.8925, grad_fn=<SubBackward0>)\n",
      "loss: 0.021178361028432846\n",
      "tensor([[855]]) tensor(844.8494, grad_fn=<SubBackward0>)\n",
      "loss: 0.0118721229955554\n",
      "tensor([[855]]) tensor(836.2863, grad_fn=<SubBackward0>)\n",
      "loss: 0.021887386217713356\n",
      "tensor([[855]]) tensor(842.0649, grad_fn=<SubBackward0>)\n",
      "loss: 0.015128758735954762\n",
      "tensor([[855]]) tensor(842.4166, grad_fn=<SubBackward0>)\n",
      "loss: 0.014717432670295238\n",
      "tensor([[855]]) tensor(837.2852, grad_fn=<SubBackward0>)\n",
      "loss: 0.020719079300761223\n",
      "tensor([[855]]) tensor(843.1926, grad_fn=<SubBackward0>)\n",
      "loss: 0.013809757307171822\n",
      "tensor([[855]]) tensor(840.7255, grad_fn=<SubBackward0>)\n",
      "loss: 0.01669529266655445\n",
      "tensor([[855]]) tensor(845.2786, grad_fn=<SubBackward0>)\n",
      "loss: 0.011370117776095867\n",
      "tensor([[855]]) tensor(845.2223, grad_fn=<SubBackward0>)\n",
      "loss: 0.01143595390021801\n",
      "tensor([[855]]) tensor(841.4489, grad_fn=<SubBackward0>)\n",
      "loss: 0.015849296003580093\n",
      "tensor([[855]]) tensor(845.5060, grad_fn=<SubBackward0>)\n",
      "loss: 0.011104150675237179\n",
      "tensor([[855]]) tensor(840.2438, grad_fn=<SubBackward0>)\n",
      "loss: 0.01725877821445465\n",
      "tensor([[855]]) tensor(842.6137, grad_fn=<SubBackward0>)\n",
      "loss: 0.014486872591078281\n",
      "tensor([[855]]) tensor(835.3721, grad_fn=<SubBackward0>)\n",
      "loss: 0.022956589236855507\n",
      "tensor([[855]]) tensor(839.2316, grad_fn=<SubBackward0>)\n",
      "loss: 0.018442539498209953\n",
      "tensor([[855]]) tensor(838.5955, grad_fn=<SubBackward0>)\n",
      "loss: 0.01918652653694153\n",
      "tensor([[855]]) tensor(840.9252, grad_fn=<SubBackward0>)\n",
      "loss: 0.016461698338389397\n",
      "tensor([[855]]) tensor(841.9976, grad_fn=<SubBackward0>)\n",
      "loss: 0.015207551419734955\n",
      "tensor([[855]]) tensor(840.5618, grad_fn=<SubBackward0>)\n",
      "loss: 0.016886821016669273\n",
      "tensor([[855]]) tensor(842.6168, grad_fn=<SubBackward0>)\n",
      "loss: 0.014483249746263027\n",
      "tensor([[855]]) tensor(832.5167, grad_fn=<SubBackward0>)\n",
      "loss: 0.026296300813555717\n",
      "tensor([[855]]) tensor(844.6447, grad_fn=<SubBackward0>)\n",
      "loss: 0.01211144495755434\n",
      "tensor([[855]]) tensor(838.1656, grad_fn=<SubBackward0>)\n",
      "loss: 0.01968933455646038\n",
      "tensor([[855]]) tensor(838.2642, grad_fn=<SubBackward0>)\n",
      "loss: 0.019574100151658058\n",
      "tensor([[855]]) tensor(843.3895, grad_fn=<SubBackward0>)\n",
      "loss: 0.013579519465565681\n",
      "tensor([[855]]) tensor(837.3879, grad_fn=<SubBackward0>)\n",
      "loss: 0.02059890143573284\n",
      "tensor([[855]]) tensor(840.6790, grad_fn=<SubBackward0>)\n",
      "loss: 0.016749724745750427\n",
      "tensor([[855]]) tensor(825.1786, grad_fn=<SubBackward0>)\n",
      "loss: 0.034878771752119064\n",
      "tensor([[855]]) tensor(828.4327, grad_fn=<SubBackward0>)\n",
      "loss: 0.03107278421521187\n",
      "tensor([[855]]) tensor(838.6759, grad_fn=<SubBackward0>)\n",
      "loss: 0.019092528149485588\n",
      "tensor([[855]]) tensor(822.8972, grad_fn=<SubBackward0>)\n",
      "loss: 0.03754713386297226\n",
      "tensor([[855]]) tensor(834.3068, grad_fn=<SubBackward0>)\n",
      "loss: 0.024202581495046616\n",
      "tensor([[855]]) tensor(833.3645, grad_fn=<SubBackward0>)\n",
      "loss: 0.02530463971197605\n",
      "tensor([[855]]) tensor(828.3273, grad_fn=<SubBackward0>)\n",
      "loss: 0.031196175143122673\n",
      "tensor([[855]]) tensor(837.9006, grad_fn=<SubBackward0>)\n",
      "loss: 0.01999925822019577\n",
      "tensor([[855]]) tensor(840.8002, grad_fn=<SubBackward0>)\n",
      "loss: 0.016607915982604027\n",
      "tensor([[855]]) tensor(838.2134, grad_fn=<SubBackward0>)\n",
      "loss: 0.019633475691080093\n",
      "tensor([[855]]) tensor(833.6535, grad_fn=<SubBackward0>)\n",
      "loss: 0.024966662749648094\n",
      "tensor([[855]]) tensor(838.8654, grad_fn=<SubBackward0>)\n",
      "loss: 0.018870964646339417\n",
      "tensor([[855]]) tensor(843.4073, grad_fn=<SubBackward0>)\n",
      "loss: 0.013558727689087391\n",
      "tensor([[855]]) tensor(840.9501, grad_fn=<SubBackward0>)\n",
      "loss: 0.016432663425803185\n",
      "tensor([[855]]) tensor(830.5775, grad_fn=<SubBackward0>)\n",
      "loss: 0.028564346954226494\n",
      "tensor([[855]]) tensor(835.1273, grad_fn=<SubBackward0>)\n",
      "loss: 0.023242954164743423\n",
      "tensor([[855]]) tensor(840.7612, grad_fn=<SubBackward0>)\n",
      "loss: 0.016653621569275856\n",
      "tensor([[855]]) tensor(844.1555, grad_fn=<SubBackward0>)\n",
      "loss: 0.012683676555752754\n",
      "tensor([[855]]) tensor(840.4885, grad_fn=<SubBackward0>)\n",
      "loss: 0.016972502693533897\n",
      "tensor([[855]]) tensor(841.6364, grad_fn=<SubBackward0>)\n",
      "loss: 0.015629924833774567\n",
      "tensor([[855]]) tensor(843.1287, grad_fn=<SubBackward0>)\n",
      "loss: 0.013884516432881355\n",
      "tensor([[855]]) tensor(840.2269, grad_fn=<SubBackward0>)\n",
      "loss: 0.017278481274843216\n",
      "tensor([[855]]) tensor(839.1931, grad_fn=<SubBackward0>)\n",
      "loss: 0.01848754845559597\n",
      "tensor([[855]]) tensor(833.5819, grad_fn=<SubBackward0>)\n",
      "loss: 0.025050362572073936\n",
      "tensor([[855]]) tensor(841.6598, grad_fn=<SubBackward0>)\n",
      "loss: 0.015602584928274155\n",
      "tensor([[855]]) tensor(829.8052, grad_fn=<SubBackward0>)\n",
      "loss: 0.029467666521668434\n",
      "tensor([[855]]) tensor(826.1874, grad_fn=<SubBackward0>)\n",
      "loss: 0.03369893878698349\n",
      "tensor([[855]]) tensor(846.0913, grad_fn=<SubBackward0>)\n",
      "loss: 0.010419522412121296\n",
      "tensor([[855]]) tensor(832.6249, grad_fn=<SubBackward0>)\n",
      "loss: 0.026169661432504654\n",
      "tensor([[855]]) tensor(836.5441, grad_fn=<SubBackward0>)\n",
      "loss: 0.021585814654827118\n",
      "tensor([[855]]) tensor(839.6673, grad_fn=<SubBackward0>)\n",
      "loss: 0.017932984977960587\n",
      "tensor([[855]]) tensor(843.0939, grad_fn=<SubBackward0>)\n",
      "loss: 0.01392520684748888\n",
      "tensor([[855]]) tensor(830.9724, grad_fn=<SubBackward0>)\n",
      "loss: 0.028102459385991096\n",
      "tensor([[855]]) tensor(827.8054, grad_fn=<SubBackward0>)\n",
      "loss: 0.03180659934878349\n",
      "tensor([[855]]) tensor(841.7254, grad_fn=<SubBackward0>)\n",
      "loss: 0.015525827184319496\n",
      "tensor([[855]]) tensor(823.2393, grad_fn=<SubBackward0>)\n",
      "loss: 0.03714703023433685\n",
      "tensor([[855]]) tensor(819.3844, grad_fn=<SubBackward0>)\n",
      "loss: 0.041655637323856354\n",
      "tensor([[855]]) tensor(834.1774, grad_fn=<SubBackward0>)\n",
      "loss: 0.024353938177227974\n",
      "tensor([[855]]) tensor(825.5842, grad_fn=<SubBackward0>)\n",
      "loss: 0.034404393285512924\n",
      "tensor([[855]]) tensor(829.0603, grad_fn=<SubBackward0>)\n",
      "loss: 0.030338792130351067\n",
      "tensor([[855]]) tensor(842.4425, grad_fn=<SubBackward0>)\n",
      "loss: 0.01468709297478199\n",
      "tensor([[855]]) tensor(831.9119, grad_fn=<SubBackward0>)\n",
      "loss: 0.0270035769790411\n",
      "tensor([[855]]) tensor(839.6450, grad_fn=<SubBackward0>)\n",
      "loss: 0.017959022894501686\n",
      "tensor([[855]]) tensor(837.4962, grad_fn=<SubBackward0>)\n",
      "loss: 0.02047228068113327\n",
      "tensor([[855]]) tensor(842.5704, grad_fn=<SubBackward0>)\n",
      "loss: 0.014537467621266842\n",
      "tensor([[855]]) tensor(837.0931, grad_fn=<SubBackward0>)\n",
      "loss: 0.02094366028904915\n",
      "tensor([[855]]) tensor(839.7208, grad_fn=<SubBackward0>)\n",
      "loss: 0.017870450392365456\n",
      "tensor([[855]]) tensor(837.7328, grad_fn=<SubBackward0>)\n",
      "loss: 0.02019551582634449\n",
      "tensor([[855]]) tensor(839.1168, grad_fn=<SubBackward0>)\n",
      "loss: 0.01857687160372734\n",
      "tensor([[855]]) tensor(843.0302, grad_fn=<SubBackward0>)\n",
      "loss: 0.013999787159264088\n",
      "tensor([[855]]) tensor(833.7827, grad_fn=<SubBackward0>)\n",
      "loss: 0.02481560967862606\n",
      "tensor([[855]]) tensor(842.9913, grad_fn=<SubBackward0>)\n",
      "loss: 0.014045242220163345\n",
      "tensor([[855]]) tensor(834.4641, grad_fn=<SubBackward0>)\n",
      "loss: 0.02401856519281864\n",
      "tensor([[855]]) tensor(834.2983, grad_fn=<SubBackward0>)\n",
      "loss: 0.024212485179305077\n",
      "tensor([[855]]) tensor(841.9512, grad_fn=<SubBackward0>)\n",
      "loss: 0.015261823311448097\n",
      "tensor([[855]]) tensor(834.6268, grad_fn=<SubBackward0>)\n",
      "loss: 0.023828303441405296\n",
      "tensor([[855]]) tensor(842.5824, grad_fn=<SubBackward0>)\n",
      "loss: 0.014523547142744064\n",
      "tensor([[855]]) tensor(826.6008, grad_fn=<SubBackward0>)\n",
      "loss: 0.03321542218327522\n",
      "tensor([[855]]) tensor(826.1194, grad_fn=<SubBackward0>)\n",
      "loss: 0.033778443932533264\n",
      "tensor([[855]]) tensor(839.5425, grad_fn=<SubBackward0>)\n",
      "loss: 0.018078934401273727\n",
      "tensor([[855]]) tensor(821.6237, grad_fn=<SubBackward0>)\n",
      "loss: 0.039036694914102554\n",
      "tensor([[855]]) tensor(817.7294, grad_fn=<SubBackward0>)\n",
      "loss: 0.04359138011932373\n",
      "tensor([[855]]) tensor(837.1187, grad_fn=<SubBackward0>)\n",
      "loss: 0.020913856104016304\n",
      "tensor([[855]]) tensor(823.6025, grad_fn=<SubBackward0>)\n",
      "loss: 0.03672223165631294\n",
      "tensor([[855]]) tensor(818.8502, grad_fn=<SubBackward0>)\n",
      "loss: 0.042280517518520355\n",
      "tensor([[855]]) tensor(832.1248, grad_fn=<SubBackward0>)\n",
      "loss: 0.026754600927233696\n",
      "tensor([[855]]) tensor(833.5214, grad_fn=<SubBackward0>)\n",
      "loss: 0.02512124925851822\n",
      "tensor([[855]]) tensor(830.4696, grad_fn=<SubBackward0>)\n",
      "loss: 0.028690503910183907\n",
      "tensor([[855]]) tensor(837.8622, grad_fn=<SubBackward0>)\n",
      "loss: 0.020044267177581787\n",
      "tensor([[855]]) tensor(828.7233, grad_fn=<SubBackward0>)\n",
      "loss: 0.030733004212379456\n",
      "tensor([[855]]) tensor(831.0851, grad_fn=<SubBackward0>)\n",
      "loss: 0.027970610186457634\n",
      "tensor([[855]]) tensor(839.0359, grad_fn=<SubBackward0>)\n",
      "loss: 0.01867147535085678\n",
      "tensor([[855]]) tensor(836.1033, grad_fn=<SubBackward0>)\n",
      "loss: 0.022101400420069695\n",
      "tensor([[855]]) tensor(843.4188, grad_fn=<SubBackward0>)\n",
      "loss: 0.013545307330787182\n",
      "tensor([[855]]) tensor(837.7757, grad_fn=<SubBackward0>)\n",
      "loss: 0.020145367830991745\n",
      "tensor([[855]]) tensor(829.2336, grad_fn=<SubBackward0>)\n",
      "loss: 0.03013617917895317\n",
      "tensor([[855]]) tensor(845.3365, grad_fn=<SubBackward0>)\n",
      "loss: 0.011302300728857517\n",
      "tensor([[855]]) tensor(840.2681, grad_fn=<SubBackward0>)\n",
      "loss: 0.017230261117219925\n",
      "tensor([[855]]) tensor(839.6278, grad_fn=<SubBackward0>)\n",
      "loss: 0.017979172989726067\n",
      "tensor([[855]]) tensor(846.6534, grad_fn=<SubBackward0>)\n",
      "loss: 0.009762055240571499\n",
      "tensor([[855]]) tensor(838.2667, grad_fn=<SubBackward0>)\n",
      "loss: 0.019571155309677124\n",
      "tensor([[855]]) tensor(847.1230, grad_fn=<SubBackward0>)\n",
      "loss: 0.009212864562869072\n",
      "tensor([[855]]) tensor(843.5795, grad_fn=<SubBackward0>)\n",
      "loss: 0.013357258401811123\n",
      "tensor([[855]]) tensor(833.2770, grad_fn=<SubBackward0>)\n",
      "loss: 0.02540704421699047\n",
      "tensor([[855]]) tensor(841.1703, grad_fn=<SubBackward0>)\n",
      "loss: 0.01617506518959999\n",
      "tensor([[855]]) tensor(846.8834, grad_fn=<SubBackward0>)\n",
      "loss: 0.009493144229054451\n",
      "tensor([[855]]) tensor(832.8759, grad_fn=<SubBackward0>)\n",
      "loss: 0.025876140221953392\n",
      "tensor([[855]]) tensor(833.0615, grad_fn=<SubBackward0>)\n",
      "loss: 0.02565905451774597\n",
      "tensor([[855]]) tensor(830.7490, grad_fn=<SubBackward0>)\n",
      "loss: 0.02836371585726738\n",
      "tensor([[855]]) tensor(839.6218, grad_fn=<SubBackward0>)\n",
      "loss: 0.017986256629228592\n",
      "tensor([[855]]) tensor(825.6007, grad_fn=<SubBackward0>)\n",
      "loss: 0.03438510000705719\n",
      "tensor([[855]]) tensor(827.3408, grad_fn=<SubBackward0>)\n",
      "loss: 0.03234993666410446\n",
      "tensor([[855]]) tensor(838.7554, grad_fn=<SubBackward0>)\n",
      "loss: 0.01899949461221695\n",
      "tensor([[855]]) tensor(837.8561, grad_fn=<SubBackward0>)\n",
      "loss: 0.02005140483379364\n",
      "tensor([[855]]) tensor(840.5752, grad_fn=<SubBackward0>)\n",
      "loss: 0.01687113381922245\n",
      "tensor([[855]]) tensor(834.4955, grad_fn=<SubBackward0>)\n",
      "loss: 0.02398192696273327\n",
      "tensor([[855]]) tensor(844.1585, grad_fn=<SubBackward0>)\n",
      "loss: 0.012680106796324253\n",
      "tensor([[855]]) tensor(827.6588, grad_fn=<SubBackward0>)\n",
      "loss: 0.0319780670106411\n",
      "tensor([[855]]) tensor(828.9886, grad_fn=<SubBackward0>)\n",
      "loss: 0.03042270615696907\n",
      "tensor([[855]]) tensor(842.1108, grad_fn=<SubBackward0>)\n",
      "loss: 0.01507507637143135\n",
      "tensor([[855]]) tensor(826.0566, grad_fn=<SubBackward0>)\n",
      "loss: 0.033851880580186844\n",
      "tensor([[855]]) tensor(816.2739, grad_fn=<SubBackward0>)\n",
      "loss: 0.04529372602701187\n",
      "tensor([[855]]) tensor(834.6877, grad_fn=<SubBackward0>)\n",
      "loss: 0.023757077753543854\n",
      "tensor([[855]]) tensor(826.0483, grad_fn=<SubBackward0>)\n",
      "loss: 0.03386155515909195\n",
      "tensor([[855]]) tensor(810.5720, grad_fn=<SubBackward0>)\n",
      "loss: 0.05196261778473854\n",
      "tensor([[855]]) tensor(825.1262, grad_fn=<SubBackward0>)\n",
      "loss: 0.03494016453623772\n",
      "tensor([[855]]) tensor(840.8549, grad_fn=<SubBackward0>)\n",
      "loss: 0.016544025391340256\n",
      "tensor([[855]]) tensor(821.3146, grad_fn=<SubBackward0>)\n",
      "loss: 0.03939806669950485\n",
      "tensor([[855]]) tensor(828.7649, grad_fn=<SubBackward0>)\n",
      "loss: 0.030684353783726692\n",
      "tensor([[855]]) tensor(830.8732, grad_fn=<SubBackward0>)\n",
      "loss: 0.02821851521730423\n",
      "tensor([[855]]) tensor(823.0968, grad_fn=<SubBackward0>)\n",
      "loss: 0.03731368109583855\n",
      "tensor([[855]]) tensor(831.6420, grad_fn=<SubBackward0>)\n",
      "loss: 0.02731926366686821\n",
      "tensor([[855]]) tensor(838.3193, grad_fn=<SubBackward0>)\n",
      "loss: 0.01950961910188198\n",
      "tensor([[855]]) tensor(839.2462, grad_fn=<SubBackward0>)\n",
      "loss: 0.018425442278385162\n",
      "tensor([[855]]) tensor(842.1383, grad_fn=<SubBackward0>)\n",
      "loss: 0.015042917802929878\n",
      "tensor([[855]]) tensor(838.1836, grad_fn=<SubBackward0>)\n",
      "loss: 0.019668275490403175\n",
      "tensor([[855]]) tensor(839.0726, grad_fn=<SubBackward0>)\n",
      "loss: 0.018628589808940887\n",
      "tensor([[855]]) tensor(830.7792, grad_fn=<SubBackward0>)\n",
      "loss: 0.028328485786914825\n",
      "tensor([[855]]) tensor(832.6618, grad_fn=<SubBackward0>)\n",
      "loss: 0.026126544922590256\n",
      "tensor([[855]]) tensor(845.3682, grad_fn=<SubBackward0>)\n",
      "loss: 0.011265269480645657\n",
      "tensor([[855]]) tensor(846.3439, grad_fn=<SubBackward0>)\n",
      "loss: 0.010124090127646923\n",
      "tensor([[855]]) tensor(845.2598, grad_fn=<SubBackward0>)\n",
      "loss: 0.011392033658921719\n",
      "tensor([[855]]) tensor(845.6489, grad_fn=<SubBackward0>)\n",
      "loss: 0.010937000624835491\n",
      "tensor([[855]]) tensor(842.0543, grad_fn=<SubBackward0>)\n",
      "loss: 0.01514116209000349\n",
      "tensor([[855]]) tensor(837.2355, grad_fn=<SubBackward0>)\n",
      "loss: 0.020777152851223946\n",
      "tensor([[855]]) tensor(844.1873, grad_fn=<SubBackward0>)\n",
      "loss: 0.012646520510315895\n",
      "tensor([[855]]) tensor(835.1578, grad_fn=<SubBackward0>)\n",
      "loss: 0.023207243531942368\n",
      "tensor([[855]]) tensor(844.4437, grad_fn=<SubBackward0>)\n",
      "loss: 0.012346555478870869\n",
      "tensor([[855]]) tensor(821.2766, grad_fn=<SubBackward0>)\n",
      "loss: 0.03944256156682968\n",
      "tensor([[855]]) tensor(817.0831, grad_fn=<SubBackward0>)\n",
      "loss: 0.044347286224365234\n",
      "tensor([[855]]) tensor(832.3865, grad_fn=<SubBackward0>)\n",
      "loss: 0.026448514312505722\n",
      "tensor([[855]]) tensor(841.5503, grad_fn=<SubBackward0>)\n",
      "loss: 0.015730686485767365\n",
      "tensor([[855]]) tensor(837.3575, grad_fn=<SubBackward0>)\n",
      "loss: 0.020634416490793228\n",
      "tensor([[855]]) tensor(831.4333, grad_fn=<SubBackward0>)\n",
      "loss: 0.027563298121094704\n",
      "tensor([[855]]) tensor(832.2538, grad_fn=<SubBackward0>)\n",
      "loss: 0.026603762060403824\n",
      "tensor([[855]]) tensor(836.0599, grad_fn=<SubBackward0>)\n",
      "loss: 0.022152157500386238\n",
      "tensor([[855]]) tensor(838.7422, grad_fn=<SubBackward0>)\n",
      "loss: 0.01901502162218094\n",
      "tensor([[855]]) tensor(843.2280, grad_fn=<SubBackward0>)\n",
      "loss: 0.013768353499472141\n",
      "tensor([[855]]) tensor(834.4128, grad_fn=<SubBackward0>)\n",
      "loss: 0.02407863736152649\n",
      "tensor([[855]]) tensor(836.9031, grad_fn=<SubBackward0>)\n",
      "loss: 0.021166028454899788\n",
      "tensor([[855]]) tensor(841.1228, grad_fn=<SubBackward0>)\n",
      "loss: 0.01623060368001461\n",
      "tensor([[855]]) tensor(845.3385, grad_fn=<SubBackward0>)\n",
      "loss: 0.011299963109195232\n",
      "tensor([[855]]) tensor(838.6599, grad_fn=<SubBackward0>)\n",
      "loss: 0.019111268222332\n",
      "tensor([[855]]) tensor(847.2128, grad_fn=<SubBackward0>)\n",
      "loss: 0.009107819758355618\n",
      "tensor([[855]]) tensor(828.3783, grad_fn=<SubBackward0>)\n",
      "loss: 0.03113647736608982\n",
      "tensor([[855]]) tensor(828.7838, grad_fn=<SubBackward0>)\n",
      "loss: 0.0306622963398695\n",
      "tensor([[855]]) tensor(848.4012, grad_fn=<SubBackward0>)\n",
      "loss: 0.007717806380242109\n",
      "tensor([[855]]) tensor(837.5056, grad_fn=<SubBackward0>)\n",
      "loss: 0.020461339503526688\n",
      "tensor([[855]]) tensor(846.2147, grad_fn=<SubBackward0>)\n",
      "loss: 0.010275214910507202\n",
      "tensor([[855]]) tensor(847.2796, grad_fn=<SubBackward0>)\n",
      "loss: 0.009029705077409744\n",
      "tensor([[855]]) tensor(842.9781, grad_fn=<SubBackward0>)\n",
      "loss: 0.014060662128031254\n",
      "tensor([[855]]) tensor(840.9099, grad_fn=<SubBackward0>)\n",
      "loss: 0.016479725018143654\n",
      "tensor([[855]]) tensor(843.9671, grad_fn=<SubBackward0>)\n",
      "loss: 0.012903992086648941\n",
      "tensor([[855]]) tensor(837.4371, grad_fn=<SubBackward0>)\n",
      "loss: 0.020541328936815262\n",
      "tensor([[855]]) tensor(837.1351, grad_fn=<SubBackward0>)\n",
      "loss: 0.020894672721624374\n",
      "tensor([[855]]) tensor(841.0488, grad_fn=<SubBackward0>)\n",
      "loss: 0.016317231580615044\n",
      "tensor([[855]]) tensor(837.3842, grad_fn=<SubBackward0>)\n",
      "loss: 0.020603327080607414\n",
      "tensor([[855]]) tensor(838.1978, grad_fn=<SubBackward0>)\n",
      "loss: 0.01965176686644554\n",
      "tensor([[855]]) tensor(841.4080, grad_fn=<SubBackward0>)\n",
      "loss: 0.015897123143076897\n",
      "tensor([[855]]) tensor(833.7559, grad_fn=<SubBackward0>)\n",
      "loss: 0.02484687604010105\n",
      "tensor([[855]]) tensor(843.2372, grad_fn=<SubBackward0>)\n",
      "loss: 0.013757645152509212\n",
      "tensor([[855]]) tensor(840.3564, grad_fn=<SubBackward0>)\n",
      "loss: 0.01712699979543686\n",
      "tensor([[855]]) tensor(840.9612, grad_fn=<SubBackward0>)\n",
      "loss: 0.01641961745917797\n",
      "tensor([[855]]) tensor(847.0477, grad_fn=<SubBackward0>)\n",
      "loss: 0.009300865232944489\n",
      "tensor([[855]]) tensor(838.3516, grad_fn=<SubBackward0>)\n",
      "loss: 0.01947176828980446\n",
      "tensor([[855]]) tensor(839.2114, grad_fn=<SubBackward0>)\n",
      "loss: 0.018466150388121605\n",
      "tensor([[855]]) tensor(846.3593, grad_fn=<SubBackward0>)\n",
      "loss: 0.01010613702237606\n",
      "tensor([[855]]) tensor(833.8720, grad_fn=<SubBackward0>)\n",
      "loss: 0.02471110038459301\n",
      "tensor([[855]]) tensor(837.6163, grad_fn=<SubBackward0>)\n",
      "loss: 0.020331792533397675\n",
      "tensor([[855]]) tensor(837.5125, grad_fn=<SubBackward0>)\n",
      "loss: 0.020453184843063354\n",
      "tensor([[855]]) tensor(836.7935, grad_fn=<SubBackward0>)\n",
      "loss: 0.021294202655553818\n",
      "tensor([[855]]) tensor(833.9261, grad_fn=<SubBackward0>)\n",
      "loss: 0.024647869169712067\n",
      "tensor([[855]]) tensor(829.8496, grad_fn=<SubBackward0>)\n",
      "loss: 0.02941569685935974\n",
      "tensor([[855]]) tensor(832.2612, grad_fn=<SubBackward0>)\n",
      "loss: 0.026595087721943855\n",
      "tensor([[855]]) tensor(832.3970, grad_fn=<SubBackward0>)\n",
      "loss: 0.026436306536197662\n",
      "tensor([[855]]) tensor(832.4233, grad_fn=<SubBackward0>)\n",
      "loss: 0.026405449956655502\n",
      "tensor([[855]]) tensor(836.9033, grad_fn=<SubBackward0>)\n",
      "loss: 0.02116577886044979\n",
      "tensor([[855]]) tensor(837.6542, grad_fn=<SubBackward0>)\n",
      "loss: 0.020287426188588142\n",
      "tensor([[855]]) tensor(832.9108, grad_fn=<SubBackward0>)\n",
      "loss: 0.025835378095507622\n",
      "tensor([[855]]) tensor(842.3668, grad_fn=<SubBackward0>)\n",
      "loss: 0.014775718562304974\n",
      "tensor([[855]]) tensor(837.0939, grad_fn=<SubBackward0>)\n",
      "loss: 0.020942768082022667\n",
      "tensor([[855]]) tensor(840.3835, grad_fn=<SubBackward0>)\n",
      "loss: 0.017095359042286873\n",
      "tensor([[855]]) tensor(841.9014, grad_fn=<SubBackward0>)\n",
      "loss: 0.015320003032684326\n",
      "tensor([[855]]) tensor(838.7603, grad_fn=<SubBackward0>)\n",
      "loss: 0.018993765115737915\n",
      "tensor([[855]]) tensor(840.6636, grad_fn=<SubBackward0>)\n",
      "loss: 0.01676778495311737\n",
      "tensor([[855]]) tensor(839.8248, grad_fn=<SubBackward0>)\n",
      "loss: 0.01774880848824978\n",
      "tensor([[855]]) tensor(844.8199, grad_fn=<SubBackward0>)\n",
      "loss: 0.011906584724783897\n",
      "tensor([[855]]) tensor(842.7640, grad_fn=<SubBackward0>)\n",
      "loss: 0.014311066828668118\n",
      "tensor([[855]]) tensor(841.2844, grad_fn=<SubBackward0>)\n",
      "loss: 0.016041573137044907\n",
      "tensor([[855]]) tensor(847.1439, grad_fn=<SubBackward0>)\n",
      "loss: 0.00918843224644661\n",
      "tensor([[855]]) tensor(841.5228, grad_fn=<SubBackward0>)\n",
      "loss: 0.015762828290462494\n",
      "tensor([[855]]) tensor(846.4732, grad_fn=<SubBackward0>)\n",
      "loss: 0.009972859174013138\n",
      "tensor([[855]]) tensor(842.8430, grad_fn=<SubBackward0>)\n",
      "loss: 0.014218728989362717\n",
      "tensor([[855]]) tensor(838.3589, grad_fn=<SubBackward0>)\n",
      "loss: 0.019463254138827324\n",
      "tensor([[855]]) tensor(844.6376, grad_fn=<SubBackward0>)\n",
      "loss: 0.012119761668145657\n",
      "tensor([[855]]) tensor(843.3932, grad_fn=<SubBackward0>)\n",
      "loss: 0.013575182296335697\n",
      "tensor([[855]]) tensor(846.1646, grad_fn=<SubBackward0>)\n",
      "loss: 0.010333876125514507\n",
      "tensor([[855]]) tensor(845.6993, grad_fn=<SubBackward0>)\n",
      "loss: 0.01087792869657278\n",
      "tensor([[855]]) tensor(843.4523, grad_fn=<SubBackward0>)\n",
      "loss: 0.01350609865039587\n",
      "tensor([[855]]) tensor(846.0659, grad_fn=<SubBackward0>)\n",
      "loss: 0.010449254885315895\n",
      "tensor([[855]]) tensor(843.5607, grad_fn=<SubBackward0>)\n",
      "loss: 0.013379299081861973\n",
      "tensor([[855]]) tensor(846.0574, grad_fn=<SubBackward0>)\n",
      "loss: 0.01045915950089693\n",
      "tensor([[855]]) tensor(832.2068, grad_fn=<SubBackward0>)\n",
      "loss: 0.02665865793824196\n",
      "tensor([[855]]) tensor(839.2435, grad_fn=<SubBackward0>)\n",
      "loss: 0.018428655341267586\n",
      "tensor([[855]]) tensor(830.2751, grad_fn=<SubBackward0>)\n",
      "loss: 0.028918027877807617\n",
      "tensor([[855]]) tensor(836.3999, grad_fn=<SubBackward0>)\n",
      "loss: 0.021754518151283264\n",
      "tensor([[855]]) tensor(834.9658, grad_fn=<SubBackward0>)\n",
      "loss: 0.023431824520230293\n",
      "tensor([[855]]) tensor(834.1798, grad_fn=<SubBackward0>)\n",
      "loss: 0.02435106411576271\n",
      "tensor([[855]]) tensor(837.6788, grad_fn=<SubBackward0>)\n",
      "loss: 0.020258747041225433\n",
      "tensor([[855]]) tensor(836.6050, grad_fn=<SubBackward0>)\n",
      "loss: 0.021514572203159332\n",
      "tensor([[855]]) tensor(838.4999, grad_fn=<SubBackward0>)\n",
      "loss: 0.019298316910862923\n",
      "tensor([[855]]) tensor(835.1158, grad_fn=<SubBackward0>)\n",
      "loss: 0.02325635775923729\n",
      "tensor([[855]]) tensor(836.5280, grad_fn=<SubBackward0>)\n",
      "loss: 0.021604731678962708\n",
      "tensor([[855]]) tensor(842.6547, grad_fn=<SubBackward0>)\n",
      "loss: 0.014438901096582413\n",
      "tensor([[855]]) tensor(843.7054, grad_fn=<SubBackward0>)\n",
      "loss: 0.013210042379796505\n",
      "tensor([[855]]) tensor(834.8529, grad_fn=<SubBackward0>)\n",
      "loss: 0.02356385439634323\n",
      "tensor([[855]]) tensor(843.0417, grad_fn=<SubBackward0>)\n",
      "loss: 0.013986224308609962\n",
      "tensor([[855]]) tensor(836.6187, grad_fn=<SubBackward0>)\n",
      "loss: 0.021498670801520348\n",
      "tensor([[855]]) tensor(840.8970, grad_fn=<SubBackward0>)\n",
      "loss: 0.016494769603013992\n",
      "tensor([[855]]) tensor(835.7599, grad_fn=<SubBackward0>)\n",
      "loss: 0.022503091022372246\n",
      "tensor([[855]]) tensor(840.4674, grad_fn=<SubBackward0>)\n",
      "loss: 0.01699714921414852\n",
      "tensor([[855]]) tensor(831.8086, grad_fn=<SubBackward0>)\n",
      "loss: 0.027124451473355293\n",
      "tensor([[855]]) tensor(829.4797, grad_fn=<SubBackward0>)\n",
      "loss: 0.02984822541475296\n",
      "tensor([[855]]) tensor(843.2947, grad_fn=<SubBackward0>)\n",
      "loss: 0.013690345920622349\n",
      "tensor([[855]]) tensor(837.8448, grad_fn=<SubBackward0>)\n",
      "loss: 0.020064469426870346\n",
      "tensor([[855]]) tensor(841.6295, grad_fn=<SubBackward0>)\n",
      "loss: 0.01563808135688305\n",
      "tensor([[855]]) tensor(838.9909, grad_fn=<SubBackward0>)\n",
      "loss: 0.01872408762574196\n",
      "tensor([[855]]) tensor(847.0974, grad_fn=<SubBackward0>)\n",
      "loss: 0.00924282893538475\n",
      "tensor([[855]]) tensor(835.0291, grad_fn=<SubBackward0>)\n",
      "loss: 0.023357832804322243\n",
      "tensor([[855]]) tensor(839.6361, grad_fn=<SubBackward0>)\n",
      "loss: 0.017969446256756783\n",
      "tensor([[855]]) tensor(839.5577, grad_fn=<SubBackward0>)\n",
      "loss: 0.01806112378835678\n",
      "tensor([[855]]) tensor(844.4359, grad_fn=<SubBackward0>)\n",
      "loss: 0.012355692684650421\n",
      "tensor([[855]]) tensor(827.9925, grad_fn=<SubBackward0>)\n",
      "loss: 0.03158774599432945\n",
      "tensor([[855]]) tensor(826.0269, grad_fn=<SubBackward0>)\n",
      "loss: 0.033886682242155075\n",
      "tensor([[855]]) tensor(842.6522, grad_fn=<SubBackward0>)\n",
      "loss: 0.014441810548305511\n",
      "tensor([[855]]) tensor(822.2268, grad_fn=<SubBackward0>)\n",
      "loss: 0.03833118453621864\n",
      "tensor([[855]]) tensor(824.0055, grad_fn=<SubBackward0>)\n",
      "loss: 0.036250848323106766\n",
      "tensor([[855]]) tensor(846.6254, grad_fn=<SubBackward0>)\n",
      "loss: 0.00979485735297203\n",
      "tensor([[855]]) tensor(830.0630, grad_fn=<SubBackward0>)\n",
      "loss: 0.02916613034904003\n",
      "tensor([[855]]) tensor(835.3700, grad_fn=<SubBackward0>)\n",
      "loss: 0.02295905165374279\n",
      "tensor([[855]]) tensor(838.6329, grad_fn=<SubBackward0>)\n",
      "loss: 0.01914273016154766\n",
      "tensor([[855]]) tensor(840.0320, grad_fn=<SubBackward0>)\n",
      "loss: 0.017506400123238564\n",
      "tensor([[855]]) tensor(833.6997, grad_fn=<SubBackward0>)\n",
      "loss: 0.02491265907883644\n",
      "tensor([[855]]) tensor(828.7562, grad_fn=<SubBackward0>)\n",
      "loss: 0.030694490298628807\n",
      "tensor([[855]]) tensor(842.9120, grad_fn=<SubBackward0>)\n",
      "loss: 0.014138062484562397\n",
      "tensor([[855]]) tensor(828.2430, grad_fn=<SubBackward0>)\n",
      "loss: 0.03129475936293602\n",
      "tensor([[855]]) tensor(824.8454, grad_fn=<SubBackward0>)\n",
      "loss: 0.03526856005191803\n",
      "tensor([[855]]) tensor(838.6609, grad_fn=<SubBackward0>)\n",
      "loss: 0.019110072404146194\n",
      "tensor([[855]]) tensor(832.8240, grad_fn=<SubBackward0>)\n",
      "loss: 0.02593689039349556\n",
      "tensor([[855]]) tensor(840.2766, grad_fn=<SubBackward0>)\n",
      "loss: 0.017220374196767807\n",
      "tensor([[855]]) tensor(836.6542, grad_fn=<SubBackward0>)\n",
      "loss: 0.02145703323185444\n",
      "tensor([[855]]) tensor(839.4443, grad_fn=<SubBackward0>)\n",
      "loss: 0.018193740397691727\n",
      "tensor([[855]]) tensor(840.1409, grad_fn=<SubBackward0>)\n",
      "loss: 0.017379136756062508\n",
      "tensor([[855]]) tensor(846.6400, grad_fn=<SubBackward0>)\n",
      "loss: 0.009777778759598732\n",
      "tensor([[855]]) tensor(840.4518, grad_fn=<SubBackward0>)\n",
      "loss: 0.01701544225215912\n",
      "tensor([[855]]) tensor(840.8640, grad_fn=<SubBackward0>)\n",
      "loss: 0.016533371061086655\n",
      "tensor([[855]]) tensor(845.3846, grad_fn=<SubBackward0>)\n",
      "loss: 0.01124606654047966\n",
      "tensor([[855]]) tensor(845.5375, grad_fn=<SubBackward0>)\n",
      "loss: 0.011067315936088562\n",
      "tensor([[855]]) tensor(833.2791, grad_fn=<SubBackward0>)\n",
      "loss: 0.025404617190361023\n",
      "tensor([[855]]) tensor(839.8411, grad_fn=<SubBackward0>)\n",
      "loss: 0.017729749903082848\n",
      "tensor([[855]]) tensor(842.7125, grad_fn=<SubBackward0>)\n",
      "loss: 0.014371352270245552\n",
      "tensor([[855]]) tensor(836.2383, grad_fn=<SubBackward0>)\n",
      "loss: 0.02194356732070446\n",
      "tensor([[855]]) tensor(840.0590, grad_fn=<SubBackward0>)\n",
      "loss: 0.017474811524152756\n",
      "tensor([[855]]) tensor(835.6163, grad_fn=<SubBackward0>)\n",
      "loss: 0.02267102710902691\n",
      "tensor([[855]]) tensor(844.3368, grad_fn=<SubBackward0>)\n",
      "loss: 0.012471552938222885\n",
      "tensor([[855]]) tensor(827.2851, grad_fn=<SubBackward0>)\n",
      "loss: 0.03241507709026337\n",
      "tensor([[855]]) tensor(821.4139, grad_fn=<SubBackward0>)\n",
      "loss: 0.0392819419503212\n",
      "tensor([[855]]) tensor(833.5787, grad_fn=<SubBackward0>)\n",
      "loss: 0.02505411021411419\n",
      "tensor([[855]]) tensor(839.6029, grad_fn=<SubBackward0>)\n",
      "loss: 0.018008261919021606\n",
      "tensor([[855]]) tensor(838.6772, grad_fn=<SubBackward0>)\n",
      "loss: 0.019091011956334114\n",
      "tensor([[855]]) tensor(830.4412, grad_fn=<SubBackward0>)\n",
      "loss: 0.028723733499646187\n",
      "tensor([[855]]) tensor(830.2289, grad_fn=<SubBackward0>)\n",
      "loss: 0.028972050175070763\n",
      "tensor([[855]]) tensor(832.8810, grad_fn=<SubBackward0>)\n",
      "loss: 0.025870179757475853\n",
      "tensor([[855]]) tensor(842.3418, grad_fn=<SubBackward0>)\n",
      "loss: 0.014804934151470661\n",
      "tensor([[855]]) tensor(817.9551, grad_fn=<SubBackward0>)\n",
      "loss: 0.04332742840051651\n",
      "tensor([[855]]) tensor(818.7681, grad_fn=<SubBackward0>)\n",
      "loss: 0.04237645864486694\n",
      "tensor([[855]]) tensor(836.4853, grad_fn=<SubBackward0>)\n",
      "loss: 0.021654648706316948\n",
      "tensor([[855]]) tensor(816.0167, grad_fn=<SubBackward0>)\n",
      "loss: 0.045594509690999985\n",
      "tensor([[855]]) tensor(805.8882, grad_fn=<SubBackward0>)\n",
      "loss: 0.05744072049856186\n",
      "tensor([[855]]) tensor(821.4327, grad_fn=<SubBackward0>)\n",
      "loss: 0.03925997018814087\n",
      "tensor([[855]]) tensor(836.7479, grad_fn=<SubBackward0>)\n",
      "loss: 0.02134745568037033\n",
      "tensor([[855]]) tensor(816.4664, grad_fn=<SubBackward0>)\n",
      "loss: 0.04506850242614746\n",
      "tensor([[855]]) tensor(819.2661, grad_fn=<SubBackward0>)\n",
      "loss: 0.0417940728366375\n",
      "tensor([[855]]) tensor(831.3506, grad_fn=<SubBackward0>)\n",
      "loss: 0.027660062536597252\n",
      "tensor([[855]]) tensor(819.8287, grad_fn=<SubBackward0>)\n",
      "loss: 0.04113594815135002\n",
      "tensor([[855]]) tensor(823.6745, grad_fn=<SubBackward0>)\n",
      "loss: 0.03663802891969681\n",
      "tensor([[855]]) tensor(838.0297, grad_fn=<SubBackward0>)\n",
      "loss: 0.019848311319947243\n",
      "tensor([[855]]) tensor(830.5248, grad_fn=<SubBackward0>)\n",
      "loss: 0.02862589806318283\n",
      "tensor([[855]]) tensor(830.3146, grad_fn=<SubBackward0>)\n",
      "loss: 0.028871823102235794\n",
      "tensor([[855]]) tensor(826.4896, grad_fn=<SubBackward0>)\n",
      "loss: 0.03334544971585274\n",
      "tensor([[855]]) tensor(837.7827, grad_fn=<SubBackward0>)\n",
      "loss: 0.020137246698141098\n",
      "tensor([[855]]) tensor(839.5142, grad_fn=<SubBackward0>)\n",
      "loss: 0.018112003803253174\n",
      "tensor([[855]]) tensor(835.5790, grad_fn=<SubBackward0>)\n",
      "loss: 0.022714590653777122\n",
      "tensor([[855]]) tensor(831.5551, grad_fn=<SubBackward0>)\n",
      "loss: 0.027420971542596817\n",
      "tensor([[855]]) tensor(839.2997, grad_fn=<SubBackward0>)\n",
      "loss: 0.01836290769279003\n",
      "tensor([[855]]) tensor(843.0063, grad_fn=<SubBackward0>)\n",
      "loss: 0.014027628116309643\n",
      "tensor([[855]]) tensor(838.2720, grad_fn=<SubBackward0>)\n",
      "loss: 0.01956496201455593\n",
      "tensor([[855]]) tensor(843.8249, grad_fn=<SubBackward0>)\n",
      "loss: 0.013070286251604557\n",
      "tensor([[855]]) tensor(835.2452, grad_fn=<SubBackward0>)\n",
      "loss: 0.023105019703507423\n",
      "tensor([[855]]) tensor(842.0649, grad_fn=<SubBackward0>)\n",
      "loss: 0.015128741040825844\n",
      "tensor([[855]]) tensor(818.7058, grad_fn=<SubBackward0>)\n",
      "loss: 0.04244934394955635\n",
      "tensor([[855]]) tensor(818.2049, grad_fn=<SubBackward0>)\n",
      "loss: 0.04303519427776337\n",
      "tensor([[855]]) tensor(837.7471, grad_fn=<SubBackward0>)\n",
      "loss: 0.020178882405161858\n",
      "tensor([[855]]) tensor(822.9324, grad_fn=<SubBackward0>)\n",
      "loss: 0.037505943328142166\n",
      "tensor([[855]]) tensor(817.6685, grad_fn=<SubBackward0>)\n",
      "loss: 0.04366258904337883\n",
      "tensor([[855]]) tensor(834.5859, grad_fn=<SubBackward0>)\n",
      "loss: 0.02387613244354725\n",
      "tensor([[855]]) tensor(833.1372, grad_fn=<SubBackward0>)\n",
      "loss: 0.02557048201560974\n",
      "tensor([[855]]) tensor(839.2435, grad_fn=<SubBackward0>)\n",
      "loss: 0.018428655341267586\n",
      "tensor([[855]]) tensor(838.6082, grad_fn=<SubBackward0>)\n",
      "loss: 0.01917167752981186\n",
      "tensor([[855]]) tensor(835.7221, grad_fn=<SubBackward0>)\n",
      "loss: 0.02254726178944111\n",
      "tensor([[855]]) tensor(837.7427, grad_fn=<SubBackward0>)\n",
      "loss: 0.02018391527235508\n",
      "tensor([[855]]) tensor(843.9654, grad_fn=<SubBackward0>)\n",
      "loss: 0.012905973009765148\n",
      "tensor([[855]]) tensor(839.1464, grad_fn=<SubBackward0>)\n",
      "loss: 0.018542302772402763\n",
      "tensor([[855]]) tensor(837.6586, grad_fn=<SubBackward0>)\n",
      "loss: 0.020282410085201263\n",
      "tensor([[855]]) tensor(833.6995, grad_fn=<SubBackward0>)\n",
      "loss: 0.024912944063544273\n",
      "tensor([[855]]) tensor(842.1146, grad_fn=<SubBackward0>)\n",
      "loss: 0.015070686116814613\n",
      "tensor([[855]]) tensor(843.9888, grad_fn=<SubBackward0>)\n",
      "loss: 0.012878596782684326\n",
      "tensor([[855]]) tensor(839.6589, grad_fn=<SubBackward0>)\n",
      "loss: 0.01794283650815487\n",
      "tensor([[855]]) tensor(842.3599, grad_fn=<SubBackward0>)\n",
      "loss: 0.014783750288188457\n",
      "tensor([[855]]) tensor(840.6074, grad_fn=<SubBackward0>)\n",
      "loss: 0.016833459958434105\n",
      "tensor([[855]]) tensor(842.0874, grad_fn=<SubBackward0>)\n",
      "loss: 0.015102453529834747\n",
      "tensor([[855]]) tensor(836.5100, grad_fn=<SubBackward0>)\n",
      "loss: 0.021625755354762077\n",
      "tensor([[855]]) tensor(843.5425, grad_fn=<SubBackward0>)\n",
      "loss: 0.01340057235211134\n",
      "tensor([[855]]) tensor(826.7786, grad_fn=<SubBackward0>)\n",
      "loss: 0.033007439225912094\n",
      "tensor([[855]]) tensor(832.5996, grad_fn=<SubBackward0>)\n",
      "loss: 0.026199322193861008\n",
      "tensor([[855]]) tensor(840.5638, grad_fn=<SubBackward0>)\n",
      "loss: 0.01688442938029766\n",
      "tensor([[855]]) tensor(840.2058, grad_fn=<SubBackward0>)\n",
      "loss: 0.017303109169006348\n",
      "tensor([[855]]) tensor(840.7515, grad_fn=<SubBackward0>)\n",
      "loss: 0.016664881259202957\n",
      "tensor([[855]]) tensor(840.4701, grad_fn=<SubBackward0>)\n",
      "loss: 0.016994044184684753\n",
      "tensor([[855]]) tensor(837.1625, grad_fn=<SubBackward0>)\n",
      "loss: 0.020862530916929245\n",
      "tensor([[855]]) tensor(841.7754, grad_fn=<SubBackward0>)\n",
      "loss: 0.015467396937310696\n",
      "tensor([[855]]) tensor(840.2516, grad_fn=<SubBackward0>)\n",
      "loss: 0.017249606549739838\n",
      "tensor([[855]]) tensor(826.5266, grad_fn=<SubBackward0>)\n",
      "loss: 0.03330228105187416\n",
      "tensor([[855]]) tensor(826.3987, grad_fn=<SubBackward0>)\n",
      "loss: 0.0334518700838089\n",
      "tensor([[855]]) tensor(841.9188, grad_fn=<SubBackward0>)\n",
      "loss: 0.015299711376428604\n",
      "tensor([[855]]) tensor(825.8104, grad_fn=<SubBackward0>)\n",
      "loss: 0.03413992375135422\n",
      "tensor([[855]]) tensor(820.0049, grad_fn=<SubBackward0>)\n",
      "loss: 0.0409298911690712\n",
      "tensor([[855]]) tensor(834.3302, grad_fn=<SubBackward0>)\n",
      "loss: 0.024175239726901054\n",
      "tensor([[855]]) tensor(821.3295, grad_fn=<SubBackward0>)\n",
      "loss: 0.03938070312142372\n",
      "tensor([[855]]) tensor(826.5521, grad_fn=<SubBackward0>)\n",
      "loss: 0.03327242285013199\n",
      "tensor([[855]]) tensor(837.9189, grad_fn=<SubBackward0>)\n",
      "loss: 0.019977841526269913\n",
      "tensor([[855]]) tensor(814.3682, grad_fn=<SubBackward0>)\n",
      "loss: 0.0475226491689682\n",
      "tensor([[855]]) tensor(808.1160, grad_fn=<SubBackward0>)\n",
      "loss: 0.05483516305685043\n",
      "tensor([[855]]) tensor(830.7634, grad_fn=<SubBackward0>)\n",
      "loss: 0.028346922248601913\n",
      "tensor([[855]]) tensor(827.0352, grad_fn=<SubBackward0>)\n",
      "loss: 0.03270745649933815\n",
      "tensor([[855]]) tensor(809.3271, grad_fn=<SubBackward0>)\n",
      "loss: 0.053418539464473724\n",
      "tensor([[855]]) tensor(820.7909, grad_fn=<SubBackward0>)\n",
      "loss: 0.04001066833734512\n",
      "tensor([[855]]) tensor(839.6345, grad_fn=<SubBackward0>)\n",
      "loss: 0.01797132007777691\n",
      "tensor([[855]]) tensor(814.6072, grad_fn=<SubBackward0>)\n",
      "loss: 0.04724299535155296\n",
      "tensor([[855]]) tensor(808.2740, grad_fn=<SubBackward0>)\n",
      "loss: 0.05465027317404747\n",
      "tensor([[855]]) tensor(829.7476, grad_fn=<SubBackward0>)\n",
      "loss: 0.029535019770264626\n",
      "tensor([[855]]) tensor(827.4761, grad_fn=<SubBackward0>)\n",
      "loss: 0.03219172731041908\n",
      "tensor([[855]]) tensor(803.4090, grad_fn=<SubBackward0>)\n",
      "loss: 0.06034035608172417\n",
      "tensor([[855]]) tensor(808.4206, grad_fn=<SubBackward0>)\n",
      "loss: 0.05447883903980255\n",
      "tensor([[855]]) tensor(829.8723, grad_fn=<SubBackward0>)\n",
      "loss: 0.029389070346951485\n",
      "tensor([[855]]) tensor(828.1689, grad_fn=<SubBackward0>)\n",
      "loss: 0.03138142079114914\n",
      "tensor([[855]]) tensor(816.4137, grad_fn=<SubBackward0>)\n",
      "loss: 0.04513021558523178\n",
      "tensor([[855]]) tensor(834.7340, grad_fn=<SubBackward0>)\n",
      "loss: 0.02370287850499153\n",
      "tensor([[855]]) tensor(826.3708, grad_fn=<SubBackward0>)\n",
      "loss: 0.03348442167043686\n",
      "tensor([[855]]) tensor(810.8715, grad_fn=<SubBackward0>)\n",
      "loss: 0.05161232873797417\n",
      "tensor([[855]]) tensor(830.2139, grad_fn=<SubBackward0>)\n",
      "loss: 0.028989611193537712\n",
      "tensor([[855]]) tensor(838.5084, grad_fn=<SubBackward0>)\n",
      "loss: 0.01928846538066864\n",
      "tensor([[855]]) tensor(823.4631, grad_fn=<SubBackward0>)\n",
      "loss: 0.036885276436805725\n",
      "tensor([[855]]) tensor(834.8386, grad_fn=<SubBackward0>)\n",
      "loss: 0.02358052134513855\n",
      "tensor([[855]]) tensor(830.2755, grad_fn=<SubBackward0>)\n",
      "loss: 0.028917599469423294\n",
      "tensor([[855]]) tensor(817.3398, grad_fn=<SubBackward0>)\n",
      "loss: 0.044047001749277115\n",
      "tensor([[855]]) tensor(827.6982, grad_fn=<SubBackward0>)\n",
      "loss: 0.031931933015584946\n",
      "tensor([[855]]) tensor(833.8229, grad_fn=<SubBackward0>)\n",
      "loss: 0.024768566712737083\n",
      "tensor([[855]]) tensor(827.3572, grad_fn=<SubBackward0>)\n",
      "loss: 0.032330822199583054\n",
      "tensor([[855]]) tensor(840.7098, grad_fn=<SubBackward0>)\n",
      "loss: 0.01671360246837139\n",
      "tensor([[855]]) tensor(831.5426, grad_fn=<SubBackward0>)\n",
      "loss: 0.02743557095527649\n",
      "tensor([[855]]) tensor(831.4949, grad_fn=<SubBackward0>)\n",
      "loss: 0.02749137580394745\n",
      "tensor([[855]]) tensor(843.7836, grad_fn=<SubBackward0>)\n",
      "loss: 0.013118668459355831\n",
      "tensor([[855]]) tensor(829.5227, grad_fn=<SubBackward0>)\n",
      "loss: 0.029797988012433052\n",
      "tensor([[855]]) tensor(831.1830, grad_fn=<SubBackward0>)\n",
      "loss: 0.02785617671906948\n",
      "tensor([[855]]) tensor(843.6260, grad_fn=<SubBackward0>)\n",
      "loss: 0.013302880339324474\n",
      "tensor([[855]]) tensor(837.5344, grad_fn=<SubBackward0>)\n",
      "loss: 0.020427575334906578\n",
      "tensor([[855]]) tensor(840.8419, grad_fn=<SubBackward0>)\n",
      "loss: 0.01655924879014492\n",
      "tensor([[855]]) tensor(843.5586, grad_fn=<SubBackward0>)\n",
      "loss: 0.013381761498749256\n",
      "tensor([[855]]) tensor(838.6743, grad_fn=<SubBackward0>)\n",
      "loss: 0.019094331189990044\n",
      "tensor([[855]]) tensor(844.8131, grad_fn=<SubBackward0>)\n",
      "loss: 0.011914526112377644\n",
      "tensor([[855]]) tensor(835.0261, grad_fn=<SubBackward0>)\n",
      "loss: 0.023361295461654663\n",
      "tensor([[855]]) tensor(838.2430, grad_fn=<SubBackward0>)\n",
      "loss: 0.01959885284304619\n",
      "tensor([[855]]) tensor(838.4922, grad_fn=<SubBackward0>)\n",
      "loss: 0.01930738240480423\n",
      "tensor([[855]]) tensor(840.8306, grad_fn=<SubBackward0>)\n",
      "loss: 0.01657247357070446\n",
      "tensor([[855]]) tensor(839.5084, grad_fn=<SubBackward0>)\n",
      "loss: 0.018118785694241524\n",
      "tensor([[855]]) tensor(835.2423, grad_fn=<SubBackward0>)\n",
      "loss: 0.02310837432742119\n",
      "tensor([[855]]) tensor(844.5414, grad_fn=<SubBackward0>)\n",
      "loss: 0.012232338078320026\n",
      "tensor([[855]]) tensor(829.2812, grad_fn=<SubBackward0>)\n",
      "loss: 0.03008049912750721\n",
      "tensor([[855]]) tensor(835.3871, grad_fn=<SubBackward0>)\n",
      "loss: 0.022939098998904228\n",
      "tensor([[855]]) tensor(818.2590, grad_fn=<SubBackward0>)\n",
      "loss: 0.0429718904197216\n",
      "tensor([[855]]) tensor(822.8761, grad_fn=<SubBackward0>)\n",
      "loss: 0.037571851164102554\n",
      "tensor([[855]]) tensor(832.7006, grad_fn=<SubBackward0>)\n",
      "loss: 0.02608114294707775\n",
      "tensor([[855]]) tensor(831.0203, grad_fn=<SubBackward0>)\n",
      "loss: 0.028046440333127975\n",
      "tensor([[855]]) tensor(824.0321, grad_fn=<SubBackward0>)\n",
      "loss: 0.036219798028469086\n",
      "tensor([[855]]) tensor(828.4750, grad_fn=<SubBackward0>)\n",
      "loss: 0.031023455783724785\n",
      "tensor([[855]]) tensor(827.2681, grad_fn=<SubBackward0>)\n",
      "loss: 0.03243504464626312\n",
      "tensor([[855]]) tensor(832.8268, grad_fn=<SubBackward0>)\n",
      "loss: 0.025933533906936646\n",
      "tensor([[855]]) tensor(835.1573, grad_fn=<SubBackward0>)\n",
      "loss: 0.023207850754261017\n",
      "tensor([[855]]) tensor(832.7631, grad_fn=<SubBackward0>)\n",
      "loss: 0.02600809745490551\n",
      "tensor([[855]]) tensor(830.2146, grad_fn=<SubBackward0>)\n",
      "loss: 0.028988737612962723\n",
      "tensor([[855]]) tensor(830.0603, grad_fn=<SubBackward0>)\n",
      "loss: 0.029169254004955292\n",
      "tensor([[855]]) tensor(836.5419, grad_fn=<SubBackward0>)\n",
      "loss: 0.021588385105133057\n",
      "tensor([[855]]) tensor(838.2545, grad_fn=<SubBackward0>)\n",
      "loss: 0.019585413858294487\n",
      "tensor([[855]]) tensor(842.0138, grad_fn=<SubBackward0>)\n",
      "loss: 0.015188580378890038\n",
      "tensor([[855]]) tensor(828.6343, grad_fn=<SubBackward0>)\n",
      "loss: 0.03083713911473751\n",
      "tensor([[855]]) tensor(827.2139, grad_fn=<SubBackward0>)\n",
      "loss: 0.03249836340546608\n",
      "tensor([[855]]) tensor(841.2800, grad_fn=<SubBackward0>)\n",
      "loss: 0.01604682020843029\n",
      "tensor([[855]]) tensor(840.9998, grad_fn=<SubBackward0>)\n",
      "loss: 0.01637457311153412\n",
      "tensor([[855]]) tensor(833.8167, grad_fn=<SubBackward0>)\n",
      "loss: 0.024775812402367592\n",
      "tensor([[855]]) tensor(839.3944, grad_fn=<SubBackward0>)\n",
      "loss: 0.018252117559313774\n",
      "tensor([[855]]) tensor(833.3148, grad_fn=<SubBackward0>)\n",
      "loss: 0.025362873449921608\n",
      "tensor([[855]]) tensor(834.5099, grad_fn=<SubBackward0>)\n",
      "loss: 0.02396497316658497\n",
      "tensor([[855]]) tensor(837.4547, grad_fn=<SubBackward0>)\n",
      "loss: 0.020520877093076706\n",
      "tensor([[855]]) tensor(839.4649, grad_fn=<SubBackward0>)\n",
      "loss: 0.018169701099395752\n",
      "tensor([[855]]) tensor(841.6516, grad_fn=<SubBackward0>)\n",
      "loss: 0.015612185932695866\n",
      "tensor([[855]]) tensor(839.2996, grad_fn=<SubBackward0>)\n",
      "loss: 0.018363086506724358\n",
      "tensor([[855]]) tensor(842.6938, grad_fn=<SubBackward0>)\n",
      "loss: 0.014393231831490993\n",
      "tensor([[855]]) tensor(844.7155, grad_fn=<SubBackward0>)\n",
      "loss: 0.01202874444425106\n",
      "tensor([[855]]) tensor(836.8002, grad_fn=<SubBackward0>)\n",
      "loss: 0.021286385133862495\n",
      "tensor([[855]]) tensor(844.7921, grad_fn=<SubBackward0>)\n",
      "loss: 0.01193904783576727\n",
      "tensor([[855]]) tensor(824.7885, grad_fn=<SubBackward0>)\n",
      "loss: 0.035335052758455276\n",
      "tensor([[855]]) tensor(824.9827, grad_fn=<SubBackward0>)\n",
      "loss: 0.035107992589473724\n",
      "tensor([[855]]) tensor(845.8705, grad_fn=<SubBackward0>)\n",
      "loss: 0.01067772600799799\n",
      "tensor([[855]]) tensor(818.2343, grad_fn=<SubBackward0>)\n",
      "loss: 0.04300091043114662\n",
      "tensor([[855]]) tensor(815.6674, grad_fn=<SubBackward0>)\n",
      "loss: 0.046003054827451706\n",
      "tensor([[855]]) tensor(839.2361, grad_fn=<SubBackward0>)\n",
      "loss: 0.01843729242682457\n",
      "tensor([[855]]) tensor(827.6478, grad_fn=<SubBackward0>)\n",
      "loss: 0.031990811228752136\n",
      "tensor([[855]]) tensor(814.9185, grad_fn=<SubBackward0>)\n",
      "loss: 0.04687892645597458\n",
      "tensor([[855]]) tensor(827.6788, grad_fn=<SubBackward0>)\n",
      "loss: 0.031954653561115265\n",
      "tensor([[855]]) tensor(839.7703, grad_fn=<SubBackward0>)\n",
      "loss: 0.017812484875321388\n",
      "tensor([[855]]) tensor(830.2629, grad_fn=<SubBackward0>)\n",
      "loss: 0.028932269662618637\n",
      "tensor([[855]]) tensor(835.3652, grad_fn=<SubBackward0>)\n",
      "loss: 0.02296467311680317\n",
      "tensor([[855]]) tensor(833.6908, grad_fn=<SubBackward0>)\n",
      "loss: 0.024923045188188553\n",
      "tensor([[855]]) tensor(841.9075, grad_fn=<SubBackward0>)\n",
      "loss: 0.01531293522566557\n",
      "tensor([[855]]) tensor(836.0077, grad_fn=<SubBackward0>)\n",
      "loss: 0.022213228046894073\n",
      "tensor([[855]]) tensor(828.6263, grad_fn=<SubBackward0>)\n",
      "loss: 0.030846454203128815\n",
      "tensor([[855]]) tensor(839.4197, grad_fn=<SubBackward0>)\n",
      "loss: 0.018222598358988762\n",
      "tensor([[855]]) tensor(828.4573, grad_fn=<SubBackward0>)\n",
      "loss: 0.031044069677591324\n",
      "tensor([[855]]) tensor(830.0035, grad_fn=<SubBackward0>)\n",
      "loss: 0.029235715046525\n",
      "tensor([[855]]) tensor(836.5029, grad_fn=<SubBackward0>)\n",
      "loss: 0.021634001284837723\n",
      "tensor([[855]]) tensor(836.6851, grad_fn=<SubBackward0>)\n",
      "loss: 0.02142096683382988\n",
      "tensor([[855]]) tensor(838.2003, grad_fn=<SubBackward0>)\n",
      "loss: 0.019648751243948936\n",
      "tensor([[855]]) tensor(830.9568, grad_fn=<SubBackward0>)\n",
      "loss: 0.028120752424001694\n",
      "tensor([[855]]) tensor(833.1658, grad_fn=<SubBackward0>)\n",
      "loss: 0.025537054985761642\n",
      "tensor([[855]]) tensor(830.1462, grad_fn=<SubBackward0>)\n",
      "loss: 0.029068760573863983\n",
      "tensor([[855]]) tensor(842.6764, grad_fn=<SubBackward0>)\n",
      "loss: 0.014413541182875633\n",
      "tensor([[855]]) tensor(835.1500, grad_fn=<SubBackward0>)\n",
      "loss: 0.02321641705930233\n",
      "tensor([[855]]) tensor(830.9573, grad_fn=<SubBackward0>)\n",
      "loss: 0.028120163828134537\n",
      "tensor([[855]]) tensor(841.3866, grad_fn=<SubBackward0>)\n",
      "loss: 0.015922091901302338\n",
      "tensor([[855]]) tensor(841.4862, grad_fn=<SubBackward0>)\n",
      "loss: 0.01580560766160488\n",
      "tensor([[855]]) tensor(844.0912, grad_fn=<SubBackward0>)\n",
      "loss: 0.012758792378008366\n",
      "tensor([[855]]) tensor(834.6310, grad_fn=<SubBackward0>)\n",
      "loss: 0.0238234493881464\n",
      "tensor([[855]]) tensor(834.7223, grad_fn=<SubBackward0>)\n",
      "loss: 0.023716654628515244\n",
      "tensor([[855]]) tensor(845.2795, grad_fn=<SubBackward0>)\n",
      "loss: 0.011368939653038979\n",
      "tensor([[855]]) tensor(836.6918, grad_fn=<SubBackward0>)\n",
      "loss: 0.021413132548332214\n",
      "tensor([[855]]) tensor(841.7689, grad_fn=<SubBackward0>)\n",
      "loss: 0.015475017949938774\n",
      "tensor([[855]]) tensor(841.9357, grad_fn=<SubBackward0>)\n",
      "loss: 0.015279918909072876\n",
      "tensor([[855]]) tensor(845.6697, grad_fn=<SubBackward0>)\n",
      "loss: 0.010912586003541946\n",
      "tensor([[855]]) tensor(840.3865, grad_fn=<SubBackward0>)\n",
      "loss: 0.017091825604438782\n",
      "tensor([[855]]) tensor(839.4543, grad_fn=<SubBackward0>)\n",
      "loss: 0.018182123079895973\n",
      "tensor([[855]]) tensor(843.4410, grad_fn=<SubBackward0>)\n",
      "loss: 0.013519287109375\n",
      "tensor([[855]]) tensor(838.6879, grad_fn=<SubBackward0>)\n",
      "loss: 0.019078554585576057\n",
      "tensor([[855]]) tensor(844.0598, grad_fn=<SubBackward0>)\n",
      "loss: 0.012795538641512394\n",
      "tensor([[855]]) tensor(832.0694, grad_fn=<SubBackward0>)\n",
      "loss: 0.026819400489330292\n",
      "tensor([[855]]) tensor(829.0411, grad_fn=<SubBackward0>)\n",
      "loss: 0.030361313372850418\n",
      "tensor([[855]]) tensor(842.4025, grad_fn=<SubBackward0>)\n",
      "loss: 0.01473388634622097\n",
      "tensor([[855]]) tensor(830.1572, grad_fn=<SubBackward0>)\n",
      "loss: 0.029055874794721603\n",
      "tensor([[855]]) tensor(828.3096, grad_fn=<SubBackward0>)\n",
      "loss: 0.031216859817504883\n",
      "tensor([[855]]) tensor(843.1300, grad_fn=<SubBackward0>)\n",
      "loss: 0.013883071020245552\n",
      "tensor([[855]]) tensor(838.0197, grad_fn=<SubBackward0>)\n",
      "loss: 0.01986009068787098\n",
      "tensor([[855]]) tensor(838.4159, grad_fn=<SubBackward0>)\n",
      "loss: 0.019396651536226273\n",
      "tensor([[855]]) tensor(831.2708, grad_fn=<SubBackward0>)\n",
      "loss: 0.027753524482250214\n",
      "tensor([[855]]) tensor(838.9414, grad_fn=<SubBackward0>)\n",
      "loss: 0.018781980499625206\n",
      "tensor([[855]]) tensor(829.1494, grad_fn=<SubBackward0>)\n",
      "loss: 0.03023456782102585\n",
      "tensor([[855]]) tensor(818.8320, grad_fn=<SubBackward0>)\n",
      "loss: 0.04230175167322159\n",
      "tensor([[855]]) tensor(830.3286, grad_fn=<SubBackward0>)\n",
      "loss: 0.02885538712143898\n",
      "tensor([[855]]) tensor(827.2965, grad_fn=<SubBackward0>)\n",
      "loss: 0.03240170702338219\n",
      "tensor([[855]]) tensor(827.1608, grad_fn=<SubBackward0>)\n",
      "loss: 0.03256047144532204\n",
      "tensor([[855]]) tensor(836.9106, grad_fn=<SubBackward0>)\n",
      "loss: 0.021157193928956985\n",
      "tensor([[855]]) tensor(830.5434, grad_fn=<SubBackward0>)\n",
      "loss: 0.028604233637452126\n",
      "tensor([[855]]) tensor(830.4410, grad_fn=<SubBackward0>)\n",
      "loss: 0.02872401848435402\n",
      "tensor([[855]]) tensor(838.9794, grad_fn=<SubBackward0>)\n",
      "loss: 0.018737614154815674\n",
      "tensor([[855]]) tensor(822.7581, grad_fn=<SubBackward0>)\n",
      "loss: 0.03770989179611206\n",
      "tensor([[855]]) tensor(822.9251, grad_fn=<SubBackward0>)\n",
      "loss: 0.037514492869377136\n",
      "tensor([[855]]) tensor(836.8285, grad_fn=<SubBackward0>)\n",
      "loss: 0.02125319093465805\n",
      "tensor([[855]]) tensor(828.7991, grad_fn=<SubBackward0>)\n",
      "loss: 0.030644306913018227\n",
      "tensor([[855]]) tensor(828.1189, grad_fn=<SubBackward0>)\n",
      "loss: 0.031439922749996185\n",
      "tensor([[855]]) tensor(840.8401, grad_fn=<SubBackward0>)\n",
      "loss: 0.016561228781938553\n",
      "tensor([[855]]) tensor(822.3903, grad_fn=<SubBackward0>)\n",
      "loss: 0.03813997656106949\n",
      "tensor([[855]]) tensor(828.0770, grad_fn=<SubBackward0>)\n",
      "loss: 0.03148883953690529\n",
      "tensor([[855]]) tensor(840.3381, grad_fn=<SubBackward0>)\n",
      "loss: 0.017148470506072044\n",
      "tensor([[855]]) tensor(826.0554, grad_fn=<SubBackward0>)\n",
      "loss: 0.033853381872177124\n",
      "tensor([[855]]) tensor(825.7358, grad_fn=<SubBackward0>)\n",
      "loss: 0.03422710672020912\n",
      "tensor([[855]]) tensor(837.7848, grad_fn=<SubBackward0>)\n",
      "loss: 0.020134713500738144\n",
      "tensor([[855]]) tensor(823.9443, grad_fn=<SubBackward0>)\n",
      "loss: 0.036322448402643204\n",
      "tensor([[855]]) tensor(824.6837, grad_fn=<SubBackward0>)\n",
      "loss: 0.035457730293273926\n",
      "tensor([[855]]) tensor(837.1254, grad_fn=<SubBackward0>)\n",
      "loss: 0.020905951038002968\n",
      "tensor([[855]]) tensor(830.2579, grad_fn=<SubBackward0>)\n",
      "loss: 0.028938159346580505\n",
      "tensor([[855]]) tensor(833.7325, grad_fn=<SubBackward0>)\n",
      "loss: 0.024874182417988777\n",
      "tensor([[855]]) tensor(843.8358, grad_fn=<SubBackward0>)\n",
      "loss: 0.01305752620100975\n",
      "tensor([[855]]) tensor(824.7208, grad_fn=<SubBackward0>)\n",
      "loss: 0.03541431203484535\n",
      "tensor([[855]]) tensor(830.4631, grad_fn=<SubBackward0>)\n",
      "loss: 0.028698105365037918\n",
      "tensor([[855]]) tensor(825.2329, grad_fn=<SubBackward0>)\n",
      "loss: 0.034815311431884766\n",
      "tensor([[855]]) tensor(828.0542, grad_fn=<SubBackward0>)\n",
      "loss: 0.03151557594537735\n",
      "tensor([[855]]) tensor(838.9436, grad_fn=<SubBackward0>)\n",
      "loss: 0.018779447302222252\n",
      "tensor([[855]]) tensor(821.7760, grad_fn=<SubBackward0>)\n",
      "loss: 0.03885844349861145\n",
      "tensor([[855]]) tensor(812.5067, grad_fn=<SubBackward0>)\n",
      "loss: 0.04969971254467964\n",
      "tensor([[855]]) tensor(827.2252, grad_fn=<SubBackward0>)\n",
      "loss: 0.03248521313071251\n",
      "tensor([[855]]) tensor(836.0354, grad_fn=<SubBackward0>)\n",
      "loss: 0.022180818021297455\n",
      "tensor([[855]]) tensor(824.7977, grad_fn=<SubBackward0>)\n",
      "loss: 0.03532438352704048\n",
      "tensor([[855]]) tensor(829.0817, grad_fn=<SubBackward0>)\n",
      "loss: 0.03031386062502861\n",
      "tensor([[855]]) tensor(835.1221, grad_fn=<SubBackward0>)\n",
      "loss: 0.023249058052897453\n",
      "tensor([[855]]) tensor(824.0120, grad_fn=<SubBackward0>)\n",
      "loss: 0.0362432487308979\n",
      "tensor([[855]]) tensor(830.3966, grad_fn=<SubBackward0>)\n",
      "loss: 0.028775863349437714\n",
      "tensor([[855]]) tensor(839.7052, grad_fn=<SubBackward0>)\n",
      "loss: 0.017888672649860382\n",
      "tensor([[855]]) tensor(832.1320, grad_fn=<SubBackward0>)\n",
      "loss: 0.026746230199933052\n",
      "tensor([[855]]) tensor(835.7717, grad_fn=<SubBackward0>)\n",
      "loss: 0.022489260882139206\n",
      "tensor([[855]]) tensor(842.5039, grad_fn=<SubBackward0>)\n",
      "loss: 0.01461527869105339\n",
      "tensor([[855]]) tensor(841.1260, grad_fn=<SubBackward0>)\n",
      "loss: 0.016226928681135178\n",
      "tensor([[855]]) tensor(841.4514, grad_fn=<SubBackward0>)\n",
      "loss: 0.015846261754631996\n",
      "tensor([[855]]) tensor(842.9960, grad_fn=<SubBackward0>)\n",
      "loss: 0.014039763249456882\n",
      "tensor([[855]]) tensor(844.1373, grad_fn=<SubBackward0>)\n",
      "loss: 0.012704913504421711\n",
      "tensor([[855]]) tensor(842.2137, grad_fn=<SubBackward0>)\n",
      "loss: 0.014954755082726479\n",
      "tensor([[855]]) tensor(838.9911, grad_fn=<SubBackward0>)\n",
      "loss: 0.018723836168646812\n",
      "tensor([[855]]) tensor(847.4435, grad_fn=<SubBackward0>)\n",
      "loss: 0.008838033303618431\n",
      "tensor([[855]]) tensor(828.9438, grad_fn=<SubBackward0>)\n",
      "loss: 0.030475085601210594\n",
      "tensor([[855]]) tensor(837.8325, grad_fn=<SubBackward0>)\n",
      "loss: 0.020078925415873528\n",
      "tensor([[855]]) tensor(827.3751, grad_fn=<SubBackward0>)\n",
      "loss: 0.03230976313352585\n",
      "tensor([[855]]) tensor(825.7693, grad_fn=<SubBackward0>)\n",
      "loss: 0.03418800234794617\n",
      "tensor([[855]]) tensor(840.2098, grad_fn=<SubBackward0>)\n",
      "loss: 0.017298398539423943\n",
      "tensor([[855]]) tensor(826.2948, grad_fn=<SubBackward0>)\n",
      "loss: 0.03357333317399025\n",
      "tensor([[855]]) tensor(823.8302, grad_fn=<SubBackward0>)\n",
      "loss: 0.03645586967468262\n",
      "tensor([[855]]) tensor(840.6339, grad_fn=<SubBackward0>)\n",
      "loss: 0.016802478581666946\n",
      "tensor([[855]]) tensor(830.8197, grad_fn=<SubBackward0>)\n",
      "loss: 0.028281085193157196\n",
      "tensor([[855]]) tensor(831.9055, grad_fn=<SubBackward0>)\n",
      "loss: 0.027011090889573097\n",
      "tensor([[855]]) tensor(839.1469, grad_fn=<SubBackward0>)\n",
      "loss: 0.018541622906923294\n",
      "tensor([[855]]) tensor(827.2359, grad_fn=<SubBackward0>)\n",
      "loss: 0.03247261419892311\n",
      "tensor([[855]]) tensor(830.8271, grad_fn=<SubBackward0>)\n",
      "loss: 0.02827230468392372\n",
      "tensor([[855]]) tensor(839.0273, grad_fn=<SubBackward0>)\n",
      "loss: 0.018681541085243225\n",
      "tensor([[855]]) tensor(834.3091, grad_fn=<SubBackward0>)\n",
      "loss: 0.02419983223080635\n",
      "tensor([[855]]) tensor(841.7471, grad_fn=<SubBackward0>)\n",
      "loss: 0.01550052035599947\n",
      "tensor([[855]]) tensor(837.8123, grad_fn=<SubBackward0>)\n",
      "loss: 0.020102623850107193\n",
      "tensor([[855]]) tensor(845.3829, grad_fn=<SubBackward0>)\n",
      "loss: 0.011248012073338032\n",
      "tensor([[855]]) tensor(831.5927, grad_fn=<SubBackward0>)\n",
      "loss: 0.027377016842365265\n",
      "tensor([[855]]) tensor(835.2301, grad_fn=<SubBackward0>)\n",
      "loss: 0.02312270551919937\n",
      "tensor([[855]]) tensor(843.6302, grad_fn=<SubBackward0>)\n",
      "loss: 0.013297918252646923\n",
      "tensor([[855]]) tensor(842.6520, grad_fn=<SubBackward0>)\n",
      "loss: 0.014442113228142262\n",
      "tensor([[855]]) tensor(841.2983, grad_fn=<SubBackward0>)\n",
      "loss: 0.01602538675069809\n",
      "tensor([[855]]) tensor(846.8373, grad_fn=<SubBackward0>)\n",
      "loss: 0.009547076188027859\n",
      "tensor([[855]]) tensor(845.6981, grad_fn=<SubBackward0>)\n",
      "loss: 0.010879427194595337\n",
      "tensor([[855]]) tensor(846.7328, grad_fn=<SubBackward0>)\n",
      "loss: 0.009669288992881775\n",
      "tensor([[855]]) tensor(839.6200, grad_fn=<SubBackward0>)\n",
      "loss: 0.01798834465444088\n",
      "tensor([[855]]) tensor(844.1677, grad_fn=<SubBackward0>)\n",
      "loss: 0.012669417075812817\n",
      "tensor([[855]]) tensor(848.2296, grad_fn=<SubBackward0>)\n",
      "loss: 0.007918561808764935\n",
      "tensor([[855]]) tensor(830.9486, grad_fn=<SubBackward0>)\n",
      "loss: 0.028130246326327324\n",
      "tensor([[855]]) tensor(830.0240, grad_fn=<SubBackward0>)\n",
      "loss: 0.029211711138486862\n",
      "tensor([[855]]) tensor(845.8893, grad_fn=<SubBackward0>)\n",
      "loss: 0.010655757039785385\n",
      "tensor([[855]]) tensor(846.0711, grad_fn=<SubBackward0>)\n",
      "loss: 0.010443150997161865\n",
      "tensor([[855]]) tensor(843.5762, grad_fn=<SubBackward0>)\n",
      "loss: 0.01336120255291462\n",
      "tensor([[855]]) tensor(839.7540, grad_fn=<SubBackward0>)\n",
      "loss: 0.017831509932875633\n",
      "tensor([[855]]) tensor(844.5684, grad_fn=<SubBackward0>)\n",
      "loss: 0.012200784869492054\n",
      "tensor([[855]]) tensor(835.1884, grad_fn=<SubBackward0>)\n",
      "loss: 0.02317144349217415\n",
      "tensor([[855]]) tensor(842.4518, grad_fn=<SubBackward0>)\n",
      "loss: 0.014676224440336227\n",
      "tensor([[855]]) tensor(839.7063, grad_fn=<SubBackward0>)\n",
      "loss: 0.01788737066090107\n",
      "tensor([[855]]) tensor(843.9456, grad_fn=<SubBackward0>)\n",
      "loss: 0.012929173186421394\n",
      "tensor([[855]]) tensor(831.0816, grad_fn=<SubBackward0>)\n",
      "loss: 0.027974732220172882\n",
      "tensor([[855]]) tensor(835.2422, grad_fn=<SubBackward0>)\n",
      "loss: 0.023108480498194695\n",
      "tensor([[855]]) tensor(835.9116, grad_fn=<SubBackward0>)\n",
      "loss: 0.022325625643134117\n",
      "tensor([[855]]) tensor(829.5422, grad_fn=<SubBackward0>)\n",
      "loss: 0.02977519854903221\n",
      "tensor([[855]]) tensor(840.6217, grad_fn=<SubBackward0>)\n",
      "loss: 0.01681668497622013\n",
      "tensor([[855]]) tensor(829.3658, grad_fn=<SubBackward0>)\n",
      "loss: 0.02998155727982521\n",
      "tensor([[855]]) tensor(826.6900, grad_fn=<SubBackward0>)\n",
      "loss: 0.03311110660433769\n",
      "tensor([[855]]) tensor(841.7865, grad_fn=<SubBackward0>)\n",
      "loss: 0.015454422682523727\n",
      "tensor([[855]]) tensor(827.9620, grad_fn=<SubBackward0>)\n",
      "loss: 0.031623367220163345\n",
      "tensor([[855]]) tensor(832.4213, grad_fn=<SubBackward0>)\n",
      "loss: 0.026407860219478607\n",
      "tensor([[855]]) tensor(839.1988, grad_fn=<SubBackward0>)\n",
      "loss: 0.018480945378541946\n",
      "tensor([[855]]) tensor(825.3322, grad_fn=<SubBackward0>)\n",
      "loss: 0.034699272364377975\n",
      "tensor([[855]]) tensor(832.7760, grad_fn=<SubBackward0>)\n",
      "loss: 0.02599296346306801\n",
      "tensor([[855]]) tensor(838.6537, grad_fn=<SubBackward0>)\n",
      "loss: 0.019118476659059525\n",
      "tensor([[855]]) tensor(829.1390, grad_fn=<SubBackward0>)\n",
      "loss: 0.030246756970882416\n",
      "tensor([[855]]) tensor(832.7762, grad_fn=<SubBackward0>)\n",
      "loss: 0.025992730632424355\n",
      "tensor([[855]]) tensor(840.3128, grad_fn=<SubBackward0>)\n",
      "loss: 0.0171780064702034\n",
      "tensor([[855]]) tensor(842.5638, grad_fn=<SubBackward0>)\n",
      "loss: 0.014545213431119919\n",
      "tensor([[855]]) tensor(843.2350, grad_fn=<SubBackward0>)\n",
      "loss: 0.013760286383330822\n",
      "tensor([[855]]) tensor(844.7409, grad_fn=<SubBackward0>)\n",
      "loss: 0.011998958885669708\n",
      "tensor([[855]]) tensor(834.0635, grad_fn=<SubBackward0>)\n",
      "loss: 0.02448716200888157\n",
      "tensor([[855]]) tensor(838.3356, grad_fn=<SubBackward0>)\n",
      "loss: 0.01949048787355423\n",
      "tensor([[855]]) tensor(835.5391, grad_fn=<SubBackward0>)\n",
      "loss: 0.022761259227991104\n",
      "tensor([[855]]) tensor(832.3119, grad_fn=<SubBackward0>)\n",
      "loss: 0.02653578296303749\n",
      "tensor([[855]]) tensor(847.8849, grad_fn=<SubBackward0>)\n",
      "loss: 0.008321697823703289\n",
      "tensor([[855]]) tensor(825.3181, grad_fn=<SubBackward0>)\n",
      "loss: 0.0347156897187233\n",
      "tensor([[855]]) tensor(826.8952, grad_fn=<SubBackward0>)\n",
      "loss: 0.032871127128601074\n",
      "tensor([[855]]) tensor(843.3192, grad_fn=<SubBackward0>)\n",
      "loss: 0.013661756180226803\n",
      "tensor([[855]]) tensor(834.9114, grad_fn=<SubBackward0>)\n",
      "loss: 0.02349541150033474\n",
      "tensor([[855]]) tensor(839.4126, grad_fn=<SubBackward0>)\n",
      "loss: 0.0182308629155159\n",
      "tensor([[855]]) tensor(837.9500, grad_fn=<SubBackward0>)\n",
      "loss: 0.019941577687859535\n",
      "tensor([[855]]) tensor(843.3359, grad_fn=<SubBackward0>)\n",
      "loss: 0.013642177917063236\n",
      "tensor([[855]]) tensor(835.4301, grad_fn=<SubBackward0>)\n",
      "loss: 0.022888807579874992\n",
      "tensor([[855]]) tensor(836.4497, grad_fn=<SubBackward0>)\n",
      "loss: 0.021696249023079872\n",
      "tensor([[855]]) tensor(841.1456, grad_fn=<SubBackward0>)\n",
      "loss: 0.016203906387090683\n",
      "tensor([[855]]) tensor(847.0612, grad_fn=<SubBackward0>)\n",
      "loss: 0.009285160340368748\n",
      "tensor([[855]]) tensor(844.0295, grad_fn=<SubBackward0>)\n",
      "loss: 0.01283101737499237\n",
      "tensor([[855]]) tensor(846.2318, grad_fn=<SubBackward0>)\n",
      "loss: 0.01025519147515297\n",
      "tensor([[855]]) tensor(834.6467, grad_fn=<SubBackward0>)\n",
      "loss: 0.023805031552910805\n",
      "tensor([[855]]) tensor(841.0619, grad_fn=<SubBackward0>)\n",
      "loss: 0.01630188338458538\n",
      "tensor([[855]]) tensor(827.0229, grad_fn=<SubBackward0>)\n",
      "loss: 0.032721731811761856\n",
      "tensor([[855]]) tensor(829.6990, grad_fn=<SubBackward0>)\n",
      "loss: 0.02959187887609005\n",
      "tensor([[855]]) tensor(836.6544, grad_fn=<SubBackward0>)\n",
      "loss: 0.021456783637404442\n",
      "tensor([[855]]) tensor(831.8992, grad_fn=<SubBackward0>)\n",
      "loss: 0.027018478140234947\n",
      "tensor([[855]]) tensor(841.3767, grad_fn=<SubBackward0>)\n",
      "loss: 0.01593370921909809\n",
      "tensor([[855]]) tensor(836.8179, grad_fn=<SubBackward0>)\n",
      "loss: 0.021265575662255287\n",
      "tensor([[855]]) tensor(838.5619, grad_fn=<SubBackward0>)\n",
      "loss: 0.019225895404815674\n",
      "tensor([[855]]) tensor(839.3231, grad_fn=<SubBackward0>)\n",
      "loss: 0.01833549700677395\n",
      "tensor([[855]]) tensor(840.6528, grad_fn=<SubBackward0>)\n",
      "loss: 0.016780313104391098\n",
      "tensor([[855]]) tensor(840.2573, grad_fn=<SubBackward0>)\n",
      "loss: 0.01724296621978283\n",
      "tensor([[855]]) tensor(836.8536, grad_fn=<SubBackward0>)\n",
      "loss: 0.02122381515800953\n",
      "tensor([[855]]) tensor(841.2038, grad_fn=<SubBackward0>)\n",
      "loss: 0.016135910525918007\n",
      "tensor([[855]]) tensor(833.7854, grad_fn=<SubBackward0>)\n",
      "loss: 0.0248123612254858\n",
      "tensor([[855]]) tensor(836.8955, grad_fn=<SubBackward0>)\n",
      "loss: 0.021174879744648933\n",
      "tensor([[855]]) tensor(829.5542, grad_fn=<SubBackward0>)\n",
      "loss: 0.029761170968413353\n",
      "tensor([[855]]) tensor(832.5142, grad_fn=<SubBackward0>)\n",
      "loss: 0.02629922702908516\n",
      "tensor([[855]]) tensor(839.1626, grad_fn=<SubBackward0>)\n",
      "loss: 0.018523242324590683\n",
      "tensor([[855]]) tensor(828.6934, grad_fn=<SubBackward0>)\n",
      "loss: 0.030767912045121193\n",
      "tensor([[855]]) tensor(829.3011, grad_fn=<SubBackward0>)\n",
      "loss: 0.030057208612561226\n",
      "tensor([[855]]) tensor(838.4726, grad_fn=<SubBackward0>)\n",
      "loss: 0.01933031529188156\n",
      "tensor([[855]]) tensor(829.8496, grad_fn=<SubBackward0>)\n",
      "loss: 0.02941569685935974\n",
      "tensor([[855]]) tensor(835.1412, grad_fn=<SubBackward0>)\n",
      "loss: 0.023226607590913773\n",
      "tensor([[855]]) tensor(840.2881, grad_fn=<SubBackward0>)\n",
      "loss: 0.017206916585564613\n",
      "tensor([[855]]) tensor(826.6940, grad_fn=<SubBackward0>)\n",
      "loss: 0.03310650214552879\n",
      "tensor([[855]]) tensor(838.6281, grad_fn=<SubBackward0>)\n",
      "loss: 0.019148388877511024\n",
      "tensor([[855]]) tensor(822.7422, grad_fn=<SubBackward0>)\n",
      "loss: 0.03772839903831482\n",
      "tensor([[855]]) tensor(817.2491, grad_fn=<SubBackward0>)\n",
      "loss: 0.04415304586291313\n",
      "tensor([[855]]) tensor(828.5670, grad_fn=<SubBackward0>)\n",
      "loss: 0.030915841460227966\n",
      "tensor([[855]]) tensor(833.8737, grad_fn=<SubBackward0>)\n",
      "loss: 0.02470913715660572\n",
      "tensor([[855]]) tensor(828.9377, grad_fn=<SubBackward0>)\n",
      "loss: 0.030482260510325432\n",
      "tensor([[855]]) tensor(840.1077, grad_fn=<SubBackward0>)\n",
      "loss: 0.01741788163781166\n",
      "tensor([[855]]) tensor(837.3113, grad_fn=<SubBackward0>)\n",
      "loss: 0.02068854495882988\n",
      "tensor([[855]]) tensor(842.1740, grad_fn=<SubBackward0>)\n",
      "loss: 0.015001210384070873\n",
      "tensor([[855]]) tensor(825.3832, grad_fn=<SubBackward0>)\n",
      "loss: 0.03463948518037796\n",
      "tensor([[855]]) tensor(829.5048, grad_fn=<SubBackward0>)\n",
      "loss: 0.029818903654813766\n",
      "tensor([[855]]) tensor(833.5793, grad_fn=<SubBackward0>)\n",
      "loss: 0.025053396821022034\n",
      "tensor([[855]]) tensor(833.4541, grad_fn=<SubBackward0>)\n",
      "loss: 0.02519991621375084\n",
      "tensor([[855]]) tensor(836.8446, grad_fn=<SubBackward0>)\n",
      "loss: 0.02123441733419895\n",
      "tensor([[855]]) tensor(832.4391, grad_fn=<SubBackward0>)\n",
      "loss: 0.02638706937432289\n",
      "tensor([[855]]) tensor(842.0829, grad_fn=<SubBackward0>)\n",
      "loss: 0.015107771381735802\n",
      "tensor([[855]]) tensor(826.4711, grad_fn=<SubBackward0>)\n",
      "loss: 0.03336717188358307\n",
      "tensor([[855]]) tensor(821.6616, grad_fn=<SubBackward0>)\n",
      "loss: 0.038992274552583694\n",
      "tensor([[855]]) tensor(835.8199, grad_fn=<SubBackward0>)\n",
      "loss: 0.022432846948504448\n",
      "tensor([[855]]) tensor(822.1714, grad_fn=<SubBackward0>)\n",
      "loss: 0.03839607536792755\n",
      "tensor([[855]]) tensor(821.4213, grad_fn=<SubBackward0>)\n",
      "loss: 0.03927334025502205\n",
      "tensor([[855]]) tensor(837.8152, grad_fn=<SubBackward0>)\n",
      "loss: 0.02009914442896843\n",
      "tensor([[855]]) tensor(824.2530, grad_fn=<SubBackward0>)\n",
      "loss: 0.035961396992206573\n",
      "tensor([[855]]) tensor(820.4120, grad_fn=<SubBackward0>)\n",
      "loss: 0.04045381769537926\n",
      "tensor([[855]]) tensor(842.7198, grad_fn=<SubBackward0>)\n",
      "loss: 0.014362714253365993\n",
      "tensor([[855]]) tensor(818.6631, grad_fn=<SubBackward0>)\n",
      "loss: 0.042499296367168427\n",
      "tensor([[855]]) tensor(805.7043, grad_fn=<SubBackward0>)\n",
      "loss: 0.05765577033162117\n",
      "tensor([[855]]) tensor(822.8499, grad_fn=<SubBackward0>)\n",
      "loss: 0.03760245814919472\n",
      "tensor([[855]]) tensor(833.1223, grad_fn=<SubBackward0>)\n",
      "loss: 0.025587936863303185\n",
      "tensor([[855]]) tensor(822.8688, grad_fn=<SubBackward0>)\n",
      "loss: 0.037580326199531555\n",
      "tensor([[855]]) tensor(828.5582, grad_fn=<SubBackward0>)\n",
      "loss: 0.030926048755645752\n",
      "tensor([[855]]) tensor(837.0223, grad_fn=<SubBackward0>)\n",
      "loss: 0.021026557311415672\n",
      "tensor([[855]]) tensor(831.7124, grad_fn=<SubBackward0>)\n",
      "loss: 0.027236957103013992\n",
      "tensor([[855]]) tensor(829.6658, grad_fn=<SubBackward0>)\n",
      "loss: 0.029630586504936218\n",
      "tensor([[855]]) tensor(836.8301, grad_fn=<SubBackward0>)\n",
      "loss: 0.021251335740089417\n",
      "tensor([[855]]) tensor(832.2780, grad_fn=<SubBackward0>)\n",
      "loss: 0.02657552808523178\n",
      "tensor([[855]]) tensor(836.7581, grad_fn=<SubBackward0>)\n",
      "loss: 0.021335605531930923\n",
      "tensor([[855]]) tensor(842.6302, grad_fn=<SubBackward0>)\n",
      "loss: 0.014467509463429451\n",
      "tensor([[855]]) tensor(836.1646, grad_fn=<SubBackward0>)\n",
      "loss: 0.022029783576726913\n",
      "tensor([[855]]) tensor(841.6991, grad_fn=<SubBackward0>)\n",
      "loss: 0.01555661205202341\n",
      "tensor([[855]]) tensor(840.6097, grad_fn=<SubBackward0>)\n",
      "loss: 0.016830747947096825\n",
      "tensor([[855]]) tensor(838.0378, grad_fn=<SubBackward0>)\n",
      "loss: 0.019838763400912285\n",
      "tensor([[855]]) tensor(833.5471, grad_fn=<SubBackward0>)\n",
      "loss: 0.025091053918004036\n",
      "tensor([[855]]) tensor(837.6945, grad_fn=<SubBackward0>)\n",
      "loss: 0.020240364596247673\n",
      "tensor([[855]]) tensor(829.6298, grad_fn=<SubBackward0>)\n",
      "loss: 0.02967277728021145\n",
      "tensor([[855]]) tensor(827.4210, grad_fn=<SubBackward0>)\n",
      "loss: 0.03225620463490486\n",
      "tensor([[855]]) tensor(832.4185, grad_fn=<SubBackward0>)\n",
      "loss: 0.026411090046167374\n",
      "tensor([[855]]) tensor(835.7349, grad_fn=<SubBackward0>)\n",
      "loss: 0.02253228798508644\n",
      "tensor([[855]]) tensor(836.7307, grad_fn=<SubBackward0>)\n",
      "loss: 0.021367676556110382\n",
      "tensor([[855]]) tensor(833.3113, grad_fn=<SubBackward0>)\n",
      "loss: 0.025366924703121185\n",
      "tensor([[855]]) tensor(827.1012, grad_fn=<SubBackward0>)\n",
      "loss: 0.03263021633028984\n",
      "tensor([[855]]) tensor(828.9857, grad_fn=<SubBackward0>)\n",
      "loss: 0.030426025390625\n",
      "tensor([[855]]) tensor(840.4705, grad_fn=<SubBackward0>)\n",
      "loss: 0.01699361577630043\n",
      "tensor([[855]]) tensor(828.4847, grad_fn=<SubBackward0>)\n",
      "loss: 0.03101208806037903\n",
      "tensor([[855]]) tensor(824.5325, grad_fn=<SubBackward0>)\n",
      "loss: 0.03563457354903221\n",
      "tensor([[855]]) tensor(834.8076, grad_fn=<SubBackward0>)\n",
      "loss: 0.023616822436451912\n",
      "tensor([[855]]) tensor(836.5836, grad_fn=<SubBackward0>)\n",
      "loss: 0.02153959311544895\n",
      "tensor([[855]]) tensor(839.4469, grad_fn=<SubBackward0>)\n",
      "loss: 0.018190760165452957\n",
      "tensor([[855]]) tensor(831.9751, grad_fn=<SubBackward0>)\n",
      "loss: 0.026929674670100212\n",
      "tensor([[855]]) tensor(835.3799, grad_fn=<SubBackward0>)\n",
      "loss: 0.0229475237429142\n",
      "tensor([[855]]) tensor(842.6545, grad_fn=<SubBackward0>)\n",
      "loss: 0.014439115300774574\n",
      "tensor([[855]]) tensor(838.8009, grad_fn=<SubBackward0>)\n",
      "loss: 0.018946276977658272\n",
      "tensor([[855]]) tensor(835.0387, grad_fn=<SubBackward0>)\n",
      "loss: 0.023346589878201485\n",
      "tensor([[855]]) tensor(837.3865, grad_fn=<SubBackward0>)\n",
      "loss: 0.020600631833076477\n",
      "tensor([[855]]) tensor(837.6256, grad_fn=<SubBackward0>)\n",
      "loss: 0.020320923998951912\n",
      "tensor([[855]]) tensor(841.8146, grad_fn=<SubBackward0>)\n",
      "loss: 0.015421495772898197\n",
      "tensor([[855]]) tensor(839.0458, grad_fn=<SubBackward0>)\n",
      "loss: 0.018659910187125206\n",
      "tensor([[855]]) tensor(842.0721, grad_fn=<SubBackward0>)\n",
      "loss: 0.015120335854589939\n",
      "tensor([[855]]) tensor(847.6910, grad_fn=<SubBackward0>)\n",
      "loss: 0.008548562414944172\n",
      "tensor([[855]]) tensor(834.2833, grad_fn=<SubBackward0>)\n",
      "loss: 0.02423006482422352\n",
      "tensor([[855]]) tensor(838.6897, grad_fn=<SubBackward0>)\n",
      "loss: 0.019076360389590263\n",
      "tensor([[855]]) tensor(835.5234, grad_fn=<SubBackward0>)\n",
      "loss: 0.022779569029808044\n",
      "tensor([[855]]) tensor(844.9839, grad_fn=<SubBackward0>)\n",
      "loss: 0.011714734137058258\n",
      "tensor([[855]]) tensor(840.8368, grad_fn=<SubBackward0>)\n",
      "loss: 0.01656515523791313\n",
      "tensor([[855]]) tensor(842.0718, grad_fn=<SubBackward0>)\n",
      "loss: 0.015120764262974262\n",
      "tensor([[855]]) tensor(846.7488, grad_fn=<SubBackward0>)\n",
      "loss: 0.009650550782680511\n",
      "tensor([[855]]) tensor(831.0207, grad_fn=<SubBackward0>)\n",
      "loss: 0.028045974671840668\n",
      "tensor([[855]]) tensor(835.3345, grad_fn=<SubBackward0>)\n",
      "loss: 0.023000599816441536\n",
      "tensor([[855]]) tensor(839.1351, grad_fn=<SubBackward0>)\n",
      "loss: 0.018555400893092155\n",
      "tensor([[855]]) tensor(831.7506, grad_fn=<SubBackward0>)\n",
      "loss: 0.027192268520593643\n",
      "tensor([[855]]) tensor(842.1441, grad_fn=<SubBackward0>)\n",
      "loss: 0.015036135911941528\n",
      "tensor([[855]]) tensor(830.3444, grad_fn=<SubBackward0>)\n",
      "loss: 0.02883693389594555\n",
      "tensor([[855]]) tensor(829.7159, grad_fn=<SubBackward0>)\n",
      "loss: 0.029572032392024994\n",
      "tensor([[855]]) tensor(838.3633, grad_fn=<SubBackward0>)\n",
      "loss: 0.019458061084151268\n",
      "tensor([[855]]) tensor(839.2389, grad_fn=<SubBackward0>)\n",
      "loss: 0.018434062600135803\n",
      "tensor([[855]]) tensor(842.6712, grad_fn=<SubBackward0>)\n",
      "loss: 0.014419645071029663\n",
      "tensor([[855]]) tensor(837.2103, grad_fn=<SubBackward0>)\n",
      "loss: 0.0208066888153553\n",
      "tensor([[855]]) tensor(830.1906, grad_fn=<SubBackward0>)\n",
      "loss: 0.02901686355471611\n",
      "tensor([[855]]) tensor(838.8501, grad_fn=<SubBackward0>)\n",
      "loss: 0.01888875663280487\n",
      "tensor([[855]]) tensor(837.9351, grad_fn=<SubBackward0>)\n",
      "loss: 0.01995903067290783\n",
      "tensor([[855]]) tensor(834.7399, grad_fn=<SubBackward0>)\n",
      "loss: 0.023695988580584526\n",
      "tensor([[855]]) tensor(839.5153, grad_fn=<SubBackward0>)\n",
      "loss: 0.018110737204551697\n",
      "tensor([[855]]) tensor(846.7757, grad_fn=<SubBackward0>)\n",
      "loss: 0.009619051590561867\n",
      "tensor([[855]]) tensor(840.7838, grad_fn=<SubBackward0>)\n",
      "loss: 0.01662719063460827\n",
      "tensor([[855]]) tensor(836.2269, grad_fn=<SubBackward0>)\n",
      "loss: 0.021956808865070343\n",
      "tensor([[855]]) tensor(847.6342, grad_fn=<SubBackward0>)\n",
      "loss: 0.008614951744675636\n",
      "tensor([[855]]) tensor(837.1660, grad_fn=<SubBackward0>)\n",
      "loss: 0.020858515053987503\n",
      "tensor([[855]]) tensor(843.6684, grad_fn=<SubBackward0>)\n",
      "loss: 0.01325333770364523\n",
      "tensor([[855]]) tensor(832.6563, grad_fn=<SubBackward0>)\n",
      "loss: 0.026132969185709953\n",
      "tensor([[855]]) tensor(830.4854, grad_fn=<SubBackward0>)\n",
      "loss: 0.028672102838754654\n",
      "tensor([[855]]) tensor(845.8555, grad_fn=<SubBackward0>)\n",
      "loss: 0.01069539412856102\n",
      "tensor([[855]]) tensor(837.7087, grad_fn=<SubBackward0>)\n",
      "loss: 0.020223749801516533\n",
      "tensor([[855]]) tensor(841.4600, grad_fn=<SubBackward0>)\n",
      "loss: 0.015836302191019058\n",
      "tensor([[855]]) tensor(837.5753, grad_fn=<SubBackward0>)\n",
      "loss: 0.020379746332764626\n",
      "tensor([[855]]) tensor(842.0815, grad_fn=<SubBackward0>)\n",
      "loss: 0.015109270811080933\n",
      "tensor([[855]]) tensor(838.9084, grad_fn=<SubBackward0>)\n",
      "loss: 0.018820583820343018\n",
      "tensor([[855]]) tensor(839.5666, grad_fn=<SubBackward0>)\n",
      "loss: 0.018050773069262505\n",
      "tensor([[855]]) tensor(841.6550, grad_fn=<SubBackward0>)\n",
      "loss: 0.015608224086463451\n",
      "tensor([[855]]) tensor(839.3377, grad_fn=<SubBackward0>)\n",
      "loss: 0.01831847056746483\n",
      "tensor([[855]]) tensor(847.7909, grad_fn=<SubBackward0>)\n",
      "loss: 0.00843170378357172\n",
      "tensor([[855]]) tensor(844.9012, grad_fn=<SubBackward0>)\n",
      "loss: 0.011811426840722561\n",
      "tensor([[855]]) tensor(844.3776, grad_fn=<SubBackward0>)\n",
      "loss: 0.012423884123563766\n",
      "tensor([[855]]) tensor(836.2604, grad_fn=<SubBackward0>)\n",
      "loss: 0.021917706355452538\n",
      "tensor([[855]]) tensor(838.7001, grad_fn=<SubBackward0>)\n",
      "loss: 0.019064277410507202\n",
      "tensor([[855]]) tensor(829.2003, grad_fn=<SubBackward0>)\n",
      "loss: 0.030175086110830307\n",
      "tensor([[855]]) tensor(834.2894, grad_fn=<SubBackward0>)\n",
      "loss: 0.0242229625582695\n",
      "tensor([[855]]) tensor(836.4514, grad_fn=<SubBackward0>)\n",
      "loss: 0.021694321185350418\n",
      "tensor([[855]]) tensor(834.4801, grad_fn=<SubBackward0>)\n",
      "loss: 0.02399984374642372\n",
      "tensor([[855]]) tensor(837.7596, grad_fn=<SubBackward0>)\n",
      "loss: 0.020164160057902336\n",
      "tensor([[855]]) tensor(841.9722, grad_fn=<SubBackward0>)\n",
      "loss: 0.015237212181091309\n",
      "tensor([[855]]) tensor(829.8395, grad_fn=<SubBackward0>)\n",
      "loss: 0.029427440837025642\n",
      "tensor([[855]]) tensor(830.2900, grad_fn=<SubBackward0>)\n",
      "loss: 0.02890061028301716\n",
      "tensor([[855]]) tensor(841.3808, grad_fn=<SubBackward0>)\n",
      "loss: 0.01592889055609703\n",
      "tensor([[855]]) tensor(828.1478, grad_fn=<SubBackward0>)\n",
      "loss: 0.03140612319111824\n",
      "tensor([[855]]) tensor(826.4889, grad_fn=<SubBackward0>)\n",
      "loss: 0.03334636241197586\n",
      "tensor([[855]]) tensor(840.4131, grad_fn=<SubBackward0>)\n",
      "loss: 0.01706068217754364\n",
      "tensor([[855]]) tensor(833.0464, grad_fn=<SubBackward0>)\n",
      "loss: 0.025676704943180084\n",
      "tensor([[855]]) tensor(827.5360, grad_fn=<SubBackward0>)\n",
      "loss: 0.03212158754467964\n",
      "tensor([[855]]) tensor(836.5118, grad_fn=<SubBackward0>)\n",
      "loss: 0.02162361331284046\n",
      "tensor([[855]]) tensor(827.6005, grad_fn=<SubBackward0>)\n",
      "loss: 0.032046277076005936\n",
      "tensor([[855]]) tensor(825.9233, grad_fn=<SubBackward0>)\n",
      "loss: 0.03400775417685509\n",
      "tensor([[855]]) tensor(839.8259, grad_fn=<SubBackward0>)\n",
      "loss: 0.017747417092323303\n",
      "tensor([[855]]) tensor(832.6998, grad_fn=<SubBackward0>)\n",
      "loss: 0.026082035154104233\n",
      "tensor([[855]]) tensor(828.0165, grad_fn=<SubBackward0>)\n",
      "loss: 0.03155965358018875\n",
      "tensor([[855]]) tensor(840.2506, grad_fn=<SubBackward0>)\n",
      "loss: 0.017250729724764824\n",
      "tensor([[855]]) tensor(828.3311, grad_fn=<SubBackward0>)\n",
      "loss: 0.031191784888505936\n",
      "tensor([[855]]) tensor(838.6668, grad_fn=<SubBackward0>)\n",
      "loss: 0.01910313032567501\n",
      "tensor([[855]]) tensor(829.4304, grad_fn=<SubBackward0>)\n",
      "loss: 0.029905905947089195\n",
      "tensor([[855]]) tensor(819.9382, grad_fn=<SubBackward0>)\n",
      "loss: 0.04100789874792099\n",
      "tensor([[855]]) tensor(835.2719, grad_fn=<SubBackward0>)\n",
      "loss: 0.023073824122548103\n",
      "tensor([[855]]) tensor(832.3177, grad_fn=<SubBackward0>)\n",
      "loss: 0.02652893029153347\n",
      "tensor([[855]]) tensor(830.8907, grad_fn=<SubBackward0>)\n",
      "loss: 0.028197921812534332\n",
      "tensor([[855]]) tensor(839.2766, grad_fn=<SubBackward0>)\n",
      "loss: 0.01839001663029194\n",
      "tensor([[855]]) tensor(833.8737, grad_fn=<SubBackward0>)\n",
      "loss: 0.02470920793712139\n",
      "tensor([[855]]) tensor(836.0680, grad_fn=<SubBackward0>)\n",
      "loss: 0.02214273437857628\n",
      "tensor([[855]]) tensor(841.3138, grad_fn=<SubBackward0>)\n",
      "loss: 0.016007183119654655\n",
      "tensor([[855]]) tensor(832.7172, grad_fn=<SubBackward0>)\n",
      "loss: 0.026061726734042168\n",
      "tensor([[855]]) tensor(844.6089, grad_fn=<SubBackward0>)\n",
      "loss: 0.012153384275734425\n",
      "tensor([[855]]) tensor(833.0097, grad_fn=<SubBackward0>)\n",
      "loss: 0.025719644501805305\n",
      "tensor([[855]]) tensor(837.3016, grad_fn=<SubBackward0>)\n",
      "loss: 0.02069980464875698\n",
      "tensor([[855]]) tensor(838.1814, grad_fn=<SubBackward0>)\n",
      "loss: 0.019670845940709114\n",
      "tensor([[855]]) tensor(837.6316, grad_fn=<SubBackward0>)\n",
      "loss: 0.0203139279037714\n",
      "tensor([[855]]) tensor(840.6452, grad_fn=<SubBackward0>)\n",
      "loss: 0.016789253801107407\n",
      "tensor([[855]]) tensor(836.1980, grad_fn=<SubBackward0>)\n",
      "loss: 0.021990610286593437\n",
      "tensor([[855]]) tensor(846.3564, grad_fn=<SubBackward0>)\n",
      "loss: 0.010109510272741318\n",
      "tensor([[855]]) tensor(840.5883, grad_fn=<SubBackward0>)\n",
      "loss: 0.016855768859386444\n",
      "tensor([[855]]) tensor(845.1831, grad_fn=<SubBackward0>)\n",
      "loss: 0.011481765657663345\n",
      "tensor([[855]]) tensor(839.4557, grad_fn=<SubBackward0>)\n",
      "loss: 0.01818046346306801\n",
      "tensor([[855]]) tensor(840.0485, grad_fn=<SubBackward0>)\n",
      "loss: 0.01748710684478283\n",
      "tensor([[855]]) tensor(838.9843, grad_fn=<SubBackward0>)\n",
      "loss: 0.01873190328478813\n",
      "tensor([[855]]) tensor(834.7507, grad_fn=<SubBackward0>)\n",
      "loss: 0.023683354258537292\n",
      "tensor([[855]]) tensor(837.9131, grad_fn=<SubBackward0>)\n",
      "loss: 0.01998472958803177\n",
      "tensor([[855]]) tensor(839.9402, grad_fn=<SubBackward0>)\n",
      "loss: 0.017613818868994713\n",
      "tensor([[855]]) tensor(842.3384, grad_fn=<SubBackward0>)\n",
      "loss: 0.014808878302574158\n",
      "tensor([[855]]) tensor(834.3121, grad_fn=<SubBackward0>)\n",
      "loss: 0.02419629879295826\n",
      "tensor([[855]]) tensor(840.1182, grad_fn=<SubBackward0>)\n",
      "loss: 0.017405692487955093\n",
      "tensor([[855]]) tensor(843.3876, grad_fn=<SubBackward0>)\n",
      "loss: 0.013581732288002968\n",
      "tensor([[855]]) tensor(843.6791, grad_fn=<SubBackward0>)\n",
      "loss: 0.013240774162113667\n",
      "tensor([[855]]) tensor(839.9845, grad_fn=<SubBackward0>)\n",
      "loss: 0.01756199263036251\n",
      "tensor([[855]]) tensor(842.8981, grad_fn=<SubBackward0>)\n",
      "loss: 0.014154266566038132\n",
      "tensor([[855]]) tensor(843.8743, grad_fn=<SubBackward0>)\n",
      "loss: 0.013012498617172241\n",
      "tensor([[855]]) tensor(847.0753, grad_fn=<SubBackward0>)\n",
      "loss: 0.009268670342862606\n",
      "tensor([[855]]) tensor(840.3854, grad_fn=<SubBackward0>)\n",
      "loss: 0.017093073576688766\n",
      "tensor([[855]]) tensor(844.6853, grad_fn=<SubBackward0>)\n",
      "loss: 0.01206393726170063\n",
      "tensor([[855]]) tensor(845.5015, grad_fn=<SubBackward0>)\n",
      "loss: 0.011109362356364727\n",
      "tensor([[855]]) tensor(839.8802, grad_fn=<SubBackward0>)\n",
      "loss: 0.017683973535895348\n",
      "tensor([[855]]) tensor(847.4661, grad_fn=<SubBackward0>)\n",
      "loss: 0.00881154928356409\n",
      "tensor([[855]]) tensor(845.8071, grad_fn=<SubBackward0>)\n",
      "loss: 0.010751895606517792\n",
      "tensor([[855]]) tensor(839.1875, grad_fn=<SubBackward0>)\n",
      "loss: 0.01849411614239216\n",
      "tensor([[855]]) tensor(842.3956, grad_fn=<SubBackward0>)\n",
      "loss: 0.014742025174200535\n",
      "tensor([[855]]) tensor(840.1218, grad_fn=<SubBackward0>)\n",
      "loss: 0.01740133762359619\n",
      "tensor([[855]]) tensor(839.8177, grad_fn=<SubBackward0>)\n",
      "loss: 0.01775708980858326\n",
      "tensor([[855]]) tensor(845.2480, grad_fn=<SubBackward0>)\n",
      "loss: 0.011405864730477333\n",
      "tensor([[855]]) tensor(845.1028, grad_fn=<SubBackward0>)\n",
      "loss: 0.011575674638152122\n",
      "tensor([[855]]) tensor(846.0939, grad_fn=<SubBackward0>)\n",
      "loss: 0.010416542179882526\n",
      "tensor([[855]]) tensor(842.6128, grad_fn=<SubBackward0>)\n",
      "loss: 0.014487996697425842\n",
      "tensor([[855]]) tensor(835.5991, grad_fn=<SubBackward0>)\n",
      "loss: 0.022691069170832634\n",
      "tensor([[855]]) tensor(848.5169, grad_fn=<SubBackward0>)\n",
      "loss: 0.007582547143101692\n",
      "tensor([[855]]) tensor(832.6346, grad_fn=<SubBackward0>)\n",
      "loss: 0.026158293709158897\n",
      "tensor([[855]]) tensor(841.1355, grad_fn=<SubBackward0>)\n",
      "loss: 0.01621582731604576\n",
      "tensor([[855]]) tensor(826.6711, grad_fn=<SubBackward0>)\n",
      "loss: 0.03313318267464638\n",
      "tensor([[855]]) tensor(822.9861, grad_fn=<SubBackward0>)\n",
      "loss: 0.03744317591190338\n",
      "tensor([[855]]) tensor(847.1634, grad_fn=<SubBackward0>)\n",
      "loss: 0.009165624156594276\n",
      "tensor([[855]]) tensor(821.2558, grad_fn=<SubBackward0>)\n",
      "loss: 0.03946690261363983\n",
      "tensor([[855]]) tensor(816.3366, grad_fn=<SubBackward0>)\n",
      "loss: 0.04522034153342247\n",
      "tensor([[855]]) tensor(838.1929, grad_fn=<SubBackward0>)\n",
      "loss: 0.01965739019215107\n",
      "tensor([[855]]) tensor(822.6068, grad_fn=<SubBackward0>)\n",
      "loss: 0.03788676857948303\n",
      "tensor([[855]]) tensor(810.8480, grad_fn=<SubBackward0>)\n",
      "loss: 0.05163981020450592\n",
      "tensor([[855]]) tensor(829.0382, grad_fn=<SubBackward0>)\n",
      "loss: 0.030364705249667168\n",
      "tensor([[855]]) tensor(833.3917, grad_fn=<SubBackward0>)\n",
      "loss: 0.025272874161601067\n",
      "tensor([[855]]) tensor(811.4079, grad_fn=<SubBackward0>)\n",
      "loss: 0.05098491534590721\n",
      "tensor([[855]]) tensor(818.3963, grad_fn=<SubBackward0>)\n",
      "loss: 0.04281136021018028\n",
      "tensor([[855]]) tensor(836.7931, grad_fn=<SubBackward0>)\n",
      "loss: 0.021294647827744484\n",
      "tensor([[855]]) tensor(820.3738, grad_fn=<SubBackward0>)\n",
      "loss: 0.04049845039844513\n",
      "tensor([[855]]) tensor(812.9031, grad_fn=<SubBackward0>)\n",
      "loss: 0.04923616722226143\n",
      "tensor([[855]]) tensor(833.2093, grad_fn=<SubBackward0>)\n",
      "loss: 0.025486210361123085\n",
      "tensor([[855]]) tensor(833.2965, grad_fn=<SubBackward0>)\n",
      "loss: 0.02538418211042881\n",
      "tensor([[855]]) tensor(815.7150, grad_fn=<SubBackward0>)\n",
      "loss: 0.045947443693876266\n",
      "tensor([[855]]) tensor(825.8680, grad_fn=<SubBackward0>)\n",
      "loss: 0.034072428941726685\n",
      "tensor([[855]]) tensor(838.3522, grad_fn=<SubBackward0>)\n",
      "loss: 0.019471142441034317\n",
      "tensor([[855]]) tensor(829.0774, grad_fn=<SubBackward0>)\n",
      "loss: 0.03031887486577034\n",
      "tensor([[855]]) tensor(832.3289, grad_fn=<SubBackward0>)\n",
      "loss: 0.026515992358326912\n",
      "tensor([[855]]) tensor(835.5829, grad_fn=<SubBackward0>)\n",
      "loss: 0.02271004021167755\n",
      "tensor([[855]]) tensor(845.2930, grad_fn=<SubBackward0>)\n",
      "loss: 0.01135321706533432\n",
      "tensor([[855]]) tensor(838.6759, grad_fn=<SubBackward0>)\n",
      "loss: 0.01909254677593708\n",
      "tensor([[855]]) tensor(831.8390, grad_fn=<SubBackward0>)\n",
      "loss: 0.02708890102803707\n",
      "tensor([[855]]) tensor(843.1013, grad_fn=<SubBackward0>)\n",
      "loss: 0.01391658652573824\n",
      "tensor([[855]]) tensor(846.6863, grad_fn=<SubBackward0>)\n",
      "loss: 0.009723560884594917\n",
      "tensor([[855]]) tensor(834.1456, grad_fn=<SubBackward0>)\n",
      "loss: 0.02439112961292267\n",
      "tensor([[855]]) tensor(840.8877, grad_fn=<SubBackward0>)\n",
      "loss: 0.016505654901266098\n",
      "tensor([[855]]) tensor(847.4442, grad_fn=<SubBackward0>)\n",
      "loss: 0.00883714109659195\n",
      "tensor([[855]]) tensor(840.9692, grad_fn=<SubBackward0>)\n",
      "loss: 0.016410211101174355\n",
      "tensor([[855]]) tensor(839.2319, grad_fn=<SubBackward0>)\n",
      "loss: 0.01844225451350212\n",
      "tensor([[855]]) tensor(843.6970, grad_fn=<SubBackward0>)\n",
      "loss: 0.013219911605119705\n",
      "tensor([[855]]) tensor(843.7928, grad_fn=<SubBackward0>)\n",
      "loss: 0.013107817620038986\n",
      "tensor([[855]]) tensor(829.8643, grad_fn=<SubBackward0>)\n",
      "loss: 0.029398474842309952\n",
      "tensor([[855]]) tensor(839.5184, grad_fn=<SubBackward0>)\n",
      "loss: 0.018107131123542786\n",
      "tensor([[855]]) tensor(832.3900, grad_fn=<SubBackward0>)\n",
      "loss: 0.026444392278790474\n",
      "tensor([[855]]) tensor(833.5391, grad_fn=<SubBackward0>)\n",
      "loss: 0.02510043978691101\n",
      "tensor([[855]]) tensor(836.4274, grad_fn=<SubBackward0>)\n",
      "loss: 0.021722357720136642\n",
      "tensor([[855]]) tensor(837.5432, grad_fn=<SubBackward0>)\n",
      "loss: 0.020417260006070137\n",
      "tensor([[855]]) tensor(840.9670, grad_fn=<SubBackward0>)\n",
      "loss: 0.01641281694173813\n",
      "tensor([[855]]) tensor(841.7878, grad_fn=<SubBackward0>)\n",
      "loss: 0.015452816151082516\n",
      "tensor([[855]]) tensor(837.0253, grad_fn=<SubBackward0>)\n",
      "loss: 0.021023113280534744\n",
      "tensor([[855]]) tensor(842.7117, grad_fn=<SubBackward0>)\n",
      "loss: 0.014372316189110279\n",
      "tensor([[855]]) tensor(839.6189, grad_fn=<SubBackward0>)\n",
      "loss: 0.017989613115787506\n",
      "tensor([[855]]) tensor(842.4516, grad_fn=<SubBackward0>)\n",
      "loss: 0.014676474034786224\n",
      "tensor([[855]]) tensor(840.5768, grad_fn=<SubBackward0>)\n",
      "loss: 0.016869207844138145\n",
      "tensor([[855]]) tensor(837.8231, grad_fn=<SubBackward0>)\n",
      "loss: 0.020089881494641304\n",
      "tensor([[855]]) tensor(832.1943, grad_fn=<SubBackward0>)\n",
      "loss: 0.02667330950498581\n",
      "tensor([[855]]) tensor(840.6713, grad_fn=<SubBackward0>)\n",
      "loss: 0.016758719459176064\n",
      "tensor([[855]]) tensor(838.3861, grad_fn=<SubBackward0>)\n",
      "loss: 0.01943148858845234\n",
      "tensor([[855]]) tensor(835.6616, grad_fn=<SubBackward0>)\n",
      "loss: 0.022617969661951065\n",
      "tensor([[855]]) tensor(836.6543, grad_fn=<SubBackward0>)\n",
      "loss: 0.02145698107779026\n",
      "tensor([[855]]) tensor(830.7462, grad_fn=<SubBackward0>)\n",
      "loss: 0.028367070481181145\n",
      "tensor([[855]]) tensor(839.2031, grad_fn=<SubBackward0>)\n",
      "loss: 0.01847589574754238\n",
      "tensor([[855]]) tensor(833.8220, grad_fn=<SubBackward0>)\n",
      "loss: 0.02476963773369789\n",
      "tensor([[855]]) tensor(834.0154, grad_fn=<SubBackward0>)\n",
      "loss: 0.02454337850213051\n",
      "tensor([[855]]) tensor(837.1042, grad_fn=<SubBackward0>)\n",
      "loss: 0.02093077450990677\n",
      "tensor([[855]]) tensor(836.6423, grad_fn=<SubBackward0>)\n",
      "loss: 0.0214709360152483\n",
      "tensor([[855]]) tensor(838.9600, grad_fn=<SubBackward0>)\n",
      "loss: 0.018760278820991516\n",
      "tensor([[855]]) tensor(832.0148, grad_fn=<SubBackward0>)\n",
      "loss: 0.026883220300078392\n",
      "tensor([[855]]) tensor(831.3640, grad_fn=<SubBackward0>)\n",
      "loss: 0.0276444461196661\n",
      "tensor([[855]]) tensor(839.1031, grad_fn=<SubBackward0>)\n",
      "loss: 0.018592843785881996\n",
      "tensor([[855]]) tensor(836.9629, grad_fn=<SubBackward0>)\n",
      "loss: 0.02109605260193348\n",
      "tensor([[855]]) tensor(838.0620, grad_fn=<SubBackward0>)\n",
      "loss: 0.019810548052191734\n",
      "tensor([[855]]) tensor(825.2561, grad_fn=<SubBackward0>)\n",
      "loss: 0.03478820249438286\n",
      "tensor([[855]]) tensor(823.7747, grad_fn=<SubBackward0>)\n",
      "loss: 0.03652084991335869\n",
      "tensor([[855]]) tensor(843.4794, grad_fn=<SubBackward0>)\n",
      "loss: 0.01347445696592331\n",
      "tensor([[855]]) tensor(829.1138, grad_fn=<SubBackward0>)\n",
      "loss: 0.030276257544755936\n",
      "tensor([[855]]) tensor(828.6891, grad_fn=<SubBackward0>)\n",
      "loss: 0.030772944912314415\n",
      "tensor([[855]]) tensor(839.4589, grad_fn=<SubBackward0>)\n",
      "loss: 0.018176697194576263\n",
      "tensor([[855]]) tensor(824.6248, grad_fn=<SubBackward0>)\n",
      "loss: 0.03552659973502159\n",
      "tensor([[855]]) tensor(822.7898, grad_fn=<SubBackward0>)\n",
      "loss: 0.037672754377126694\n",
      "tensor([[855]]) tensor(842.2636, grad_fn=<SubBackward0>)\n",
      "loss: 0.014896361157298088\n",
      "tensor([[855]]) tensor(816.2881, grad_fn=<SubBackward0>)\n",
      "loss: 0.045277129858732224\n",
      "tensor([[855]]) tensor(803.9932, grad_fn=<SubBackward0>)\n",
      "loss: 0.05965704843401909\n",
      "tensor([[855]]) tensor(820.3457, grad_fn=<SubBackward0>)\n",
      "loss: 0.040531307458877563\n",
      "tensor([[855]]) tensor(838.9194, grad_fn=<SubBackward0>)\n",
      "loss: 0.018807733431458473\n",
      "tensor([[855]]) tensor(804.6743, grad_fn=<SubBackward0>)\n",
      "loss: 0.05886046588420868\n",
      "tensor([[855]]) tensor(794.8170, grad_fn=<SubBackward0>)\n",
      "loss: 0.070389524102211\n",
      "tensor([[855]]) tensor(805.1414, grad_fn=<SubBackward0>)\n",
      "loss: 0.058314185589551926\n",
      "tensor([[855]]) tensor(836.4117, grad_fn=<SubBackward0>)\n",
      "loss: 0.021740686148405075\n",
      "tensor([[855]]) tensor(823.5317, grad_fn=<SubBackward0>)\n",
      "loss: 0.03680494800209999\n",
      "tensor([[855]]) tensor(813.2317, grad_fn=<SubBackward0>)\n",
      "loss: 0.048851825296878815\n",
      "tensor([[855]]) tensor(817.1100, grad_fn=<SubBackward0>)\n",
      "loss: 0.04431577026844025\n",
      "tensor([[855]]) tensor(835.7925, grad_fn=<SubBackward0>)\n",
      "loss: 0.02246493473649025\n",
      "tensor([[855]]) tensor(802.7465, grad_fn=<SubBackward0>)\n",
      "loss: 0.06111517921090126\n",
      "tensor([[855]]) tensor(792.9058, grad_fn=<SubBackward0>)\n",
      "loss: 0.07262483984231949\n",
      "tensor([[855]]) tensor(811.1396, grad_fn=<SubBackward0>)\n",
      "loss: 0.05129864066839218\n",
      "tensor([[855]]) tensor(835.8442, grad_fn=<SubBackward0>)\n",
      "loss: 0.022404363378882408\n",
      "tensor([[855]]) tensor(825.1366, grad_fn=<SubBackward0>)\n",
      "loss: 0.03492799401283264\n",
      "tensor([[855]]) tensor(827.2061, grad_fn=<SubBackward0>)\n",
      "loss: 0.03250744938850403\n",
      "tensor([[855]]) tensor(832.8560, grad_fn=<SubBackward0>)\n",
      "loss: 0.02589939348399639\n",
      "tensor([[855]]) tensor(822.8337, grad_fn=<SubBackward0>)\n",
      "loss: 0.0376213937997818\n",
      "tensor([[855]]) tensor(823.5627, grad_fn=<SubBackward0>)\n",
      "loss: 0.03676868602633476\n",
      "tensor([[855]]) tensor(838.4755, grad_fn=<SubBackward0>)\n",
      "loss: 0.019326889887452126\n",
      "tensor([[855]]) tensor(839.0267, grad_fn=<SubBackward0>)\n",
      "loss: 0.018682273104786873\n",
      "tensor([[855]]) tensor(842.4397, grad_fn=<SubBackward0>)\n",
      "loss: 0.01469044853001833\n",
      "tensor([[855]]) tensor(839.4826, grad_fn=<SubBackward0>)\n",
      "loss: 0.0181489996612072\n",
      "tensor([[855]]) tensor(844.6809, grad_fn=<SubBackward0>)\n",
      "loss: 0.01206909492611885\n",
      "tensor([[855]]) tensor(838.5879, grad_fn=<SubBackward0>)\n",
      "loss: 0.019195467233657837\n",
      "tensor([[855]]) tensor(844.4464, grad_fn=<SubBackward0>)\n",
      "loss: 0.012343468144536018\n",
      "tensor([[855]]) tensor(837.9119, grad_fn=<SubBackward0>)\n",
      "loss: 0.019986052066087723\n",
      "tensor([[855]]) tensor(843.2535, grad_fn=<SubBackward0>)\n",
      "loss: 0.013738549314439297\n",
      "tensor([[855]]) tensor(830.9529, grad_fn=<SubBackward0>)\n",
      "loss: 0.02812519669532776\n",
      "tensor([[855]]) tensor(831.8049, grad_fn=<SubBackward0>)\n",
      "loss: 0.027128735557198524\n",
      "tensor([[855]]) tensor(843.4302, grad_fn=<SubBackward0>)\n",
      "loss: 0.013531886972486973\n",
      "tensor([[855]]) tensor(839.8243, grad_fn=<SubBackward0>)\n",
      "loss: 0.017749344930052757\n",
      "tensor([[855]]) tensor(839.0635, grad_fn=<SubBackward0>)\n",
      "loss: 0.018639208748936653\n",
      "tensor([[855]]) tensor(843.7461, grad_fn=<SubBackward0>)\n",
      "loss: 0.013162481598556042\n",
      "tensor([[855]]) tensor(839.1547, grad_fn=<SubBackward0>)\n",
      "loss: 0.018532486632466316\n",
      "tensor([[855]]) tensor(842.4186, grad_fn=<SubBackward0>)\n",
      "loss: 0.014715148136019707\n",
      "tensor([[855]]) tensor(839.3353, grad_fn=<SubBackward0>)\n",
      "loss: 0.018321219831705093\n",
      "tensor([[855]]) tensor(839.1349, grad_fn=<SubBackward0>)\n",
      "loss: 0.018555669113993645\n",
      "tensor([[855]]) tensor(841.3628, grad_fn=<SubBackward0>)\n",
      "loss: 0.0159499142318964\n",
      "tensor([[855]]) tensor(839.2123, grad_fn=<SubBackward0>)\n",
      "loss: 0.01846516877412796\n",
      "tensor([[855]]) tensor(843.9908, grad_fn=<SubBackward0>)\n",
      "loss: 0.012876275926828384\n",
      "tensor([[855]]) tensor(847.8721, grad_fn=<SubBackward0>)\n",
      "loss: 0.008336723782122135\n",
      "tensor([[855]]) tensor(841.7108, grad_fn=<SubBackward0>)\n",
      "loss: 0.015542923472821712\n",
      "tensor([[855]]) tensor(841.2063, grad_fn=<SubBackward0>)\n",
      "loss: 0.01613294892013073\n",
      "tensor([[855]]) tensor(846.9615, grad_fn=<SubBackward0>)\n",
      "loss: 0.009401733987033367\n",
      "tensor([[855]]) tensor(837.0375, grad_fn=<SubBackward0>)\n",
      "loss: 0.021008729934692383\n",
      "tensor([[855]]) tensor(843.8079, grad_fn=<SubBackward0>)\n",
      "loss: 0.013090184889733791\n",
      "tensor([[855]]) tensor(825.8733, grad_fn=<SubBackward0>)\n",
      "loss: 0.034066326916217804\n",
      "tensor([[855]]) tensor(826.8468, grad_fn=<SubBackward0>)\n",
      "loss: 0.03292769938707352\n",
      "tensor([[855]]) tensor(845.4656, grad_fn=<SubBackward0>)\n",
      "loss: 0.011151391081511974\n",
      "tensor([[855]]) tensor(840.2147, grad_fn=<SubBackward0>)\n",
      "loss: 0.0172926876693964\n",
      "tensor([[855]]) tensor(843.0884, grad_fn=<SubBackward0>)\n",
      "loss: 0.013931648805737495\n",
      "tensor([[855]]) tensor(845.0826, grad_fn=<SubBackward0>)\n",
      "loss: 0.011599213816225529\n",
      "tensor([[855]]) tensor(847.1567, grad_fn=<SubBackward0>)\n",
      "loss: 0.009173369966447353\n",
      "tensor([[855]]) tensor(835.5314, grad_fn=<SubBackward0>)\n",
      "loss: 0.02277032472193241\n",
      "tensor([[855]]) tensor(842.3062, grad_fn=<SubBackward0>)\n",
      "loss: 0.014846534468233585\n",
      "tensor([[855]]) tensor(831.6454, grad_fn=<SubBackward0>)\n",
      "loss: 0.02731526643037796\n",
      "tensor([[855]]) tensor(832.8010, grad_fn=<SubBackward0>)\n",
      "loss: 0.02596374787390232\n",
      "tensor([[855]]) tensor(842.5900, grad_fn=<SubBackward0>)\n",
      "loss: 0.014514606446027756\n",
      "tensor([[855]]) tensor(830.5089, grad_fn=<SubBackward0>)\n",
      "loss: 0.02864454872906208\n",
      "tensor([[855]]) tensor(841.1767, grad_fn=<SubBackward0>)\n",
      "loss: 0.016167588531970978\n",
      "tensor([[855]]) tensor(837.8794, grad_fn=<SubBackward0>)\n",
      "loss: 0.02002408169209957\n",
      "tensor([[855]]) tensor(838.0281, grad_fn=<SubBackward0>)\n",
      "loss: 0.01985013112425804\n",
      "tensor([[855]]) tensor(838.2560, grad_fn=<SubBackward0>)\n",
      "loss: 0.01958366483449936\n",
      "tensor([[855]]) tensor(839.4465, grad_fn=<SubBackward0>)\n",
      "loss: 0.01819118857383728\n",
      "tensor([[855]]) tensor(840.4026, grad_fn=<SubBackward0>)\n",
      "loss: 0.01707296073436737\n",
      "tensor([[855]]) tensor(838.7603, grad_fn=<SubBackward0>)\n",
      "loss: 0.018993889912962914\n",
      "tensor([[855]]) tensor(839.9914, grad_fn=<SubBackward0>)\n",
      "loss: 0.01755392551422119\n",
      "tensor([[855]]) tensor(839.1677, grad_fn=<SubBackward0>)\n",
      "loss: 0.01851726323366165\n",
      "tensor([[855]]) tensor(840.9017, grad_fn=<SubBackward0>)\n",
      "loss: 0.016489200294017792\n",
      "tensor([[855]]) tensor(839.8868, grad_fn=<SubBackward0>)\n",
      "loss: 0.017676174640655518\n",
      "tensor([[855]]) tensor(845.6489, grad_fn=<SubBackward0>)\n",
      "loss: 0.010937000624835491\n",
      "tensor([[855]]) tensor(834.9679, grad_fn=<SubBackward0>)\n",
      "loss: 0.023429326713085175\n",
      "tensor([[855]]) tensor(835.4744, grad_fn=<SubBackward0>)\n",
      "loss: 0.022836964577436447\n",
      "tensor([[855]]) tensor(832.7516, grad_fn=<SubBackward0>)\n",
      "loss: 0.026021447032690048\n",
      "tensor([[855]]) tensor(830.2489, grad_fn=<SubBackward0>)\n",
      "loss: 0.028948672115802765\n",
      "tensor([[855]]) tensor(845.0625, grad_fn=<SubBackward0>)\n",
      "loss: 0.011622807011008263\n",
      "tensor([[855]]) tensor(838.1572, grad_fn=<SubBackward0>)\n",
      "loss: 0.019699132069945335\n",
      "tensor([[855]]) tensor(843.7036, grad_fn=<SubBackward0>)\n",
      "loss: 0.01321214810013771\n",
      "tensor([[855]]) tensor(828.4160, grad_fn=<SubBackward0>)\n",
      "loss: 0.031092343851923943\n",
      "tensor([[855]]) tensor(829.0302, grad_fn=<SubBackward0>)\n",
      "loss: 0.030374109745025635\n",
      "tensor([[855]]) tensor(845.1216, grad_fn=<SubBackward0>)\n",
      "loss: 0.011553633958101273\n",
      "tensor([[855]]) tensor(837.9139, grad_fn=<SubBackward0>)\n",
      "loss: 0.019983766600489616\n",
      "tensor([[855]]) tensor(838.9914, grad_fn=<SubBackward0>)\n",
      "loss: 0.018723534420132637\n",
      "tensor([[855]]) tensor(839.7435, grad_fn=<SubBackward0>)\n",
      "loss: 0.01784389652311802\n",
      "tensor([[855]]) tensor(840.4982, grad_fn=<SubBackward0>)\n",
      "loss: 0.016961241140961647\n",
      "tensor([[855]]) tensor(842.2441, grad_fn=<SubBackward0>)\n",
      "loss: 0.014919205568730831\n",
      "tensor([[855]]) tensor(834.6984, grad_fn=<SubBackward0>)\n",
      "loss: 0.023744530975818634\n",
      "tensor([[855]]) tensor(848.4366, grad_fn=<SubBackward0>)\n",
      "loss: 0.0076765273697674274\n",
      "tensor([[855]]) tensor(838.3472, grad_fn=<SubBackward0>)\n",
      "loss: 0.01947699673473835\n",
      "tensor([[855]]) tensor(837.6938, grad_fn=<SubBackward0>)\n",
      "loss: 0.02024116739630699\n",
      "tensor([[855]]) tensor(841.9806, grad_fn=<SubBackward0>)\n",
      "loss: 0.0152273615822196\n",
      "tensor([[855]]) tensor(843.6829, grad_fn=<SubBackward0>)\n",
      "loss: 0.01323638390749693\n",
      "tensor([[855]]) tensor(835.3484, grad_fn=<SubBackward0>)\n",
      "loss: 0.022984305396676064\n",
      "tensor([[855]]) tensor(838.7875, grad_fn=<SubBackward0>)\n",
      "loss: 0.01896205171942711\n",
      "tensor([[855]]) tensor(842.6796, grad_fn=<SubBackward0>)\n",
      "loss: 0.014409900642931461\n",
      "tensor([[855]]) tensor(847.6729, grad_fn=<SubBackward0>)\n",
      "loss: 0.008569800294935703\n",
      "tensor([[855]]) tensor(842.5071, grad_fn=<SubBackward0>)\n",
      "loss: 0.014611601829528809\n",
      "tensor([[855]]) tensor(834.6462, grad_fn=<SubBackward0>)\n",
      "loss: 0.023805638775229454\n",
      "tensor([[855]]) tensor(839.1058, grad_fn=<SubBackward0>)\n",
      "loss: 0.018589649349451065\n",
      "tensor([[855]]) tensor(840.4966, grad_fn=<SubBackward0>)\n",
      "loss: 0.01696309819817543\n",
      "tensor([[855]]) tensor(842.1081, grad_fn=<SubBackward0>)\n",
      "loss: 0.015078253112733364\n",
      "tensor([[855]]) tensor(838.9682, grad_fn=<SubBackward0>)\n",
      "loss: 0.018750624731183052\n",
      "tensor([[855]]) tensor(829.6764, grad_fn=<SubBackward0>)\n",
      "loss: 0.02961825579404831\n",
      "tensor([[855]]) tensor(837.2061, grad_fn=<SubBackward0>)\n",
      "loss: 0.02081155963242054\n",
      "tensor([[855]]) tensor(828.5631, grad_fn=<SubBackward0>)\n",
      "loss: 0.03092033788561821\n",
      "tensor([[855]]) tensor(835.8798, grad_fn=<SubBackward0>)\n",
      "loss: 0.022362887859344482\n",
      "tensor([[855]]) tensor(830.8025, grad_fn=<SubBackward0>)\n",
      "loss: 0.028301145881414413\n",
      "tensor([[855]]) tensor(828.4134, grad_fn=<SubBackward0>)\n",
      "loss: 0.03109544888138771\n",
      "tensor([[855]]) tensor(841.6385, grad_fn=<SubBackward0>)\n",
      "loss: 0.015627481043338776\n",
      "tensor([[855]]) tensor(834.2960, grad_fn=<SubBackward0>)\n",
      "loss: 0.024215180426836014\n",
      "tensor([[855]]) tensor(832.4350, grad_fn=<SubBackward0>)\n",
      "loss: 0.02639179863035679\n",
      "tensor([[855]]) tensor(832.6107, grad_fn=<SubBackward0>)\n",
      "loss: 0.026186294853687286\n",
      "tensor([[855]]) tensor(835.7631, grad_fn=<SubBackward0>)\n",
      "loss: 0.022499272599816322\n",
      "tensor([[855]]) tensor(840.9994, grad_fn=<SubBackward0>)\n",
      "loss: 0.01637498289346695\n",
      "tensor([[855]]) tensor(841.5880, grad_fn=<SubBackward0>)\n",
      "loss: 0.015686534345149994\n",
      "tensor([[855]]) tensor(838.5077, grad_fn=<SubBackward0>)\n",
      "loss: 0.019289251416921616\n",
      "tensor([[855]]) tensor(841.2070, grad_fn=<SubBackward0>)\n",
      "loss: 0.016132162883877754\n",
      "tensor([[855]]) tensor(838.0479, grad_fn=<SubBackward0>)\n",
      "loss: 0.019827038049697876\n",
      "tensor([[855]]) tensor(842.8405, grad_fn=<SubBackward0>)\n",
      "loss: 0.014221691526472569\n",
      "tensor([[855]]) tensor(836.8503, grad_fn=<SubBackward0>)\n",
      "loss: 0.021227706223726273\n",
      "tensor([[855]]) tensor(843.3760, grad_fn=<SubBackward0>)\n",
      "loss: 0.013595277443528175\n",
      "tensor([[855]]) tensor(828.9786, grad_fn=<SubBackward0>)\n",
      "loss: 0.03043443150818348\n",
      "tensor([[855]]) tensor(837.9307, grad_fn=<SubBackward0>)\n",
      "loss: 0.019964171573519707\n",
      "tensor([[855]]) tensor(835.4758, grad_fn=<SubBackward0>)\n",
      "loss: 0.022835321724414825\n",
      "tensor([[855]]) tensor(835.1965, grad_fn=<SubBackward0>)\n",
      "loss: 0.023161930963397026\n",
      "tensor([[855]]) tensor(829.4153, grad_fn=<SubBackward0>)\n",
      "loss: 0.029923556372523308\n",
      "tensor([[855]]) tensor(828.0420, grad_fn=<SubBackward0>)\n",
      "loss: 0.031529832631349564\n",
      "tensor([[855]]) tensor(831.7726, grad_fn=<SubBackward0>)\n",
      "loss: 0.02716648019850254\n",
      "tensor([[855]]) tensor(836.5581, grad_fn=<SubBackward0>)\n",
      "loss: 0.021569503471255302\n",
      "tensor([[855]]) tensor(827.8413, grad_fn=<SubBackward0>)\n",
      "loss: 0.03176455199718475\n",
      "tensor([[855]]) tensor(835.6281, grad_fn=<SubBackward0>)\n",
      "loss: 0.022657213732600212\n",
      "tensor([[855]]) tensor(831.7148, grad_fn=<SubBackward0>)\n",
      "loss: 0.02723410166800022\n",
      "tensor([[855]]) tensor(821.7899, grad_fn=<SubBackward0>)\n",
      "loss: 0.03884216770529747\n",
      "tensor([[855]]) tensor(832.0261, grad_fn=<SubBackward0>)\n",
      "loss: 0.026870103552937508\n",
      "tensor([[855]]) tensor(839.2620, grad_fn=<SubBackward0>)\n",
      "loss: 0.018406972289085388\n",
      "tensor([[855]]) tensor(824.9086, grad_fn=<SubBackward0>)\n",
      "loss: 0.03519463911652565\n",
      "tensor([[855]]) tensor(835.8510, grad_fn=<SubBackward0>)\n",
      "loss: 0.022396475076675415\n",
      "tensor([[855]]) tensor(831.1115, grad_fn=<SubBackward0>)\n",
      "loss: 0.02793973498046398\n",
      "tensor([[855]]) tensor(819.6576, grad_fn=<SubBackward0>)\n",
      "loss: 0.04133618623018265\n",
      "tensor([[855]]) tensor(833.8228, grad_fn=<SubBackward0>)\n",
      "loss: 0.02476867288351059\n",
      "tensor([[855]]) tensor(835.3665, grad_fn=<SubBackward0>)\n",
      "loss: 0.02296324633061886\n",
      "tensor([[855]]) tensor(829.3180, grad_fn=<SubBackward0>)\n",
      "loss: 0.030037416145205498\n",
      "tensor([[855]]) tensor(844.5218, grad_fn=<SubBackward0>)\n",
      "loss: 0.01225521694868803\n",
      "tensor([[855]]) tensor(832.6122, grad_fn=<SubBackward0>)\n",
      "loss: 0.02618454582989216\n",
      "tensor([[855]]) tensor(834.2372, grad_fn=<SubBackward0>)\n",
      "loss: 0.0242839977145195\n",
      "tensor([[855]]) tensor(830.9936, grad_fn=<SubBackward0>)\n",
      "loss: 0.02807765267789364\n",
      "tensor([[855]]) tensor(831.3416, grad_fn=<SubBackward0>)\n",
      "loss: 0.027670608833432198\n",
      "tensor([[855]]) tensor(832.1376, grad_fn=<SubBackward0>)\n",
      "loss: 0.02673971652984619\n",
      "tensor([[855]]) tensor(832.6173, grad_fn=<SubBackward0>)\n",
      "loss: 0.026178620755672455\n",
      "tensor([[855]]) tensor(839.6683, grad_fn=<SubBackward0>)\n",
      "loss: 0.017931753769516945\n",
      "tensor([[855]]) tensor(834.5388, grad_fn=<SubBackward0>)\n",
      "loss: 0.023931223899126053\n",
      "tensor([[855]]) tensor(833.7454, grad_fn=<SubBackward0>)\n",
      "loss: 0.024859154596924782\n",
      "tensor([[855]]) tensor(833.5760, grad_fn=<SubBackward0>)\n",
      "loss: 0.02505723387002945\n",
      "tensor([[855]]) tensor(839.0076, grad_fn=<SubBackward0>)\n",
      "loss: 0.018704509362578392\n",
      "tensor([[855]]) tensor(836.0217, grad_fn=<SubBackward0>)\n",
      "loss: 0.022196773439645767\n",
      "tensor([[855]]) tensor(836.4275, grad_fn=<SubBackward0>)\n",
      "loss: 0.02172219753265381\n",
      "tensor([[855]]) tensor(829.9342, grad_fn=<SubBackward0>)\n",
      "loss: 0.0293167382478714\n",
      "tensor([[855]]) tensor(834.0490, grad_fn=<SubBackward0>)\n",
      "loss: 0.02450418658554554\n",
      "tensor([[855]]) tensor(835.5555, grad_fn=<SubBackward0>)\n",
      "loss: 0.02274210937321186\n",
      "tensor([[855]]) tensor(845.9847, grad_fn=<SubBackward0>)\n",
      "loss: 0.010544233955442905\n",
      "tensor([[855]]) tensor(841.1909, grad_fn=<SubBackward0>)\n",
      "loss: 0.016150938346982002\n",
      "tensor([[855]]) tensor(837.6254, grad_fn=<SubBackward0>)\n",
      "loss: 0.02032117359340191\n",
      "tensor([[855]]) tensor(842.7466, grad_fn=<SubBackward0>)\n",
      "loss: 0.014331446960568428\n",
      "tensor([[855]]) tensor(841.3082, grad_fn=<SubBackward0>)\n",
      "loss: 0.016013840213418007\n",
      "tensor([[855]]) tensor(843.3396, grad_fn=<SubBackward0>)\n",
      "loss: 0.01363789476454258\n",
      "tensor([[855]]) tensor(841.7114, grad_fn=<SubBackward0>)\n",
      "loss: 0.01554219238460064\n",
      "tensor([[855]]) tensor(838.4927, grad_fn=<SubBackward0>)\n",
      "loss: 0.019306758418679237\n",
      "tensor([[855]]) tensor(839.6893, grad_fn=<SubBackward0>)\n",
      "loss: 0.017907286062836647\n",
      "tensor([[855]]) tensor(840.2543, grad_fn=<SubBackward0>)\n",
      "loss: 0.01724650152027607\n",
      "tensor([[855]]) tensor(842.0052, grad_fn=<SubBackward0>)\n",
      "loss: 0.015198610723018646\n",
      "tensor([[855]]) tensor(846.7156, grad_fn=<SubBackward0>)\n",
      "loss: 0.009689313359558582\n",
      "tensor([[855]]) tensor(842.6736, grad_fn=<SubBackward0>)\n",
      "loss: 0.014416825026273727\n",
      "tensor([[855]]) tensor(845.8707, grad_fn=<SubBackward0>)\n",
      "loss: 0.01067749410867691\n",
      "tensor([[855]]) tensor(846.3617, grad_fn=<SubBackward0>)\n",
      "loss: 0.010103246197104454\n",
      "tensor([[855]]) tensor(847.6705, grad_fn=<SubBackward0>)\n",
      "loss: 0.008572512306272984\n",
      "tensor([[855]]) tensor(846.3193, grad_fn=<SubBackward0>)\n",
      "loss: 0.010152912698686123\n",
      "tensor([[855]]) tensor(844.9989, grad_fn=<SubBackward0>)\n",
      "loss: 0.011697209440171719\n",
      "tensor([[855]]) tensor(839.1571, grad_fn=<SubBackward0>)\n",
      "loss: 0.01852973736822605\n",
      "tensor([[855]]) tensor(842.2461, grad_fn=<SubBackward0>)\n",
      "loss: 0.014916813932359219\n",
      "tensor([[855]]) tensor(825.2515, grad_fn=<SubBackward0>)\n",
      "loss: 0.03479357436299324\n",
      "tensor([[855]]) tensor(825.4658, grad_fn=<SubBackward0>)\n",
      "loss: 0.03454289957880974\n",
      "tensor([[855]]) tensor(846.8198, grad_fn=<SubBackward0>)\n",
      "loss: 0.009567457251250744\n",
      "tensor([[855]]) tensor(826.2129, grad_fn=<SubBackward0>)\n",
      "loss: 0.03366909921169281\n",
      "tensor([[855]]) tensor(827.1018, grad_fn=<SubBackward0>)\n",
      "loss: 0.032629501074552536\n",
      "tensor([[855]]) tensor(845.5945, grad_fn=<SubBackward0>)\n",
      "loss: 0.01100064069032669\n",
      "tensor([[855]]) tensor(836.9110, grad_fn=<SubBackward0>)\n",
      "loss: 0.021156730130314827\n",
      "tensor([[855]]) tensor(838.9126, grad_fn=<SubBackward0>)\n",
      "loss: 0.018815675750374794\n",
      "tensor([[855]]) tensor(841.5259, grad_fn=<SubBackward0>)\n",
      "loss: 0.015759116038680077\n",
      "tensor([[855]]) tensor(842.7015, grad_fn=<SubBackward0>)\n",
      "loss: 0.014384201727807522\n",
      "tensor([[855]]) tensor(840.0663, grad_fn=<SubBackward0>)\n",
      "loss: 0.017466261982917786\n",
      "tensor([[855]]) tensor(842.8704, grad_fn=<SubBackward0>)\n",
      "loss: 0.014186711981892586\n",
      "tensor([[855]]) tensor(838.7696, grad_fn=<SubBackward0>)\n",
      "loss: 0.018982933834195137\n",
      "tensor([[855]]) tensor(840.6305, grad_fn=<SubBackward0>)\n",
      "loss: 0.01680644042789936\n",
      "tensor([[855]]) tensor(840.4415, grad_fn=<SubBackward0>)\n",
      "loss: 0.017027433961629868\n",
      "tensor([[855]]) tensor(843.5944, grad_fn=<SubBackward0>)\n",
      "loss: 0.013339893892407417\n",
      "tensor([[855]]) tensor(844.2324, grad_fn=<SubBackward0>)\n",
      "loss: 0.012593694031238556\n",
      "tensor([[855]]) tensor(842.7851, grad_fn=<SubBackward0>)\n",
      "loss: 0.014286438003182411\n",
      "tensor([[855]]) tensor(841.4103, grad_fn=<SubBackward0>)\n",
      "loss: 0.015894321724772453\n",
      "tensor([[855]]) tensor(844.8423, grad_fn=<SubBackward0>)\n",
      "loss: 0.011880278587341309\n",
      "tensor([[855]]) tensor(840.7562, grad_fn=<SubBackward0>)\n",
      "loss: 0.016659438610076904\n",
      "tensor([[855]]) tensor(842.0825, grad_fn=<SubBackward0>)\n",
      "loss: 0.015108129009604454\n",
      "tensor([[855]]) tensor(843.9378, grad_fn=<SubBackward0>)\n",
      "loss: 0.012938239611685276\n",
      "tensor([[855]]) tensor(829.8442, grad_fn=<SubBackward0>)\n",
      "loss: 0.029421906918287277\n",
      "tensor([[855]]) tensor(830.1833, grad_fn=<SubBackward0>)\n",
      "loss: 0.02902539260685444\n",
      "tensor([[855]]) tensor(844.7783, grad_fn=<SubBackward0>)\n",
      "loss: 0.011955251917243004\n",
      "tensor([[855]]) tensor(838.0786, grad_fn=<SubBackward0>)\n",
      "loss: 0.01979111321270466\n",
      "tensor([[855]]) tensor(842.5397, grad_fn=<SubBackward0>)\n",
      "loss: 0.01457342877984047\n",
      "tensor([[855]]) tensor(840.7837, grad_fn=<SubBackward0>)\n",
      "loss: 0.016627242788672447\n",
      "tensor([[855]]) tensor(844.9484, grad_fn=<SubBackward0>)\n",
      "loss: 0.011756245978176594\n",
      "tensor([[855]]) tensor(846.1005, grad_fn=<SubBackward0>)\n",
      "loss: 0.010408760979771614\n",
      "tensor([[855]]) tensor(844.6484, grad_fn=<SubBackward0>)\n",
      "loss: 0.012107091024518013\n",
      "tensor([[855]]) tensor(844.0867, grad_fn=<SubBackward0>)\n",
      "loss: 0.012764093466103077\n",
      "tensor([[855]]) tensor(848.2197, grad_fn=<SubBackward0>)\n",
      "loss: 0.007930180057883263\n",
      "tensor([[855]]) tensor(840.3702, grad_fn=<SubBackward0>)\n",
      "loss: 0.01711086742579937\n",
      "tensor([[855]]) tensor(842.2423, grad_fn=<SubBackward0>)\n",
      "loss: 0.014921274967491627\n",
      "tensor([[855]]) tensor(840.5059, grad_fn=<SubBackward0>)\n",
      "loss: 0.016952121630311012\n",
      "tensor([[855]]) tensor(840.4451, grad_fn=<SubBackward0>)\n",
      "loss: 0.01702331192791462\n",
      "tensor([[855]]) tensor(839.8966, grad_fn=<SubBackward0>)\n",
      "loss: 0.017664823681116104\n",
      "tensor([[855]]) tensor(842.0256, grad_fn=<SubBackward0>)\n",
      "loss: 0.015174767933785915\n",
      "tensor([[855]]) tensor(835.3571, grad_fn=<SubBackward0>)\n",
      "loss: 0.022974204272031784\n",
      "tensor([[855]]) tensor(845.8079, grad_fn=<SubBackward0>)\n",
      "loss: 0.01075100339949131\n",
      "tensor([[855]]) tensor(844.5340, grad_fn=<SubBackward0>)\n",
      "loss: 0.012240939773619175\n",
      "tensor([[855]]) tensor(835.9149, grad_fn=<SubBackward0>)\n",
      "loss: 0.02232176996767521\n",
      "tensor([[855]]) tensor(842.4876, grad_fn=<SubBackward0>)\n",
      "loss: 0.014634392224252224\n",
      "tensor([[855]]) tensor(845.2776, grad_fn=<SubBackward0>)\n",
      "loss: 0.011371171101927757\n",
      "tensor([[855]]) tensor(840.0033, grad_fn=<SubBackward0>)\n",
      "loss: 0.017539968714118004\n",
      "tensor([[855]]) tensor(845.3340, grad_fn=<SubBackward0>)\n",
      "loss: 0.011305263265967369\n",
      "tensor([[855]]) tensor(834.0486, grad_fn=<SubBackward0>)\n",
      "loss: 0.024504544213414192\n",
      "tensor([[855]]) tensor(838.0358, grad_fn=<SubBackward0>)\n",
      "loss: 0.01984117366373539\n",
      "tensor([[855]]) tensor(840.0865, grad_fn=<SubBackward0>)\n",
      "loss: 0.01744263432919979\n",
      "tensor([[855]]) tensor(839.1218, grad_fn=<SubBackward0>)\n",
      "loss: 0.01857103407382965\n",
      "tensor([[855]]) tensor(836.9227, grad_fn=<SubBackward0>)\n",
      "loss: 0.021143076941370964\n",
      "tensor([[855]]) tensor(835.2874, grad_fn=<SubBackward0>)\n",
      "loss: 0.02305569127202034\n",
      "tensor([[855]]) tensor(837.8859, grad_fn=<SubBackward0>)\n",
      "loss: 0.020016515627503395\n",
      "tensor([[855]]) tensor(839.2418, grad_fn=<SubBackward0>)\n",
      "loss: 0.018430599942803383\n",
      "tensor([[855]]) tensor(837.8037, grad_fn=<SubBackward0>)\n",
      "loss: 0.020112618803977966\n",
      "tensor([[855]]) tensor(846.0375, grad_fn=<SubBackward0>)\n",
      "loss: 0.01048244908452034\n",
      "tensor([[855]]) tensor(845.5834, grad_fn=<SubBackward0>)\n",
      "loss: 0.011013561859726906\n",
      "tensor([[855]]) tensor(835.0146, grad_fn=<SubBackward0>)\n",
      "loss: 0.0233746450394392\n",
      "tensor([[855]]) tensor(841.3769, grad_fn=<SubBackward0>)\n",
      "loss: 0.015933459624648094\n",
      "tensor([[855]]) tensor(831.4768, grad_fn=<SubBackward0>)\n",
      "loss: 0.02751254290342331\n",
      "tensor([[855]]) tensor(832.4600, grad_fn=<SubBackward0>)\n",
      "loss: 0.026362618431448936\n",
      "tensor([[855]]) tensor(842.3601, grad_fn=<SubBackward0>)\n",
      "loss: 0.014783499762415886\n",
      "tensor([[855]]) tensor(825.6934, grad_fn=<SubBackward0>)\n",
      "loss: 0.03427672013640404\n",
      "tensor([[855]]) tensor(835.8989, grad_fn=<SubBackward0>)\n",
      "loss: 0.022340472787618637\n",
      "tensor([[855]]) tensor(832.6144, grad_fn=<SubBackward0>)\n",
      "loss: 0.026181994006037712\n",
      "tensor([[855]]) tensor(827.2327, grad_fn=<SubBackward0>)\n",
      "loss: 0.032476432621479034\n",
      "tensor([[855]]) tensor(841.0249, grad_fn=<SubBackward0>)\n",
      "loss: 0.016345178708434105\n",
      "tensor([[855]]) tensor(841.7806, grad_fn=<SubBackward0>)\n",
      "loss: 0.015461204573512077\n",
      "tensor([[855]]) tensor(835.8959, grad_fn=<SubBackward0>)\n",
      "loss: 0.022344043478369713\n",
      "tensor([[855]]) tensor(841.0846, grad_fn=<SubBackward0>)\n",
      "loss: 0.016275327652692795\n",
      "tensor([[855]]) tensor(837.7225, grad_fn=<SubBackward0>)\n",
      "loss: 0.020207561552524567\n",
      "tensor([[855]]) tensor(831.9901, grad_fn=<SubBackward0>)\n",
      "loss: 0.026912113651633263\n",
      "tensor([[855]]) tensor(837.3574, grad_fn=<SubBackward0>)\n",
      "loss: 0.02063455805182457\n",
      "tensor([[855]]) tensor(834.4130, grad_fn=<SubBackward0>)\n",
      "loss: 0.024078369140625\n",
      "tensor([[855]]) tensor(841.4475, grad_fn=<SubBackward0>)\n",
      "loss: 0.01585090160369873\n",
      "tensor([[855]]) tensor(831.2065, grad_fn=<SubBackward0>)\n",
      "loss: 0.02782856859266758\n",
      "tensor([[855]]) tensor(839.5037, grad_fn=<SubBackward0>)\n",
      "loss: 0.018124282360076904\n",
      "tensor([[855]]) tensor(822.1120, grad_fn=<SubBackward0>)\n",
      "loss: 0.03846549615263939\n",
      "tensor([[855]]) tensor(812.3451, grad_fn=<SubBackward0>)\n",
      "loss: 0.04988878220319748\n",
      "tensor([[855]]) tensor(829.1479, grad_fn=<SubBackward0>)\n",
      "loss: 0.030236316844820976\n",
      "tensor([[855]]) tensor(828.3014, grad_fn=<SubBackward0>)\n",
      "loss: 0.03122640773653984\n",
      "tensor([[855]]) tensor(821.0061, grad_fn=<SubBackward0>)\n",
      "loss: 0.03975890576839447\n",
      "tensor([[855]]) tensor(840.1278, grad_fn=<SubBackward0>)\n",
      "loss: 0.01739434152841568\n",
      "tensor([[855]]) tensor(819.5768, grad_fn=<SubBackward0>)\n",
      "loss: 0.041430700570344925\n",
      "tensor([[855]]) tensor(811.0353, grad_fn=<SubBackward0>)\n",
      "loss: 0.05142069235444069\n",
      "tensor([[855]]) tensor(822.1192, grad_fn=<SubBackward0>)\n",
      "loss: 0.03845707327127457\n",
      "tensor([[855]]) tensor(831.5614, grad_fn=<SubBackward0>)\n",
      "loss: 0.02741353027522564\n",
      "tensor([[855]]) tensor(813.1877, grad_fn=<SubBackward0>)\n",
      "loss: 0.048903223127126694\n",
      "tensor([[855]]) tensor(823.7500, grad_fn=<SubBackward0>)\n",
      "loss: 0.03654967248439789\n",
      "tensor([[855]]) tensor(834.7633, grad_fn=<SubBackward0>)\n",
      "loss: 0.02366868406534195\n",
      "tensor([[855]]) tensor(824.3322, grad_fn=<SubBackward0>)\n",
      "loss: 0.035868771374225616\n",
      "tensor([[855]]) tensor(826.6489, grad_fn=<SubBackward0>)\n",
      "loss: 0.033159222453832626\n",
      "tensor([[855]]) tensor(829.4334, grad_fn=<SubBackward0>)\n",
      "loss: 0.029902443289756775\n",
      "tensor([[855]]) tensor(836.4314, grad_fn=<SubBackward0>)\n",
      "loss: 0.021717701107263565\n",
      "tensor([[855]]) tensor(831.9891, grad_fn=<SubBackward0>)\n",
      "loss: 0.02691325545310974\n",
      "tensor([[855]]) tensor(840.4233, grad_fn=<SubBackward0>)\n",
      "loss: 0.017048796638846397\n",
      "tensor([[855]]) tensor(841.9973, grad_fn=<SubBackward0>)\n",
      "loss: 0.015207872726023197\n",
      "tensor([[855]]) tensor(835.9054, grad_fn=<SubBackward0>)\n",
      "loss: 0.02233283594250679\n",
      "tensor([[855]]) tensor(831.9468, grad_fn=<SubBackward0>)\n",
      "loss: 0.02696276269853115\n",
      "tensor([[855]]) tensor(838.9637, grad_fn=<SubBackward0>)\n",
      "loss: 0.0187558364123106\n",
      "tensor([[855]]) tensor(844.3091, grad_fn=<SubBackward0>)\n",
      "loss: 0.01250396203249693\n",
      "tensor([[855]]) tensor(835.8488, grad_fn=<SubBackward0>)\n",
      "loss: 0.022399064153432846\n",
      "tensor([[855]]) tensor(841.0209, grad_fn=<SubBackward0>)\n",
      "loss: 0.016349855810403824\n",
      "tensor([[855]]) tensor(846.0316, grad_fn=<SubBackward0>)\n",
      "loss: 0.01048933807760477\n",
      "tensor([[855]]) tensor(840.1807, grad_fn=<SubBackward0>)\n",
      "loss: 0.01733255572617054\n",
      "tensor([[855]]) tensor(838.0366, grad_fn=<SubBackward0>)\n",
      "loss: 0.019840262830257416\n",
      "tensor([[855]]) tensor(840.2232, grad_fn=<SubBackward0>)\n",
      "loss: 0.017282800748944283\n",
      "tensor([[855]]) tensor(844.3018, grad_fn=<SubBackward0>)\n",
      "loss: 0.012512581422924995\n",
      "tensor([[855]]) tensor(833.6069, grad_fn=<SubBackward0>)\n",
      "loss: 0.02502109482884407\n",
      "tensor([[855]]) tensor(831.0200, grad_fn=<SubBackward0>)\n",
      "loss: 0.02804679609835148\n",
      "tensor([[855]]) tensor(841.6395, grad_fn=<SubBackward0>)\n",
      "loss: 0.015626249834895134\n",
      "tensor([[855]]) tensor(844.7351, grad_fn=<SubBackward0>)\n",
      "loss: 0.012005722150206566\n",
      "tensor([[855]]) tensor(835.4463, grad_fn=<SubBackward0>)\n",
      "loss: 0.022869836539030075\n",
      "tensor([[855]]) tensor(832.7920, grad_fn=<SubBackward0>)\n",
      "loss: 0.025974296033382416\n",
      "tensor([[855]]) tensor(843.1044, grad_fn=<SubBackward0>)\n",
      "loss: 0.013913053087890148\n",
      "tensor([[855]]) tensor(825.6221, grad_fn=<SubBackward0>)\n",
      "loss: 0.03436009958386421\n",
      "tensor([[855]]) tensor(834.1179, grad_fn=<SubBackward0>)\n",
      "loss: 0.02442350424826145\n",
      "tensor([[855]]) tensor(827.0792, grad_fn=<SubBackward0>)\n",
      "loss: 0.032655950635671616\n",
      "tensor([[855]]) tensor(822.1914, grad_fn=<SubBackward0>)\n",
      "loss: 0.038372624665498734\n",
      "tensor([[855]]) tensor(834.5745, grad_fn=<SubBackward0>)\n",
      "loss: 0.023889517411589622\n",
      "tensor([[855]]) tensor(837.3346, grad_fn=<SubBackward0>)\n",
      "loss: 0.02066129259765148\n",
      "tensor([[855]]) tensor(836.5754, grad_fn=<SubBackward0>)\n",
      "loss: 0.021549265831708908\n",
      "tensor([[855]]) tensor(840.2549, grad_fn=<SubBackward0>)\n",
      "loss: 0.017245734110474586\n",
      "tensor([[855]]) tensor(837.6328, grad_fn=<SubBackward0>)\n",
      "loss: 0.02031257189810276\n",
      "tensor([[855]]) tensor(841.6895, grad_fn=<SubBackward0>)\n",
      "loss: 0.015567891299724579\n",
      "tensor([[855]]) tensor(838.5247, grad_fn=<SubBackward0>)\n",
      "loss: 0.019269388169050217\n",
      "tensor([[855]]) tensor(843.9950, grad_fn=<SubBackward0>)\n",
      "loss: 0.012871368788182735\n",
      "tensor([[855]]) tensor(837.2744, grad_fn=<SubBackward0>)\n",
      "loss: 0.02073175087571144\n",
      "tensor([[855]]) tensor(839.5171, grad_fn=<SubBackward0>)\n",
      "loss: 0.018108665943145752\n",
      "tensor([[855]]) tensor(832.8784, grad_fn=<SubBackward0>)\n",
      "loss: 0.025873176753520966\n",
      "tensor([[855]]) tensor(838.4401, grad_fn=<SubBackward0>)\n",
      "loss: 0.01936836540699005\n",
      "tensor([[855]]) tensor(834.0892, grad_fn=<SubBackward0>)\n",
      "loss: 0.02445712685585022\n",
      "tensor([[855]]) tensor(834.1222, grad_fn=<SubBackward0>)\n",
      "loss: 0.024418488144874573\n",
      "tensor([[855]]) tensor(844.9723, grad_fn=<SubBackward0>)\n",
      "loss: 0.011728351004421711\n",
      "tensor([[855]]) tensor(838.3137, grad_fn=<SubBackward0>)\n",
      "loss: 0.01951613463461399\n",
      "tensor([[855]]) tensor(837.2415, grad_fn=<SubBackward0>)\n",
      "loss: 0.02077019214630127\n",
      "tensor([[855]]) tensor(844.3811, grad_fn=<SubBackward0>)\n",
      "loss: 0.012419779784977436\n",
      "tensor([[855]]) tensor(839.7693, grad_fn=<SubBackward0>)\n",
      "loss: 0.017813680693507195\n",
      "tensor([[855]]) tensor(826.3801, grad_fn=<SubBackward0>)\n",
      "loss: 0.033473607152700424\n",
      "tensor([[855]]) tensor(830.4702, grad_fn=<SubBackward0>)\n",
      "loss: 0.02868984267115593\n",
      "tensor([[855]]) tensor(829.8790, grad_fn=<SubBackward0>)\n",
      "loss: 0.029381325468420982\n",
      "tensor([[855]]) tensor(839.5458, grad_fn=<SubBackward0>)\n",
      "loss: 0.018075132742524147\n",
      "tensor([[855]]) tensor(827.3203, grad_fn=<SubBackward0>)\n",
      "loss: 0.032373975962400436\n",
      "tensor([[855]]) tensor(821.8530, grad_fn=<SubBackward0>)\n",
      "loss: 0.03876838833093643\n",
      "tensor([[855]]) tensor(839.9728, grad_fn=<SubBackward0>)\n",
      "loss: 0.017575643956661224\n",
      "tensor([[855]]) tensor(827.4153, grad_fn=<SubBackward0>)\n",
      "loss: 0.03226286172866821\n",
      "tensor([[855]]) tensor(828.6965, grad_fn=<SubBackward0>)\n",
      "loss: 0.030764341354370117\n",
      "tensor([[855]]) tensor(824.8521, grad_fn=<SubBackward0>)\n",
      "loss: 0.03526068851351738\n",
      "tensor([[855]]) tensor(814.8704, grad_fn=<SubBackward0>)\n",
      "loss: 0.046935178339481354\n",
      "tensor([[855]]) tensor(827.2460, grad_fn=<SubBackward0>)\n",
      "loss: 0.032460834830999374\n",
      "tensor([[855]]) tensor(835.3019, grad_fn=<SubBackward0>)\n",
      "loss: 0.023038772866129875\n",
      "tensor([[855]]) tensor(824.2629, grad_fn=<SubBackward0>)\n",
      "loss: 0.035949867218732834\n",
      "tensor([[855]]) tensor(833.3127, grad_fn=<SubBackward0>)\n",
      "loss: 0.02536526508629322\n",
      "tensor([[855]]) tensor(836.8890, grad_fn=<SubBackward0>)\n",
      "loss: 0.02118244767189026\n",
      "tensor([[855]]) tensor(841.8218, grad_fn=<SubBackward0>)\n",
      "loss: 0.015413143672049046\n",
      "tensor([[855]]) tensor(839.4479, grad_fn=<SubBackward0>)\n",
      "loss: 0.018189547583460808\n",
      "tensor([[855]]) tensor(839.7153, grad_fn=<SubBackward0>)\n",
      "loss: 0.017876841127872467\n",
      "tensor([[855]]) tensor(841.5260, grad_fn=<SubBackward0>)\n",
      "loss: 0.015759099274873734\n",
      "tensor([[855]]) tensor(844.6182, grad_fn=<SubBackward0>)\n",
      "loss: 0.012142498046159744\n",
      "tensor([[855]]) tensor(837.9507, grad_fn=<SubBackward0>)\n",
      "loss: 0.019940685480833054\n",
      "tensor([[855]]) tensor(844.2740, grad_fn=<SubBackward0>)\n",
      "loss: 0.012545009143650532\n",
      "tensor([[855]]) tensor(829.3257, grad_fn=<SubBackward0>)\n",
      "loss: 0.03002840466797352\n",
      "tensor([[855]]) tensor(827.8787, grad_fn=<SubBackward0>)\n",
      "loss: 0.03172079101204872\n",
      "tensor([[855]]) tensor(843.5620, grad_fn=<SubBackward0>)\n",
      "loss: 0.013377764262259007\n",
      "tensor([[855]]) tensor(821.5325, grad_fn=<SubBackward0>)\n",
      "loss: 0.039143238216638565\n",
      "tensor([[855]]) tensor(818.6842, grad_fn=<SubBackward0>)\n",
      "loss: 0.0424746498465538\n",
      "tensor([[855]]) tensor(842.6612, grad_fn=<SubBackward0>)\n",
      "loss: 0.01443135179579258\n",
      "tensor([[855]]) tensor(813.2462, grad_fn=<SubBackward0>)\n",
      "loss: 0.0488349050283432\n",
      "tensor([[855]]) tensor(797.0952, grad_fn=<SubBackward0>)\n",
      "loss: 0.06772496551275253\n",
      "tensor([[855]]) tensor(818.2889, grad_fn=<SubBackward0>)\n",
      "loss: 0.042936909943819046\n",
      "tensor([[855]]) tensor(841.7686, grad_fn=<SubBackward0>)\n",
      "loss: 0.01547539234161377\n",
      "tensor([[855]]) tensor(815.8741, grad_fn=<SubBackward0>)\n",
      "loss: 0.04576130583882332\n",
      "tensor([[855]]) tensor(820.3655, grad_fn=<SubBackward0>)\n",
      "loss: 0.040508247911930084\n",
      "tensor([[855]]) tensor(836.6804, grad_fn=<SubBackward0>)\n",
      "loss: 0.021426374092698097\n",
      "tensor([[855]]) tensor(824.4257, grad_fn=<SubBackward0>)\n",
      "loss: 0.03575949743390083\n",
      "tensor([[855]]) tensor(828.1179, grad_fn=<SubBackward0>)\n",
      "loss: 0.03144102916121483\n",
      "tensor([[855]]) tensor(829.7245, grad_fn=<SubBackward0>)\n",
      "loss: 0.02956203930079937\n",
      "tensor([[855]]) tensor(824.9139, grad_fn=<SubBackward0>)\n",
      "loss: 0.0351884625852108\n",
      "tensor([[855]]) tensor(828.2672, grad_fn=<SubBackward0>)\n",
      "loss: 0.031266383826732635\n",
      "tensor([[855]]) tensor(822.0430, grad_fn=<SubBackward0>)\n",
      "loss: 0.03854616358876228\n",
      "tensor([[855]]) tensor(819.7687, grad_fn=<SubBackward0>)\n",
      "loss: 0.041206154972314835\n",
      "tensor([[855]]) tensor(827.1088, grad_fn=<SubBackward0>)\n",
      "loss: 0.03262127563357353\n",
      "tensor([[855]]) tensor(838.9543, grad_fn=<SubBackward0>)\n",
      "loss: 0.018766935914754868\n",
      "tensor([[855]]) tensor(820.0150, grad_fn=<SubBackward0>)\n",
      "loss: 0.04091818258166313\n",
      "tensor([[855]]) tensor(819.6118, grad_fn=<SubBackward0>)\n",
      "loss: 0.041389741003513336\n",
      "tensor([[855]]) tensor(840.7347, grad_fn=<SubBackward0>)\n",
      "loss: 0.016684478148818016\n",
      "tensor([[855]]) tensor(821.0342, grad_fn=<SubBackward0>)\n",
      "loss: 0.03972607105970383\n",
      "tensor([[855]]) tensor(803.6913, grad_fn=<SubBackward0>)\n",
      "loss: 0.06001022830605507\n",
      "tensor([[855]]) tensor(811.1940, grad_fn=<SubBackward0>)\n",
      "loss: 0.051235049962997437\n",
      "tensor([[855]]) tensor(837.7734, grad_fn=<SubBackward0>)\n",
      "loss: 0.020147990435361862\n",
      "tensor([[855]]) tensor(819.8239, grad_fn=<SubBackward0>)\n",
      "loss: 0.04114164039492607\n",
      "tensor([[855]]) tensor(807.3018, grad_fn=<SubBackward0>)\n",
      "loss: 0.05578739941120148\n",
      "tensor([[855]]) tensor(819.8180, grad_fn=<SubBackward0>)\n",
      "loss: 0.04114854708313942\n",
      "tensor([[855]]) tensor(837.4200, grad_fn=<SubBackward0>)\n",
      "loss: 0.020561352372169495\n",
      "tensor([[855]]) tensor(829.0826, grad_fn=<SubBackward0>)\n",
      "loss: 0.03031270019710064\n",
      "tensor([[855]]) tensor(831.0715, grad_fn=<SubBackward0>)\n",
      "loss: 0.02798658236861229\n",
      "tensor([[855]]) tensor(837.9459, grad_fn=<SubBackward0>)\n",
      "loss: 0.019946325570344925\n",
      "tensor([[855]]) tensor(832.2778, grad_fn=<SubBackward0>)\n",
      "loss: 0.026575706899166107\n",
      "tensor([[855]]) tensor(833.6989, grad_fn=<SubBackward0>)\n",
      "loss: 0.024913586676120758\n",
      "tensor([[855]]) tensor(829.2338, grad_fn=<SubBackward0>)\n",
      "loss: 0.030135948210954666\n",
      "tensor([[855]]) tensor(832.8211, grad_fn=<SubBackward0>)\n",
      "loss: 0.02594020962715149\n",
      "tensor([[855]]) tensor(843.1401, grad_fn=<SubBackward0>)\n",
      "loss: 0.013871166855096817\n",
      "tensor([[855]]) tensor(828.0771, grad_fn=<SubBackward0>)\n",
      "loss: 0.031488679349422455\n",
      "tensor([[855]]) tensor(831.0276, grad_fn=<SubBackward0>)\n",
      "loss: 0.028037944808602333\n",
      "tensor([[855]]) tensor(838.4802, grad_fn=<SubBackward0>)\n",
      "loss: 0.019321339204907417\n",
      "tensor([[855]]) tensor(836.7062, grad_fn=<SubBackward0>)\n",
      "loss: 0.021396320313215256\n",
      "tensor([[855]]) tensor(841.2450, grad_fn=<SubBackward0>)\n",
      "loss: 0.01608772575855255\n",
      "tensor([[855]]) tensor(832.3716, grad_fn=<SubBackward0>)\n",
      "loss: 0.026465967297554016\n",
      "tensor([[855]]) tensor(845.6012, grad_fn=<SubBackward0>)\n",
      "loss: 0.010992716997861862\n",
      "tensor([[855]]) tensor(835.1032, grad_fn=<SubBackward0>)\n",
      "loss: 0.023271117359399796\n",
      "tensor([[855]]) tensor(834.4050, grad_fn=<SubBackward0>)\n",
      "loss: 0.024087756872177124\n",
      "tensor([[855]]) tensor(842.3948, grad_fn=<SubBackward0>)\n",
      "loss: 0.014742952771484852\n",
      "tensor([[855]]) tensor(846.5509, grad_fn=<SubBackward0>)\n",
      "loss: 0.00988196674734354\n",
      "tensor([[855]]) tensor(834.5706, grad_fn=<SubBackward0>)\n",
      "loss: 0.0238940492272377\n",
      "tensor([[855]]) tensor(833.8267, grad_fn=<SubBackward0>)\n",
      "loss: 0.02476406842470169\n",
      "tensor([[855]]) tensor(834.0289, grad_fn=<SubBackward0>)\n",
      "loss: 0.024527601897716522\n",
      "tensor([[855]]) tensor(845.3531, grad_fn=<SubBackward0>)\n",
      "loss: 0.011282865889370441\n",
      "tensor([[855]]) tensor(839.5939, grad_fn=<SubBackward0>)\n",
      "loss: 0.018018774688243866\n",
      "tensor([[855]]) tensor(839.3455, grad_fn=<SubBackward0>)\n",
      "loss: 0.018309369683265686\n",
      "tensor([[855]]) tensor(836.6954, grad_fn=<SubBackward0>)\n",
      "loss: 0.021408867090940475\n",
      "tensor([[855]]) tensor(828.5999, grad_fn=<SubBackward0>)\n",
      "loss: 0.030877364799380302\n",
      "tensor([[855]]) tensor(834.3794, grad_fn=<SubBackward0>)\n",
      "loss: 0.02411763183772564\n",
      "tensor([[855]]) tensor(845.2045, grad_fn=<SubBackward0>)\n",
      "loss: 0.011456727050244808\n",
      "tensor([[855]]) tensor(838.5787, grad_fn=<SubBackward0>)\n",
      "loss: 0.019206246361136436\n",
      "tensor([[855]]) tensor(839.2303, grad_fn=<SubBackward0>)\n",
      "loss: 0.01844407431781292\n",
      "tensor([[855]]) tensor(844.0757, grad_fn=<SubBackward0>)\n",
      "loss: 0.012776978313922882\n",
      "tensor([[855]]) tensor(833.6450, grad_fn=<SubBackward0>)\n",
      "loss: 0.024976549670100212\n",
      "tensor([[855]]) tensor(830.4169, grad_fn=<SubBackward0>)\n",
      "loss: 0.028752127662301064\n",
      "tensor([[855]]) tensor(833.6470, grad_fn=<SubBackward0>)\n",
      "loss: 0.02497430145740509\n",
      "tensor([[855]]) tensor(845.1327, grad_fn=<SubBackward0>)\n",
      "loss: 0.011540748178958893\n",
      "tensor([[855]]) tensor(823.2161, grad_fn=<SubBackward0>)\n",
      "loss: 0.03717412054538727\n",
      "tensor([[855]]) tensor(813.7012, grad_fn=<SubBackward0>)\n",
      "loss: 0.04830272123217583\n",
      "tensor([[855]]) tensor(833.6259, grad_fn=<SubBackward0>)\n",
      "loss: 0.02499891072511673\n",
      "tensor([[855]]) tensor(827.5538, grad_fn=<SubBackward0>)\n",
      "loss: 0.0321008525788784\n",
      "tensor([[855]]) tensor(817.9937, grad_fn=<SubBackward0>)\n",
      "loss: 0.04328227788209915\n",
      "tensor([[855]]) tensor(834.3658, grad_fn=<SubBackward0>)\n",
      "loss: 0.024133479222655296\n",
      "tensor([[855]]) tensor(828.4625, grad_fn=<SubBackward0>)\n",
      "loss: 0.031038036569952965\n",
      "tensor([[855]]) tensor(821.6577, grad_fn=<SubBackward0>)\n",
      "loss: 0.03899680823087692\n",
      "tensor([[855]]) tensor(829.5051, grad_fn=<SubBackward0>)\n",
      "loss: 0.029818635433912277\n",
      "tensor([[855]]) tensor(836.2222, grad_fn=<SubBackward0>)\n",
      "loss: 0.021962376311421394\n",
      "tensor([[855]]) tensor(833.1580, grad_fn=<SubBackward0>)\n",
      "loss: 0.025546282529830933\n",
      "tensor([[855]]) tensor(842.3604, grad_fn=<SubBackward0>)\n",
      "loss: 0.014783178456127644\n",
      "tensor([[855]]) tensor(825.4675, grad_fn=<SubBackward0>)\n",
      "loss: 0.03454086557030678\n",
      "tensor([[855]]) tensor(831.4644, grad_fn=<SubBackward0>)\n",
      "loss: 0.027527034282684326\n",
      "tensor([[855]]) tensor(841.9061, grad_fn=<SubBackward0>)\n",
      "loss: 0.015314506366848946\n",
      "tensor([[855]]) tensor(829.9009, grad_fn=<SubBackward0>)\n",
      "loss: 0.029355715960264206\n",
      "tensor([[855]]) tensor(843.8854, grad_fn=<SubBackward0>)\n",
      "loss: 0.012999488972127438\n",
      "tensor([[855]]) tensor(827.5776, grad_fn=<SubBackward0>)\n",
      "loss: 0.03207302838563919\n",
      "tensor([[855]]) tensor(821.1952, grad_fn=<SubBackward0>)\n",
      "loss: 0.03953775390982628\n",
      "tensor([[855]]) tensor(833.3828, grad_fn=<SubBackward0>)\n",
      "loss: 0.02528334967792034\n",
      "tensor([[855]]) tensor(833.5846, grad_fn=<SubBackward0>)\n",
      "loss: 0.02504725754261017\n",
      "tensor([[855]]) tensor(829.7830, grad_fn=<SubBackward0>)\n",
      "loss: 0.029493579640984535\n",
      "tensor([[855]]) tensor(836.1992, grad_fn=<SubBackward0>)\n",
      "loss: 0.021989254280924797\n",
      "tensor([[855]]) tensor(832.7073, grad_fn=<SubBackward0>)\n",
      "loss: 0.026073327288031578\n",
      "tensor([[855]]) tensor(838.4290, grad_fn=<SubBackward0>)\n",
      "loss: 0.01938130334019661\n",
      "tensor([[855]]) tensor(841.1542, grad_fn=<SubBackward0>)\n",
      "loss: 0.01619398407638073\n",
      "tensor([[855]]) tensor(842.6393, grad_fn=<SubBackward0>)\n",
      "loss: 0.014456979930400848\n",
      "tensor([[855]]) tensor(840.9196, grad_fn=<SubBackward0>)\n",
      "loss: 0.016468320041894913\n",
      "tensor([[855]]) tensor(841.6853, grad_fn=<SubBackward0>)\n",
      "loss: 0.01557270996272564\n",
      "tensor([[855]]) tensor(844.0405, grad_fn=<SubBackward0>)\n",
      "loss: 0.012818185612559319\n",
      "tensor([[855]]) tensor(836.4277, grad_fn=<SubBackward0>)\n",
      "loss: 0.02172194793820381\n",
      "tensor([[855]]) tensor(836.3295, grad_fn=<SubBackward0>)\n",
      "loss: 0.021836843341588974\n",
      "tensor([[855]]) tensor(829.8354, grad_fn=<SubBackward0>)\n",
      "loss: 0.029432186856865883\n",
      "tensor([[855]]) tensor(831.4312, grad_fn=<SubBackward0>)\n",
      "loss: 0.02756584994494915\n",
      "tensor([[855]]) tensor(841.0562, grad_fn=<SubBackward0>)\n",
      "loss: 0.016308629885315895\n",
      "tensor([[855]]) tensor(838.9235, grad_fn=<SubBackward0>)\n",
      "loss: 0.01880296878516674\n",
      "tensor([[855]]) tensor(841.1193, grad_fn=<SubBackward0>)\n",
      "loss: 0.016234708949923515\n",
      "tensor([[855]]) tensor(840.4930, grad_fn=<SubBackward0>)\n",
      "loss: 0.016967201605439186\n",
      "tensor([[855]]) tensor(839.5443, grad_fn=<SubBackward0>)\n",
      "loss: 0.018076900392770767\n",
      "tensor([[855]]) tensor(840.9282, grad_fn=<SubBackward0>)\n",
      "loss: 0.01645827293395996\n",
      "tensor([[855]]) tensor(836.2839, grad_fn=<SubBackward0>)\n",
      "loss: 0.021890223026275635\n",
      "tensor([[855]]) tensor(846.2928, grad_fn=<SubBackward0>)\n",
      "loss: 0.010183840990066528\n",
      "tensor([[855]]) tensor(822.3864, grad_fn=<SubBackward0>)\n",
      "loss: 0.03814465180039406\n",
      "tensor([[855]]) tensor(814.5276, grad_fn=<SubBackward0>)\n",
      "loss: 0.0473361536860466\n",
      "tensor([[855]]) tensor(835.3891, grad_fn=<SubBackward0>)\n",
      "loss: 0.022936725988984108\n",
      "tensor([[855]]) tensor(827.7173, grad_fn=<SubBackward0>)\n",
      "loss: 0.03190960735082626\n",
      "tensor([[855]]) tensor(820.1741, grad_fn=<SubBackward0>)\n",
      "loss: 0.04073207825422287\n",
      "tensor([[855]]) tensor(840.9154, grad_fn=<SubBackward0>)\n",
      "loss: 0.016473209485411644\n",
      "tensor([[855]]) tensor(820.1576, grad_fn=<SubBackward0>)\n",
      "loss: 0.040751390159130096\n",
      "tensor([[855]]) tensor(806.0917, grad_fn=<SubBackward0>)\n",
      "loss: 0.057202719151973724\n",
      "tensor([[855]]) tensor(822.8632, grad_fn=<SubBackward0>)\n",
      "loss: 0.03758698329329491\n",
      "tensor([[855]]) tensor(837.9723, grad_fn=<SubBackward0>)\n",
      "loss: 0.019915450364351273\n",
      "tensor([[855]]) tensor(817.1970, grad_fn=<SubBackward0>)\n",
      "loss: 0.044213972985744476\n",
      "tensor([[855]]) tensor(817.1140, grad_fn=<SubBackward0>)\n",
      "loss: 0.04431118443608284\n",
      "tensor([[855]]) tensor(838.8029, grad_fn=<SubBackward0>)\n",
      "loss: 0.01894395612180233\n",
      "tensor([[855]]) tensor(822.7854, grad_fn=<SubBackward0>)\n",
      "loss: 0.03767785802483559\n",
      "tensor([[855]]) tensor(813.5047, grad_fn=<SubBackward0>)\n",
      "loss: 0.04853251576423645\n",
      "tensor([[855]]) tensor(827.1396, grad_fn=<SubBackward0>)\n",
      "loss: 0.032585278153419495\n",
      "tensor([[855]]) tensor(840.4078, grad_fn=<SubBackward0>)\n",
      "loss: 0.01706685684621334\n",
      "tensor([[855]]) tensor(825.8253, grad_fn=<SubBackward0>)\n",
      "loss: 0.03412243723869324\n",
      "tensor([[855]]) tensor(834.3955, grad_fn=<SubBackward0>)\n",
      "loss: 0.02409878559410572\n",
      "tensor([[855]]) tensor(830.2190, grad_fn=<SubBackward0>)\n",
      "loss: 0.02898363210260868\n",
      "tensor([[855]]) tensor(836.5468, grad_fn=<SubBackward0>)\n",
      "loss: 0.021582690998911858\n",
      "tensor([[855]]) tensor(837.6382, grad_fn=<SubBackward0>)\n",
      "loss: 0.020306218415498734\n",
      "tensor([[855]]) tensor(833.0613, grad_fn=<SubBackward0>)\n",
      "loss: 0.02565932273864746\n",
      "tensor([[855]]) tensor(825.7318, grad_fn=<SubBackward0>)\n",
      "loss: 0.03423188999295235\n",
      "tensor([[855]]) tensor(832.1351, grad_fn=<SubBackward0>)\n",
      "loss: 0.026742571964859962\n",
      "tensor([[855]]) tensor(839.2996, grad_fn=<SubBackward0>)\n",
      "loss: 0.018363086506724358\n",
      "tensor([[855]]) tensor(838.2861, grad_fn=<SubBackward0>)\n",
      "loss: 0.019548382610082626\n",
      "tensor([[855]]) tensor(832.8867, grad_fn=<SubBackward0>)\n",
      "loss: 0.0258635226637125\n",
      "tensor([[855]]) tensor(831.5835, grad_fn=<SubBackward0>)\n",
      "loss: 0.027387723326683044\n",
      "tensor([[855]]) tensor(844.5805, grad_fn=<SubBackward0>)\n",
      "loss: 0.012186543084681034\n",
      "tensor([[855]]) tensor(829.4189, grad_fn=<SubBackward0>)\n",
      "loss: 0.029919397085905075\n",
      "tensor([[855]]) tensor(833.7877, grad_fn=<SubBackward0>)\n",
      "loss: 0.024809719994664192\n",
      "tensor([[855]]) tensor(836.5966, grad_fn=<SubBackward0>)\n",
      "loss: 0.02152452990412712\n",
      "tensor([[855]]) tensor(826.4660, grad_fn=<SubBackward0>)\n",
      "loss: 0.033373113721609116\n",
      "tensor([[855]]) tensor(835.1670, grad_fn=<SubBackward0>)\n",
      "loss: 0.023196464404463768\n",
      "tensor([[855]]) tensor(838.8011, grad_fn=<SubBackward0>)\n",
      "loss: 0.018946098163723946\n",
      "tensor([[855]]) tensor(827.4702, grad_fn=<SubBackward0>)\n",
      "loss: 0.032198578119277954\n",
      "tensor([[855]]) tensor(842.7723, grad_fn=<SubBackward0>)\n",
      "loss: 0.014301411807537079\n",
      "tensor([[855]]) tensor(834.0854, grad_fn=<SubBackward0>)\n",
      "loss: 0.0244615338742733\n",
      "tensor([[855]]) tensor(832.8786, grad_fn=<SubBackward0>)\n",
      "loss: 0.02587299980223179\n",
      "tensor([[855]]) tensor(844.7461, grad_fn=<SubBackward0>)\n",
      "loss: 0.011992872692644596\n",
      "tensor([[855]]) tensor(846.0406, grad_fn=<SubBackward0>)\n",
      "loss: 0.010478808544576168\n",
      "tensor([[855]]) tensor(844.7915, grad_fn=<SubBackward0>)\n",
      "loss: 0.011939797550439835\n",
      "tensor([[855]]) tensor(846.6617, grad_fn=<SubBackward0>)\n",
      "loss: 0.009752311743795872\n",
      "tensor([[855]]) tensor(847.6263, grad_fn=<SubBackward0>)\n",
      "loss: 0.008624124340713024\n",
      "tensor([[855]]) tensor(841.1864, grad_fn=<SubBackward0>)\n",
      "loss: 0.016156256198883057\n",
      "tensor([[855]]) tensor(847.2920, grad_fn=<SubBackward0>)\n",
      "loss: 0.009015178307890892\n",
      "tensor([[855]]) tensor(845.4320, grad_fn=<SubBackward0>)\n",
      "loss: 0.011190599761903286\n",
      "tensor([[855]]) tensor(839.1408, grad_fn=<SubBackward0>)\n",
      "loss: 0.01854878105223179\n",
      "tensor([[855]]) tensor(846.8088, grad_fn=<SubBackward0>)\n",
      "loss: 0.009580306708812714\n",
      "tensor([[855]]) tensor(846.2977, grad_fn=<SubBackward0>)\n",
      "loss: 0.010178076103329659\n",
      "tensor([[855]]) tensor(846.4039, grad_fn=<SubBackward0>)\n",
      "loss: 0.01005395408719778\n",
      "tensor([[855]]) tensor(844.9966, grad_fn=<SubBackward0>)\n",
      "loss: 0.011699868366122246\n",
      "tensor([[855]]) tensor(843.6117, grad_fn=<SubBackward0>)\n",
      "loss: 0.013319691643118858\n",
      "tensor([[855]]) tensor(843.7620, grad_fn=<SubBackward0>)\n",
      "loss: 0.01314388494938612\n",
      "tensor([[855]]) tensor(841.0691, grad_fn=<SubBackward0>)\n",
      "loss: 0.0162934772670269\n",
      "tensor([[855]]) tensor(835.2928, grad_fn=<SubBackward0>)\n",
      "loss: 0.02304939180612564\n",
      "tensor([[855]]) tensor(842.0365, grad_fn=<SubBackward0>)\n",
      "loss: 0.015161971561610699\n",
      "tensor([[855]]) tensor(831.9902, grad_fn=<SubBackward0>)\n",
      "loss: 0.026912007480859756\n",
      "tensor([[855]]) tensor(834.7750, grad_fn=<SubBackward0>)\n",
      "loss: 0.023654941469430923\n",
      "tensor([[855]]) tensor(839.9775, grad_fn=<SubBackward0>)\n",
      "loss: 0.0175701305270195\n",
      "tensor([[855]]) tensor(833.9741, grad_fn=<SubBackward0>)\n",
      "loss: 0.02459167130291462\n",
      "tensor([[855]]) tensor(838.5272, grad_fn=<SubBackward0>)\n",
      "loss: 0.019266443327069283\n",
      "tensor([[855]]) tensor(827.9063, grad_fn=<SubBackward0>)\n",
      "loss: 0.03168852627277374\n",
      "tensor([[855]]) tensor(832.7842, grad_fn=<SubBackward0>)\n",
      "loss: 0.02598341554403305\n",
      "tensor([[855]]) tensor(841.0983, grad_fn=<SubBackward0>)\n",
      "loss: 0.016259372234344482\n",
      "tensor([[855]]) tensor(832.2928, grad_fn=<SubBackward0>)\n",
      "loss: 0.026558073237538338\n",
      "tensor([[855]]) tensor(844.5707, grad_fn=<SubBackward0>)\n",
      "loss: 0.012198001146316528\n",
      "tensor([[855]]) tensor(833.7459, grad_fn=<SubBackward0>)\n",
      "loss: 0.024858566001057625\n",
      "tensor([[855]]) tensor(838.0347, grad_fn=<SubBackward0>)\n",
      "loss: 0.019842511042952538\n",
      "tensor([[855]]) tensor(839.8054, grad_fn=<SubBackward0>)\n",
      "loss: 0.01777140237390995\n",
      "tensor([[855]]) tensor(841.5083, grad_fn=<SubBackward0>)\n",
      "loss: 0.015779729932546616\n",
      "tensor([[855]]) tensor(838.9474, grad_fn=<SubBackward0>)\n",
      "loss: 0.018774913623929024\n",
      "tensor([[855]]) tensor(829.3964, grad_fn=<SubBackward0>)\n",
      "loss: 0.0299457386136055\n",
      "tensor([[855]]) tensor(842.5539, grad_fn=<SubBackward0>)\n",
      "loss: 0.014556849375367165\n",
      "tensor([[855]]) tensor(829.8979, grad_fn=<SubBackward0>)\n",
      "loss: 0.02935919538140297\n",
      "tensor([[855]]) tensor(828.5486, grad_fn=<SubBackward0>)\n",
      "loss: 0.030937258154153824\n",
      "tensor([[855]]) tensor(843.6799, grad_fn=<SubBackward0>)\n",
      "loss: 0.013239845633506775\n",
      "tensor([[855]]) tensor(828.3165, grad_fn=<SubBackward0>)\n",
      "loss: 0.031208738684654236\n",
      "tensor([[855]]) tensor(830.1498, grad_fn=<SubBackward0>)\n",
      "loss: 0.029064495116472244\n",
      "tensor([[855]]) tensor(841.8027, grad_fn=<SubBackward0>)\n",
      "loss: 0.015435398556292057\n",
      "tensor([[855]]) tensor(834.2362, grad_fn=<SubBackward0>)\n",
      "loss: 0.024285104125738144\n",
      "tensor([[855]]) tensor(840.4757, grad_fn=<SubBackward0>)\n",
      "loss: 0.01698744110763073\n",
      "tensor([[855]]) tensor(841.7297, grad_fn=<SubBackward0>)\n",
      "loss: 0.015520812012255192\n",
      "tensor([[855]]) tensor(845.1686, grad_fn=<SubBackward0>)\n",
      "loss: 0.011498701758682728\n",
      "tensor([[855]]) tensor(838.7563, grad_fn=<SubBackward0>)\n",
      "loss: 0.018998494371771812\n",
      "tensor([[855]]) tensor(847.7722, grad_fn=<SubBackward0>)\n",
      "loss: 0.008453618735074997\n",
      "tensor([[855]]) tensor(832.2332, grad_fn=<SubBackward0>)\n",
      "loss: 0.0266278013586998\n",
      "tensor([[855]]) tensor(837.1277, grad_fn=<SubBackward0>)\n",
      "loss: 0.02090325579047203\n",
      "tensor([[855]]) tensor(835.8098, grad_fn=<SubBackward0>)\n",
      "loss: 0.02244466170668602\n",
      "tensor([[855]]) tensor(835.8560, grad_fn=<SubBackward0>)\n",
      "loss: 0.022390658035874367\n",
      "tensor([[855]]) tensor(841.7849, grad_fn=<SubBackward0>)\n",
      "loss: 0.01545620709657669\n",
      "tensor([[855]]) tensor(841.5700, grad_fn=<SubBackward0>)\n",
      "loss: 0.0157075934112072\n",
      "tensor([[855]]) tensor(834.8055, grad_fn=<SubBackward0>)\n",
      "loss: 0.023619230836629868\n",
      "tensor([[855]]) tensor(839.8403, grad_fn=<SubBackward0>)\n",
      "loss: 0.01773056946694851\n",
      "tensor([[855]]) tensor(842.6628, grad_fn=<SubBackward0>)\n",
      "loss: 0.0144294248893857\n",
      "tensor([[855]]) tensor(841.6005, grad_fn=<SubBackward0>)\n",
      "loss: 0.015671972185373306\n",
      "tensor([[855]]) tensor(844.8849, grad_fn=<SubBackward0>)\n",
      "loss: 0.011830540373921394\n",
      "tensor([[855]]) tensor(840.5228, grad_fn=<SubBackward0>)\n",
      "loss: 0.016932401806116104\n",
      "tensor([[855]]) tensor(839.5019, grad_fn=<SubBackward0>)\n",
      "loss: 0.01812642440199852\n",
      "tensor([[855]]) tensor(828.5247, grad_fn=<SubBackward0>)\n",
      "loss: 0.03096524067223072\n",
      "tensor([[855]]) tensor(841.2242, grad_fn=<SubBackward0>)\n",
      "loss: 0.0161120668053627\n",
      "tensor([[855]]) tensor(830.3677, grad_fn=<SubBackward0>)\n",
      "loss: 0.028809664770960808\n",
      "tensor([[855]]) tensor(826.2040, grad_fn=<SubBackward0>)\n",
      "loss: 0.03367946669459343\n",
      "tensor([[855]]) tensor(843.6208, grad_fn=<SubBackward0>)\n",
      "loss: 0.013308930210769176\n",
      "tensor([[855]]) tensor(820.7304, grad_fn=<SubBackward0>)\n",
      "loss: 0.04008137807250023\n",
      "tensor([[855]]) tensor(817.1574, grad_fn=<SubBackward0>)\n",
      "loss: 0.044260356575250626\n",
      "tensor([[855]]) tensor(837.0288, grad_fn=<SubBackward0>)\n",
      "loss: 0.021018972620368004\n",
      "tensor([[855]]) tensor(828.9687, grad_fn=<SubBackward0>)\n",
      "loss: 0.030445994809269905\n",
      "tensor([[855]]) tensor(824.8734, grad_fn=<SubBackward0>)\n",
      "loss: 0.03523584455251694\n",
      "tensor([[855]]) tensor(835.2197, grad_fn=<SubBackward0>)\n",
      "loss: 0.023134911432862282\n",
      "tensor([[855]]) tensor(836.4196, grad_fn=<SubBackward0>)\n",
      "loss: 0.021731477230787277\n",
      "tensor([[855]]) tensor(838.2678, grad_fn=<SubBackward0>)\n",
      "loss: 0.01956983469426632\n",
      "tensor([[855]]) tensor(841.7867, grad_fn=<SubBackward0>)\n",
      "loss: 0.015454101376235485\n",
      "tensor([[855]]) tensor(834.7143, grad_fn=<SubBackward0>)\n",
      "loss: 0.023725952953100204\n",
      "tensor([[855]]) tensor(841.1118, grad_fn=<SubBackward0>)\n",
      "loss: 0.016243454068899155\n",
      "tensor([[855]]) tensor(841.5143, grad_fn=<SubBackward0>)\n",
      "loss: 0.015772679820656776\n",
      "tensor([[855]]) tensor(841.3181, grad_fn=<SubBackward0>)\n",
      "loss: 0.016002275049686432\n",
      "tensor([[855]]) tensor(842.9918, grad_fn=<SubBackward0>)\n",
      "loss: 0.014044618234038353\n",
      "tensor([[855]]) tensor(845.1783, grad_fn=<SubBackward0>)\n",
      "loss: 0.011487280018627644\n",
      "tensor([[855]]) tensor(840.0585, grad_fn=<SubBackward0>)\n",
      "loss: 0.017475470900535583\n",
      "tensor([[855]]) tensor(848.5184, grad_fn=<SubBackward0>)\n",
      "loss: 0.007580798584967852\n",
      "tensor([[855]]) tensor(841.3895, grad_fn=<SubBackward0>)\n",
      "loss: 0.01591871865093708\n",
      "tensor([[855]]) tensor(840.2317, grad_fn=<SubBackward0>)\n",
      "loss: 0.01727287843823433\n",
      "tensor([[855]]) tensor(847.1038, grad_fn=<SubBackward0>)\n",
      "loss: 0.009235279634594917\n",
      "tensor([[855]]) tensor(846.5173, grad_fn=<SubBackward0>)\n",
      "loss: 0.009921210817992687\n",
      "tensor([[855]]) tensor(839.6777, grad_fn=<SubBackward0>)\n",
      "loss: 0.01792081445455551\n",
      "tensor([[855]]) tensor(840.7630, grad_fn=<SubBackward0>)\n",
      "loss: 0.016651460900902748\n",
      "tensor([[855]]) tensor(839.1152, grad_fn=<SubBackward0>)\n",
      "loss: 0.018578672781586647\n",
      "tensor([[855]]) tensor(840.6140, grad_fn=<SubBackward0>)\n",
      "loss: 0.016825750470161438\n",
      "tensor([[855]]) tensor(844.4210, grad_fn=<SubBackward0>)\n",
      "loss: 0.012373093515634537\n",
      "tensor([[855]]) tensor(843.0759, grad_fn=<SubBackward0>)\n",
      "loss: 0.013946318998932838\n",
      "tensor([[855]]) tensor(843.9552, grad_fn=<SubBackward0>)\n",
      "loss: 0.012917930260300636\n",
      "tensor([[855]]) tensor(845.0970, grad_fn=<SubBackward0>)\n",
      "loss: 0.01158247422426939\n",
      "tensor([[855]]) tensor(836.1088, grad_fn=<SubBackward0>)\n",
      "loss: 0.022095046937465668\n",
      "tensor([[855]]) tensor(844.4395, grad_fn=<SubBackward0>)\n",
      "loss: 0.012351445853710175\n",
      "tensor([[855]]) tensor(829.2776, grad_fn=<SubBackward0>)\n",
      "loss: 0.030084656551480293\n",
      "tensor([[855]]) tensor(831.5334, grad_fn=<SubBackward0>)\n",
      "loss: 0.027446260675787926\n",
      "tensor([[855]]) tensor(835.4339, grad_fn=<SubBackward0>)\n",
      "loss: 0.022884346544742584\n",
      "tensor([[855]]) tensor(834.5882, grad_fn=<SubBackward0>)\n",
      "loss: 0.02387343719601631\n",
      "tensor([[855]]) tensor(839.1133, grad_fn=<SubBackward0>)\n",
      "loss: 0.01858092099428177\n",
      "tensor([[855]]) tensor(827.8765, grad_fn=<SubBackward0>)\n",
      "loss: 0.03172345086932182\n",
      "tensor([[855]]) tensor(833.1945, grad_fn=<SubBackward0>)\n",
      "loss: 0.025503557175397873\n",
      "tensor([[855]]) tensor(835.6443, grad_fn=<SubBackward0>)\n",
      "loss: 0.02263822592794895\n",
      "tensor([[855]]) tensor(828.1932, grad_fn=<SubBackward0>)\n",
      "loss: 0.031352922320365906\n",
      "tensor([[855]]) tensor(833.6425, grad_fn=<SubBackward0>)\n",
      "loss: 0.024979548528790474\n",
      "tensor([[855]]) tensor(839.8416, grad_fn=<SubBackward0>)\n",
      "loss: 0.01772908866405487\n",
      "tensor([[855]]) tensor(826.4050, grad_fn=<SubBackward0>)\n",
      "loss: 0.03344448283314705\n",
      "tensor([[855]]) tensor(839.0499, grad_fn=<SubBackward0>)\n",
      "loss: 0.018655039370059967\n",
      "tensor([[855]]) tensor(829.4865, grad_fn=<SubBackward0>)\n",
      "loss: 0.02984035573899746\n",
      "tensor([[855]]) tensor(815.4071, grad_fn=<SubBackward0>)\n",
      "loss: 0.04630744457244873\n",
      "tensor([[855]]) tensor(832.9651, grad_fn=<SubBackward0>)\n",
      "loss: 0.025771791115403175\n",
      "tensor([[855]]) tensor(835.9538, grad_fn=<SubBackward0>)\n",
      "loss: 0.022276243194937706\n",
      "tensor([[855]]) tensor(828.8677, grad_fn=<SubBackward0>)\n",
      "loss: 0.03056415729224682\n",
      "tensor([[855]]) tensor(840.4402, grad_fn=<SubBackward0>)\n",
      "loss: 0.017029058188199997\n",
      "tensor([[855]]) tensor(840.1349, grad_fn=<SubBackward0>)\n",
      "loss: 0.017386114224791527\n",
      "tensor([[855]]) tensor(842.1935, grad_fn=<SubBackward0>)\n",
      "loss: 0.014978384599089622\n",
      "tensor([[855]]) tensor(831.9435, grad_fn=<SubBackward0>)\n",
      "loss: 0.02696661651134491\n",
      "tensor([[855]]) tensor(839.2876, grad_fn=<SubBackward0>)\n",
      "loss: 0.01837707869708538\n",
      "tensor([[855]]) tensor(837.0609, grad_fn=<SubBackward0>)\n",
      "loss: 0.020981458947062492\n",
      "tensor([[855]]) tensor(833.5411, grad_fn=<SubBackward0>)\n",
      "loss: 0.02509813755750656\n",
      "tensor([[855]]) tensor(846.6727, grad_fn=<SubBackward0>)\n",
      "loss: 0.009739569388329983\n",
      "tensor([[855]]) tensor(830.2876, grad_fn=<SubBackward0>)\n",
      "loss: 0.028903430327773094\n",
      "tensor([[855]]) tensor(832.0310, grad_fn=<SubBackward0>)\n",
      "loss: 0.026864320039749146\n",
      "tensor([[855]]) tensor(839.9172, grad_fn=<SubBackward0>)\n",
      "loss: 0.01764065958559513\n",
      "tensor([[855]]) tensor(830.4993, grad_fn=<SubBackward0>)\n",
      "loss: 0.028655756264925003\n",
      "tensor([[855]]) tensor(828.8286, grad_fn=<SubBackward0>)\n",
      "loss: 0.030609773471951485\n",
      "tensor([[855]]) tensor(836.7861, grad_fn=<SubBackward0>)\n",
      "loss: 0.02130276896059513\n",
      "tensor([[855]]) tensor(832.2208, grad_fn=<SubBackward0>)\n",
      "loss: 0.026642274111509323\n",
      "tensor([[855]]) tensor(840.7902, grad_fn=<SubBackward0>)\n",
      "loss: 0.016619712114334106\n",
      "tensor([[855]]) tensor(832.9618, grad_fn=<SubBackward0>)\n",
      "loss: 0.02577568218111992\n",
      "tensor([[855]]) tensor(834.7549, grad_fn=<SubBackward0>)\n",
      "loss: 0.02367851696908474\n",
      "tensor([[855]]) tensor(843.6417, grad_fn=<SubBackward0>)\n",
      "loss: 0.013284534215927124\n",
      "tensor([[855]]) tensor(833.0077, grad_fn=<SubBackward0>)\n",
      "loss: 0.025721963495016098\n",
      "tensor([[855]]) tensor(842.2671, grad_fn=<SubBackward0>)\n",
      "loss: 0.014892328530550003\n",
      "tensor([[855]]) tensor(829.3805, grad_fn=<SubBackward0>)\n",
      "loss: 0.02996433526277542\n",
      "tensor([[855]]) tensor(828.5328, grad_fn=<SubBackward0>)\n",
      "loss: 0.03095574676990509\n",
      "tensor([[855]]) tensor(844.5721, grad_fn=<SubBackward0>)\n",
      "loss: 0.012196359224617481\n",
      "tensor([[855]]) tensor(821.3917, grad_fn=<SubBackward0>)\n",
      "loss: 0.03930792585015297\n",
      "tensor([[855]]) tensor(821.0079, grad_fn=<SubBackward0>)\n",
      "loss: 0.03975680097937584\n",
      "tensor([[855]]) tensor(843.2101, grad_fn=<SubBackward0>)\n",
      "loss: 0.013789287768304348\n",
      "tensor([[855]]) tensor(810.8982, grad_fn=<SubBackward0>)\n",
      "loss: 0.05158105865120888\n",
      "tensor([[855]]) tensor(797.2244, grad_fn=<SubBackward0>)\n",
      "loss: 0.06757380813360214\n",
      "tensor([[855]]) tensor(816.8680, grad_fn=<SubBackward0>)\n",
      "loss: 0.0445987805724144\n",
      "tensor([[855]]) tensor(843.4380, grad_fn=<SubBackward0>)\n",
      "loss: 0.013522856868803501\n",
      "tensor([[855]]) tensor(820.4352, grad_fn=<SubBackward0>)\n",
      "loss: 0.04042663425207138\n",
      "tensor([[855]]) tensor(825.0793, grad_fn=<SubBackward0>)\n",
      "loss: 0.03499490022659302\n",
      "tensor([[855]]) tensor(842.1963, grad_fn=<SubBackward0>)\n",
      "loss: 0.014975064434111118\n",
      "tensor([[855]]) tensor(829.7706, grad_fn=<SubBackward0>)\n",
      "loss: 0.029508089646697044\n",
      "tensor([[855]]) tensor(834.5984, grad_fn=<SubBackward0>)\n",
      "loss: 0.023861443623900414\n",
      "tensor([[855]]) tensor(834.3672, grad_fn=<SubBackward0>)\n",
      "loss: 0.024131925776600838\n",
      "tensor([[855]]) tensor(833.7098, grad_fn=<SubBackward0>)\n",
      "loss: 0.02490084432065487\n",
      "tensor([[855]]) tensor(839.2417, grad_fn=<SubBackward0>)\n",
      "loss: 0.0184307973831892\n",
      "tensor([[855]]) tensor(833.5702, grad_fn=<SubBackward0>)\n",
      "loss: 0.025064105167984962\n",
      "tensor([[855]]) tensor(842.6370, grad_fn=<SubBackward0>)\n",
      "loss: 0.014459710568189621\n",
      "tensor([[855]]) tensor(837.3715, grad_fn=<SubBackward0>)\n",
      "loss: 0.020618140697479248\n",
      "tensor([[855]]) tensor(836.4127, grad_fn=<SubBackward0>)\n",
      "loss: 0.021739579737186432\n",
      "tensor([[855]]) tensor(842.2859, grad_fn=<SubBackward0>)\n",
      "loss: 0.014870340935885906\n",
      "tensor([[855]]) tensor(841.7968, grad_fn=<SubBackward0>)\n",
      "loss: 0.015442394651472569\n",
      "tensor([[855]]) tensor(842.0434, grad_fn=<SubBackward0>)\n",
      "loss: 0.015153905376791954\n",
      "tensor([[855]]) tensor(835.5762, grad_fn=<SubBackward0>)\n",
      "loss: 0.022717874497175217\n",
      "tensor([[855]]) tensor(842.9345, grad_fn=<SubBackward0>)\n",
      "loss: 0.014111684635281563\n",
      "tensor([[855]]) tensor(837.3698, grad_fn=<SubBackward0>)\n",
      "loss: 0.020620139315724373\n",
      "tensor([[855]]) tensor(842.6516, grad_fn=<SubBackward0>)\n",
      "loss: 0.014442523941397667\n",
      "tensor([[855]]) tensor(836.0462, grad_fn=<SubBackward0>)\n",
      "loss: 0.02216816507279873\n",
      "tensor([[855]]) tensor(837.4967, grad_fn=<SubBackward0>)\n",
      "loss: 0.02047165483236313\n",
      "tensor([[855]]) tensor(840.6042, grad_fn=<SubBackward0>)\n",
      "loss: 0.016837118193507195\n",
      "tensor([[855]]) tensor(827.3027, grad_fn=<SubBackward0>)\n",
      "loss: 0.03239449858665466\n",
      "tensor([[855]]) tensor(831.2726, grad_fn=<SubBackward0>)\n",
      "loss: 0.02775132842361927\n",
      "tensor([[855]]) tensor(839.4768, grad_fn=<SubBackward0>)\n",
      "loss: 0.018155746161937714\n",
      "tensor([[855]]) tensor(832.6035, grad_fn=<SubBackward0>)\n",
      "loss: 0.026194682344794273\n",
      "tensor([[855]]) tensor(836.5854, grad_fn=<SubBackward0>)\n",
      "loss: 0.02153748646378517\n",
      "tensor([[855]]) tensor(837.6251, grad_fn=<SubBackward0>)\n",
      "loss: 0.02032145857810974\n",
      "tensor([[855]]) tensor(839.8585, grad_fn=<SubBackward0>)\n",
      "loss: 0.017709404230117798\n",
      "tensor([[855]]) tensor(840.7040, grad_fn=<SubBackward0>)\n",
      "loss: 0.016720419749617577\n",
      "tensor([[855]]) tensor(840.8857, grad_fn=<SubBackward0>)\n",
      "loss: 0.016507867723703384\n",
      "tensor([[855]]) tensor(840.5137, grad_fn=<SubBackward0>)\n",
      "loss: 0.016943037509918213\n",
      "tensor([[855]]) tensor(846.4052, grad_fn=<SubBackward0>)\n",
      "loss: 0.01005245465785265\n",
      "tensor([[855]]) tensor(840.7484, grad_fn=<SubBackward0>)\n",
      "loss: 0.016668593510985374\n",
      "tensor([[855]]) tensor(841.0823, grad_fn=<SubBackward0>)\n",
      "loss: 0.016277987509965897\n",
      "tensor([[855]]) tensor(837.3267, grad_fn=<SubBackward0>)\n",
      "loss: 0.020670607686042786\n",
      "tensor([[855]]) tensor(841.2255, grad_fn=<SubBackward0>)\n",
      "loss: 0.016110531985759735\n",
      "tensor([[855]]) tensor(835.7667, grad_fn=<SubBackward0>)\n",
      "loss: 0.02249504253268242\n",
      "tensor([[855]]) tensor(840.7650, grad_fn=<SubBackward0>)\n",
      "loss: 0.01664917729794979\n",
      "tensor([[855]]) tensor(842.2501, grad_fn=<SubBackward0>)\n",
      "loss: 0.014912191778421402\n",
      "tensor([[855]]) tensor(835.9468, grad_fn=<SubBackward0>)\n",
      "loss: 0.02228439971804619\n",
      "tensor([[855]]) tensor(844.5022, grad_fn=<SubBackward0>)\n",
      "loss: 0.012278132140636444\n",
      "tensor([[855]]) tensor(825.6650, grad_fn=<SubBackward0>)\n",
      "loss: 0.03430989757180214\n",
      "tensor([[855]]) tensor(825.2510, grad_fn=<SubBackward0>)\n",
      "loss: 0.03479412570595741\n",
      "tensor([[855]]) tensor(832.8979, grad_fn=<SubBackward0>)\n",
      "loss: 0.025850370526313782\n",
      "tensor([[855]]) tensor(828.9336, grad_fn=<SubBackward0>)\n",
      "loss: 0.03048698976635933\n",
      "tensor([[855]]) tensor(833.4529, grad_fn=<SubBackward0>)\n",
      "loss: 0.025201236829161644\n",
      "tensor([[855]]) tensor(830.6102, grad_fn=<SubBackward0>)\n",
      "loss: 0.02852601185441017\n",
      "tensor([[855]]) tensor(828.7106, grad_fn=<SubBackward0>)\n",
      "loss: 0.030747799202799797\n",
      "tensor([[855]]) tensor(837.9075, grad_fn=<SubBackward0>)\n",
      "loss: 0.019991226494312286\n",
      "tensor([[855]]) tensor(827.7607, grad_fn=<SubBackward0>)\n",
      "loss: 0.031858816742897034\n",
      "tensor([[855]]) tensor(818.5768, grad_fn=<SubBackward0>)\n",
      "loss: 0.04260021820664406\n",
      "tensor([[855]]) tensor(829.1638, grad_fn=<SubBackward0>)\n",
      "loss: 0.030217792838811874\n",
      "tensor([[855]]) tensor(830.1553, grad_fn=<SubBackward0>)\n",
      "loss: 0.029058195650577545\n",
      "tensor([[855]]) tensor(827.2789, grad_fn=<SubBackward0>)\n",
      "loss: 0.03242228552699089\n",
      "tensor([[855]]) tensor(830.4044, grad_fn=<SubBackward0>)\n",
      "loss: 0.028766797855496407\n",
      "tensor([[855]]) tensor(831.1904, grad_fn=<SubBackward0>)\n",
      "loss: 0.027847539633512497\n",
      "tensor([[855]]) tensor(821.5274, grad_fn=<SubBackward0>)\n",
      "loss: 0.03914923593401909\n",
      "tensor([[855]]) tensor(828.1680, grad_fn=<SubBackward0>)\n",
      "loss: 0.031382422894239426\n",
      "tensor([[855]]) tensor(844.3971, grad_fn=<SubBackward0>)\n",
      "loss: 0.01240102294832468\n",
      "tensor([[855]]) tensor(826.7443, grad_fn=<SubBackward0>)\n",
      "loss: 0.03304760903120041\n",
      "tensor([[855]]) tensor(826.2343, grad_fn=<SubBackward0>)\n",
      "loss: 0.03364414721727371\n",
      "tensor([[855]]) tensor(844.4221, grad_fn=<SubBackward0>)\n",
      "loss: 0.012371755205094814\n",
      "tensor([[855]]) tensor(835.7801, grad_fn=<SubBackward0>)\n",
      "loss: 0.02247944474220276\n",
      "tensor([[855]]) tensor(844.7224, grad_fn=<SubBackward0>)\n",
      "loss: 0.012020624242722988\n",
      "tensor([[855]]) tensor(832.9349, grad_fn=<SubBackward0>)\n",
      "loss: 0.025807181373238564\n",
      "tensor([[855]]) tensor(839.6354, grad_fn=<SubBackward0>)\n",
      "loss: 0.017970357090234756\n",
      "tensor([[855]]) tensor(833.5391, grad_fn=<SubBackward0>)\n",
      "loss: 0.025100475177168846\n",
      "tensor([[855]]) tensor(830.2999, grad_fn=<SubBackward0>)\n",
      "loss: 0.028889009729027748\n",
      "tensor([[855]]) tensor(843.3799, grad_fn=<SubBackward0>)\n",
      "loss: 0.013590780086815357\n",
      "tensor([[855]]) tensor(833.7250, grad_fn=<SubBackward0>)\n",
      "loss: 0.024883069097995758\n",
      "tensor([[855]]) tensor(838.2373, grad_fn=<SubBackward0>)\n",
      "loss: 0.019605526700615883\n",
      "tensor([[855]]) tensor(834.6970, grad_fn=<SubBackward0>)\n",
      "loss: 0.023746173828840256\n",
      "tensor([[855]]) tensor(830.0527, grad_fn=<SubBackward0>)\n",
      "loss: 0.029178088530898094\n",
      "tensor([[855]]) tensor(838.7524, grad_fn=<SubBackward0>)\n",
      "loss: 0.019003063440322876\n",
      "tensor([[855]]) tensor(835.4684, grad_fn=<SubBackward0>)\n",
      "loss: 0.02284390665590763\n",
      "tensor([[855]]) tensor(843.8885, grad_fn=<SubBackward0>)\n",
      "loss: 0.012995848432183266\n",
      "tensor([[855]]) tensor(832.6553, grad_fn=<SubBackward0>)\n",
      "loss: 0.02613416500389576\n",
      "tensor([[855]]) tensor(834.1443, grad_fn=<SubBackward0>)\n",
      "loss: 0.02439255826175213\n",
      "tensor([[855]]) tensor(844.9486, grad_fn=<SubBackward0>)\n",
      "loss: 0.01175601314753294\n",
      "tensor([[855]]) tensor(837.9114, grad_fn=<SubBackward0>)\n",
      "loss: 0.019986657425761223\n",
      "tensor([[855]]) tensor(833.0231, grad_fn=<SubBackward0>)\n",
      "loss: 0.02570393867790699\n",
      "tensor([[855]]) tensor(829.3671, grad_fn=<SubBackward0>)\n",
      "loss: 0.029980041086673737\n",
      "tensor([[855]]) tensor(840.0750, grad_fn=<SubBackward0>)\n",
      "loss: 0.017456160858273506\n",
      "tensor([[855]]) tensor(838.3145, grad_fn=<SubBackward0>)\n",
      "loss: 0.019515277817845345\n",
      "tensor([[855]]) tensor(841.3918, grad_fn=<SubBackward0>)\n",
      "loss: 0.01591593399643898\n",
      "tensor([[855]]) tensor(834.8489, grad_fn=<SubBackward0>)\n",
      "loss: 0.023568565025925636\n",
      "tensor([[855]]) tensor(840.4443, grad_fn=<SubBackward0>)\n",
      "loss: 0.017024222761392593\n",
      "tensor([[855]]) tensor(825.0232, grad_fn=<SubBackward0>)\n",
      "loss: 0.03506062924861908\n",
      "tensor([[855]]) tensor(824.9949, grad_fn=<SubBackward0>)\n",
      "loss: 0.03509371727705002\n",
      "tensor([[855]]) tensor(837.0414, grad_fn=<SubBackward0>)\n",
      "loss: 0.02100423164665699\n",
      "tensor([[855]]) tensor(824.8640, grad_fn=<SubBackward0>)\n",
      "loss: 0.03524673357605934\n",
      "tensor([[855]]) tensor(815.5760, grad_fn=<SubBackward0>)\n",
      "loss: 0.046109847724437714\n",
      "tensor([[855]]) tensor(828.3994, grad_fn=<SubBackward0>)\n",
      "loss: 0.031111832708120346\n",
      "tensor([[855]]) tensor(835.8931, grad_fn=<SubBackward0>)\n",
      "loss: 0.02234721928834915\n",
      "tensor([[855]]) tensor(823.2202, grad_fn=<SubBackward0>)\n",
      "loss: 0.03716934099793434\n",
      "tensor([[855]]) tensor(827.7769, grad_fn=<SubBackward0>)\n",
      "loss: 0.031839918345212936\n",
      "tensor([[855]]) tensor(835.7809, grad_fn=<SubBackward0>)\n",
      "loss: 0.022478533908724785\n",
      "tensor([[855]]) tensor(832.3366, grad_fn=<SubBackward0>)\n",
      "loss: 0.026506908237934113\n",
      "tensor([[855]]) tensor(831.7496, grad_fn=<SubBackward0>)\n",
      "loss: 0.027193410322070122\n",
      "tensor([[855]]) tensor(831.8390, grad_fn=<SubBackward0>)\n",
      "loss: 0.02708890102803707\n",
      "tensor([[855]]) tensor(838.8995, grad_fn=<SubBackward0>)\n",
      "loss: 0.01883096992969513\n",
      "tensor([[855]]) tensor(830.4431, grad_fn=<SubBackward0>)\n",
      "loss: 0.028721574693918228\n",
      "tensor([[855]]) tensor(835.4335, grad_fn=<SubBackward0>)\n",
      "loss: 0.02288486436009407\n",
      "tensor([[855]]) tensor(836.6201, grad_fn=<SubBackward0>)\n",
      "loss: 0.021497027948498726\n",
      "tensor([[855]]) tensor(837.9666, grad_fn=<SubBackward0>)\n",
      "loss: 0.01992208883166313\n",
      "tensor([[855]]) tensor(835.6012, grad_fn=<SubBackward0>)\n",
      "loss: 0.02268865890800953\n",
      "tensor([[855]]) tensor(830.5182, grad_fn=<SubBackward0>)\n",
      "loss: 0.028633661568164825\n",
      "tensor([[855]]) tensor(838.7169, grad_fn=<SubBackward0>)\n",
      "loss: 0.019044503569602966\n",
      "tensor([[855]]) tensor(827.1434, grad_fn=<SubBackward0>)\n",
      "loss: 0.03258081525564194\n",
      "tensor([[855]]) tensor(830.4432, grad_fn=<SubBackward0>)\n",
      "loss: 0.02872137725353241\n",
      "tensor([[855]]) tensor(838.8854, grad_fn=<SubBackward0>)\n",
      "loss: 0.018847424536943436\n",
      "tensor([[855]]) tensor(823.9217, grad_fn=<SubBackward0>)\n",
      "loss: 0.03634889796376228\n",
      "tensor([[855]]) tensor(831.2052, grad_fn=<SubBackward0>)\n",
      "loss: 0.0278302114456892\n",
      "tensor([[855]]) tensor(844.2267, grad_fn=<SubBackward0>)\n",
      "loss: 0.01260040421038866\n",
      "tensor([[855]]) tensor(843.2138, grad_fn=<SubBackward0>)\n",
      "loss: 0.013785022310912609\n",
      "tensor([[855]]) tensor(843.7380, grad_fn=<SubBackward0>)\n",
      "loss: 0.013171957805752754\n",
      "tensor([[855]]) tensor(841.4257, grad_fn=<SubBackward0>)\n",
      "loss: 0.015876350924372673\n",
      "tensor([[855]]) tensor(841.3329, grad_fn=<SubBackward0>)\n",
      "loss: 0.015984857454895973\n",
      "tensor([[855]]) tensor(843.9050, grad_fn=<SubBackward0>)\n",
      "loss: 0.012976609170436859\n",
      "tensor([[855]]) tensor(841.9556, grad_fn=<SubBackward0>)\n",
      "loss: 0.015256665647029877\n",
      "tensor([[855]]) tensor(841.2660, grad_fn=<SubBackward0>)\n",
      "loss: 0.016063133254647255\n",
      "tensor([[855]]) tensor(841.8461, grad_fn=<SubBackward0>)\n",
      "loss: 0.015384731814265251\n",
      "tensor([[855]]) tensor(838.4731, grad_fn=<SubBackward0>)\n",
      "loss: 0.019329655915498734\n",
      "tensor([[855]]) tensor(845.6693, grad_fn=<SubBackward0>)\n",
      "loss: 0.010913068428635597\n",
      "tensor([[855]]) tensor(827.8339, grad_fn=<SubBackward0>)\n",
      "loss: 0.031773172318935394\n",
      "tensor([[855]]) tensor(829.1541, grad_fn=<SubBackward0>)\n",
      "loss: 0.030229195952415466\n",
      "tensor([[855]]) tensor(844.6789, grad_fn=<SubBackward0>)\n",
      "loss: 0.012071451172232628\n",
      "tensor([[855]]) tensor(836.9641, grad_fn=<SubBackward0>)\n",
      "loss: 0.021094607189297676\n",
      "tensor([[855]]) tensor(845.5753, grad_fn=<SubBackward0>)\n",
      "loss: 0.01102305669337511\n",
      "tensor([[855]]) tensor(836.3912, grad_fn=<SubBackward0>)\n",
      "loss: 0.021764708682894707\n",
      "tensor([[855]]) tensor(841.8160, grad_fn=<SubBackward0>)\n",
      "loss: 0.015419800765812397\n",
      "tensor([[855]]) tensor(817.1607, grad_fn=<SubBackward0>)\n",
      "loss: 0.044256485998630524\n",
      "tensor([[855]]) tensor(815.9374, grad_fn=<SubBackward0>)\n",
      "loss: 0.04568720608949661\n",
      "tensor([[855]]) tensor(831.5514, grad_fn=<SubBackward0>)\n",
      "loss: 0.027425255626440048\n",
      "tensor([[855]]) tensor(827.7018, grad_fn=<SubBackward0>)\n",
      "loss: 0.03192777559161186\n",
      "tensor([[855]]) tensor(820.4232, grad_fn=<SubBackward0>)\n",
      "loss: 0.040440645068883896\n",
      "tensor([[855]]) tensor(836.4272, grad_fn=<SubBackward0>)\n",
      "loss: 0.02172255516052246\n",
      "tensor([[855]]) tensor(833.3266, grad_fn=<SubBackward0>)\n",
      "loss: 0.025349006056785583\n",
      "tensor([[855]]) tensor(824.6655, grad_fn=<SubBackward0>)\n",
      "loss: 0.035478878766298294\n",
      "tensor([[855]]) tensor(835.0289, grad_fn=<SubBackward0>)\n",
      "loss: 0.023358047008514404\n",
      "tensor([[855]]) tensor(836.5546, grad_fn=<SubBackward0>)\n",
      "loss: 0.021573606878519058\n",
      "tensor([[855]]) tensor(828.7357, grad_fn=<SubBackward0>)\n",
      "loss: 0.03071845881640911\n",
      "tensor([[855]]) tensor(837.8240, grad_fn=<SubBackward0>)\n",
      "loss: 0.020088953897356987\n",
      "tensor([[855]]) tensor(830.7418, grad_fn=<SubBackward0>)\n",
      "loss: 0.028372138738632202\n",
      "tensor([[855]]) tensor(834.0284, grad_fn=<SubBackward0>)\n",
      "loss: 0.02452820912003517\n",
      "tensor([[855]]) tensor(835.7449, grad_fn=<SubBackward0>)\n",
      "loss: 0.022520562633872032\n",
      "tensor([[855]]) tensor(832.8467, grad_fn=<SubBackward0>)\n",
      "loss: 0.02591024525463581\n",
      "tensor([[855]]) tensor(841.1396, grad_fn=<SubBackward0>)\n",
      "loss: 0.016210991889238358\n",
      "tensor([[855]]) tensor(822.0872, grad_fn=<SubBackward0>)\n",
      "loss: 0.03849451616406441\n",
      "tensor([[855]]) tensor(818.7699, grad_fn=<SubBackward0>)\n",
      "loss: 0.04237435385584831\n",
      "tensor([[855]]) tensor(836.2721, grad_fn=<SubBackward0>)\n",
      "loss: 0.021904001012444496\n",
      "tensor([[855]]) tensor(829.2292, grad_fn=<SubBackward0>)\n",
      "loss: 0.03014126606285572\n",
      "tensor([[855]]) tensor(822.6990, grad_fn=<SubBackward0>)\n",
      "loss: 0.037778958678245544\n",
      "tensor([[855]]) tensor(839.9809, grad_fn=<SubBackward0>)\n",
      "loss: 0.01756618544459343\n",
      "tensor([[855]]) tensor(835.3339, grad_fn=<SubBackward0>)\n",
      "loss: 0.023001329973340034\n",
      "tensor([[855]]) tensor(827.6693, grad_fn=<SubBackward0>)\n",
      "loss: 0.03196568042039871\n",
      "tensor([[855]]) tensor(840.9991, grad_fn=<SubBackward0>)\n",
      "loss: 0.01637532189488411\n",
      "tensor([[855]]) tensor(833.2653, grad_fn=<SubBackward0>)\n",
      "loss: 0.025420714169740677\n",
      "tensor([[855]]) tensor(836.1678, grad_fn=<SubBackward0>)\n",
      "loss: 0.022025911137461662\n",
      "tensor([[855]]) tensor(838.2766, grad_fn=<SubBackward0>)\n",
      "loss: 0.019559573382139206\n",
      "tensor([[855]]) tensor(833.5793, grad_fn=<SubBackward0>)\n",
      "loss: 0.025053467601537704\n",
      "tensor([[855]]) tensor(837.1182, grad_fn=<SubBackward0>)\n",
      "loss: 0.020914463326334953\n",
      "tensor([[855]]) tensor(835.8034, grad_fn=<SubBackward0>)\n",
      "loss: 0.022452156990766525\n",
      "tensor([[855]]) tensor(835.3765, grad_fn=<SubBackward0>)\n",
      "loss: 0.022951431572437286\n",
      "tensor([[855]]) tensor(840.9890, grad_fn=<SubBackward0>)\n",
      "loss: 0.01638719066977501\n",
      "tensor([[855]]) tensor(838.7039, grad_fn=<SubBackward0>)\n",
      "loss: 0.019059762358665466\n",
      "tensor([[855]]) tensor(842.1388, grad_fn=<SubBackward0>)\n",
      "loss: 0.015042345970869064\n",
      "tensor([[855]]) tensor(829.2144, grad_fn=<SubBackward0>)\n",
      "loss: 0.030158666893839836\n",
      "tensor([[855]]) tensor(827.0539, grad_fn=<SubBackward0>)\n",
      "loss: 0.032685503363609314\n",
      "tensor([[855]]) tensor(846.8531, grad_fn=<SubBackward0>)\n",
      "loss: 0.009528533555567265\n",
      "tensor([[855]]) tensor(832.6254, grad_fn=<SubBackward0>)\n",
      "loss: 0.026169126853346825\n",
      "tensor([[855]]) tensor(834.2831, grad_fn=<SubBackward0>)\n",
      "loss: 0.02423027902841568\n",
      "tensor([[855]]) tensor(843.0832, grad_fn=<SubBackward0>)\n",
      "loss: 0.01393778808414936\n",
      "tensor([[855]]) tensor(844.9858, grad_fn=<SubBackward0>)\n",
      "loss: 0.011712431907653809\n",
      "tensor([[855]]) tensor(832.2468, grad_fn=<SubBackward0>)\n",
      "loss: 0.02661186270415783\n",
      "tensor([[855]]) tensor(822.4514, grad_fn=<SubBackward0>)\n",
      "loss: 0.038068484514951706\n",
      "tensor([[855]]) tensor(833.3254, grad_fn=<SubBackward0>)\n",
      "loss: 0.025350380688905716\n",
      "tensor([[855]]) tensor(840.7319, grad_fn=<SubBackward0>)\n",
      "loss: 0.01668781414628029\n",
      "tensor([[855]]) tensor(828.7015, grad_fn=<SubBackward0>)\n",
      "loss: 0.030758505687117577\n",
      "tensor([[855]]) tensor(842.5477, grad_fn=<SubBackward0>)\n",
      "loss: 0.01456411276012659\n",
      "tensor([[855]]) tensor(819.9927, grad_fn=<SubBackward0>)\n",
      "loss: 0.040944237262010574\n",
      "tensor([[855]]) tensor(811.9738, grad_fn=<SubBackward0>)\n",
      "loss: 0.05032305791974068\n",
      "tensor([[855]]) tensor(829.4658, grad_fn=<SubBackward0>)\n",
      "loss: 0.02986450120806694\n",
      "tensor([[855]]) tensor(840.8795, grad_fn=<SubBackward0>)\n",
      "loss: 0.016515186056494713\n",
      "tensor([[855]]) tensor(823.8474, grad_fn=<SubBackward0>)\n",
      "loss: 0.036435846239328384\n",
      "tensor([[855]]) tensor(835.3176, grad_fn=<SubBackward0>)\n",
      "loss: 0.023020319640636444\n",
      "tensor([[855]]) tensor(832.6705, grad_fn=<SubBackward0>)\n",
      "loss: 0.02611640840768814\n",
      "tensor([[855]]) tensor(823.9302, grad_fn=<SubBackward0>)\n",
      "loss: 0.03633890300989151\n",
      "tensor([[855]]) tensor(837.1898, grad_fn=<SubBackward0>)\n",
      "loss: 0.020830584689974785\n",
      "tensor([[855]]) tensor(837.3969, grad_fn=<SubBackward0>)\n",
      "loss: 0.020588478073477745\n",
      "tensor([[855]]) tensor(825.6811, grad_fn=<SubBackward0>)\n",
      "loss: 0.03429112210869789\n",
      "tensor([[855]]) tensor(838.9227, grad_fn=<SubBackward0>)\n",
      "loss: 0.018803860992193222\n",
      "tensor([[855]]) tensor(838.6084, grad_fn=<SubBackward0>)\n",
      "loss: 0.019171498715877533\n",
      "tensor([[855]]) tensor(840.2208, grad_fn=<SubBackward0>)\n",
      "loss: 0.017285620793700218\n",
      "tensor([[855]]) tensor(841.7491, grad_fn=<SubBackward0>)\n",
      "loss: 0.015498128719627857\n",
      "tensor([[855]]) tensor(843.5245, grad_fn=<SubBackward0>)\n",
      "loss: 0.01342166680842638\n",
      "tensor([[855]]) tensor(836.6371, grad_fn=<SubBackward0>)\n",
      "loss: 0.021477075293660164\n",
      "tensor([[855]]) tensor(846.7003, grad_fn=<SubBackward0>)\n",
      "loss: 0.00970723107457161\n",
      "tensor([[855]]) tensor(830.9244, grad_fn=<SubBackward0>)\n",
      "loss: 0.028158623725175858\n",
      "tensor([[855]]) tensor(834.7464, grad_fn=<SubBackward0>)\n",
      "loss: 0.023688403889536858\n",
      "tensor([[855]]) tensor(842.8884, grad_fn=<SubBackward0>)\n",
      "loss: 0.01416565291583538\n",
      "tensor([[855]]) tensor(830.9448, grad_fn=<SubBackward0>)\n",
      "loss: 0.02813476137816906\n",
      "tensor([[855]]) tensor(837.9356, grad_fn=<SubBackward0>)\n",
      "loss: 0.01995835267007351\n",
      "tensor([[855]]) tensor(841.2147, grad_fn=<SubBackward0>)\n",
      "loss: 0.016123168170452118\n",
      "tensor([[855]]) tensor(842.0774, grad_fn=<SubBackward0>)\n",
      "loss: 0.015114161185920238\n",
      "tensor([[855]]) tensor(845.4324, grad_fn=<SubBackward0>)\n",
      "loss: 0.011190171353518963\n",
      "tensor([[855]]) tensor(844.6315, grad_fn=<SubBackward0>)\n",
      "loss: 0.01212697196751833\n",
      "tensor([[855]]) tensor(846.4996, grad_fn=<SubBackward0>)\n",
      "loss: 0.009942002594470978\n",
      "tensor([[855]]) tensor(843.5408, grad_fn=<SubBackward0>)\n",
      "loss: 0.013402534648776054\n",
      "tensor([[855]]) tensor(840.1460, grad_fn=<SubBackward0>)\n",
      "loss: 0.017373068258166313\n",
      "tensor([[855]]) tensor(847.8304, grad_fn=<SubBackward0>)\n",
      "loss: 0.008385409601032734\n",
      "tensor([[855]]) tensor(832.4613, grad_fn=<SubBackward0>)\n",
      "loss: 0.02636108361184597\n",
      "tensor([[855]]) tensor(837.2161, grad_fn=<SubBackward0>)\n",
      "loss: 0.02079996094107628\n",
      "tensor([[855]]) tensor(836.9124, grad_fn=<SubBackward0>)\n",
      "loss: 0.021155070513486862\n",
      "tensor([[855]]) tensor(835.9034, grad_fn=<SubBackward0>)\n",
      "loss: 0.022335190325975418\n",
      "tensor([[855]]) tensor(844.1207, grad_fn=<SubBackward0>)\n",
      "loss: 0.012724312953650951\n",
      "tensor([[855]]) tensor(833.7145, grad_fn=<SubBackward0>)\n",
      "loss: 0.024895383045077324\n",
      "tensor([[855]]) tensor(845.0875, grad_fn=<SubBackward0>)\n",
      "loss: 0.011593538336455822\n",
      "tensor([[855]]) tensor(840.9037, grad_fn=<SubBackward0>)\n",
      "loss: 0.016486916691064835\n",
      "tensor([[855]]) tensor(847.0510, grad_fn=<SubBackward0>)\n",
      "loss: 0.009297064505517483\n",
      "tensor([[855]]) tensor(846.0771, grad_fn=<SubBackward0>)\n",
      "loss: 0.010436154901981354\n",
      "tensor([[855]]) tensor(832.9193, grad_fn=<SubBackward0>)\n",
      "loss: 0.025825366377830505\n",
      "tensor([[855]]) tensor(837.2937, grad_fn=<SubBackward0>)\n",
      "loss: 0.020709138363599777\n",
      "tensor([[855]]) tensor(846.1235, grad_fn=<SubBackward0>)\n",
      "loss: 0.01038181222975254\n",
      "tensor([[855]]) tensor(848.6091, grad_fn=<SubBackward0>)\n",
      "loss: 0.007474718615412712\n",
      "tensor([[855]]) tensor(840.9487, grad_fn=<SubBackward0>)\n",
      "loss: 0.016434233635663986\n",
      "tensor([[855]]) tensor(842.4352, grad_fn=<SubBackward0>)\n",
      "loss: 0.014695623889565468\n",
      "tensor([[855]]) tensor(846.6882, grad_fn=<SubBackward0>)\n",
      "loss: 0.009721401147544384\n",
      "tensor([[855]]) tensor(841.9499, grad_fn=<SubBackward0>)\n",
      "loss: 0.015263286419212818\n",
      "tensor([[855]]) tensor(848.6054, grad_fn=<SubBackward0>)\n",
      "loss: 0.007479055318981409\n",
      "tensor([[855]]) tensor(841.4587, grad_fn=<SubBackward0>)\n",
      "loss: 0.01583773083984852\n",
      "tensor([[855]]) tensor(834.5921, grad_fn=<SubBackward0>)\n",
      "loss: 0.02386888675391674\n",
      "tensor([[855]]) tensor(840.1693, grad_fn=<SubBackward0>)\n",
      "loss: 0.01734592393040657\n",
      "tensor([[855]]) tensor(834.9341, grad_fn=<SubBackward0>)\n",
      "loss: 0.023468928411602974\n",
      "tensor([[855]]) tensor(832.3315, grad_fn=<SubBackward0>)\n",
      "loss: 0.02651277929544449\n",
      "tensor([[855]]) tensor(836.5166, grad_fn=<SubBackward0>)\n",
      "loss: 0.021618010476231575\n",
      "tensor([[855]]) tensor(835.7947, grad_fn=<SubBackward0>)\n",
      "loss: 0.02246229350566864\n",
      "tensor([[855]]) tensor(844.5588, grad_fn=<SubBackward0>)\n",
      "loss: 0.012211885303258896\n",
      "tensor([[855]]) tensor(836.4048, grad_fn=<SubBackward0>)\n",
      "loss: 0.021748753264546394\n",
      "tensor([[855]]) tensor(833.0517, grad_fn=<SubBackward0>)\n",
      "loss: 0.02567051164805889\n",
      "tensor([[855]]) tensor(832.2388, grad_fn=<SubBackward0>)\n",
      "loss: 0.026621323078870773\n",
      "tensor([[855]]) tensor(840.4582, grad_fn=<SubBackward0>)\n",
      "loss: 0.017007963731884956\n",
      "tensor([[855]]) tensor(840.9592, grad_fn=<SubBackward0>)\n",
      "loss: 0.016421955078840256\n",
      "tensor([[855]]) tensor(840.4117, grad_fn=<SubBackward0>)\n",
      "loss: 0.017062325030565262\n",
      "tensor([[855]]) tensor(841.2111, grad_fn=<SubBackward0>)\n",
      "loss: 0.016127344220876694\n",
      "tensor([[855]]) tensor(842.6962, grad_fn=<SubBackward0>)\n",
      "loss: 0.014390448108315468\n",
      "tensor([[855]]) tensor(839.1898, grad_fn=<SubBackward0>)\n",
      "loss: 0.018491510301828384\n",
      "tensor([[855]]) tensor(838.4476, grad_fn=<SubBackward0>)\n",
      "loss: 0.01935947686433792\n",
      "tensor([[855]]) tensor(829.0638, grad_fn=<SubBackward0>)\n",
      "loss: 0.03033468686044216\n",
      "tensor([[855]]) tensor(826.2659, grad_fn=<SubBackward0>)\n",
      "loss: 0.03360715135931969\n",
      "tensor([[855]]) tensor(843.2361, grad_fn=<SubBackward0>)\n",
      "loss: 0.0137589480727911\n",
      "tensor([[855]]) tensor(832.8649, grad_fn=<SubBackward0>)\n",
      "loss: 0.025889061391353607\n",
      "tensor([[855]]) tensor(834.0151, grad_fn=<SubBackward0>)\n",
      "loss: 0.02454373612999916\n",
      "tensor([[855]]) tensor(840.5531, grad_fn=<SubBackward0>)\n",
      "loss: 0.016896957531571388\n",
      "tensor([[855]]) tensor(832.6780, grad_fn=<SubBackward0>)\n",
      "loss: 0.026107627898454666\n",
      "tensor([[855]]) tensor(842.1510, grad_fn=<SubBackward0>)\n",
      "loss: 0.015028033405542374\n",
      "tensor([[855]]) tensor(838.1069, grad_fn=<SubBackward0>)\n",
      "loss: 0.019758062437176704\n",
      "tensor([[855]]) tensor(841.5139, grad_fn=<SubBackward0>)\n",
      "loss: 0.01577325165271759\n",
      "tensor([[855]]) tensor(837.7478, grad_fn=<SubBackward0>)\n",
      "loss: 0.02017800882458687\n",
      "tensor([[855]]) tensor(841.4700, grad_fn=<SubBackward0>)\n",
      "loss: 0.01582452468574047\n",
      "tensor([[855]]) tensor(819.4490, grad_fn=<SubBackward0>)\n",
      "loss: 0.04158014804124832\n",
      "tensor([[855]]) tensor(822.2911, grad_fn=<SubBackward0>)\n",
      "loss: 0.03825594484806061\n",
      "tensor([[855]]) tensor(843.1016, grad_fn=<SubBackward0>)\n",
      "loss: 0.013916336931288242\n",
      "tensor([[855]]) tensor(819.5564, grad_fn=<SubBackward0>)\n",
      "loss: 0.04145454242825508\n",
      "tensor([[855]]) tensor(816.3923, grad_fn=<SubBackward0>)\n",
      "loss: 0.045155130326747894\n",
      "tensor([[855]]) tensor(835.2428, grad_fn=<SubBackward0>)\n",
      "loss: 0.023107821121811867\n",
      "tensor([[855]]) tensor(815.4622, grad_fn=<SubBackward0>)\n",
      "loss: 0.046243052929639816\n",
      "tensor([[855]]) tensor(801.5888, grad_fn=<SubBackward0>)\n",
      "loss: 0.062469232827425\n",
      "tensor([[855]]) tensor(815.4125, grad_fn=<SubBackward0>)\n",
      "loss: 0.04630117863416672\n",
      "tensor([[855]]) tensor(839.0629, grad_fn=<SubBackward0>)\n",
      "loss: 0.01863986812531948\n",
      "tensor([[855]]) tensor(810.5507, grad_fn=<SubBackward0>)\n",
      "loss: 0.05198746174573898\n",
      "tensor([[855]]) tensor(803.3726, grad_fn=<SubBackward0>)\n",
      "loss: 0.06038297340273857\n",
      "tensor([[855]]) tensor(824.5471, grad_fn=<SubBackward0>)\n",
      "loss: 0.035617370158433914\n",
      "tensor([[855]]) tensor(830.8781, grad_fn=<SubBackward0>)\n",
      "loss: 0.028212768957018852\n",
      "tensor([[855]]) tensor(815.9235, grad_fn=<SubBackward0>)\n",
      "loss: 0.04570348188281059\n",
      "tensor([[855]]) tensor(821.8862, grad_fn=<SubBackward0>)\n",
      "loss: 0.03872964531183243\n",
      "tensor([[855]]) tensor(836.6149, grad_fn=<SubBackward0>)\n",
      "loss: 0.021503061056137085\n",
      "tensor([[855]]) tensor(816.8931, grad_fn=<SubBackward0>)\n",
      "loss: 0.044569458812475204\n",
      "tensor([[855]]) tensor(811.8882, grad_fn=<SubBackward0>)\n",
      "loss: 0.05042310431599617\n",
      "tensor([[855]]) tensor(833.0208, grad_fn=<SubBackward0>)\n",
      "loss: 0.02570665068924427\n",
      "tensor([[855]]) tensor(838.0453, grad_fn=<SubBackward0>)\n",
      "loss: 0.019830001518130302\n",
      "tensor([[855]]) tensor(834.6689, grad_fn=<SubBackward0>)\n",
      "loss: 0.02377901040017605\n",
      "tensor([[855]]) tensor(839.3167, grad_fn=<SubBackward0>)\n",
      "loss: 0.018343117088079453\n",
      "tensor([[855]]) tensor(835.8783, grad_fn=<SubBackward0>)\n",
      "loss: 0.022364530712366104\n",
      "tensor([[855]]) tensor(828.8226, grad_fn=<SubBackward0>)\n",
      "loss: 0.030616769567131996\n",
      "tensor([[855]]) tensor(842.0231, grad_fn=<SubBackward0>)\n",
      "loss: 0.015177694149315357\n",
      "tensor([[855]]) tensor(834.4867, grad_fn=<SubBackward0>)\n",
      "loss: 0.023992206901311874\n",
      "tensor([[855]]) tensor(837.7786, grad_fn=<SubBackward0>)\n",
      "loss: 0.020141959190368652\n",
      "tensor([[855]]) tensor(832.7177, grad_fn=<SubBackward0>)\n",
      "loss: 0.026061154901981354\n",
      "tensor([[855]]) tensor(835.3842, grad_fn=<SubBackward0>)\n",
      "loss: 0.022942544892430305\n",
      "tensor([[855]]) tensor(844.6312, grad_fn=<SubBackward0>)\n",
      "loss: 0.012127203866839409\n",
      "tensor([[855]]) tensor(842.0958, grad_fn=<SubBackward0>)\n",
      "loss: 0.01509256660938263\n",
      "tensor([[855]]) tensor(841.1627, grad_fn=<SubBackward0>)\n",
      "loss: 0.01618393510580063\n",
      "tensor([[855]]) tensor(841.7678, grad_fn=<SubBackward0>)\n",
      "loss: 0.015476284548640251\n",
      "tensor([[855]]) tensor(840.2246, grad_fn=<SubBackward0>)\n",
      "loss: 0.017281122505664825\n",
      "tensor([[855]]) tensor(840.8423, grad_fn=<SubBackward0>)\n",
      "loss: 0.0165586955845356\n",
      "tensor([[855]]) tensor(840.1584, grad_fn=<SubBackward0>)\n",
      "loss: 0.017358630895614624\n",
      "tensor([[855]]) tensor(840.8713, grad_fn=<SubBackward0>)\n",
      "loss: 0.01652478612959385\n",
      "tensor([[855]]) tensor(842.4834, grad_fn=<SubBackward0>)\n",
      "loss: 0.01463928259909153\n",
      "tensor([[855]]) tensor(842.1503, grad_fn=<SubBackward0>)\n",
      "loss: 0.015028872527182102\n",
      "tensor([[855]]) tensor(843.3978, grad_fn=<SubBackward0>)\n",
      "loss: 0.013569757342338562\n",
      "tensor([[855]]) tensor(845.6655, grad_fn=<SubBackward0>)\n",
      "loss: 0.010917583480477333\n",
      "tensor([[855]]) tensor(842.7421, grad_fn=<SubBackward0>)\n",
      "loss: 0.014336783438920975\n",
      "tensor([[855]]) tensor(846.8963, grad_fn=<SubBackward0>)\n",
      "loss: 0.00947801023721695\n",
      "tensor([[855]]) tensor(842.4246, grad_fn=<SubBackward0>)\n",
      "loss: 0.01470808032900095\n",
      "tensor([[855]]) tensor(847.3359, grad_fn=<SubBackward0>)\n",
      "loss: 0.008963851258158684\n",
      "tensor([[855]]) tensor(846.4326, grad_fn=<SubBackward0>)\n",
      "loss: 0.010020366869866848\n",
      "tensor([[855]]) tensor(844.8439, grad_fn=<SubBackward0>)\n",
      "loss: 0.011878476478159428\n",
      "tensor([[855]]) tensor(846.2311, grad_fn=<SubBackward0>)\n",
      "loss: 0.01025597658008337\n",
      "tensor([[855]]) tensor(841.2565, grad_fn=<SubBackward0>)\n",
      "loss: 0.016074322164058685\n",
      "tensor([[855]]) tensor(847.7843, grad_fn=<SubBackward0>)\n",
      "loss: 0.008439413271844387\n",
      "tensor([[855]]) tensor(842.7607, grad_fn=<SubBackward0>)\n",
      "loss: 0.014314939267933369\n",
      "tensor([[855]]) tensor(841.0070, grad_fn=<SubBackward0>)\n",
      "loss: 0.01636609621345997\n",
      "tensor([[855]]) tensor(843.0200, grad_fn=<SubBackward0>)\n",
      "loss: 0.01401170901954174\n",
      "tensor([[855]]) tensor(848.4902, grad_fn=<SubBackward0>)\n",
      "loss: 0.00761385029181838\n",
      "tensor([[855]]) tensor(833.2798, grad_fn=<SubBackward0>)\n",
      "loss: 0.02540372498333454\n",
      "tensor([[855]]) tensor(841.4309, grad_fn=<SubBackward0>)\n",
      "loss: 0.015870317816734314\n",
      "tensor([[855]]) tensor(825.5566, grad_fn=<SubBackward0>)\n",
      "loss: 0.03443664312362671\n",
      "tensor([[855]]) tensor(819.9965, grad_fn=<SubBackward0>)\n",
      "loss: 0.040939778089523315\n",
      "tensor([[855]]) tensor(832.9812, grad_fn=<SubBackward0>)\n",
      "loss: 0.025752980262041092\n",
      "tensor([[855]]) tensor(820.9525, grad_fn=<SubBackward0>)\n",
      "loss: 0.03982162103056908\n",
      "tensor([[855]]) tensor(815.2028, grad_fn=<SubBackward0>)\n",
      "loss: 0.04654650017619133\n",
      "tensor([[855]]) tensor(832.3953, grad_fn=<SubBackward0>)\n",
      "loss: 0.02643832378089428\n",
      "tensor([[855]]) tensor(822.3546, grad_fn=<SubBackward0>)\n",
      "loss: 0.03818175569176674\n",
      "tensor([[855]]) tensor(810.8921, grad_fn=<SubBackward0>)\n",
      "loss: 0.05158820003271103\n",
      "tensor([[855]]) tensor(824.6187, grad_fn=<SubBackward0>)\n",
      "loss: 0.03553370386362076\n",
      "tensor([[855]]) tensor(841.5595, grad_fn=<SubBackward0>)\n",
      "loss: 0.01571987196803093\n",
      "tensor([[855]]) tensor(813.1250, grad_fn=<SubBackward0>)\n",
      "loss: 0.048976607620716095\n",
      "tensor([[855]]) tensor(808.0662, grad_fn=<SubBackward0>)\n",
      "loss: 0.0548933781683445\n",
      "tensor([[855]]) tensor(823.2544, grad_fn=<SubBackward0>)\n",
      "loss: 0.03712939843535423\n",
      "tensor([[855]]) tensor(830.2644, grad_fn=<SubBackward0>)\n",
      "loss: 0.028930485248565674\n",
      "tensor([[855]]) tensor(829.8505, grad_fn=<SubBackward0>)\n",
      "loss: 0.029414625838398933\n",
      "tensor([[855]]) tensor(829.4457, grad_fn=<SubBackward0>)\n",
      "loss: 0.029888059943914413\n",
      "tensor([[855]]) tensor(836.1288, grad_fn=<SubBackward0>)\n",
      "loss: 0.022071598097682\n",
      "tensor([[855]]) tensor(823.7319, grad_fn=<SubBackward0>)\n",
      "loss: 0.03657092899084091\n",
      "tensor([[855]]) tensor(832.4780, grad_fn=<SubBackward0>)\n",
      "loss: 0.02634148858487606\n",
      "tensor([[855]]) tensor(838.6646, grad_fn=<SubBackward0>)\n",
      "loss: 0.019105717539787292\n",
      "tensor([[855]]) tensor(826.3196, grad_fn=<SubBackward0>)\n",
      "loss: 0.03354429826140404\n",
      "tensor([[855]]) tensor(831.7650, grad_fn=<SubBackward0>)\n",
      "loss: 0.027175510302186012\n",
      "tensor([[855]]) tensor(834.8829, grad_fn=<SubBackward0>)\n",
      "loss: 0.023528819903731346\n",
      "tensor([[855]]) tensor(819.4159, grad_fn=<SubBackward0>)\n",
      "loss: 0.04161880165338516\n",
      "tensor([[855]]) tensor(830.6773, grad_fn=<SubBackward0>)\n",
      "loss: 0.028447575867176056\n",
      "tensor([[855]]) tensor(836.6732, grad_fn=<SubBackward0>)\n",
      "loss: 0.021434905007481575\n",
      "tensor([[855]]) tensor(828.6151, grad_fn=<SubBackward0>)\n",
      "loss: 0.03085958957672119\n",
      "tensor([[855]]) tensor(840.5778, grad_fn=<SubBackward0>)\n",
      "loss: 0.016868118196725845\n",
      "tensor([[855]]) tensor(831.8993, grad_fn=<SubBackward0>)\n",
      "loss: 0.02701837196946144\n",
      "tensor([[855]]) tensor(830.9112, grad_fn=<SubBackward0>)\n",
      "loss: 0.0281740240752697\n",
      "tensor([[855]]) tensor(835.5551, grad_fn=<SubBackward0>)\n",
      "loss: 0.02274259179830551\n",
      "tensor([[855]]) tensor(829.0430, grad_fn=<SubBackward0>)\n",
      "loss: 0.03035901114344597\n",
      "tensor([[855]]) tensor(843.8337, grad_fn=<SubBackward0>)\n",
      "loss: 0.013059916906058788\n",
      "tensor([[855]]) tensor(833.0087, grad_fn=<SubBackward0>)\n",
      "loss: 0.025720786303281784\n",
      "tensor([[855]]) tensor(822.0289, grad_fn=<SubBackward0>)\n",
      "loss: 0.03856268897652626\n",
      "tensor([[855]]) tensor(832.3621, grad_fn=<SubBackward0>)\n",
      "loss: 0.026477033272385597\n",
      "tensor([[855]]) tensor(838.8909, grad_fn=<SubBackward0>)\n",
      "loss: 0.018841035664081573\n",
      "tensor([[855]]) tensor(832.1209, grad_fn=<SubBackward0>)\n",
      "loss: 0.026759186759591103\n",
      "tensor([[855]]) tensor(839.6554, grad_fn=<SubBackward0>)\n",
      "loss: 0.017946923151612282\n",
      "tensor([[855]]) tensor(838.6874, grad_fn=<SubBackward0>)\n",
      "loss: 0.01907912641763687\n",
      "tensor([[855]]) tensor(840.5734, grad_fn=<SubBackward0>)\n",
      "loss: 0.01687316969037056\n",
      "tensor([[855]]) tensor(844.0775, grad_fn=<SubBackward0>)\n",
      "loss: 0.012774800881743431\n",
      "tensor([[855]]) tensor(846.7875, grad_fn=<SubBackward0>)\n",
      "loss: 0.009605220519006252\n",
      "tensor([[855]]) tensor(842.9510, grad_fn=<SubBackward0>)\n",
      "loss: 0.01409237552434206\n",
      "tensor([[855]]) tensor(842.2073, grad_fn=<SubBackward0>)\n",
      "loss: 0.01496219728142023\n",
      "tensor([[855]]) tensor(840.6611, grad_fn=<SubBackward0>)\n",
      "loss: 0.01677056960761547\n",
      "tensor([[855]]) tensor(845.2122, grad_fn=<SubBackward0>)\n",
      "loss: 0.011447696946561337\n",
      "tensor([[855]]) tensor(821.0740, grad_fn=<SubBackward0>)\n",
      "loss: 0.039679598063230515\n",
      "tensor([[855]]) tensor(820.5486, grad_fn=<SubBackward0>)\n",
      "loss: 0.04029398411512375\n",
      "tensor([[855]]) tensor(843.4778, grad_fn=<SubBackward0>)\n",
      "loss: 0.013476187363266945\n",
      "tensor([[855]]) tensor(828.3469, grad_fn=<SubBackward0>)\n",
      "loss: 0.031173188239336014\n",
      "tensor([[855]]) tensor(821.3984, grad_fn=<SubBackward0>)\n",
      "loss: 0.039300110191106796\n",
      "tensor([[855]]) tensor(836.9724, grad_fn=<SubBackward0>)\n",
      "loss: 0.021084951236844063\n",
      "tensor([[855]]) tensor(823.8840, grad_fn=<SubBackward0>)\n",
      "loss: 0.03639296069741249\n",
      "tensor([[855]]) tensor(827.1306, grad_fn=<SubBackward0>)\n",
      "loss: 0.032595861703157425\n",
      "tensor([[855]]) tensor(841.6258, grad_fn=<SubBackward0>)\n",
      "loss: 0.015642328187823296\n",
      "tensor([[855]]) tensor(825.5477, grad_fn=<SubBackward0>)\n",
      "loss: 0.03444706276059151\n",
      "tensor([[855]]) tensor(831.1683, grad_fn=<SubBackward0>)\n",
      "loss: 0.027873292565345764\n",
      "tensor([[855]]) tensor(833.9046, grad_fn=<SubBackward0>)\n",
      "loss: 0.02467297948896885\n",
      "tensor([[855]]) tensor(822.5736, grad_fn=<SubBackward0>)\n",
      "loss: 0.03792556747794151\n",
      "tensor([[855]]) tensor(832.7654, grad_fn=<SubBackward0>)\n",
      "loss: 0.026005437597632408\n",
      "tensor([[855]]) tensor(831.8644, grad_fn=<SubBackward0>)\n",
      "loss: 0.02705911546945572\n",
      "tensor([[855]]) tensor(832.3596, grad_fn=<SubBackward0>)\n",
      "loss: 0.026479942724108696\n",
      "tensor([[855]]) tensor(835.0604, grad_fn=<SubBackward0>)\n",
      "loss: 0.02332112193107605\n",
      "tensor([[855]]) tensor(828.4369, grad_fn=<SubBackward0>)\n",
      "loss: 0.031067965552210808\n",
      "tensor([[855]]) tensor(836.8566, grad_fn=<SubBackward0>)\n",
      "loss: 0.02122035250067711\n",
      "tensor([[855]]) tensor(833.1749, grad_fn=<SubBackward0>)\n",
      "loss: 0.025526437908411026\n",
      "tensor([[855]]) tensor(835.6743, grad_fn=<SubBackward0>)\n",
      "loss: 0.02260321006178856\n",
      "tensor([[855]]) tensor(835.9504, grad_fn=<SubBackward0>)\n",
      "loss: 0.022280223667621613\n",
      "tensor([[855]]) tensor(829.8123, grad_fn=<SubBackward0>)\n",
      "loss: 0.029459314420819283\n",
      "tensor([[855]]) tensor(844.0807, grad_fn=<SubBackward0>)\n",
      "loss: 0.012771053239703178\n",
      "tensor([[855]]) tensor(827.0643, grad_fn=<SubBackward0>)\n",
      "loss: 0.03267328068614006\n",
      "tensor([[855]]) tensor(825.9089, grad_fn=<SubBackward0>)\n",
      "loss: 0.03402472659945488\n",
      "tensor([[855]]) tensor(843.6853, grad_fn=<SubBackward0>)\n",
      "loss: 0.013233600184321404\n",
      "tensor([[855]]) tensor(825.8177, grad_fn=<SubBackward0>)\n",
      "loss: 0.03413132205605507\n",
      "tensor([[855]]) tensor(827.0621, grad_fn=<SubBackward0>)\n",
      "loss: 0.03267586603760719\n",
      "tensor([[855]]) tensor(841.2653, grad_fn=<SubBackward0>)\n",
      "loss: 0.016063936054706573\n",
      "tensor([[855]]) tensor(834.8145, grad_fn=<SubBackward0>)\n",
      "loss: 0.023608773946762085\n",
      "tensor([[855]]) tensor(844.3492, grad_fn=<SubBackward0>)\n",
      "loss: 0.012457096949219704\n",
      "tensor([[855]]) tensor(833.4420, grad_fn=<SubBackward0>)\n",
      "loss: 0.02521410398185253\n",
      "tensor([[855]]) tensor(837.0745, grad_fn=<SubBackward0>)\n",
      "loss: 0.02096550539135933\n",
      "tensor([[855]]) tensor(838.8447, grad_fn=<SubBackward0>)\n",
      "loss: 0.018895091488957405\n",
      "tensor([[855]]) tensor(837.4821, grad_fn=<SubBackward0>)\n",
      "loss: 0.020488806068897247\n",
      "tensor([[855]]) tensor(835.4202, grad_fn=<SubBackward0>)\n",
      "loss: 0.02290039137005806\n",
      "tensor([[855]]) tensor(834.8676, grad_fn=<SubBackward0>)\n",
      "loss: 0.023546703159809113\n",
      "tensor([[855]]) tensor(846.7212, grad_fn=<SubBackward0>)\n",
      "loss: 0.00968281738460064\n",
      "tensor([[855]]) tensor(822.3047, grad_fn=<SubBackward0>)\n",
      "loss: 0.03824016824364662\n",
      "tensor([[855]]) tensor(819.0251, grad_fn=<SubBackward0>)\n",
      "loss: 0.04207581654191017\n",
      "tensor([[855]]) tensor(838.0173, grad_fn=<SubBackward0>)\n",
      "loss: 0.01986280269920826\n",
      "tensor([[855]]) tensor(827.8611, grad_fn=<SubBackward0>)\n",
      "loss: 0.03174138814210892\n",
      "tensor([[855]]) tensor(815.8513, grad_fn=<SubBackward0>)\n",
      "loss: 0.04578796774148941\n",
      "tensor([[855]]) tensor(825.7823, grad_fn=<SubBackward0>)\n",
      "loss: 0.03417274355888367\n",
      "tensor([[855]]) tensor(838.9160, grad_fn=<SubBackward0>)\n",
      "loss: 0.018811678513884544\n",
      "tensor([[855]]) tensor(826.9310, grad_fn=<SubBackward0>)\n",
      "loss: 0.0328291691839695\n",
      "tensor([[855]]) tensor(824.0135, grad_fn=<SubBackward0>)\n",
      "loss: 0.03624153509736061\n",
      "tensor([[855]]) tensor(839.6177, grad_fn=<SubBackward0>)\n",
      "loss: 0.01799100451171398\n",
      "tensor([[855]]) tensor(831.6256, grad_fn=<SubBackward0>)\n",
      "loss: 0.027338502928614616\n",
      "tensor([[855]]) tensor(831.6100, grad_fn=<SubBackward0>)\n",
      "loss: 0.02735677734017372\n",
      "tensor([[855]]) tensor(843.3940, grad_fn=<SubBackward0>)\n",
      "loss: 0.01357421837747097\n",
      "tensor([[855]]) tensor(832.3008, grad_fn=<SubBackward0>)\n",
      "loss: 0.0265487227588892\n",
      "tensor([[855]]) tensor(841.9825, grad_fn=<SubBackward0>)\n",
      "loss: 0.015225166454911232\n",
      "tensor([[855]]) tensor(828.5592, grad_fn=<SubBackward0>)\n",
      "loss: 0.030924871563911438\n",
      "tensor([[855]]) tensor(827.0620, grad_fn=<SubBackward0>)\n",
      "loss: 0.032676082104444504\n",
      "tensor([[855]]) tensor(844.2761, grad_fn=<SubBackward0>)\n",
      "loss: 0.01254261750727892\n",
      "tensor([[855]]) tensor(827.9623, grad_fn=<SubBackward0>)\n",
      "loss: 0.0316229909658432\n",
      "tensor([[855]]) tensor(831.9839, grad_fn=<SubBackward0>)\n",
      "loss: 0.026919394731521606\n",
      "tensor([[855]]) tensor(834.7819, grad_fn=<SubBackward0>)\n",
      "loss: 0.023646876215934753\n",
      "tensor([[855]]) tensor(823.8290, grad_fn=<SubBackward0>)\n",
      "loss: 0.03645726293325424\n",
      "tensor([[855]]) tensor(830.6313, grad_fn=<SubBackward0>)\n",
      "loss: 0.028501329943537712\n",
      "tensor([[855]]) tensor(842.0875, grad_fn=<SubBackward0>)\n",
      "loss: 0.015102274715900421\n",
      "tensor([[855]]) tensor(819.6135, grad_fn=<SubBackward0>)\n",
      "loss: 0.04138772562146187\n",
      "tensor([[855]]) tensor(824.0377, grad_fn=<SubBackward0>)\n",
      "loss: 0.03621317446231842\n",
      "tensor([[855]]) tensor(838.1484, grad_fn=<SubBackward0>)\n",
      "loss: 0.019709430634975433\n",
      "tensor([[855]]) tensor(830.7623, grad_fn=<SubBackward0>)\n",
      "loss: 0.028348242864012718\n",
      "tensor([[855]]) tensor(837.2270, grad_fn=<SubBackward0>)\n",
      "loss: 0.020787164568901062\n",
      "tensor([[855]]) tensor(842.3000, grad_fn=<SubBackward0>)\n",
      "loss: 0.014853708446025848\n",
      "tensor([[855]]) tensor(834.2505, grad_fn=<SubBackward0>)\n",
      "loss: 0.024268362671136856\n",
      "tensor([[855]]) tensor(844.5288, grad_fn=<SubBackward0>)\n",
      "loss: 0.01224697194993496\n",
      "tensor([[855]]) tensor(831.8221, grad_fn=<SubBackward0>)\n",
      "loss: 0.02710863947868347\n",
      "tensor([[855]]) tensor(837.6268, grad_fn=<SubBackward0>)\n",
      "loss: 0.02031954936683178\n",
      "tensor([[855]]) tensor(839.4148, grad_fn=<SubBackward0>)\n",
      "loss: 0.01822829246520996\n",
      "tensor([[855]]) tensor(837.7792, grad_fn=<SubBackward0>)\n",
      "loss: 0.020141243934631348\n",
      "tensor([[855]]) tensor(841.3958, grad_fn=<SubBackward0>)\n",
      "loss: 0.01591132953763008\n",
      "tensor([[855]]) tensor(837.4242, grad_fn=<SubBackward0>)\n",
      "loss: 0.020556533709168434\n",
      "tensor([[855]]) tensor(842.2153, grad_fn=<SubBackward0>)\n",
      "loss: 0.014952863566577435\n",
      "tensor([[855]]) tensor(836.9761, grad_fn=<SubBackward0>)\n",
      "loss: 0.021080614998936653\n",
      "tensor([[855]]) tensor(839.7318, grad_fn=<SubBackward0>)\n",
      "loss: 0.017857493832707405\n",
      "tensor([[855]]) tensor(842.5537, grad_fn=<SubBackward0>)\n",
      "loss: 0.014557098969817162\n",
      "tensor([[855]]) tensor(839.7994, grad_fn=<SubBackward0>)\n",
      "loss: 0.01777839846909046\n",
      "tensor([[855]]) tensor(844.2191, grad_fn=<SubBackward0>)\n",
      "loss: 0.01260925643146038\n",
      "tensor([[855]]) tensor(843.1125, grad_fn=<SubBackward0>)\n",
      "loss: 0.013903452083468437\n",
      "tensor([[855]]) tensor(836.3137, grad_fn=<SubBackward0>)\n",
      "loss: 0.021855369210243225\n",
      "tensor([[855]]) tensor(843.9714, grad_fn=<SubBackward0>)\n",
      "loss: 0.012898976914584637\n",
      "tensor([[855]]) tensor(827.9365, grad_fn=<SubBackward0>)\n",
      "loss: 0.03165316954255104\n",
      "tensor([[855]]) tensor(822.7954, grad_fn=<SubBackward0>)\n",
      "loss: 0.037666186690330505\n",
      "tensor([[855]]) tensor(839.6015, grad_fn=<SubBackward0>)\n",
      "loss: 0.018009940162301064\n",
      "tensor([[855]]) tensor(830.4433, grad_fn=<SubBackward0>)\n",
      "loss: 0.02872130647301674\n",
      "tensor([[855]]) tensor(827.0099, grad_fn=<SubBackward0>)\n",
      "loss: 0.03273695707321167\n",
      "tensor([[855]]) tensor(840.3701, grad_fn=<SubBackward0>)\n",
      "loss: 0.017110973596572876\n",
      "tensor([[855]]) tensor(831.1292, grad_fn=<SubBackward0>)\n",
      "loss: 0.0279191043227911\n",
      "tensor([[855]]) tensor(842.1416, grad_fn=<SubBackward0>)\n",
      "loss: 0.015039026737213135\n",
      "tensor([[855]]) tensor(836.3992, grad_fn=<SubBackward0>)\n",
      "loss: 0.021755356341600418\n",
      "tensor([[855]]) tensor(832.0898, grad_fn=<SubBackward0>)\n",
      "loss: 0.026795469224452972\n",
      "tensor([[855]]) tensor(844.8724, grad_fn=<SubBackward0>)\n",
      "loss: 0.011845103465020657\n",
      "tensor([[855]]) tensor(840.3932, grad_fn=<SubBackward0>)\n",
      "loss: 0.01708402670919895\n",
      "tensor([[855]]) tensor(837.2704, grad_fn=<SubBackward0>)\n",
      "loss: 0.02073642611503601\n",
      "tensor([[855]]) tensor(834.9796, grad_fn=<SubBackward0>)\n",
      "loss: 0.02341572754085064\n",
      "tensor([[855]]) tensor(845.6530, grad_fn=<SubBackward0>)\n",
      "loss: 0.01093214564025402\n",
      "tensor([[855]]) tensor(827.7760, grad_fn=<SubBackward0>)\n",
      "loss: 0.031840935349464417\n",
      "tensor([[855]]) tensor(832.7376, grad_fn=<SubBackward0>)\n",
      "loss: 0.026037883013486862\n",
      "tensor([[855]]) tensor(837.6398, grad_fn=<SubBackward0>)\n",
      "loss: 0.02030429057776928\n",
      "tensor([[855]]) tensor(830.6308, grad_fn=<SubBackward0>)\n",
      "loss: 0.02850198931992054\n",
      "tensor([[855]]) tensor(839.8188, grad_fn=<SubBackward0>)\n",
      "loss: 0.017755769193172455\n",
      "tensor([[855]]) tensor(825.9263, grad_fn=<SubBackward0>)\n",
      "loss: 0.03400438278913498\n",
      "tensor([[855]]) tensor(832.1581, grad_fn=<SubBackward0>)\n",
      "loss: 0.026715677231550217\n",
      "tensor([[855]]) tensor(841.6812, grad_fn=<SubBackward0>)\n",
      "loss: 0.015577509999275208\n",
      "tensor([[855]]) tensor(829.9935, grad_fn=<SubBackward0>)\n",
      "loss: 0.029247405007481575\n",
      "tensor([[855]]) tensor(839.2186, grad_fn=<SubBackward0>)\n",
      "loss: 0.018457798287272453\n",
      "tensor([[855]]) tensor(834.8169, grad_fn=<SubBackward0>)\n",
      "loss: 0.023606007918715477\n",
      "tensor([[855]]) tensor(830.8726, grad_fn=<SubBackward0>)\n",
      "loss: 0.028219157829880714\n",
      "tensor([[855]]) tensor(844.0801, grad_fn=<SubBackward0>)\n",
      "loss: 0.012771766632795334\n",
      "tensor([[855]]) tensor(827.4210, grad_fn=<SubBackward0>)\n",
      "loss: 0.03225618600845337\n",
      "tensor([[855]]) tensor(827.2341, grad_fn=<SubBackward0>)\n",
      "loss: 0.03247470036149025\n",
      "tensor([[855]]) tensor(841.7716, grad_fn=<SubBackward0>)\n",
      "loss: 0.01547184120863676\n",
      "tensor([[855]]) tensor(826.9923, grad_fn=<SubBackward0>)\n",
      "loss: 0.03275749832391739\n",
      "tensor([[855]]) tensor(821.9987, grad_fn=<SubBackward0>)\n",
      "loss: 0.03859804570674896\n",
      "tensor([[855]]) tensor(838.0510, grad_fn=<SubBackward0>)\n",
      "loss: 0.019823433831334114\n",
      "tensor([[855]]) tensor(836.5420, grad_fn=<SubBackward0>)\n",
      "loss: 0.021588312461972237\n",
      "tensor([[855]]) tensor(822.7950, grad_fn=<SubBackward0>)\n",
      "loss: 0.03766661509871483\n",
      "tensor([[855]]) tensor(832.7135, grad_fn=<SubBackward0>)\n",
      "loss: 0.026066098362207413\n",
      "tensor([[855]]) tensor(825.0381, grad_fn=<SubBackward0>)\n",
      "loss: 0.03504320979118347\n",
      "tensor([[855]]) tensor(828.2304, grad_fn=<SubBackward0>)\n",
      "loss: 0.03130946308374405\n",
      "tensor([[855]]) tensor(842.7944, grad_fn=<SubBackward0>)\n",
      "loss: 0.014275534078478813\n",
      "tensor([[855]]) tensor(827.9117, grad_fn=<SubBackward0>)\n",
      "loss: 0.03168224170804024\n",
      "tensor([[855]]) tensor(834.7045, grad_fn=<SubBackward0>)\n",
      "loss: 0.023737428709864616\n",
      "tensor([[855]]) tensor(841.9400, grad_fn=<SubBackward0>)\n",
      "loss: 0.015274868346750736\n",
      "tensor([[855]]) tensor(827.9297, grad_fn=<SubBackward0>)\n",
      "loss: 0.03166118264198303\n",
      "tensor([[855]]) tensor(842.9865, grad_fn=<SubBackward0>)\n",
      "loss: 0.01405093539506197\n",
      "tensor([[855]]) tensor(832.1130, grad_fn=<SubBackward0>)\n",
      "loss: 0.026768412441015244\n",
      "tensor([[855]]) tensor(830.3173, grad_fn=<SubBackward0>)\n",
      "loss: 0.02886861190199852\n",
      "tensor([[855]]) tensor(837.2413, grad_fn=<SubBackward0>)\n",
      "loss: 0.020770441740751266\n",
      "tensor([[855]]) tensor(839.9994, grad_fn=<SubBackward0>)\n",
      "loss: 0.017544537782669067\n",
      "tensor([[855]]) tensor(838.6617, grad_fn=<SubBackward0>)\n",
      "loss: 0.01910916157066822\n",
      "tensor([[855]]) tensor(839.4519, grad_fn=<SubBackward0>)\n",
      "loss: 0.018184924498200417\n",
      "tensor([[855]]) tensor(838.8993, grad_fn=<SubBackward0>)\n",
      "loss: 0.01883123815059662\n",
      "tensor([[855]]) tensor(841.0046, grad_fn=<SubBackward0>)\n",
      "loss: 0.016368897631764412\n",
      "tensor([[855]]) tensor(836.3897, grad_fn=<SubBackward0>)\n",
      "loss: 0.021766422316432\n",
      "tensor([[855]]) tensor(838.1737, grad_fn=<SubBackward0>)\n",
      "loss: 0.01967991143465042\n",
      "tensor([[855]]) tensor(844.3507, grad_fn=<SubBackward0>)\n",
      "loss: 0.012455294840037823\n",
      "tensor([[855]]) tensor(839.9294, grad_fn=<SubBackward0>)\n",
      "loss: 0.017626453191041946\n",
      "tensor([[855]]) tensor(843.8639, grad_fn=<SubBackward0>)\n",
      "loss: 0.013024724088609219\n",
      "tensor([[855]]) tensor(841.9257, grad_fn=<SubBackward0>)\n",
      "loss: 0.015291644260287285\n",
      "tensor([[855]]) tensor(844.5690, grad_fn=<SubBackward0>)\n",
      "loss: 0.012200071476399899\n",
      "tensor([[855]]) tensor(833.8615, grad_fn=<SubBackward0>)\n",
      "loss: 0.02472344972193241\n",
      "tensor([[855]]) tensor(835.8741, grad_fn=<SubBackward0>)\n",
      "loss: 0.02236945554614067\n",
      "tensor([[855]]) tensor(831.0004, grad_fn=<SubBackward0>)\n",
      "loss: 0.028069712221622467\n",
      "tensor([[855]]) tensor(828.0917, grad_fn=<SubBackward0>)\n",
      "loss: 0.031471654772758484\n",
      "tensor([[855]]) tensor(842.7386, grad_fn=<SubBackward0>)\n",
      "loss: 0.014340799301862717\n",
      "tensor([[855]]) tensor(838.1901, grad_fn=<SubBackward0>)\n",
      "loss: 0.019660726189613342\n",
      "tensor([[855]]) tensor(844.4126, grad_fn=<SubBackward0>)\n",
      "loss: 0.012382891029119492\n",
      "tensor([[855]]) tensor(827.9239, grad_fn=<SubBackward0>)\n",
      "loss: 0.03166796639561653\n",
      "tensor([[855]]) tensor(830.4466, grad_fn=<SubBackward0>)\n",
      "loss: 0.028717434033751488\n",
      "tensor([[855]]) tensor(845.0414, grad_fn=<SubBackward0>)\n",
      "loss: 0.011647524312138557\n",
      "tensor([[855]]) tensor(837.5430, grad_fn=<SubBackward0>)\n",
      "loss: 0.020417561754584312\n",
      "tensor([[855]]) tensor(838.7759, grad_fn=<SubBackward0>)\n",
      "loss: 0.018975598737597466\n",
      "tensor([[855]]) tensor(837.1453, grad_fn=<SubBackward0>)\n",
      "loss: 0.020882660523056984\n",
      "tensor([[855]]) tensor(839.7585, grad_fn=<SubBackward0>)\n",
      "loss: 0.01782626286149025\n",
      "tensor([[855]]) tensor(830.6938, grad_fn=<SubBackward0>)\n",
      "loss: 0.02842826582491398\n",
      "tensor([[855]]) tensor(839.9291, grad_fn=<SubBackward0>)\n",
      "loss: 0.017626775428652763\n",
      "tensor([[855]]) tensor(840.6371, grad_fn=<SubBackward0>)\n",
      "loss: 0.01679864153265953\n",
      "tensor([[855]]) tensor(840.6196, grad_fn=<SubBackward0>)\n",
      "loss: 0.01681918278336525\n",
      "tensor([[855]]) tensor(842.3440, grad_fn=<SubBackward0>)\n",
      "loss: 0.014802346006035805\n",
      "tensor([[855]]) tensor(841.5547, grad_fn=<SubBackward0>)\n",
      "loss: 0.01572549343109131\n",
      "tensor([[855]]) tensor(832.5524, grad_fn=<SubBackward0>)\n",
      "loss: 0.026254575699567795\n",
      "tensor([[855]]) tensor(833.6370, grad_fn=<SubBackward0>)\n",
      "loss: 0.024986043572425842\n",
      "tensor([[855]]) tensor(840.2830, grad_fn=<SubBackward0>)\n",
      "loss: 0.017212824895977974\n",
      "tensor([[855]]) tensor(839.5735, grad_fn=<SubBackward0>)\n",
      "loss: 0.018042705953121185\n",
      "tensor([[855]]) tensor(843.0625, grad_fn=<SubBackward0>)\n",
      "loss: 0.013961952179670334\n",
      "tensor([[855]]) tensor(846.0073, grad_fn=<SubBackward0>)\n",
      "loss: 0.010517713613808155\n",
      "tensor([[855]]) tensor(832.0607, grad_fn=<SubBackward0>)\n",
      "loss: 0.026829661801457405\n",
      "tensor([[855]]) tensor(836.7438, grad_fn=<SubBackward0>)\n",
      "loss: 0.021352222189307213\n",
      "tensor([[855]]) tensor(836.7018, grad_fn=<SubBackward0>)\n",
      "loss: 0.021401388570666313\n",
      "tensor([[855]]) tensor(834.5927, grad_fn=<SubBackward0>)\n",
      "loss: 0.023868262767791748\n",
      "tensor([[855]]) tensor(844.5424, grad_fn=<SubBackward0>)\n",
      "loss: 0.012231177650392056\n",
      "tensor([[855]]) tensor(835.3544, grad_fn=<SubBackward0>)\n",
      "loss: 0.022977344691753387\n",
      "tensor([[855]]) tensor(842.6833, grad_fn=<SubBackward0>)\n",
      "loss: 0.014405438676476479\n",
      "tensor([[855]]) tensor(837.0188, grad_fn=<SubBackward0>)\n",
      "loss: 0.02103060856461525\n",
      "tensor([[855]]) tensor(836.9258, grad_fn=<SubBackward0>)\n",
      "loss: 0.021139366552233696\n",
      "tensor([[855]]) tensor(844.1497, grad_fn=<SubBackward0>)\n",
      "loss: 0.012690422125160694\n",
      "tensor([[855]]) tensor(835.6473, grad_fn=<SubBackward0>)\n",
      "loss: 0.02263474464416504\n",
      "tensor([[855]]) tensor(844.2275, grad_fn=<SubBackward0>)\n",
      "loss: 0.012599441222846508\n",
      "tensor([[855]]) tensor(835.0767, grad_fn=<SubBackward0>)\n",
      "loss: 0.023302115499973297\n",
      "tensor([[855]]) tensor(838.9081, grad_fn=<SubBackward0>)\n",
      "loss: 0.018820922821760178\n",
      "tensor([[855]]) tensor(833.3277, grad_fn=<SubBackward0>)\n",
      "loss: 0.025347722694277763\n",
      "tensor([[855]]) tensor(839.0107, grad_fn=<SubBackward0>)\n",
      "loss: 0.0187009759247303\n",
      "tensor([[855]]) tensor(836.9058, grad_fn=<SubBackward0>)\n",
      "loss: 0.02116285264492035\n",
      "tensor([[855]]) tensor(832.5027, grad_fn=<SubBackward0>)\n",
      "loss: 0.02631266601383686\n",
      "tensor([[855]]) tensor(843.3276, grad_fn=<SubBackward0>)\n",
      "loss: 0.013651958666741848\n",
      "tensor([[855]]) tensor(839.6044, grad_fn=<SubBackward0>)\n",
      "loss: 0.018006548285484314\n",
      "tensor([[855]]) tensor(842.7516, grad_fn=<SubBackward0>)\n",
      "loss: 0.014325540512800217\n",
      "tensor([[855]]) tensor(837.9341, grad_fn=<SubBackward0>)\n",
      "loss: 0.019960101693868637\n",
      "tensor([[855]]) tensor(840.1668, grad_fn=<SubBackward0>)\n",
      "loss: 0.01734876073896885\n",
      "tensor([[855]]) tensor(844.7820, grad_fn=<SubBackward0>)\n",
      "loss: 0.011950880289077759\n",
      "tensor([[855]]) tensor(847.0381, grad_fn=<SubBackward0>)\n",
      "loss: 0.009312109090387821\n",
      "tensor([[855]]) tensor(844.6067, grad_fn=<SubBackward0>)\n",
      "loss: 0.012155900709331036\n",
      "tensor([[855]]) tensor(842.7812, grad_fn=<SubBackward0>)\n",
      "loss: 0.014290899969637394\n",
      "tensor([[855]]) tensor(847.6670, grad_fn=<SubBackward0>)\n",
      "loss: 0.008576581254601479\n",
      "tensor([[855]]) tensor(847.6264, grad_fn=<SubBackward0>)\n",
      "loss: 0.008624071255326271\n",
      "tensor([[855]]) tensor(841.3895, grad_fn=<SubBackward0>)\n",
      "loss: 0.015918772667646408\n",
      "tensor([[855]]) tensor(842.4735, grad_fn=<SubBackward0>)\n",
      "loss: 0.014650882221758366\n",
      "tensor([[855]]) tensor(848.3695, grad_fn=<SubBackward0>)\n",
      "loss: 0.007754962891340256\n",
      "tensor([[855]]) tensor(845.7604, grad_fn=<SubBackward0>)\n",
      "loss: 0.01080654188990593\n",
      "tensor([[855]]) tensor(832.4478, grad_fn=<SubBackward0>)\n",
      "loss: 0.026376860216259956\n",
      "tensor([[855]]) tensor(843.6779, grad_fn=<SubBackward0>)\n",
      "loss: 0.013242291286587715\n",
      "tensor([[855]]) tensor(830.3433, grad_fn=<SubBackward0>)\n",
      "loss: 0.028838254511356354\n",
      "tensor([[855]]) tensor(826.3698, grad_fn=<SubBackward0>)\n",
      "loss: 0.033485669642686844\n",
      "tensor([[855]]) tensor(843.1968, grad_fn=<SubBackward0>)\n",
      "loss: 0.013804974034428596\n",
      "tensor([[855]]) tensor(829.7219, grad_fn=<SubBackward0>)\n",
      "loss: 0.029564984142780304\n",
      "tensor([[ 0.4437],\n",
      "        [ 0.4437],\n",
      "        [ 0.4437],\n",
      "        [ 6.7021],\n",
      "        [ 3.3856],\n",
      "        [ 7.5824],\n",
      "        [-1.2083],\n",
      "        [ 7.7480],\n",
      "        [ 4.3320],\n",
      "        [ 4.5745],\n",
      "        [ 4.2519],\n",
      "        [ 4.6101],\n",
      "        [ 7.3214],\n",
      "        [ 9.3731],\n",
      "        [ 2.6345],\n",
      "        [ 8.8078],\n",
      "        [ 1.4581],\n",
      "        [ 8.5021],\n",
      "        [ 5.2153],\n",
      "        [14.5621]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "args = {\n",
    "    'num_layers': 5, \n",
    "    'batch_size': 32, \n",
    "    'hidden_dim': 64, \n",
    "    'dropout': 0, \n",
    "    'epochs': 500, \n",
    "    'opt': 'adam', \n",
    "    'opt_scheduler': 'none', \n",
    "    'opt_restart': 0, \n",
    "    'weight_decay': 5e-3, \n",
    "    'lr': 0.00001\n",
    "}\n",
    "args = objectview(args)\n",
    "model = CBN(1, 1, 2, args)\n",
    "loss_fn = DualLoss()\n",
    "data = dataset[50]\n",
    "\n",
    "\n",
    "scheduler, opt = build_optimizer(args, model.parameters())\n",
    "for i in range(7500):\n",
    "    model.train()\n",
    "    opt.zero_grad()\n",
    "    pred = model(data.x, data.edge_index, data.edge_attr)\n",
    "    loss = loss_fn(pred, data.y, data.x, data.edge_index, data.edge_attr)\n",
    "    print(f\"loss: {loss.item()}\")\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([482.83713, 468.93777,   0.     ,   0.     ,   0.     ,   0.     ,\n",
       "         0.     ,   0.     ,   0.     ,   0.     , 164.39926,   0.     ,\n",
       "         0.     ,   0.     ,   0.     ,   0.     ,   0.     ,   0.     ,\n",
       "         0.     ,   0.     ], dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = pred.detach().numpy().flatten()\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import trange\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "import torch_geometric.nn as pyg_nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def train(dataset, args):\n",
    "\n",
    "    print(\"Node task. test set size:\", np.sum(dataset[0]['test_mask'].numpy()))\n",
    "    print()\n",
    "    test_loader = loader = DataLoader(dataset, batch_size=args.batch_size, shuffle=False)\n",
    "\n",
    "    # build model\n",
    "    output_dim = 1 # we predict scalar potential values for each vertex\n",
    "    model = CBN(dataset.num_node_features, output_dim, dataset.num_edge_features, args)\n",
    "    scheduler, opt = build_optimizer(args, model.parameters())\n",
    "\n",
    "    # train\n",
    "    losses = []\n",
    "    test_accs = []\n",
    "    best_acc = 0\n",
    "    best_model = None\n",
    "    for epoch in trange(args.epochs, desc=\"Training\", unit=\"Epochs\"):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        for batch in loader:\n",
    "            print(f\"BATCH {batch}\")\n",
    "            opt.zero_grad()\n",
    "            pred = model(batch)\n",
    "            label = batch.y\n",
    "            print(f\"BATCH y: {batch.y.shape}\")\n",
    "            # pred = pred[batch.train_mask]\n",
    "            # label = label[batch.train_mask]\n",
    "            loss = model.loss(pred, label)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total_loss += loss.item() * batch.num_graphs\n",
    "        total_loss /= len(loader.dataset)\n",
    "        losses.append(total_loss)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "          test_acc = test(test_loader, model)\n",
    "          test_accs.append(test_acc)\n",
    "          if test_acc > best_acc:\n",
    "            best_acc = test_acc\n",
    "            best_model = copy.deepcopy(model)\n",
    "        else:\n",
    "          test_accs.append(test_accs[-1])\n",
    "\n",
    "    return test_accs, losses, best_model, best_acc, test_loader\n",
    "\n",
    "def test(loader, test_model, is_validation=False, save_model_preds=False, model_type=None):\n",
    "    test_model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    # Note that Cora is only one graph!\n",
    "    for data in loader:\n",
    "        with torch.no_grad():\n",
    "            # max(dim=1) returns values, indices tuple; only need indices\n",
    "            pred = test_model(data).max(dim=1)[1]\n",
    "            label = data.y\n",
    "\n",
    "        mask = data.val_mask if is_validation else data.test_mask\n",
    "        # node classification: only evaluate on nodes in test set\n",
    "        pred = pred[mask]\n",
    "        label = label[mask]\n",
    "\n",
    "        if save_model_preds:\n",
    "          print (\"Saving Model Predictions for Model Type\", model_type)\n",
    "\n",
    "          data = {}\n",
    "          data['pred'] = pred.view(-1).cpu().detach().numpy()\n",
    "          data['label'] = label.view(-1).cpu().detach().numpy()\n",
    "\n",
    "          df = pd.DataFrame(data=data)\n",
    "          # Save locally as csv\n",
    "          df.to_csv('MinCostFlow-' + model_type + '.csv', sep=',', index=False)\n",
    "\n",
    "        correct += pred.eq(label).sum().item()\n",
    "\n",
    "    total = 0\n",
    "    for data in loader.dataset:\n",
    "        total += torch.sum(data.val_mask if is_validation else data.test_mask).item()\n",
    "\n",
    "    return correct / total\n",
    "\n",
    "class objectview(object):\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
