{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch has version 1.13.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch has version {}\".format(torch.__version__))\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import NNConv, TransformerConv\n",
    "import torch.nn.functional as F\n",
    "\n",
    "np.random.seed(1)\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from MinCostDataset import MinCostDataset\n",
    "\n",
    "dataset = MinCostDataset(root = \"./data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinCostDataset(100)\n",
      "num features: 1\n",
      "num edge features: 2\n",
      "first graph: Data(x=[77, 1], edge_index=[2, 230], edge_attr=[230, 2], y=[77, 2], reduced_cost=[230, 3], filename='netgen_72.txt')\n"
     ]
    }
   ],
   "source": [
    "def dataset_information(dataset):\n",
    "    print(dataset)\n",
    "    print(f\"num features: {dataset.num_features}\")\n",
    "    print(f\"num edge features: {dataset.num_edge_features}\")\n",
    "    print(f\"first graph: {dataset[0]}\")\n",
    "\n",
    "dataset_information(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_test_validation_split(dataset, train = 0.7, validation = 0.15):\n",
    "    \"\"\"\n",
    "    Test split is 1 - train - validation\n",
    "    \"\"\"\n",
    "\n",
    "    length = dataset.len()\n",
    "    shuffled_dataset = np.arange(length)\n",
    "    np.random.shuffle(shuffled_dataset)\n",
    "\n",
    "    train_cutoff = int(train * length)\n",
    "    validation_cutoff = int((train + validation) * length)\n",
    "\n",
    "    train_data = shuffled_dataset[:train_cutoff]\n",
    "    validation_data = shuffled_dataset[train_cutoff: validation_cutoff]\n",
    "    test_data = shuffled_dataset[validation_cutoff:]\n",
    "\n",
    "    return train_data, validation_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_split_directories(dataset, split, split_name):\n",
    "    src_folder = dataset.processed_dir\n",
    "    dst_folder = os.path.join(dataset.root, split_name)\n",
    "\n",
    "    # Remove files in case some were already present\n",
    "    if os.path.exists(dst_folder):\n",
    "        shutil.rmtree(dst_folder)\n",
    "    os.makedirs(dst_folder)\n",
    "    dst_index = 0\n",
    "    for file_id in split:\n",
    "        src_file_name = f\"data_{file_id}.pt\"\n",
    "        # The files are always expected by PyG to be ordered\n",
    "        dst_file_name = f\"data_{dst_index}.pt\"\n",
    "        src = os.path.join(src_folder, src_file_name)\n",
    "        dst = os.path.join(dst_folder, dst_file_name)\n",
    "        shutil.copyfile(src, dst)\n",
    "        dst_index += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_dataset(dataset, train_frac = 0.7, validation_frac = 0.15):\n",
    "    train, validation, test = train_test_validation_split(dataset, train_frac, validation_frac)\n",
    "    create_split_directories(dataset, train, \"data_train/processed\")\n",
    "    create_split_directories(dataset, test, \"data_test/processed\")\n",
    "    create_split_directories(dataset, validation, \"data_validation/processed\")\n",
    "split_dataset(dataset, validation_frac = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CBN(torch.nn.Module):\n",
    "    #TODO cite the colab\n",
    "    def __init__(self, input_dim, output_dim, edge_feature_dim, args):\n",
    "        super(CBN, self).__init__()\n",
    "\n",
    "        hidden_dim = args.hidden_dim\n",
    "        num_layers = args.num_layers\n",
    "        dropout = args.dropout\n",
    "\n",
    "        if num_layers > 1:\n",
    "            conv_modules = [NNConv(input_dim, hidden_dim, nn.Linear(edge_feature_dim, input_dim * hidden_dim))]\n",
    "            conv_modules.extend([NNConv(hidden_dim, hidden_dim, nn.Linear(edge_feature_dim, hidden_dim * hidden_dim)) for _ in range(num_layers - 2)])\n",
    "            conv_modules.append(NNConv(hidden_dim, output_dim, nn.Linear(edge_feature_dim, hidden_dim * output_dim)))\n",
    "\n",
    "            self.convs = nn.ModuleList(conv_modules)\n",
    "        else:\n",
    "            self.convs = nn.ModuleList([NNConv(input_dim, output_dim, nn.Linear(edge_feature_dim, input_dim * output_dim))])\n",
    "\n",
    "        self.bns = nn.ModuleList([nn.BatchNorm1d(hidden_dim) for _ in range(num_layers - 1)])\n",
    "\n",
    "        # self.post_mp = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Probability of an element getting zeroed\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "        # self.post_mp.reset_parameters()\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        for i in range(self.num_layers - 1):\n",
    "            x = self.convs[i](x, edge_index, edge_attr)\n",
    "            x = self.bns[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, self.dropout, self.training)\n",
    "        x = self.convs[-1](x, edge_index, edge_attr)\n",
    "        # x = F.relu(x)\n",
    "        # x = self.post_mp(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def dual_value(pred, x, edge_attr, edge_index):\n",
    "        reduced_cost = edge_attr[:, 1] + pred[edge_index[0]].squeeze() - pred[edge_index[1]].squeeze()\n",
    "        return -torch.dot(pred.squeeze(), x.squeeze()) - torch.dot(edge_attr[:, 0], F.relu(-reduced_cost))\n",
    "\n",
    "    # def loss(self, pred, label, x, edge_index, edge_attr):\n",
    "    #     # edge_attr[0] is capacity, edge_attr[1] is cost\n",
    "    #     print(pred.shape)\n",
    "    #     print(edge_index[0].shape)\n",
    "    #     print(pred[edge_index[1]].shape)\n",
    "    #     print(edge_attr[:, 1].shape)\n",
    "    #     reduced_cost = pred[edge_index[1]].squeeze() - pred[edge_index[0]].squeeze() - edge_attr[:, 1]\n",
    "    #     print(reduced_cost.shape)\n",
    "    #     return label - torch.dot(pred.squeeze(), x.squeeze()) - torch.dot(edge_attr[:, 0], F.relu(reduced_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "outputs": [],
   "source": [
    "class CBN_GAT(torch.nn.Module):\n",
    "    #TODO cite the colab\n",
    "    def __init__(self, input_dim, output_dim, edge_feature_dim, args):\n",
    "        super(CBN_GAT, self).__init__()\n",
    "\n",
    "        hidden_dim = args.hidden_dim\n",
    "        num_layers = args.num_layers\n",
    "        dropout = args.dropout\n",
    "\n",
    "        if num_layers > 1:\n",
    "            conv_modules = [TransformerConv(input_dim, hidden_dim, heads = args.heads, edge_dim = edge_feature_dim)]\n",
    "            conv_modules.extend([TransformerConv(hidden_dim * args.heads, hidden_dim, heads = args.heads, edge_dim = edge_feature_dim) for _ in range(num_layers - 2)])\n",
    "            conv_modules.append(TransformerConv(hidden_dim * args.heads, output_dim, heads = args.heads, edge_dim = edge_feature_dim))\n",
    "\n",
    "            self.convs = nn.ModuleList(conv_modules)\n",
    "        else:\n",
    "            self.convs = nn.ModuleList([TransformerConv(input_dim, output_dim, heads = args.heads, edge_dim = edge_feature_dim)])\n",
    "\n",
    "        self.bns = nn.ModuleList([nn.BatchNorm1d(hidden_dim) for _ in range(num_layers - 1)])\n",
    "\n",
    "        # self.post_mp = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Probability of an element getting zeroed\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "        # self.post_mp.reset_parameters()\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        print(\"h\")\n",
    "        for i in range(self.num_layers - 1):\n",
    "            x = self.convs[i](x, edge_index, edge_attr)\n",
    "            x = self.bns[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, self.dropout, self.training)\n",
    "        x = self.convs[-1](x, edge_index, edge_attr)\n",
    "        # x = F.relu(x)\n",
    "        # x = self.post_mp(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def dual_value(N, p):\n",
    "        return np.sum([p[i] * N.b[i] for i in N.V]) + np.sum([N.u[e] * max(0, p[e[1]] - p[e[0]] - N.c[e]) for e in N.E])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DualLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DualLoss, self).__init__()\n",
    "\n",
    "    def forward(self, pred, label, x, edge_index, edge_attr):\n",
    "        reduced_cost = edge_attr[:, 1] + pred[edge_index[0]].squeeze() - pred[edge_index[1]].squeeze()\n",
    "        potentials = label[:, 1]\n",
    "        opt = label[0, 0]\n",
    "        opt_loss = (opt + torch.dot(pred.squeeze(), x.squeeze()) + torch.dot(edge_attr[:, 0], F.relu(-reduced_cost))) / opt\n",
    "        potential_loss = torch.linalg.vector_norm(pred-potentials, ord=2)\n",
    "        loss = opt_loss + 0.000005 * potential_loss\n",
    "        print(f\"opt_loss: {opt_loss}, 'pot_loss: {0.000005 * potential_loss}\")\n",
    "        return loss\n",
    "        # edge_attr[0] is capacity, edge_attr[1] is cost\n",
    "        reduced_cost = pred[edge_index[1]].squeeze() - pred[edge_index[0]].squeeze() - edge_attr[:, 1]\n",
    "\n",
    "        reg = 0.0005 * sum(F.relu(-reduced_cost))\n",
    "\n",
    "        return loss + reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "outputs": [],
   "source": [
    "class CBN_GAT_reduced_cost(torch.nn.Module):\n",
    "    #TODO cite the colab\n",
    "    def __init__(self, input_dim, output_dim, edge_feature_dim, args):\n",
    "        super(CBN_GAT_reduced_cost, self).__init__()\n",
    "\n",
    "        hidden_dim = args.hidden_dim\n",
    "        num_layers = args.num_layers\n",
    "        dropout = args.dropout\n",
    "\n",
    "        conv_modules = [TransformerConv(input_dim, hidden_dim, heads = args.heads, edge_dim = edge_feature_dim)]\n",
    "        conv_modules.extend([TransformerConv(hidden_dim * args.heads, hidden_dim, heads = args.heads, edge_dim = edge_feature_dim) for _ in range(num_layers - 1)])\n",
    "\n",
    "        self.convs = nn.ModuleList(conv_modules)\n",
    "\n",
    "        self.bns = nn.ModuleList([nn.BatchNorm1d(hidden_dim * args.heads) for _ in range(num_layers - 1)])\n",
    "\n",
    "        # self.predictor = nn.Linear(2 * hidden_dim * args.heads, output_dim)\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(2 * args.heads * hidden_dim, hidden_dim), nn.Dropout(args.dropout),\n",
    "            nn.Linear(hidden_dim, output_dim))\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Probability of an element getting zeroed\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "        self.predictor.reset_parameters()\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        for i in range(self.num_layers - 1):\n",
    "            x = self.convs[i](x, edge_index, edge_attr)\n",
    "            x = self.bns[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, self.dropout, self.training)\n",
    "        x = self.convs[-1](x, edge_index, edge_attr)\n",
    "        edges = torch.concat((x[edge_index[0]], x[edge_index[1]]), dim = -1)\n",
    "        x = self.predictor(edges)\n",
    "        x = F.log_softmax(x, dim = 1)\n",
    "        return x\n",
    "\n",
    "    def loss(self):\n",
    "        return nn.CrossEntropyLoss()\n",
    "\n",
    "    def accuracy(self, preds, labels):\n",
    "        predicted_classes = torch.argmax(preds, dim = 1)\n",
    "        label_values = torch.argmax(labels, dim = 1)\n",
    "        # print(preds[:10])\n",
    "        # print(predicted_classes[:10])\n",
    "        # print(labels[:10])\n",
    "        # print(torch.where(predicted_classes == label_values, 1, 0)[:10])\n",
    "        accuracy = torch.mean(torch.where(predicted_classes == label_values, 1, 0).float()).item()\n",
    "        return round(accuracy, 4)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class objectview(object):\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def build_optimizer(args, params):\n",
    "    weight_decay = args.weight_decay\n",
    "    filter_fn = filter(lambda p : p.requires_grad, params)\n",
    "    if args.opt == 'adam':\n",
    "        optimizer = optim.Adam(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
    "    elif args.opt == 'sgd':\n",
    "        optimizer = optim.SGD(filter_fn, lr=args.lr, momentum=0.95, weight_decay=weight_decay)\n",
    "    elif args.opt == 'rmsprop':\n",
    "        optimizer = optim.RMSprop(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
    "    elif args.opt == 'adagrad':\n",
    "        optimizer = optim.Adagrad(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
    "    if args.opt_scheduler == 'none':\n",
    "        return None, optimizer\n",
    "    elif args.opt_scheduler == 'step':\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=args.opt_decay_step, gamma=args.opt_decay_rate)\n",
    "    elif args.opt_scheduler == 'cos':\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.opt_restart)\n",
    "    return scheduler, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "outputs": [],
   "source": [
    "#TODO handle batch size > 1\n",
    "args = {\n",
    "    'num_layers': 3,\n",
    "    'batch_size': 1, # TODO implement\n",
    "    'hidden_dim': 32,\n",
    "    'heads': 4,\n",
    "    'dropout': 0, #TODO put back for training\n",
    "    'epochs': 50, # TODO put back to 500\n",
    "    'opt': 'adam',\n",
    "    'opt_scheduler': 'none',\n",
    "    'opt_restart': 0,\n",
    "    'weight_decay': 5e-3,\n",
    "    'lr': 0.001,\n",
    "    'model_type': \"GAT\"\n",
    "}\n",
    "args = objectview(args)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.5322763919830322\n",
      "loss: 6.383935451507568\n",
      "loss: 3.2436819076538086\n",
      "loss: 1.3105891942977905\n",
      "loss: 2.2963016033172607\n",
      "loss: 2.2947781085968018\n",
      "loss: 1.5433287620544434\n",
      "loss: 0.9617912769317627\n",
      "loss: 1.3167959451675415\n",
      "loss: 1.611685037612915\n",
      "loss: 1.2087196111679077\n",
      "loss: 0.834313690662384\n",
      "loss: 0.8661108016967773\n",
      "loss: 1.015351414680481\n",
      "loss: 1.0669523477554321\n",
      "loss: 0.9550005197525024\n",
      "loss: 0.7628633379936218\n",
      "loss: 0.6728307604789734\n",
      "loss: 0.6848090887069702\n",
      "loss: 0.7870627641677856\n",
      "loss: 0.6968690752983093\n",
      "loss: 0.5640633702278137\n",
      "loss: 0.560569167137146\n",
      "loss: 0.6266055107116699\n",
      "loss: 0.6454276442527771\n",
      "loss: 0.6004884243011475\n",
      "loss: 0.525609016418457\n",
      "loss: 0.5461789965629578\n",
      "loss: 0.5813808441162109\n",
      "loss: 0.5477529764175415\n",
      "loss: 0.4947778880596161\n",
      "loss: 0.49248936772346497\n",
      "loss: 0.5164047479629517\n",
      "loss: 0.5192716717720032\n",
      "loss: 0.49093693494796753\n",
      "loss: 0.4601995646953583\n",
      "loss: 0.4607696533203125\n",
      "loss: 0.4715564250946045\n",
      "loss: 0.4629460871219635\n",
      "loss: 0.44121015071868896\n",
      "loss: 0.4482826590538025\n",
      "loss: 0.4364873170852661\n",
      "loss: 0.4343588650226593\n",
      "loss: 0.4252574145793915\n",
      "loss: 0.4207128584384918\n",
      "loss: 0.41905325651168823\n",
      "loss: 0.4155343472957611\n",
      "loss: 0.4143778681755066\n",
      "loss: 0.40217775106430054\n",
      "loss: 0.40102091431617737\n",
      "loss: 0.3987219035625458\n",
      "loss: 0.39378634095191956\n",
      "loss: 0.3898850679397583\n",
      "loss: 0.38801226019859314\n",
      "loss: 0.3839506208896637\n",
      "loss: 0.37849679589271545\n",
      "loss: 0.37526771426200867\n",
      "loss: 0.3736666440963745\n",
      "loss: 0.3705989122390747\n",
      "loss: 0.36674100160598755\n",
      "loss: 0.36439183354377747\n",
      "loss: 0.3623950481414795\n",
      "loss: 0.35865089297294617\n",
      "loss: 0.3548865020275116\n",
      "loss: 0.3515215218067169\n",
      "loss: 0.3482776880264282\n",
      "loss: 0.34504491090774536\n",
      "loss: 0.3428608179092407\n",
      "loss: 0.34018048644065857\n",
      "loss: 0.3368406295776367\n",
      "loss: 0.33431607484817505\n",
      "loss: 0.33185961842536926\n",
      "loss: 0.328870952129364\n",
      "loss: 0.3264157474040985\n",
      "loss: 0.32398727536201477\n",
      "loss: 0.3210769295692444\n",
      "loss: 0.3186987638473511\n",
      "loss: 0.3165557086467743\n",
      "loss: 0.31393519043922424\n",
      "loss: 0.3116074204444885\n",
      "loss: 0.3091254234313965\n",
      "loss: 0.30688944458961487\n",
      "loss: 0.3046942949295044\n",
      "loss: 0.30242517590522766\n",
      "loss: 0.3001615107059479\n",
      "loss: 0.297887921333313\n",
      "loss: 0.2957039177417755\n",
      "loss: 0.2936815023422241\n",
      "loss: 0.2915719151496887\n",
      "loss: 0.2893734276294708\n",
      "loss: 0.28728175163269043\n",
      "loss: 0.28520721197128296\n",
      "loss: 0.2830657362937927\n",
      "loss: 0.28091922402381897\n",
      "loss: 0.2788603603839874\n",
      "loss: 0.2767940163612366\n",
      "loss: 0.2746042311191559\n",
      "loss: 0.2725653052330017\n",
      "loss: 0.27045297622680664\n",
      "loss: 0.2684140205383301\n",
      "loss: 0.2662949562072754\n",
      "loss: 0.2641105055809021\n",
      "loss: 0.2621491849422455\n",
      "loss: 0.2600100636482239\n",
      "loss: 0.25798171758651733\n",
      "loss: 0.2558833360671997\n",
      "loss: 0.2537652850151062\n",
      "loss: 0.25178271532058716\n",
      "loss: 0.24972887337207794\n",
      "loss: 0.24778136610984802\n",
      "loss: 0.24585534632205963\n",
      "loss: 0.24378077685832977\n",
      "loss: 0.2415851354598999\n",
      "loss: 0.23954708874225616\n",
      "loss: 0.237509086728096\n",
      "loss: 0.2354682981967926\n",
      "loss: 0.23367571830749512\n",
      "loss: 0.2316308170557022\n",
      "loss: 0.2296566516160965\n",
      "loss: 0.22779925167560577\n",
      "loss: 0.22594328224658966\n",
      "loss: 0.22379674017429352\n",
      "loss: 0.22181177139282227\n",
      "loss: 0.219849094748497\n",
      "loss: 0.2177223265171051\n",
      "loss: 0.21566669642925262\n",
      "loss: 0.2139090895652771\n",
      "loss: 0.21223698556423187\n",
      "loss: 0.21036911010742188\n",
      "loss: 0.20855200290679932\n",
      "loss: 0.2068251073360443\n",
      "loss: 0.20520304143428802\n",
      "loss: 0.20373724400997162\n",
      "loss: 0.20178276300430298\n",
      "loss: 0.20095930993556976\n",
      "loss: 0.19939671456813812\n",
      "loss: 0.19790364801883698\n",
      "loss: 0.19640924036502838\n",
      "loss: 0.19497767090797424\n",
      "loss: 0.19333049654960632\n",
      "loss: 0.19171670079231262\n",
      "loss: 0.1901060789823532\n",
      "loss: 0.18864980340003967\n",
      "loss: 0.18756647408008575\n",
      "loss: 0.18642698228359222\n",
      "loss: 0.18542039394378662\n",
      "loss: 0.18383841216564178\n",
      "loss: 0.18198427557945251\n",
      "loss: 0.1808841973543167\n",
      "loss: 0.17988868057727814\n",
      "loss: 0.1789008378982544\n",
      "loss: 0.17744837701320648\n",
      "loss: 0.17588992416858673\n",
      "loss: 0.1749936193227768\n",
      "loss: 0.17414763569831848\n",
      "loss: 0.17291587591171265\n",
      "loss: 0.17163237929344177\n",
      "loss: 0.17053240537643433\n",
      "loss: 0.1699223667383194\n",
      "loss: 0.16878187656402588\n",
      "loss: 0.1674915850162506\n",
      "loss: 0.16648253798484802\n",
      "loss: 0.1656745970249176\n",
      "loss: 0.16488705575466156\n",
      "loss: 0.1639298051595688\n",
      "loss: 0.16289550065994263\n",
      "loss: 0.16167539358139038\n",
      "loss: 0.1610305905342102\n",
      "loss: 0.16085727512836456\n",
      "loss: 0.160175621509552\n",
      "loss: 0.15907739102840424\n",
      "loss: 0.15765570104122162\n",
      "loss: 0.1568746268749237\n",
      "loss: 0.1566472202539444\n",
      "loss: 0.15593485534191132\n",
      "loss: 0.1549205631017685\n",
      "loss: 0.1536872386932373\n",
      "loss: 0.15295156836509705\n",
      "loss: 0.1647380143404007\n",
      "loss: 0.15677525103092194\n",
      "loss: 0.1804257035255432\n",
      "loss: 0.17696833610534668\n",
      "loss: 0.166428342461586\n",
      "loss: 0.16864298284053802\n",
      "loss: 0.1627921164035797\n",
      "loss: 0.160241037607193\n",
      "loss: 0.163282111287117\n",
      "loss: 0.16189253330230713\n",
      "loss: 0.15896189212799072\n",
      "loss: 0.15788504481315613\n",
      "loss: 0.15552827715873718\n",
      "loss: 0.15409258008003235\n",
      "loss: 0.15295861661434174\n",
      "loss: 0.15179555118083954\n",
      "loss: 0.15178385376930237\n",
      "loss: 0.14831353724002838\n",
      "loss: 0.14693401753902435\n",
      "loss: 0.14709557592868805\n",
      "loss: 0.1454983800649643\n",
      "loss: 0.14407040178775787\n",
      "loss: 0.14298902451992035\n",
      "loss: 0.14231930673122406\n",
      "loss: 0.14161993563175201\n",
      "loss: 0.14045947790145874\n",
      "loss: 0.1397773176431656\n",
      "loss: 0.13910047709941864\n",
      "loss: 0.13826392590999603\n",
      "loss: 0.13736863434314728\n",
      "loss: 0.13701315224170685\n",
      "loss: 0.13631854951381683\n",
      "loss: 0.1355496048927307\n",
      "loss: 0.13498732447624207\n",
      "loss: 0.1344050019979477\n",
      "loss: 0.13374316692352295\n",
      "loss: 0.1331997811794281\n",
      "loss: 0.13266173005104065\n",
      "loss: 0.13202691078186035\n",
      "loss: 0.131566122174263\n",
      "loss: 0.13102971017360687\n",
      "loss: 0.1305869072675705\n",
      "loss: 0.1301518678665161\n",
      "loss: 0.1295931041240692\n",
      "loss: 0.12912751734256744\n",
      "loss: 0.12869635224342346\n",
      "loss: 0.12825679779052734\n",
      "loss: 0.12788328528404236\n",
      "loss: 0.12743854522705078\n",
      "loss: 0.1270301640033722\n",
      "loss: 0.1266528218984604\n",
      "loss: 0.1262204349040985\n",
      "loss: 0.1258513480424881\n",
      "loss: 0.12547044456005096\n",
      "loss: 0.12507747113704681\n",
      "loss: 0.12469907850027084\n",
      "loss: 0.12438549846410751\n",
      "loss: 0.12405521422624588\n",
      "loss: 0.12368978559970856\n",
      "loss: 0.1232827678322792\n",
      "loss: 0.12294086813926697\n",
      "loss: 0.12265482544898987\n",
      "loss: 0.12232667207717896\n",
      "loss: 0.12201330065727234\n",
      "loss: 0.12170970439910889\n",
      "loss: 0.12137051671743393\n",
      "loss: 0.12105567753314972\n",
      "loss: 0.12074790894985199\n",
      "loss: 0.12047573924064636\n",
      "loss: 0.12020845711231232\n",
      "loss: 0.12001045793294907\n",
      "loss: 0.11993175745010376\n",
      "loss: 0.12024451792240143\n",
      "loss: 0.12226471304893494\n",
      "loss: 0.12473928928375244\n",
      "loss: 0.12681981921195984\n",
      "loss: 0.12693928182125092\n",
      "loss: 0.12289053946733475\n",
      "loss: 0.11915912479162216\n",
      "loss: 0.12003994733095169\n",
      "loss: 0.12283144146203995\n",
      "loss: 0.12083595991134644\n",
      "loss: 0.11758387833833694\n",
      "loss: 0.11785857379436493\n",
      "loss: 0.11981942504644394\n",
      "loss: 0.11959147453308105\n",
      "loss: 0.11721304804086685\n",
      "loss: 0.11626356095075607\n",
      "loss: 0.11715041100978851\n",
      "loss: 0.11769916862249374\n",
      "loss: 0.11638625711202621\n",
      "loss: 0.11505785584449768\n",
      "loss: 0.11551640182733536\n",
      "loss: 0.11589019000530243\n",
      "loss: 0.11527720838785172\n",
      "loss: 0.11432985216379166\n",
      "loss: 0.113982193171978\n",
      "loss: 0.11445695161819458\n",
      "loss: 0.11431368440389633\n",
      "loss: 0.11378738284111023\n",
      "loss: 0.11306925863027573\n",
      "loss: 0.11276170611381531\n",
      "loss: 0.1128312349319458\n",
      "loss: 0.11274155229330063\n",
      "loss: 0.11260057240724564\n",
      "loss: 0.11212680488824844\n",
      "loss: 0.11173632740974426\n",
      "loss: 0.11137884110212326\n",
      "loss: 0.11117775738239288\n",
      "loss: 0.11116047203540802\n",
      "loss: 0.1113443672657013\n",
      "loss: 0.11165531724691391\n",
      "loss: 0.11194287985563278\n",
      "loss: 0.11308572441339493\n",
      "loss: 0.12050781399011612\n",
      "loss: 0.12526321411132812\n",
      "loss: 0.11793629825115204\n",
      "loss: 0.11521542817354202\n",
      "loss: 0.1154257208108902\n",
      "loss: 0.11850857734680176\n",
      "loss: 0.13228808343410492\n",
      "loss: 0.12074654549360275\n",
      "loss: 0.10995636135339737\n",
      "loss: 0.11655658483505249\n",
      "loss: 0.1228504627943039\n",
      "loss: 0.12034393101930618\n",
      "loss: 0.11666632443666458\n",
      "loss: 0.11725395917892456\n",
      "loss: 0.12512481212615967\n",
      "loss: 0.11230636388063431\n",
      "loss: 0.11537321656942368\n",
      "loss: 0.12260446697473526\n",
      "loss: 0.11199318617582321\n",
      "loss: 0.11491519957780838\n",
      "loss: 0.12508773803710938\n",
      "loss: 0.11462614685297012\n",
      "loss: 0.11044478416442871\n",
      "loss: 0.11243666708469391\n",
      "loss: 0.11251363158226013\n",
      "loss: 0.1090209111571312\n",
      "loss: 0.10991309583187103\n",
      "loss: 0.1108333095908165\n",
      "loss: 0.1095627024769783\n",
      "loss: 0.11019758135080338\n",
      "loss: 0.10900676250457764\n",
      "loss: 0.10797101259231567\n",
      "loss: 0.1073218435049057\n",
      "loss: 0.10765865445137024\n",
      "loss: 0.10754888504743576\n",
      "loss: 0.10664308816194534\n",
      "loss: 0.10676907747983932\n",
      "loss: 0.10692638903856277\n",
      "loss: 0.1060461550951004\n",
      "loss: 0.10582516342401505\n",
      "loss: 0.10598928481340408\n",
      "loss: 0.10556171834468842\n",
      "loss: 0.10507608205080032\n",
      "loss: 0.10499672591686249\n",
      "loss: 0.10514725744724274\n",
      "loss: 0.10488717257976532\n",
      "loss: 0.1043149009346962\n",
      "loss: 0.10423749685287476\n",
      "loss: 0.10431239008903503\n",
      "loss: 0.1040182039141655\n",
      "loss: 0.10367091000080109\n",
      "loss: 0.10357058048248291\n",
      "loss: 0.10354627668857574\n",
      "loss: 0.10335291177034378\n",
      "loss: 0.1030559092760086\n",
      "loss: 0.10286316275596619\n",
      "loss: 0.10280230641365051\n",
      "loss: 0.1027107834815979\n",
      "loss: 0.10249849408864975\n",
      "loss: 0.10227274149656296\n",
      "loss: 0.10209239274263382\n",
      "loss: 0.101970374584198\n",
      "loss: 0.1018693819642067\n",
      "loss: 0.10175377130508423\n",
      "loss: 0.10158538818359375\n",
      "loss: 0.10142122209072113\n",
      "loss: 0.10123231261968613\n",
      "loss: 0.10105600208044052\n",
      "loss: 0.100914865732193\n",
      "loss: 0.10078363865613937\n",
      "loss: 0.10066810250282288\n",
      "loss: 0.10055137425661087\n",
      "loss: 0.10046884417533875\n",
      "loss: 0.10048045217990875\n",
      "loss: 0.10073504596948624\n",
      "loss: 0.10239063203334808\n",
      "loss: 0.10477486252784729\n",
      "loss: 0.1078447625041008\n",
      "loss: 0.11402798444032669\n",
      "loss: 0.1281680017709732\n",
      "loss: 0.14854265749454498\n",
      "loss: 0.12947505712509155\n",
      "loss: 0.13629034161567688\n",
      "loss: 0.11901143193244934\n",
      "loss: 0.11710898578166962\n",
      "loss: 0.109913669526577\n",
      "loss: 0.11008136719465256\n",
      "loss: 0.11365672945976257\n",
      "loss: 0.11231217533349991\n",
      "loss: 0.10744750499725342\n",
      "loss: 0.1053977832198143\n",
      "loss: 0.1083584800362587\n",
      "loss: 0.10909312963485718\n",
      "loss: 0.10518800467252731\n",
      "loss: 0.1035490557551384\n",
      "loss: 0.10567283630371094\n",
      "loss: 0.10602615773677826\n",
      "loss: 0.1033911183476448\n",
      "loss: 0.1017962098121643\n",
      "loss: 0.10306358337402344\n",
      "loss: 0.1034257784485817\n",
      "loss: 0.10152916610240936\n",
      "loss: 0.10050033777952194\n",
      "loss: 0.10087019950151443\n",
      "loss: 0.10093464702367783\n",
      "loss: 0.100080206990242\n",
      "loss: 0.09952495992183685\n",
      "loss: 0.09985300153493881\n",
      "loss: 0.09995678067207336\n",
      "loss: 0.09937472641468048\n",
      "loss: 0.09880916029214859\n",
      "loss: 0.0985899567604065\n",
      "loss: 0.09863642603158951\n",
      "loss: 0.09866918623447418\n",
      "loss: 0.09833209216594696\n",
      "loss: 0.09796003252267838\n",
      "loss: 0.09772471338510513\n",
      "loss: 0.09767540544271469\n",
      "loss: 0.09765896946191788\n",
      "loss: 0.09745198488235474\n",
      "loss: 0.09712308645248413\n",
      "loss: 0.09692463278770447\n",
      "loss: 0.0968499481678009\n",
      "loss: 0.09684336930513382\n",
      "loss: 0.09671012312173843\n",
      "loss: 0.09652203321456909\n",
      "loss: 0.0962691456079483\n",
      "loss: 0.0960724875330925\n",
      "loss: 0.09589587152004242\n",
      "loss: 0.09579897671937943\n",
      "loss: 0.09569451212882996\n",
      "loss: 0.09556735306978226\n",
      "loss: 0.09541357308626175\n",
      "loss: 0.09531962871551514\n",
      "loss: 0.09519528597593307\n",
      "loss: 0.09511082619428635\n",
      "loss: 0.09508953243494034\n",
      "loss: 0.09521066397428513\n",
      "loss: 0.09535715728998184\n",
      "loss: 0.09563576430082321\n",
      "loss: 0.09620731323957443\n",
      "loss: 0.09724076092243195\n",
      "loss: 0.09879421442747116\n",
      "loss: 0.09893323481082916\n",
      "loss: 0.09867366403341293\n",
      "loss: 0.09702533483505249\n",
      "loss: 0.0954185351729393\n",
      "loss: 0.09422420710325241\n",
      "loss: 0.0939229354262352\n",
      "loss: 0.09434782713651657\n",
      "loss: 0.09520053118467331\n",
      "loss: 0.09650465846061707\n",
      "loss: 0.09747181832790375\n",
      "loss: 0.09853028506040573\n",
      "loss: 0.09809991717338562\n",
      "loss: 0.09752713143825531\n",
      "loss: 0.09587874263525009\n",
      "loss: 0.09474407881498337\n",
      "loss: 0.09369064122438431\n",
      "loss: 0.09308484941720963\n",
      "loss: 0.09288174659013748\n",
      "loss: 0.09270762652158737\n",
      "loss: 0.09251043200492859\n",
      "loss: 0.09246194362640381\n",
      "loss: 0.09236056357622147\n",
      "loss: 0.09225745499134064\n",
      "loss: 0.092284195125103\n",
      "loss: 0.09240908920764923\n",
      "loss: 0.09292712062597275\n",
      "loss: 0.09444741904735565\n",
      "loss: 0.0998232364654541\n",
      "loss: 0.11740626394748688\n",
      "loss: 0.17738862335681915\n",
      "loss: 0.34090107679367065\n",
      "loss: 0.5540781021118164\n",
      "loss: 0.163108229637146\n",
      "loss: 0.4154101312160492\n",
      "loss: 0.36174800992012024\n",
      "loss: 0.42001873254776\n",
      "loss: 0.37670400738716125\n",
      "loss: 0.19589455425739288\n",
      "loss: 0.28287026286125183\n",
      "loss: 0.2133627086877823\n",
      "loss: 0.2643347680568695\n",
      "loss: 0.2609582841396332\n",
      "loss: 0.200193852186203\n",
      "loss: 0.21140272915363312\n",
      "loss: 0.17518137395381927\n",
      "loss: 0.2425045669078827\n",
      "loss: 0.2032133787870407\n",
      "loss: 0.2753177881240845\n",
      "loss: 0.20829488337039948\n",
      "loss: 0.2222280651330948\n",
      "loss: 0.21431605517864227\n",
      "loss: 0.19454799592494965\n",
      "loss: 0.1968865990638733\n",
      "loss: 0.17673546075820923\n",
      "loss: 0.17777131497859955\n",
      "loss: 0.15369336307048798\n",
      "loss: 0.1615457832813263\n",
      "loss: 0.15002061426639557\n",
      "loss: 0.14884741604328156\n",
      "loss: 0.14166605472564697\n",
      "loss: 0.14270564913749695\n",
      "loss: 0.13749843835830688\n",
      "loss: 0.13692964613437653\n",
      "loss: 0.14091472327709198\n",
      "loss: 0.13464011251926422\n",
      "0.9304\n",
      "Data(x=[77, 1], edge_index=[2, 230], edge_attr=[230, 2], y=[77, 2], reduced_cost=[230, 3], filename='netgen_72.txt')\n"
     ]
    }
   ],
   "source": [
    "model = CBN_GAT_reduced_cost(1, 3, 2, args)\n",
    "loss_fn = model.loss()\n",
    "data = dataset[0]\n",
    "\n",
    "\n",
    "scheduler, opt = build_optimizer(args, model.parameters())\n",
    "\n",
    "for i in range(500):\n",
    "    model.eval()\n",
    "    opt.zero_grad()\n",
    "    preds = model(data.x, data.edge_index, data.edge_attr)\n",
    "    loss = loss_fn(preds, data.reduced_cost)\n",
    "    print(f\"loss: {loss.item()}\")\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "print(model.accuracy(preds, data.reduced_cost))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import trange\n",
    "import copy\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_loader = DataLoader(MinCostDataset(root = \"./data/data_train\"), batch_size = args.batch_size, shuffle = True)\n",
    "test_loader = DataLoader(MinCostDataset(root = \"./data/data_test\"), batch_size = args.batch_size, shuffle = True)\n",
    "# TODO also define the validation loader (and set validation fraction > 0 lol)\n",
    "\n",
    "# Output dimension is 1 since we predict scalar potential values for each vertex\n",
    "model = CBN_GAT_reduced_cost(1, 3, 2, args)\n",
    "loss_fn = model.loss()\n",
    "scheduler, opt = build_optimizer(args, model.parameters())\n",
    "\n",
    "def train(args):\n",
    "\n",
    "    # train\n",
    "    losses = []\n",
    "    train_accs = []\n",
    "    test_accs = []\n",
    "    test_losses = []\n",
    "    best_acc = 0\n",
    "    best_model = None\n",
    "    for epoch in trange(args.epochs, desc=\"Training\", unit=\"Epochs\"):\n",
    "        total_loss = 0\n",
    "        total_accuracy = 0\n",
    "        model.train()\n",
    "\n",
    "        for batch in train_loader:\n",
    "            opt.zero_grad()\n",
    "            pred = model(batch.x, batch.edge_index, batch.edge_attr)\n",
    "            # pred = pred[batch.train_mask]\n",
    "            # label = label[batch.train_mask]\n",
    "            loss = loss_fn(pred, batch.reduced_cost)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total_accuracy += model.accuracy(pred, batch.reduced_cost) * batch.num_graphs\n",
    "            total_loss += loss.item() * batch.num_graphs\n",
    "        total_loss /= len(train_loader.dataset)\n",
    "        total_accuracy /= len(train_loader.dataset)\n",
    "        losses.append(total_loss)\n",
    "        train_accs.append(total_accuracy)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "          test_acc, test_loss = test(test_loader, model)\n",
    "          test_accs.append(test_acc)\n",
    "          test_losses.append(test_loss)\n",
    "          if test_acc > best_acc:\n",
    "            best_acc = test_acc\n",
    "            best_model = copy.deepcopy(model)\n",
    "        else:\n",
    "          test_accs.append(test_accs[-1])\n",
    "          test_losses.append(test_losses[-1])\n",
    "\n",
    "    return test_accs, test_losses, losses, train_accs, best_model, best_acc\n",
    "\n",
    "def test(loader, test_model, is_validation=False, save_model_preds=False, model_type=None):\n",
    "    # TODO handle is_validation\n",
    "    test_model.eval()\n",
    "    total_accuracy = 0\n",
    "    total_loss = 0\n",
    "    predictions = {}\n",
    "\n",
    "    for batch in loader:\n",
    "        with torch.no_grad():\n",
    "            pred = model(batch.x, batch.edge_index, batch.edge_attr)\n",
    "            # print(f\"accuracy: {model.accuracy(pred, batch.reduced_cost)}\")\n",
    "\n",
    "            total_accuracy += model.accuracy(pred, batch.reduced_cost)\n",
    "            total_loss += loss_fn(pred, batch.reduced_cost)\n",
    "\n",
    "            # TODO handle save_model_preds (Q: how to keep track of which original file we're working on?) inspiration in commented code below\n",
    "\n",
    "            # if save_model_preds:\n",
    "            #     print (\"Saving Model Predictions for Model Type\", model_type)\n",
    "            #\n",
    "            #     data = {}\n",
    "            #     data['pred'] = pred.view(-1).cpu().detach().numpy()\n",
    "            #     data['label'] = label.view(-1).cpu().detach().numpy()\n",
    "            #\n",
    "            #     df = pd.DataFrame(data=data)\n",
    "            #     # Save locally as csv\n",
    "            #     df.to_csv('MinCostFlow-' + model_type + '.csv', sep=',', index=False)\n",
    "\n",
    "    total_accuracy /= len(test_loader.dataset)\n",
    "    total_loss /= len(test_loader.dataset)\n",
    "\n",
    "    return total_accuracy, total_loss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:40<00:00,  1.23Epochs/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum test set accuracy: 0.7525200000000001\n",
      "Minimum loss: 0.5763220561402185\n",
      "Minimum test loss: 0.5720123052597046\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_accs, test_losses, losses, train_accs, best_model, best_acc = train(args)\n",
    "\n",
    "print(\"Maximum test set accuracy: {0}\".format(max(test_accs)))\n",
    "print(\"Minimum loss: {0}\".format(min(losses)))\n",
    "print(\"Minimum test loss: {0}\".format(min(test_losses)))\n",
    "\n",
    "# Run test for our best model to save the predictions!\n",
    "# test(test_loader, best_model, is_validation=False, save_model_preds=True, model_type=model)\n",
    "print()\n",
    "\n",
    "plt.plot(losses, label=\"training loss\" + \" - \" + args.model_type, color = 'red', linestyle='solid')\n",
    "plt.plot(train_accs, label=\"training accuracy\" + \" - \" + args.model_type, color = 'red', linestyle='dashed')\n",
    "plt.plot(test_losses, label=\"test loss\" + \" - \" + args.model_type, color = 'green', linestyle='solid')\n",
    "plt.plot(test_accs, label=\"test accuracy\" + \" - \" + args.model_type, color = 'green', linestyle='dashed')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "true_pos = np.array([round(costs[neg_edges[j]] + y.value[neg_edges[j][0]] - y.value[neg_edges[j][1]], 4) for j in range(len(neg_edges))])\n",
    "print(len(true_pos))\n",
    "print(len(true_pos[true_pos < 0]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "false_pos = np.array([round(costs[pos_edges[j]] + y.value[pos_edges[j][0]] - y.value[pos_edges[j][1]], 4) for j in range(len(pos_edges))])\n",
    "print(len(false_pos[false_pos < 0]))\n",
    "print(len(false_pos[false_pos == 0]))\n",
    "print(len(false_pos))\n",
    "#print(list(zip(pos_edges, false_pos)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reduced_cost = -preds[data.edge_index[1]].squeeze() + preds[data.edge_index[0]].squeeze() + data.edge_attr[:, 1]\n",
    "reduced_cost = reduced_cost.detach().numpy().flatten()\n",
    "threshold = np.quantile(reduced_cost[reduced_cost < 0], 0.1)\n",
    "neg_edges = list(zip(*data.edge_index[:, reduced_cost < threshold].numpy()))\n",
    "pos_edges = list(zip(*data.edge_index[:, reduced_cost > threshold].numpy()))\n",
    "edges = list(zip(*data.edge_index.numpy()))\n",
    "costs = dict(zip(edges, list(data.edge_attr[:, 1].numpy())))\n",
    "caps = dict(zip(edges, list(data.edge_attr[:, 0].numpy())))\n",
    "caps = np.array([caps[(i,j)] for (i,j) in pos_edges])\n",
    "\n",
    "import cvxpy as cp\n",
    "N = data.x.size(0)\n",
    "y = cp.Variable(N)\n",
    "t = cp.Variable(len(neg_edges))\n",
    "s = cp.Variable(len(pos_edges))\n",
    "\n",
    "prob = cp.Problem(\n",
    "    cp.Minimize(10000*cp.sum(-cp.minimum(s, 0)) + 10*cp.norm(s.T @ caps, 1)),\n",
    "    [\n",
    "      *[costs[neg_edges[i]] + y[neg_edges[i][0]] - y[neg_edges[i][1]] <= t[i] for i in range(len(neg_edges))],\n",
    "      *[costs[pos_edges[j]] + y[pos_edges[j][0]] - y[pos_edges[j][1]] == s[j] for j in range(len(pos_edges))],\n",
    "      t <= -0.01\n",
    "    ]\n",
    ")\n",
    "\n",
    "prob.solve()\n",
    "\n",
    "y.value"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
