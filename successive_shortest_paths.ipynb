{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf0af95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Dict, Tuple, List\n",
    "from copy import copy\n",
    "from collections import defaultdict\n",
    "from heapq import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc7a6059",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(\n",
    "        self,\n",
    "        nodes: List[object],\n",
    "        edges: List[Tuple[object, object]],\n",
    "        capacities: List[int],\n",
    "        costs: List[int],\n",
    "        supplies: List[int] \n",
    "    ) -> None:\n",
    "        \n",
    "        # -1: meta source\n",
    "        # -2: meta sink\n",
    "        self.V = [*nodes, -1, -2]\n",
    "\n",
    "        # Update input for meta nodes\n",
    "        source_indices = [i for i in range(len(nodes)) if supplies[i] > 0]\n",
    "        sink_indices = [i for i in range(len(nodes)) if supplies[i] < 0]\n",
    "\n",
    "        source_connections = [(-1, nodes[i]) for i in source_indices]\n",
    "        sink_connections = [(nodes[i], -2) for i in sink_indices]\n",
    "\n",
    "        edges = [\n",
    "            *edges,\n",
    "            *source_connections,\n",
    "            *sink_connections,\n",
    "        ]\n",
    "\n",
    "        capacities = [\n",
    "            *capacities,\n",
    "            *[supplies[i] for i in source_indices],\n",
    "            *[-supplies[i] for i in sink_indices]\n",
    "        ]\n",
    "\n",
    "        costs = [\n",
    "            *costs,\n",
    "            *[0 for _, i in source_connections],\n",
    "            *[0 for _, i in sink_connections]\n",
    "        ]\n",
    "\n",
    "        total_supply = sum(np.abs(supplies)) // 2\n",
    "        supplies = [*np.zeros(len(supplies)), total_supply, -total_supply]\n",
    "        self.E = [(*edges[i-1], i) for i in range(1, len(edges) + 1)]\n",
    "        self.u = dict(zip(self.E, capacities))\n",
    "        self.c = dict(zip(self.E, costs))\n",
    "        self.b = dict(zip(self.V, supplies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0415d02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://gist.github.com/kachayev/5990802\n",
    "\n",
    "def rev(edge):\n",
    "    return (edge[1], edge[0], -edge[2])\n",
    "\n",
    "def dijkstra(\n",
    "    S_f: object,\n",
    "    T_f: object,\n",
    "    adj: Dict[Tuple[object, object], int]\n",
    ") -> Tuple[Dict[object, int], List[Tuple[object, object]]]:\n",
    "    '''\n",
    "    Computes the shortest path distances from [s] to all other nodes \n",
    "    and the shortest path from [s] to [t] on the graph with edges/weights \n",
    "    given by the entries of [adj]. Implementation of Dijkstra's shortest\n",
    "    path algorithm for graphs with non-negative edge costs.\n",
    "    \n",
    "    Args:\n",
    "        s: Start node\n",
    "        t: End node (for path)\n",
    "        adj: Dictionary containing edges and their respective weights, with\n",
    "            adj[(i, j)] = w_{ij} for nodes i and j.\n",
    "    '''\n",
    "    def _format_path(lst):\n",
    "        return [(lst[i][0], *lst[i+1]) for i in range(len(lst) - 1)]\n",
    "            \n",
    "            \n",
    "    # Generate underlying adjacency lists\n",
    "    adjacency = defaultdict(list)\n",
    "    for (i, j, id), c in adj.items():\n",
    "        if c < 0:\n",
    "            print(f\"cost can't be < 0: {(i,j,id,c)}\")\n",
    "        assert(c >= 0)\n",
    "        adjacency[i].append((j, id, c))\n",
    "\n",
    "    # Initialize queue, distances\n",
    "    queue, seen, distances = [(0, s, 0, []) for s in S_f], set(), {s: 0 for s in S_f}\n",
    "    \n",
    "    while queue:\n",
    "        cost, v1, id, path = heappop(queue)\n",
    "        if v1 not in seen:\n",
    "            seen.add(v1)\n",
    "            path = [*path, (v1, id)]\n",
    "            if v1 in T_f: \n",
    "                out_path = _format_path(path)\n",
    "\n",
    "            for v2, id, c in adjacency.get(v1, ()):\n",
    "                if v2 in seen: \n",
    "                    continue\n",
    "                prev = distances.get(v2, None)\n",
    "                nxt = cost + c\n",
    "                if prev is None or nxt < prev:\n",
    "                    distances[v2] = nxt\n",
    "                    heappush(queue, (nxt, v2, id, path))\n",
    "    return distances, out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def BFS(\n",
    "        S_f: object,\n",
    "        T_f: object,\n",
    "        adj: List[Tuple[object, object]]\n",
    ") -> Tuple[Dict[object, int], List[Tuple[object, object]]]:\n",
    "\n",
    "\n",
    "    def _format_path(lst):\n",
    "        return [(lst[i][0], *lst[i+1]) for i in range(len(lst) - 1)]\n",
    "\n",
    "    # Generate underlying adjacency lists\n",
    "    adjacency = defaultdict(list)\n",
    "    for (i, j, id) in adj:\n",
    "        adjacency[i].append((j, id))\n",
    "\n",
    "    # Initialize queue, distances\n",
    "    queue, seen = (deque([(s, 0, []) for s in S_f]), set())\n",
    "\n",
    "    found = False\n",
    "\n",
    "    while not found:\n",
    "        v1, id, path = queue[0]\n",
    "\n",
    "        if v1 not in seen:\n",
    "            seen.add(v1)\n",
    "            path = [*path, (v1, id)]\n",
    "            if v1 in T_f:\n",
    "                out_path = _format_path(path)\n",
    "                return out_path\n",
    "\n",
    "            for v2, id in adjacency.get(v1, ()):\n",
    "                if v2 in seen:\n",
    "                    continue\n",
    "                queue.append((v2, id, path))\n",
    "\n",
    "        queue.popleft()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "60e25d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduced_cost(\n",
    "    N: Network,\n",
    "    u_f: Dict[Tuple[object, object], int],\n",
    "    p: Dict[object, int]\n",
    ") -> Dict[Tuple[object, object], int]:\n",
    "    '''\n",
    "    Computes reduced costs of the edges in the residual graph [u_f] with respect to edge\n",
    "    costs [N.c] and node potentials [p].\n",
    "    \n",
    "    Args:\n",
    "        N: Network representing the problem input\n",
    "        u_f: Dictionary encoding the residual graph w.r.t the current flow\n",
    "        p: Current node potentials\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary which gives the reduced cost for each edge (u, v) according to\n",
    "        c_p[(u, v)] = c[(u, v)] + p[u] - p[v].\n",
    "    '''\n",
    "    reduced_costs = {}\n",
    "    for e in u_f.keys():\n",
    "        (u, v, _) = e\n",
    "        if e in N.c:\n",
    "            reduced_costs[e] = int(N.c[e] + p[u] - p[v])\n",
    "        else:\n",
    "            reduced_costs[e] = int(-N.c[rev(e)] + p[u] - p[v])\n",
    "    return reduced_costs\n",
    "    \n",
    "def excess_nodes(\n",
    "    N: Network,\n",
    "    f: Dict[Tuple[object, object], int],\n",
    ") -> Tuple[List, List, Dict]:\n",
    "    '''\n",
    "    Compute nodes in the network [N] where flow conservation is violated by at least [K] units\n",
    "    for the flow [f]. \n",
    "    \n",
    "    Args:\n",
    "        N: Network object representing the problem input\n",
    "        f: Potentially infeasible flow\n",
    "    \n",
    "    Returns:\n",
    "        A tuple consisting of a list of nodes where net flow in is greater than [K]\n",
    "        and a list of nodes where the net flow in is less than -[K].\n",
    "    '''\n",
    "    def _excess(N, f) -> Dict[object, int]:\n",
    "        # Initialize excess to be supply\n",
    "        excess = {v: N.b[v] for v in N.V}\n",
    "        for (u, v, _), val in f.items():\n",
    "            excess[u] -= val\n",
    "            excess[v] += val\n",
    "\n",
    "        return excess\n",
    "    \n",
    "    e_f = _excess(N, f)\n",
    "    S_f = [i for (i, val) in e_f.items() if val > 0]\n",
    "    T_f = [i for (i, val) in e_f.items() if val < 0]\n",
    "    return S_f, T_f, e_f\n",
    "\n",
    "def update_potentials(\n",
    "    p: Dict[object, int],\n",
    "    distances: Dict[object, int],\n",
    "    P\n",
    ") -> None:\n",
    "    '''\n",
    "    Updates node potentials [p] with the shortest path distances in\n",
    "    [distances] according to p[i] <- p[i] + distances[i].\n",
    "    \n",
    "    Args:\n",
    "        p: Previous node potentials\n",
    "        distances: Shortest path distance to each node in graph from a node with\n",
    "            surplus above the current scaling threshold\n",
    "        \n",
    "    '''\n",
    "    t = P[-1][1]\n",
    "\n",
    "    for i in p.keys():\n",
    "        if i in distances:\n",
    "            p[i] += (min(distances[i], distances[t]))\n",
    "        else:\n",
    "            p[i] += (distances[t])\n",
    "                   \n",
    "def saturate_edges(\n",
    "    N: Network,\n",
    "    f: Dict[Tuple[object, object], int],\n",
    "    u_f: Dict[Tuple[object, object], int],\n",
    "    edges: List[Tuple[object, object]]\n",
    ") -> None:\n",
    "    '''\n",
    "    Updates the flow [f] and residual graph [u_f] by saturating\n",
    "    all edges in [edges].\n",
    "    \n",
    "    Args:\n",
    "        N: Flow network encoding the problem input\n",
    "        u_f: The residual graph for the current flow\n",
    "        f: The current flow\n",
    "        edges: List of edges to saturate\n",
    "        \n",
    "    '''\n",
    "\n",
    "    for e in edges:\n",
    "        if e in f:\n",
    "            f[e] = N.u[e]                              # Saturate foward edge\n",
    "            u_f[e] = 0                                 # Zero forward residual edge\n",
    "            u_f[rev(e)] = N.u[e]                       # Saturate backward residual edge\n",
    "\n",
    "        else:\n",
    "            f[rev(e)] = 0                              # Zero forward edge\n",
    "            u_f[e] = 0                                 # Saturate forward residual edge\n",
    "            u_f[rev(e)] = N.u[rev(e)]                  # Zero backward residual edge\n",
    "\n",
    "        \n",
    "def saturate_neg_cost_admissible(\n",
    "    N: Network,\n",
    "    c_p: Dict[Tuple[object, object], int],\n",
    "    f: Dict[Tuple[object, object], int],\n",
    "    u_f: Dict[Tuple[object, object], int]\n",
    ") -> None:\n",
    "    '''\n",
    "    Updates the current flow [f] and residual graph [u_f] by\n",
    "    saturating all edges with residual capacity of at least [K]\n",
    "    and negative reduced cost [c_p] to preserve invariants in the\n",
    "    algorithm.\n",
    "    \n",
    "    Args:\n",
    "        N: Flow network encoding the problem input\n",
    "        c_p: Current reduced costs\n",
    "        f: The current flow\n",
    "        u_f: The residual graph for the current flow\n",
    "    '''\n",
    "    neg_cost_admissible = [\n",
    "        e\n",
    "        for e, u in u_f.items() \n",
    "        if c_p[e] < 0 and u > 0\n",
    "    ]\n",
    "    print(f\"Number of negative cost admissible edges: {len(neg_cost_admissible)}\")\n",
    "    \n",
    "    saturate_edges(N, f, u_f, neg_cost_admissible)\n",
    "    \n",
    "def augment_flow_along_path(\n",
    "    P: List[Tuple[object, object]],\n",
    "    f: Dict[Tuple[object, object], int],\n",
    "    u_f: Dict[Tuple[object, object], int],\n",
    "    e_f\n",
    ") -> None:\n",
    "    ''' \n",
    "    Updates the current flow [f] and residual graph [u_f] by\n",
    "    pushing [K] units of flow along the directed path P.\n",
    "    \n",
    "    Args:\n",
    "        P: Path of edges to push flow\n",
    "        f: Current flow\n",
    "        c_f: Current residual graph\n",
    "        K: Scaling parameter\n",
    "    \n",
    "    '''\n",
    "    s = P[0][0]\n",
    "    t = P[-1][1]\n",
    "\n",
    "    min_capacity = min(u_f[e] for e in P)\n",
    "    delta = min(e_f[s], -e_f[t], min_capacity)\n",
    "    \n",
    "    for e in P:\n",
    "        if e in f:\n",
    "            f[e] += delta\n",
    "            u_f[e] -= delta\n",
    "            u_f[rev(e)] = u_f.get(rev(e), 0) + delta\n",
    "            \n",
    "        else:\n",
    "            f[rev(e)] -= delta\n",
    "            u_f[rev(e)] += delta\n",
    "            u_f[e] -= delta\n",
    "\n",
    "def value(N, f):\n",
    "    return np.sum([f[e]*N.c[e] for e in N.E if e in f])\n",
    "\n",
    "def init_residual_graph(N, f):\n",
    "    u_f = {}\n",
    "    for e in N.E:\n",
    "        if e in f:\n",
    "            u_f[e] = N.u[e] - f[e]\n",
    "            u_f[rev(e)] = f[e]\n",
    "        else:\n",
    "            u_f[e] = N.u[e]\n",
    "    return u_f        \n",
    "    \n",
    "def preprocess(\n",
    "    N: Network,\n",
    "    f,\n",
    "    p,\n",
    "    c_p\n",
    "):\n",
    "    for e, c in c_p.items():\n",
    "        # print(f\"{e}, {c}\")\n",
    "        if c > 0 and e in N.E: #TODO very much not efficient, edges could be a set\n",
    "            N.E.remove(e)\n",
    "            #f.pop(e) TODO should we remove it from the flow in this case?\n",
    "    u_f = init_residual_graph(N,f)\n",
    "    c_p = reduced_cost(N, u_f, p)\n",
    "    return N, u_f, c_p\n",
    "    \n",
    "def successive_shortest_paths(\n",
    "    N: Network,\n",
    "    **kwargs\n",
    ") -> Tuple[Dict[Tuple[object, object], int], Dict[object, int]]:\n",
    "    '''\n",
    "    Primal-dual algorithm for computing a minimum-cost flow for the \n",
    "    network [N] starting from dual-feasible node potentials [p].\n",
    "    \n",
    "    Args:\n",
    "        N: Flow network encoding the problem input\n",
    "        p: Initial node potentials for warm start\n",
    "        \n",
    "    Returns:\n",
    "        Minimum cost flow and corresponding optimal node potentials\n",
    "    '''\n",
    "    \n",
    "    # Init zero flow and potentials\n",
    "    if 'f' not in kwargs:\n",
    "        f = {e: 0 for e in N.E}\n",
    "    else:\n",
    "        f = copy(kwargs['f'])\n",
    "\n",
    "    if 'p' not in kwargs:\n",
    "        p = {v: 0 for v in N.V}\n",
    "    else:\n",
    "        p = copy(kwargs['p'])\n",
    "\n",
    "    u_f = init_residual_graph(N, f)\n",
    "    \n",
    "    iters=0\n",
    "    \n",
    "    # Compute reduced costs w.r.t potentials p\n",
    "    c_p = reduced_cost(N, u_f, p)\n",
    "    \n",
    "    # Preprocessing step\n",
    "    if kwargs.get('preprocess', False):\n",
    "        N, u_f, c_p = preprocess(N, f, p, c_p)\n",
    "\n",
    "\n",
    "    # for e in N.E:\n",
    "    #     print(f\"{e}: cost: {c_p[e]}, flow: {f[e]}\")\n",
    "\n",
    "    # Saturate admissible edges with negative reduced cost\n",
    "    saturate_neg_cost_admissible(N, c_p, f, u_f)\n",
    "\n",
    "\n",
    "    prepoc_iter = 0\n",
    "    if kwargs.get('preprocess', False):\n",
    "        S_f, T_f, e_f = excess_nodes(N, f)\n",
    "        while len(S_f) > 0:\n",
    "\n",
    "            # Admissible edges\n",
    "            adj = [e for (e, c) in c_p.items() if u_f[e] > 0]\n",
    "            P = BFS(S_f, T_f, adj)\n",
    "            augment_flow_along_path(P, f, u_f, e_f)\n",
    "            S_f, T_f, e_f = excess_nodes(N, f)\n",
    "            prepoc_iter += 1\n",
    "\n",
    "    S_f, T_f, e_f = excess_nodes(N, f)\n",
    "\n",
    "\n",
    "    while len(S_f) > 0:\n",
    "        print(f\"iteration: {iters}, flow value: {value(N, f)}, excess: {sum(np.abs(list(e_f.values())))}\")\n",
    "\n",
    "        # Admissible edges\n",
    "        adj = {e: c for (e, c) in c_p.items() if u_f[e] > 0}\n",
    "        D, P = dijkstra(S_f, T_f, adj)\n",
    "        update_potentials(p, D, P)\n",
    "        augment_flow_along_path(P, f, u_f, e_f)\n",
    "        c_p = reduced_cost(N, u_f, p)\n",
    "        S_f, T_f, e_f = excess_nodes(N, f)\n",
    "\n",
    "        iters += 1\n",
    "        \n",
    "    #print(f\"end reduced costs:\\n{c_p}\")\n",
    "    #print(f\"end flow:\\n{f}\")\n",
    "    # for e in N.E:\n",
    "        # print(f\"{e}: cost: {c_p[e]}, flow: {f[e]}\")\n",
    "    print(f\"number of edges: {len(c_p)}\")\n",
    "    print(f\"Number of flow updates: {iters}, number of preprocessing iterations: {prepoc_iter}, final flow value: {value(N, f)}\")\n",
    "    return f, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "803c62d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feasibility_check(N, f):\n",
    "    assert np.all(np.array([len(excess_nodes(N, f)[i]) == 0 for i in [0,1]]))\n",
    "    assert np.all(np.array(list(f.values())) >= 0)\n",
    "    assert np.all(np.array(list(f.values())) <= np.array(list(N.u.values())))\n",
    "    \n",
    "def optimality_check(N, f, p):\n",
    "    primal = np.sum([f[e]*N.c[e] for e, _ in f.items()])\n",
    "    dual = -np.sum([p[i] * N.b[i] for i in N.V]) - np.sum([N.u[e] * max(0, p[e[1]] - p[e[0]] - N.c[e]) for e in N.E])\n",
    "    print(primal)\n",
    "    print(dual)\n",
    "    assert np.isclose(primal, dual, atol=0.0)\n",
    "    return primal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "26f206d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of negative cost admissible edges: 0\n",
      "iteration: 0, flow value: 0, excess: 40.0\n",
      "iteration: 1, flow value: 25, excess: 30.0\n",
      "iteration: 2, flow value: 46, excess: 24.0\n",
      "iteration: 3, flow value: 78, excess: 16.0\n",
      "iteration: 4, flow value: 87, excess: 14.0\n",
      "number of edges: 24\n",
      "Number of flow updates: 5, number of preprocessing iterations: 0, final flow value: 150\n"
     ]
    }
   ],
   "source": [
    "edges = [(0,1), (0,2), (1,2), (1,3), (1,4), (2,3), (2,4), (3,4), (4,2)]\n",
    "capacities = np.array([15, 8, 20, 4, 10, 15, 4, 20, 5])\n",
    "costs = np.array([4, 4, 2, 2, 6, 1, 3, 2, 3])\n",
    "supplies = [20, 0, 0, -5, -15]\n",
    "nodes = [0, 1, 2, 3, 4]\n",
    "N = Network(nodes, edges, capacities, costs, supplies)     \n",
    "\n",
    "f, p = successive_shortest_paths(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "promotional-intention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of negative cost admissible edges: 0\n",
      "number of edges: 20\n",
      "Number of flow updates: 0, number of preprocessing iterations: 6, final flow value: 150.0\n"
     ]
    }
   ],
   "source": [
    "c_p = reduced_cost(N, {e: 0 for e in N.E}, p)\n",
    "vals = [N.u[e] if c_p[e] < 0 else 0 for e in N.E]\n",
    "f_cons = dict(zip(N.E, vals))  \n",
    "\n",
    "f, p = successive_shortest_paths(N, f=f_cons, p=p, preprocess = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "operational-intake",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150.0\n",
      "150.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "150.0"
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feasibility_check(N, f)\n",
    "optimality_check(N, f, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1a236f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(filename) -> Network:\n",
    "    \"\"\"\n",
    "    Parses a network file following the DIMACS problem specification \n",
    "    structure and transforms it into a Network object\n",
    "    \n",
    "    Some elements of the specification:\n",
    "    - Lines starting in c are comments\n",
    "    - Lines starting in p explain what problem to solve (can be ignored, \n",
    "      we only consider minimum-cost flow problems)\n",
    "    - Lines starting in n define nodes\n",
    "    - Lines starting in a define arcs (edges)\n",
    "    \n",
    "    Args:\n",
    "        filename: name of the file containing the network data\n",
    "        \n",
    "    Returns:\n",
    "        The corresponding Network object\n",
    "    \"\"\"\n",
    "    # Lines we can ignore\n",
    "    ignore_list = ['c', 'p']\n",
    "    \n",
    "    file = open(filename, 'r')\n",
    "    \n",
    "    # Nodes is a hashmap from node values to their supply\n",
    "    nodes = {}\n",
    "    # Edges is a hashmap from edges to a tuple with their capacity and cost\n",
    "    edges = {}\n",
    "    \n",
    "    for line in file:\n",
    "        if len(line) > 0 and line[0] not in ignore_list:\n",
    "            if line[0] == 'n':\n",
    "                # Node parsing\n",
    "                node = [int(elem) for elem in line.split(' ')[1:]]\n",
    "                nodes[node[0]] = node[1]\n",
    "            elif line[0] == 'a':\n",
    "                arc = [int(elem) for elem in line.split(' ')[1:]]\n",
    "                node1 = arc[0]\n",
    "                node2 = arc[1]\n",
    "                capacity = arc[3]\n",
    "                cost = arc[4]\n",
    "                \n",
    "                # Only nodes with non-zero supply are in a \"node line\"\n",
    "                if node1 not in nodes:\n",
    "                    nodes[node1] = 0\n",
    "                if node2 not in nodes:\n",
    "                    nodes[node2] = 0\n",
    "                if (node1, node2) in edges:\n",
    "                    # TODO not amazing (reaverages every time)\n",
    "                    old_capacity, old_cost = edges[(node1, node2)]\n",
    "                    new_cost = old_cost * old_capacity + cost * capacity\n",
    "                    new_cost /= (old_capacity + capacity)\n",
    "                    edges[(node1, node2)] = (old_capacity + capacity, new_cost)\n",
    "                else:\n",
    "                    edges[(node1, node2)] = (capacity, cost)\n",
    "    file.close()\n",
    "    \n",
    "    capacities, costs = zip(*edges.values())\n",
    "    network = Network(list(nodes.keys()), list(edges.keys()), capacities, costs, list(nodes.values())) \n",
    "    \n",
    "    print(f\"This dataset contains: {len(nodes.keys())} nodes and {len(edges.keys())} edges\")\n",
    "\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "38b7dd30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset contains: 9559 nodes and 29682 edges\n",
      "Number of negative cost admissible edges: 0\n",
      "iteration: 0, flow value: 0.0, excess: 19440.0\n",
      "iteration: 1, flow value: 442320.0, excess: 18960.0\n",
      "iteration: 2, flow value: 745560.0, excess: 18720.0\n",
      "iteration: 3, flow value: 1060560.0, excess: 18480.0\n",
      "iteration: 4, flow value: 1388760.0, excess: 18240.0\n",
      "iteration: 5, flow value: 2433840.0, excess: 17520.0\n",
      "iteration: 6, flow value: 2811840.0, excess: 17280.0\n",
      "iteration: 7, flow value: 3959520.0, excess: 16560.0\n",
      "iteration: 8, flow value: 4744080.0, excess: 16080.0\n",
      "iteration: 9, flow value: 5206440.0, excess: 15840.0\n",
      "iteration: 10, flow value: 6154440.0, excess: 15360.0\n",
      "iteration: 11, flow value: 7200360.0, excess: 14880.0\n",
      "iteration: 12, flow value: 7754880.0, excess: 14640.0\n",
      "iteration: 13, flow value: 8313960.0, excess: 14400.0\n",
      "iteration: 14, flow value: 8902560.0, excess: 14160.0\n",
      "iteration: 15, flow value: 9530280.0, excess: 13920.0\n",
      "iteration: 16, flow value: 10945560.0, excess: 13440.0\n",
      "iteration: 17, flow value: 11676480.0, excess: 13200.0\n",
      "iteration: 18, flow value: 12422040.0, excess: 12960.0\n",
      "iteration: 19, flow value: 13169040.0, excess: 12720.0\n",
      "iteration: 20, flow value: 14143320.0, excess: 12480.0\n",
      "iteration: 21, flow value: 15127440.0, excess: 12240.0\n",
      "iteration: 22, flow value: 16177680.0, excess: 12000.0\n",
      "iteration: 23, flow value: 17263800.0, excess: 11760.0\n",
      "iteration: 24, flow value: 19447080.0, excess: 11280.0\n",
      "iteration: 25, flow value: 20547840.0, excess: 11040.0\n",
      "iteration: 26, flow value: 21648870.0, excess: 10800.0\n",
      "iteration: 27, flow value: 22775070.0, excess: 10560.0\n",
      "iteration: 28, flow value: 23943030.0, excess: 10320.0\n",
      "iteration: 29, flow value: 25111500.0, excess: 10080.0\n",
      "iteration: 30, flow value: 26295300.0, excess: 9840.0\n",
      "iteration: 31, flow value: 27480060.0, excess: 9600.0\n",
      "iteration: 32, flow value: 28668060.0, excess: 9360.0\n",
      "iteration: 33, flow value: 32296500.0, excess: 8640.0\n",
      "iteration: 34, flow value: 33579420.0, excess: 8400.0\n",
      "iteration: 35, flow value: 34871700.0, excess: 8160.0\n",
      "iteration: 36, flow value: 37560900.0, excess: 7680.0\n",
      "iteration: 37, flow value: 38915820.0, excess: 7440.0\n",
      "iteration: 38, flow value: 41661180.0, excess: 6960.0\n",
      "iteration: 39, flow value: 44429100.0, excess: 6480.0\n",
      "iteration: 40, flow value: 45820225.71428572, excess: 6240.0\n",
      "iteration: 41, flow value: 47268745.71428572, excess: 6000.0\n",
      "iteration: 42, flow value: 50197225.71428572, excess: 5520.0\n",
      "iteration: 43, flow value: 51665545.71428572, excess: 5280.0\n",
      "iteration: 44, flow value: 53188105.71428572, excess: 5040.0\n",
      "iteration: 45, flow value: 54710905.71428572, excess: 4800.0\n",
      "iteration: 46, flow value: 56329825.71428572, excess: 4560.0\n",
      "iteration: 47, flow value: 57961465.71428572, excess: 4320.0\n",
      "iteration: 48, flow value: 61261705.71428572, excess: 3840.0\n",
      "iteration: 49, flow value: 62913025.71428572, excess: 3600.0\n",
      "iteration: 50, flow value: 64601545.71428572, excess: 3360.0\n",
      "iteration: 51, flow value: 66318985.71428572, excess: 3120.0\n",
      "iteration: 52, flow value: 68046505.71428572, excess: 2880.0\n",
      "iteration: 53, flow value: 69825145.71428572, excess: 2640.0\n",
      "iteration: 54, flow value: 71620860.0, excess: 2400.0\n",
      "iteration: 55, flow value: 73417980.0, excess: 2160.0\n",
      "iteration: 56, flow value: 75285900.0, excess: 1920.0\n",
      "iteration: 57, flow value: 77220900.0, excess: 1680.0\n",
      "iteration: 58, flow value: 79401300.0, excess: 1440.0\n",
      "iteration: 59, flow value: 81954540.0, excess: 1200.0\n",
      "iteration: 60, flow value: 84710700.0, excess: 960.0\n",
      "iteration: 61, flow value: 93236940.0, excess: 240.0\n",
      "number of edges: 59396\n",
      "Number of flow updates: 62, number of preprocessing iterations: 0, final flow value: 96478500.0\n",
      "CPU times: user 7.32 s, sys: 20 ms, total: 7.34 s\n",
      "Wall time: 7.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "network = parse(\"resources/road_flow_01_DC_a.txt\")\n",
    "f, p = successive_shortest_paths(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5b213619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96478500.0\n",
      "96478440.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "96478500.0"
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feasibility_check(network, f)\n",
    "optimality_check(network, f, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "232f351b",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_p = reduced_cost(network, {e: 0 for e in network.E}, p)\n",
    "vals = [network.u[e] if c_p[e] < 0 else 0 for e in network.E]\n",
    "f_cons = dict(zip(network.E, vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f02b29dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of negative cost admissible edges: 200\n",
      "number of edges: 19474\n",
      "Number of flow updates: 0, number of preprocessing iterations: 158, final flow value: 97712130.0\n",
      "CPU times: user 8.87 s, sys: 3.95 ms, total: 8.87 s\n",
      "Wall time: 8.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "f2, p2 = successive_shortest_paths(network, p=p, preprocess=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97712130.0\n",
      "96478440.0\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-89-839ff9f3e16f>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mfeasibility_check\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnetwork\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mf2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0moptimality_check\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnetwork\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mf2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mp2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m<ipython-input-85-c1d9c9cad53f>\u001B[0m in \u001B[0;36moptimality_check\u001B[0;34m(N, f, p)\u001B[0m\n\u001B[1;32m      9\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprimal\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdual\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 11\u001B[0;31m     \u001B[0;32massert\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0misclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprimal\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdual\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     12\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mprimal\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAssertionError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "feasibility_check(network, f2)\n",
    "optimality_check(network, f2, p2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "f2, p2 = successive_shortest_paths(network, p=p, preprocess=True)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "2b779124e3a4e6d8c8a2b37ae091af61a76ec1040bdbfb0023feb468ad696fe9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
